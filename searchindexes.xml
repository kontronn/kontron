<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<search>
  
  <entry>
    <title>欢迎加入 VxWorks 俱乐部！</title>
    <url>/post/welcome-to-vxworks-club/</url>
    <categories><category>Announce</category>
    </categories>
    <tags>
      <tag>VxWorks</tag>
      <tag>WindRiver</tag>
    </tags>
    <content type="html"><![CDATA[欢迎来到 北南南北 文档站点！ 相关文章来源于 VxWorks 俱乐部  ，也可能发布于 AI 嵌入式开发  ，专注于技术分享和交流。
免责声明 所有资源均来自网络，版权归原作者，如有侵权，请联系删除！
欢迎投稿  欢迎广大网友投稿 欢迎加入网友微信群  ]]></content>
  </entry>
  
  <entry>
    <title>一个超级精简高可移植的shell命令行C实现</title>
    <url>/post/mcu/a-super-streamlined-and-highly-portable-shell-command-line-implemented-by-c.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>Shell</tag>
    </tags>
    <content type="html"><![CDATA[在嵌入式开发中,一般需要使用shell命令行来进行交互。在一些资源非常受限的平台比如8位单片机平台，则各种开源的shell框架都显得过于大和复杂。此时实现一个超级精简的shell命令行则显得很必要。我们这里就来实现一个，方便以后快速集成到任何平台中使用。
前言 有几点开发前提:
  考虑可移植性，不使用任何编译器扩展。
  考虑可移植性，不依赖任何的库函数，仅依赖stdint的数据类型。
  考虑可移植性, 核心代码无需任何修改，只需要调用初始化配置接口来适配不同平台。
  尽可能少的代码量和ram使用量。
  精简，一切都刚好够用，可以快速嵌入任何平台，针对不同需要可以直接在此基础上增加实现。
  实现 首先定义一个数据结构，用于记录命令字符串和对应的执行函数和帮助字符串的对应关系
typedef void (*shell_command_pf)(uint8_t *); /**&lt; 命令回调函数 */ typedef uint32_t (*shell_read_pf)(uint8_t *buff, uint32_t len); /**&lt; 底层收接口 */ typedef void (*shell_write_pf)(uint8_t *buff, uint32_t len); /**&lt; 底层接口 */ /** * \struct shell_cmd_cfg * 命令信息 */ typedef struct { uint8_t * name; /**&lt; 命令字符串 */ shell_command_pf func; /**&lt; 命令回调函数 */ uint8_t * helpstr; /**&lt; 命令帮助信息 */ }shell_cmd_cfg; 对接口抽象，初始化指定输入输出接口
/** * \fn shell_set_itf * 设置底层输入输出接口,以及命令列表 * 调用shell_exec_shellcmd之前,需要先调用该接口初始化 * \param[in] input \ref shell_read_pf 输入接口 * \param[in] output \ref shell_write_pf 输出接口 * \param[in] cmd_list \ref shell_cmd_cfg 命令列表 * \param[in] enableecho 0:不使能回显, 其他值:使能回显 */ void shell_set_itf(shell_read_pf input, shell_write_pf output, shell_cmd_cfg* cmd_list, uint8_t enableecho); 非阻塞，主循环调用以下函数进行处理
/** * \fn shell_exec * 周期调用该函数,读取底层输入,并判断是否有命令进行处理 * 非阻塞 */ void shell_exec(void); 通过以下宏配置缓存大小，这里实际可以修改下改为调用者分配，而不是静态数组，这样可以由调用者决定分配和释放，更灵活，也在不用的时候不占用空间。
#define SHELL_CMD_LEN 64 /**&lt; 命令缓冲区大小 */核心逻辑
shell_exec调用 shell_read_line从输入接口读数据到缓冲区,读到一行后调用
shell_exec_cmdlist查询命令信息表，匹配字符串再调用对应的实现函数。
所以核心代码是读命令行，直接看注释即可
/** * 读取一行命令 */ static uint32_t shell_read_line(void) { uint8_t ch; uint32_t count; /* 初始打印sh&gt; */ if(s_cmd_buf_au8[0]==&#39;\r&#39;) { shell_putstring(&#34;sh&gt;\r\n&#34;); s_cmd_buf_au8[0] = 0; } /* 非阻塞读取一个字符 */ if(shell_getchar(&amp;ch) !=0 ) { return 0; } /* 遇到除了退格之外的不可打印字符,则认为收到一行命令 * 退格需要单独处理,需要删除一个字符 */ if((ch == &#39;\r&#39; || ch == &#39;\n&#39; || ch &lt; &#39; &#39; || ch &gt; &#39;~&#39;) &amp;&amp; (ch != &#39;\b&#39;)) { if(s_cmd_buf_index_u32==0) { /* 缓冲区没有数据就收到了非打印字符串,则打印提示sh&gt; */ shell_putstring(&#34;sh&gt;\r\n&#34;); } else { /* 收到了非打印字符,且缓冲区有数据则认为收到了一行 * 返回缓冲区数据长度,并清零计数,打印回车换行 * 并且添加结束符0 */ count = s_cmd_buf_index_u32; s_cmd_buf_au8[s_cmd_buf_index_u32]=0; s_cmd_buf_index_u32 =0; shell_putstring(&#34;\r\n&#34;); return count; } } else { if(ch == &#39;\b&#39;) { /* 退格处理,注意只有有数据才会删除一个字符，添加结束符 */ if(s_cmd_buf_index_u32 != 0) { s_cmd_buf_index_u32--; shell_putchar(&#39;\b&#39;); shell_putchar(&#39; &#39;); shell_putchar(&#39;\b&#39;); s_cmd_buf_au8[s_cmd_buf_index_u32]= &#39;\0&#39;; } } else { /* 可打印字符，添加到缓冲区 * 如果数据量已经到了缓冲区大小-1,则也认为是一行命令 * -1是保证最后有结束符0空间 */ if(s_enableecho_u8 != 0) { shell_putchar(ch); } s_cmd_buf_au8[s_cmd_buf_index_u32++] = ch; if(s_cmd_buf_index_u32&gt;=(sizeof(s_cmd_buf_au8)-1)) { count = s_cmd_buf_index_u32; s_cmd_buf_au8[s_cmd_buf_index_u32]=0; s_cmd_buf_index_u32 =0; shell_putstring(&#34;\r\n&#34;); return count; } } } return 0; } 代码量很少，直接看源码即可
shell.c/h为核心代码，无需修改
shell_func.c/h为命令实现，需要自己额添加
shell.c #include &lt;stdint.h&gt;#include &#34;shell.h&#34; shell_read_pf s_input_pf = 0; /* 输入接口指针 */ shell_write_pf s_output_pf = 0; /* 输出接口指针 */ shell_cmd_cfg* s_cmd_cfg_pst = 0; /* 命令列表指针 */ uint8_t s_enableecho_u8 = 0; /* 是否使能echo标志 */ static uint8_t s_cmd_buf_au8[SHELL_CMD_LEN]=&#34;\r&#34;; /* 命令缓冲区 */ static uint32_t s_cmd_buf_index_u32 = 0; /* 当前命令缓冲区中字符数 */ /** * 输出字符接口 */ static void shell_putchar(uint8_t val) { uint8_t tmp; if(s_output_pf != 0) { tmp = val; s_output_pf(&amp;tmp, 1); } } /** * 输出字符串接口 */ static void shell_putstring(char* str) { uint32_t len = 0; uint8_t*p = (uint8_t*)str; while(*str++) { len++; } s_output_pf(p, len); } /** * 读字符接口 */ static int shell_getchar(uint8_t *data) { if(s_input_pf == 0) { return -1; } if(0 == s_input_pf(data, 1)) { return -1; } else { return 0; } } /** * 判断命令字符串的长度 * 命令字符串不能有空格 */ static uint32_t shell_cmd_len(uint8_t *cmd) { uint8_t *p = cmd; uint32_t len = 0; while((*p != &#39; &#39;) &amp;&amp; (*p != 0)) { p++; len++; } return len; } /** * 判断两个字符串是否相等,相等返回0 */ static int shell_cmd_check(uint8_t *cmd, uint8_t *str) { uint32_t len1 = shell_cmd_len(cmd); uint32_t len2 = shell_cmd_len(str); if(len1 != len2) { return -1; } for(uint32_t i=0; i&lt;len1; i++) { if(*cmd++ != *str++) { return -1; } } return 0; } /** * 读取一行命令 */ static uint32_t shell_read_line(void) { uint8_t ch; uint32_t count; /* 初始打印sh&gt; */ if(s_cmd_buf_au8[0]==&#39;\r&#39;) { shell_putstring(&#34;sh&gt;\r\n&#34;); s_cmd_buf_au8[0] = 0; } /* 非阻塞读取一个字符 */ if(shell_getchar(&amp;ch) !=0 ) { return 0; } /* 遇到除了退格之外的不可打印字符,则认为收到一行命令 * 退格需要单独处理,需要删除一个字符 */ if((ch == &#39;\r&#39; || ch == &#39;\n&#39; || ch &lt; &#39; &#39; || ch &gt; &#39;~&#39;) &amp;&amp; (ch != &#39;\b&#39;)) { if(s_cmd_buf_index_u32==0) { /* 缓冲区没有数据就收到了非打印字符串,则打印提示sh&gt; */ shell_putstring(&#34;sh&gt;\r\n&#34;); } else { /* 收到了非打印字符,且缓冲区有数据则认为收到了一行 * 返回缓冲区数据长度,并清零计数,打印回车换行 * 并且添加结束符0 */ count = s_cmd_buf_index_u32; s_cmd_buf_au8[s_cmd_buf_index_u32]=0; s_cmd_buf_index_u32 =0; shell_putstring(&#34;\r\n&#34;); return count; } } else { if(ch == &#39;\b&#39;) { /* 退格处理,注意只有有数据才会删除一个字符，添加结束符 */ if(s_cmd_buf_index_u32 != 0) { s_cmd_buf_index_u32--; shell_putchar(&#39;\b&#39;); shell_putchar(&#39; &#39;); shell_putchar(&#39;\b&#39;); s_cmd_buf_au8[s_cmd_buf_index_u32]= &#39;\0&#39;; } } else { /* 可打印字符，添加到缓冲区 * 如果数据量已经到了缓冲区大小-1,则也认为是一行命令 * -1是保证最后有结束符0空间 */ if(s_enableecho_u8 != 0) { shell_putchar(ch); } s_cmd_buf_au8[s_cmd_buf_index_u32++] = ch; if(s_cmd_buf_index_u32&gt;=(sizeof(s_cmd_buf_au8)-1)) { count = s_cmd_buf_index_u32; s_cmd_buf_au8[s_cmd_buf_index_u32]=0; s_cmd_buf_index_u32 =0; shell_putstring(&#34;\r\n&#34;); return count; } } } return 0; } /** * 搜寻命令列表处理命令 */ static int shell_exec_cmdlist(uint8_t* cmd) { int i; if(s_cmd_cfg_pst == 0) { return -1; } for (i=0; s_cmd_cfg_pst[i].name != 0; i++) { if (shell_cmd_check(cmd, s_cmd_cfg_pst[i].name) == 0) { s_cmd_cfg_pst[i].func(cmd); return 0; } } if(s_cmd_cfg_pst[i].name == 0) { shell_putstring(&#34;unkown command\r\n&#34;); return -1; } return 0; } /** * 对外接口,周期执行 */ void shell_exec(void) { if(shell_read_line() &gt; 0) { shell_exec_cmdlist(s_cmd_buf_au8); } } /** * 对外接口,初始化配置接口 */ void shell_set_itf(shell_read_pf input, shell_write_pf output, shell_cmd_cfg* cmd_list, uint8_t enableecho) { s_input_pf = input; s_output_pf = output; s_cmd_cfg_pst = cmd_list; s_enableecho_u8 = enableecho; } shell.h #ifndef SHELL_H #define SHELL_H  #ifdef __cplusplus extern &#34;C&#34; { #endif  #include &lt;stdint.h&gt; #define SHELL_CMD_LEN 64 /**&lt; 命令缓冲区大小 */ typedef void (*shell_command_pf)(uint8_t *); /**&lt; 命令回调函数 */ typedef uint32_t (*shell_read_pf)(uint8_t *buff, uint32_t len); /**&lt; 底层收接口 */ typedef void (*shell_write_pf)(uint8_t *buff, uint32_t len); /**&lt; 底层发接口 */ /** * \struct shell_cmd_cfg * 命令信息 */ typedef struct { uint8_t * name; /**&lt; 命令字符串 */ shell_command_pf func; /**&lt; 命令回调函数 */ uint8_t * helpstr; /**&lt; 命令帮助信息 */ }shell_cmd_cfg; /** * \fn shell_exec * 周期调用该函数,读取底层输入,并判断是否有命令进行处理 * 非阻塞 */ void shell_exec(void); /** * \fn shell_set_itf * 设置底层输入输出接口,以及命令列表 * 调用shell_exec_shellcmd之前,需要先调用该接口初始化 * \param[in] input \ref shell_read_pf 输入接口 * \param[in] output \ref shell_write_pf 输出接口 * \param[in] cmd_list \ref shell_cmd_cfg 命令列表 * \param[in] enableecho 0:不使能回显, 其他值:使能回显 */ void shell_set_itf(shell_read_pf input, shell_write_pf output, shell_cmd_cfg* cmd_list, uint8_t enableecho); #ifdef __cplusplus } #endif  #endif shell_func.c #include &lt;stdio.h&gt;#include &lt;stdint.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt; #include &#34;shell.h&#34;#include &#34;shell_func.h&#34;#include &#34;xmodem.h&#34;#include &#34;uart_api.h&#34;#include &#34;iot_flash.h&#34; static void helpfunc(uint8_t* param); static void rxmemfunc(uint8_t* param); static void sxmemfunc(uint8_t* param); static void rxflashfunc(uint8_t* param); static void sxflashfunc(uint8_t* param); static void uarttestfunc(uint8_t* param); /** * 最后一行必须为0,用于结束判断 */ const shell_cmd_cfg g_shell_cmd_list_ast[ ] = { { (uint8_t*)&#34;help&#34;, helpfunc, (uint8_t*)&#34;help&#34;}, { (uint8_t*)&#34;rxmem&#34;, rxmemfunc, (uint8_t*)&#34;rxmem addr len&#34;}, { (uint8_t*)&#34;sxmem&#34;, sxmemfunc, (uint8_t*)&#34;sxmem addr len&#34;}, { (uint8_t*)&#34;rxflash&#34;, rxflashfunc, (uint8_t*)&#34;rxflash addr len&#34;}, { (uint8_t*)&#34;sxflash&#34;, sxflashfunc, (uint8_t*)&#34;sxflash addr len&#34;}, { (uint8_t*)&#34;uarttest&#34;, uarttestfunc, (uint8_t*)&#34;uarttest&#34;}, { (uint8_t*)0, 0 , 0}, }; void helpfunc(uint8_t* param) { (void)param; unsigned int i; printf(&#34;\r\n&#34;); printf(&#34;**************\r\n&#34;); printf(&#34;* SHELL *\r\n&#34;); printf(&#34;* V1.0 *\r\n&#34;); printf(&#34;**************\r\n&#34;); printf(&#34;\r\n&#34;); for (i=0; g_shell_cmd_list_ast[i].name != 0; i++) { printf(&#34;%02d.&#34;,i); printf(&#34;%-16s&#34;,g_shell_cmd_list_ast[i].name); printf(&#34;%s\r\n&#34;,g_shell_cmd_list_ast[i].helpstr); } } uint8_t rxtx_buf[1029]; extern uint32_t g_tick_u32; static uint32_t getms(void) { return g_tick_u32; } static uint32_t io_read(uint8_t* buffer, uint32_t len) { return uart_api_read(buffer, len); } static void io_read_flush(void) { uint8_t tmp; while(0 != uart_api_read(&amp;tmp, 1)); } static uint32_t io_write(uint8_t* buffer, uint32_t len) { uart_api_write(buffer, len); return len; } static uint32_t mem_read(uint32_t addr, uint8_t* buffer, uint32_t len) { memcpy(buffer, (uint8_t*)addr, len); return len; } static uint32_t mem_write(uint32_t addr, uint8_t* buffer, uint32_t len) { memcpy((uint8_t*)addr, buffer, len); return len; } static uint32_t flash_read(uint32_t addr, uint8_t* buffer, uint32_t len) { iot_flash_read(IOT_FLASH_SFC_PORT_0, addr, buffer, len); return len; } static uint32_t flash_write(uint32_t addr, uint8_t* buffer, uint32_t len) { iot_flash_write(IOT_FLASH_SFC_PORT_0, addr, buffer, len); return len; } void rxmemfunc(uint8_t* param) { uint32_t addr; uint32_t len; uint8_t* p = param; int res = 0; //if(3 == sscanf((const char*)param, &#34;%*s %s %d %d&#34;, type, &amp;addr, &amp;len))  while(1) { if((*p &gt; &#39;z&#39;) || (*p &lt; &#39;a&#39;)) { break; } else { p++; } } while(1) { if(*p != &#39; &#39;) { break; } else { p++; } } addr = atoi((const char*)p); while(1) { if((*p &gt; &#39;9&#39;) || (*p &lt; &#39;0&#39;)) { break; } else { p++; } } while(1) { if(*p != &#39; &#39;) { break; } else { p++; } } len = atoi((const char*)p); xmodem_cfg_st cfg= { .buffer = rxtx_buf, .crccheck = 1, .getms = getms, .io_read = io_read, .io_read_flush = io_read_flush, .io_write = io_write, .start_timeout = 60, .packet_timeout = 1000, .ack_timeout = 1000, .mem_write = mem_write, .addr = addr, .totallen = len, }; xmodem_init_rx(&amp;cfg); while((res = xmodem_rx()) == 0); printf(&#34;res:%d\r\n&#34;,res); } void sxmemfunc(uint8_t* param) { uint32_t addr; uint32_t len; uint8_t* p = param; int res = 0; //if(3 == sscanf((const char*)param, &#34;%*s %s %d %d&#34;, type, &amp;addr, &amp;len))  while(1) { if((*p &gt; &#39;z&#39;) || (*p &lt; &#39;a&#39;)) { break; } else { p++; } } while(1) { if(*p != &#39; &#39;) { break; } else { p++; } } addr = atoi((const char*)p); while(1) { if((*p &gt; &#39;9&#39;) || (*p &lt; &#39;0&#39;)) { break; } else { p++; } } while(1) { if(*p != &#39; &#39;) { break; } else { p++; } } len = atoi((const char*)p); xmodem_cfg_st cfg= { .buffer = rxtx_buf, .plen = 1024, .getms = getms, .io_read = io_read, .io_read_flush = io_read_flush, .io_write = io_write, .start_timeout = 60, .packet_timeout = 1000, .ack_timeout = 1000, .mem_read = mem_read, .addr = addr, .totallen = len, }; xmodem_init_tx(&amp;cfg); while((res = xmodem_tx()) == 0); printf(&#34;res:%d\r\n&#34;,res); } void rxflashfunc(uint8_t* param) { uint32_t addr; uint32_t len; uint8_t* p = param; int res = 0; //if(3 == sscanf((const char*)param, &#34;%*s %s %d %d&#34;, type, &amp;addr, &amp;len))  while(1) { if((*p &gt; &#39;z&#39;) || (*p &lt; &#39;a&#39;)) { break; } else { p++; } } while(1) { if(*p != &#39; &#39;) { break; } else { p++; } } addr = atoi((const char*)p); while(1) { if((*p &gt; &#39;9&#39;) || (*p &lt; &#39;0&#39;)) { break; } else { p++; } } while(1) { if(*p != &#39; &#39;) { break; } else { p++; } } len = atoi((const char*)p); xmodem_cfg_st cfg= { .buffer = rxtx_buf, .crccheck = 1, .getms = getms, .io_read = io_read, .io_read_flush = io_read_flush, .io_write = io_write, .start_timeout = 60, .packet_timeout = 1000, .ack_timeout = 1000, .mem_write = flash_write, .addr = addr, .totallen = len, }; xmodem_init_rx(&amp;cfg); while((res = xmodem_rx()) == 0); printf(&#34;res:%d\r\n&#34;,res); } void sxflashfunc(uint8_t* param) { uint32_t addr; uint32_t len; uint8_t* p = param; int res = 0; //if(3 == sscanf((const char*)param, &#34;%*s %s %d %d&#34;, type, &amp;addr, &amp;len))  while(1) { if((*p &gt; &#39;z&#39;) || (*p &lt; &#39;a&#39;)) { break; } else { p++; } } while(1) { if(*p != &#39; &#39;) { break; } else { p++; } } addr = atoi((const char*)p); while(1) { if((*p &gt; &#39;9&#39;) || (*p &lt; &#39;0&#39;)) { break; } else { p++; } } while(1) { if(*p != &#39; &#39;) { break; } else { p++; } } len = atoi((const char*)p); xmodem_cfg_st cfg= { .buffer = rxtx_buf, .plen = 1024, .getms = getms, .io_read = io_read, .io_read_flush = io_read_flush, .io_write = io_write, .start_timeout = 60, .packet_timeout = 1000, .ack_timeout = 1000, .mem_read = flash_read, .addr = addr, .totallen = len, }; xmodem_init_tx(&amp;cfg); while((res = xmodem_tx()) == 0); printf(&#34;res:%d\r\n&#34;,res); } void uarttestfunc(uint8_t* param) { (void)param; uint8_t tmp[64]; uint32_t len; uint32_t total = 0; while(1) { while(0 != (len = uart_api_read(tmp, sizeof(tmp)))) { uart_api_write(tmp, len); total+=len; } if(total &gt;= 10*1024) { break; } } } shell_func.h #ifndef SHELL_FUNC_H #define SHELL_FUNC_H  #include &lt;stdint.h&gt; #ifdef __cplusplus  extern &#34;C&#34; { #endif  extern const shell_cmd_cfg g_shell_cmd_list_ast[ ]; #ifdef __cplusplus } #endif  #endif 测试 添加命令行只需要在shell_func.c中先申明
实现函数，比如
static void helpfunc(uint8_t* param); 然后在数组g_shell_cmd_list_ast中添加一行
用于指定命令行字符和对应的实现函数，以及帮助字符串。
比如
{ (uint8_t*)&#34;help&#34;, helpfunc, (uint8_t*)&#34;help&#34;}, 然后实现函数
void helpfunc(uint8_t* param) { (void)param; unsigned int i; printf(&#34;\r\n&#34;); printf(&#34;**************\r\n&#34;); printf(&#34;* SHELL *\r\n&#34;); printf(&#34;* V1.0 *\r\n&#34;); printf(&#34;**************\r\n&#34;); printf(&#34;\r\n&#34;); for (i=0; g_shell_cmd_list_ast[i].name != 0; i++) { printf(&#34;%02d.&#34;,i); printf(&#34;%-16s&#34;,g_shell_cmd_list_ast[i].name); printf(&#34;%s\r\n&#34;,g_shell_cmd_list_ast[i].helpstr); } } 然后初始化接口，执行
uart_bsp_init(115200); shell_set_itf(uart_api_read, uart_api_write, (shell_cmd_cfg*)g_shell_cmd_list_ast, 1); while(1) { shell_exec(); } 此时就可以输入对应命令字符串回车来执行对应的函数，比如
总结 以上以最简单的方式,实现了命令行shell。代码量和占用ram非常小，可以快速嵌入资源非常受限的开发平台。
Shell.c和shell.h完全可移植，无需任何修改。
只需初始化shell_set_itf设置对应的底层接口，然后shell_func.c中添加对应的命令实现即可。
非阻塞方式实现,方便应用。
以最简形式实现,支持退格，但是不支持历史命令等，但是可以快速的修改代码实现。
命令行以数组静态添加，而不是动态添加和使用编译器的扩展将代码放置于指定段的方式来添加，是因为考虑可移植性和简单性。也可以快速修改使用后者。
有很多人总是在感慨为什么嵌入式领域热衷于”造轮子”,这是由于其特定的需求决定的,在嵌入式领域有诸多前提条件的限制,比如资源就是一个必须要考虑的前提,所以很难一个”轮子”适应所有路况。比如在8位单片机上几k的ram,十几k的rom,这时候也要使用比如shell命令行,那么就不可能使用大而全的框架,则存储资源，运行占用CPU等等都会无法满足。。甚至编译器都是专用针对嵌入式场景的,可能都不能用各种花哨的处理方式编译器扩展等(比如获取段地址,大小,指定代码位于某个段),另外在嵌入式领域编译器相关的扩展也会影响可移植性，其实不建议过多使用。
正是因为有这么多的限制所以在嵌入式领域才会有这么的多需要定制开发，重复”造轮子”的事，而积累自己的轮子，积累自己的小代码库,组件库,则是嵌入式高手积累经验的一条路径。积累了足够多的自己的轮子，将来面对需求就能够得心应手,才能快速开发出不同需求的”轮子”。
]]></content>
  </entry>
  
  <entry>
    <title>新的架构，更快的芯片</title>
    <url>/post/soc/faster-chip-with-new-architecture.html</url>
    <categories><category>SOC</category>
    </categories>
    <tags>
      <tag>Chip</tag>
    </tags>
    <content type="html"><![CDATA[芯片行业在多个物理维度和多种架构方法方面取得了进展。基于更多模块化和异构设计、新的先进封装选项以及至少几个工艺节点的数字逻辑的持续扩展，为性能的巨大提升奠定了基础。
大规模创新，推动性能提升数量级。 在最近的会议上讨论了其中的一些变化。就部分个体而言，它们具有潜在的意义。但从整体上看，随着设备扩展的好处减少和市场需求的变化，他们指出了一些重要的趋势。其中：
 对于高性能应用，芯片的设计基于更有限的数据移动和近内存计算。这可以从I/O位于芯片周边而不是中心的平面图中看出，这种方法将通过减少数据需要传输的距离来提高性能，从而降低整体功耗。 使用高数值孔径 EUV、各种全栅极 FET（CFET、纳米片/纳米线 FET）和碳纳米管器件，数字逻辑的缩放将继续超过 3nm。同时，光罩尺寸将增加，以允许更多的组件适合封装，如果不是单个芯片。这两项举措都将通过缩小功能来增加更多的空间，从而实现更高的计算密度。此外，SRAM的扩展将继续进行，并将为高带宽存储器（HBM）模块和3D-NAND闪存添加更多层。 设计正变得越来越模块化和异构化，为更多的定制和更快的上市时间奠定了基础。所有主要的晶圆代工厂和OSAT现在都支持小芯片战略，他们根据价格和性能要求提供多种选择。  其中一些已经进行了多年，但大部分开发都是零碎的。不再有单一的行业路线图，过去一直被用作所有发展如何结合在一起的指南。在没有该路线图的情况下，所有方面的工作仍在继续，但通常很难理解大局是如何发展的，因为并非一切都在同步发展。例如，ASML甚至在EUV商业上可行之前就公开谈论高数值孔径EUV，它用变形透镜取代了平面透镜。在这十年的大部分时间里，ASE 和 Amkor 等公司一直在开发多个版本的扇出、2.5D 和 3D-IC，尽管这些封装方案的市场与最初想象的截然不同。
还有许多新的发展即将到来。台积电、联电、GlobalFoundries和三星等主要晶圆代工厂正在将先进的封装能力融入到制造后端。台积电还计划使用无凸块混合键合（称为SoIC）将小芯片添加到前端。所有这些都可能需要整个行业进行重大变革，从EDA工具到测试和硅后监控。
目前尚不清楚所有这些不同元素的结合速度有多快。没有人喜欢成为第一，在这一点上，这些方法和技术中哪一种会获胜，甚至它们是否会相互竞争，都不清楚。但是，随着数据量的持续增长，改变是必不可少的。这推动了更多定制的解决方案，以在更接近源头的地方处理和利用这些数据，其中包括几乎无处不在的某种程度的智能。
过去，解决方案是围绕最先进的硬件或软件开发的，其假设是下一代工艺将大大提高性能。这不再起作用。扩展变得越来越困难和昂贵，缩小功能的功耗/性能优势正在减弱。此外，一种尺寸不再适合所有人。根据最终客户在计算层次结构中的位置（端点、边缘或云）以及需要如何构建数据和确定其优先级，它可能会有很大差异。因此，芯片制造商已将重点转移到新的、更模块化的架构上，这些架构能够从云中的大规模模拟和训练算法，到从源头剔除无用的图像和流式视频数据。
从长远来看，需要在任何地方更快地进行更多的处理，并且需要使用相同或更少的功率来完成。此外，系统需要更快地创建，并且随着市场需求的发展和算法的不断变化，它们需要能够更快地发生变化。
架构转变 为了实现这一目标，硬件架构需要改变。芯片制造商已经看到这种情况已经有一段时间了。例如，IBM 的新型 Power 10 芯片将定制的计算元素集中在芯片的中心，并将外围设备和 I/O 移动到边缘。
“加速需要被推到处理器核心中，”该芯片的首席架构师比尔·斯塔克（Bill Starke）在最近的Hot Chips会议上说。“芯片周边是PHY。”IBM 还引入了 Pod 级集群，并添加了一个新的微架构来支持所有这些。
其他的也在采取类似的方法。英特尔推出了一种基于内部开发的小芯片的新架构，该架构使用其嵌入式多芯片互连桥接到 HBM 模块，将模块化处理元件聚集在一起。此外，它还更新了其最新的服务器芯片架构，以最大限度地减少数据移动。
同样，制造人工智能系统的 Tenstorrent 创建了一个高度模块化的系统，其中包括 120 个独立的内核，这些内核与 2D 双向环面 NoC 相连。“每个核心都按照自己的节奏发展，”Tenstorrent 软件工程总监 Jasmina Vasiljevic 说。
扩展仍在继续 数据中心芯片对成本的敏感度远低于消费类应用，因此它们在性能方面往往处于行业领先地位。例如，高性能服务器将芯片开发成本与系统价格摊销，而不是通过体积来分摊，这对于手机应用处理器来说至关重要。因此，尽管关于摩尔定律终结的预测永无止境，但出于密度原因，许多这些设备中的数字逻辑将继续使用最新的工艺几何形状。
然而，不同的是，对性能不太关键的电路以及模拟模块越来越多地被分流到单独的芯片上，这些芯片使用高速接口连接。
“你现在可以按节点进行分区，”西门子旗下公司 Mentor 的产品总监 Matt Hogan 说。“因此，您可以确定设计特定部分的正确技术是什么。这也允许你扩大一些副作用。
戈登·摩尔（Gordon Moore）在1965年首次发表他现在著名的观察结果时提到了这种方法。
Synopsys首席应用工程师Tim Kogel表示：“随着工艺技术的快速发展，使用现成的解决方案通常比开发定制芯片更便宜。“到现在为止，每个新工艺节点的高性能和低功耗的免费午餐几乎已经结束。另一方面，人工智能、自动驾驶、AR/VR等杀手级应用对处理能力和计算效率的需求不可抑制。谷歌的TPU和特斯拉的FSD芯片等著名例子表明，根据目标工作负载的特定特征定制架构，其投资回报率令人印象深刻。
尽管如此，摩尔定律的价值正在减弱，这既有经济意义，也有技术意义。平面缩放的经济效益随着finFET的引入而结束，当时每个晶体管的成本从前一个节点停止下降。同样，自90nm以来，功耗/性能优势一直在下降。台积电研发高级副总裁Y.J. Mii表示，在相同功率下，3nm将带来10%至15%的性能提升，或在相同速度下降低25%至30%的功耗。
然而，从技术角度来看，这并不是一条死胡同。架构改进，包括不同的封装方法和 3D 布局，可以将性能提高几个数量级。缩放仍然有助于将更多的密度封装到这些封装中，即使缩小的晶体管本身的运行速度并没有明显加快。
“多年来，我们一直被超越摩尔定律的话题轰炸，”Cadence设计IP营销总监Tom Wong说。“但是，真的是面积减小、功耗降低或晶体管性能改进（传统PPA）推动了这些讨论，还是硅经济性和光刻/设备的局限性导致我们撞上了砖墙？事实证明，硅经济性和掩模版尺寸的限制是推动颠覆的两大因素，这促使设计人员寻找新的芯片设计方法，并转向新的架构。
通过不同的封装方案和光罩尺寸的增加，经济性和光罩尺寸限制都得到了解决，从而允许更大的单个芯片。台积电研发副总裁Doug Yu表示，通过晶圆代工厂的InFO（集成扇出）封装方法，掩模版尺寸将增加1.7倍。此外，台积电计划在明年第一季度推出 110 x 110 mm² 的光罩，这将使光罩尺寸增加 2.5 倍。
所有这些都是必要的，因为将所有东西都放在一个芯片上的成本不断上升。模块化允许芯片制造商根据平台类型的方法相对快速地定制芯片。CPU、GPU 和 FPGA 芯片设计人员在五年多前就发现了这一点，此后开始向分解实现迈进，采用多芯片，让中介层/封装负责集成。Wong说，这就是为什么die-to-die连接IP成为当今舞台的中心舞台的原因之一。
“CPU、GPU 和 FPGA 都走上了小芯片的路线，因为这些公司自己设计芯片（小芯片），不需要依赖商业小芯片生态系统。他们可以利用基于小芯片的设计可以提供的功能，“Wong指出。“包括 CPU、GPU 和 FPGA 在内的多核设计可以从这种架构变化/趋势中受益。能够分离“核心计算”和高速 I/O 的 SoC 设计也可以从中受益。AI 加速 SoC 和加密 SoC 就是两个例子。数据中心交换机和结构（例如用于超大规模计算和云构建者的 25.6Tb/s）也可以从这种架构更改为基于小芯片的设计中受益。这些设计可以像 200 亿+ 晶体管一样复杂。
到目前为止，Intel、AMD和Marvell等IDM已经采用了这种方法，每个IDM都创建了自己的模块化方案和互连。因此，他们没有制造芯片并试图向广泛的客户推销其优势，而是使用小芯片提供一系列选项，在英特尔的情况下，还提供各种连接选项，例如高速桥接器。
变化无处不在，有大有小 正确看待所有这些变化通常很困难，因为整个行业都在运动，尽管不一定以相同的速度或出于相同的原因。因此，例如，当处理器和进程发生变化时，内存会远远滞后。
此外，有些技术需要完全重新思考，而另一些技术则保持不变。这在 GPU 中尤为明显，GPU 一直是 AI/ML 训练的首选解决方案，因为它们价格便宜且可扩展。但它们并不是最节能的方法。
Imagination Technologies产品管理和技术营销高级总监Kristof Beets表示：“我们已经看到了带宽，我们已经看到了它的强大功能，”所有这些不同的限制都会发挥作用。从 GPU 的角度来看，这是一个棘手的演变，因为显然 GPU 是巨大的数字运算器，显示器越来越大，设备越来越小。所以很多这样的问题一直在发生。有一个蛮力阶段，这有点取决于摩尔定律。我们将 GPU 翻了一番，这在一段时间内是可以的，因为工艺技术跟上了。但现在回报正在减少，所以虽然我们可以放下更多的逻辑，但我们基本上不能再打开它了，因为它消耗了太多的电量。所以蛮力的方式是行不通的。
动态电压和频率调节 （DVFS） 在一定程度上有助于降低电压，从而允许更大的 GPU 在较低频率下运行。然而，即使是这种方法也有局限性，因为在固定的功率预算内可以使用的 GPU 内核数量有限。“这为我们提供了更好的每瓦FPS（每秒帧数），但即使这样，现在也开始变慢，因为泄漏再次上升，”Beets说。“对于 GPU 来说，这就是光线追踪的有趣之处。这是一种摆脱蛮力的方式。它们非常灵活。我们在人工智能和神经网络处理方面也看到了同样的情况。这是完全相同的概念。在这里，你真正看到了比GPU好10到20倍的解决方案，考虑到数据流和具体操作，所以这很有趣。它并不像过去的固定函数处理那么糟糕。我们还没有回到那里。但其中一些肯定会开始以更专用的处理类型回归。
有许多方法可以增强扩展性能。Codasip高级营销总监Roddy Urquhart表示：“在一些领域，例如应用处理器、GPU、MCU、DSP，我们已经有相当通用的架构利用摩尔定律来做越来越多的事情。“但现在有大量的想法围绕着尝试新颖的架构，新颖的结构，具有一系列可编程性。在脉动阵列端，有些东西往往是硬连线的处理元素，或者它们具有已上传固件并处于静态状态一段时间的进程。另一个极端是特定于域的进程，这些进程是高度可编程的。我看到了高度并行、高度流水线的数组类型结构的创新回归，这与不同类型的神经网络非常契合。另一方面，人们更多地跳出框框思考，以摆脱MCU、GPU、DSP和应用处理器的孤岛，并创造一些更像这些东西的混合版本来满足特定需求。
微架构 除了这些广泛的架构转变之外，还有微架构创新。在许多方面，这是一个分区问题，在更大的系统中，某些计算功能优先于其他计算功能。这可能会对性能和计算效率产生重大影响。
“利用固有的并行性，应用程序应该映射到一组最佳的异构处理元素，”Synopsys的Kogel说。“为每个函数选择一个提供最低灵活性的处理内核，可以提供尽可能高的计算效率。此外，内存架构的组织对性能和功耗有非常大的影响。由于外部存储器访问成本高昂，因此数据应保存在片上存储器中，靠近处理位置。
然而，这说起来容易做起来难，它需要多学科和越来越多的多维规划。Kogel说：“管理复杂性并预测在具有分布式内存的异构多处理平台上运行的高度并行应用程序的动态效果是一个相当大的挑战。“我们建议在开发过程的早期使用虚拟原型来定量分析架构权衡。这使得来自应用程序和实施团队的利益相关者能够在承诺实施规范之前进行协作。
新的平衡 展望未来，如何进行功耗和性能的权衡取决于市场。一些市场对成本高度敏感，因此他们还没有解决这个问题。同时，其他软件对成本的敏感度较低，对延迟的敏感度较高。
“人们越来越不耐烦了。你想尽快得到你想要的东西，“英特尔首席技术官迈克·梅伯里（Mike Mayberry）在DARPA最近的电子复兴倡议（ERI）峰会的小组演讲中说。“但我们也看到了平衡的系统和更多的计算能力，这是我们看到的持续趋势之一。
Mayberry 指出，密度缩放没有硬性停止，但它将越来越多地包括 Z 轴。“我们还看到了新型的超越CMOS器件，这些器件将支持异构架构。十年后，你会看到这些在货架上。
英特尔等公司正在研究除了沉积和蚀刻不同材料之外的器件生长方法。多年来，人们一直在谈论定向自组装等方法。在某种程度上，这在经济上仍然是可行的，但普遍的共识可能要等到3nm之后。
除此之外，光子学也开始积聚一些动力，以最小的热量在这些日益密集的结构中和周围移动大量数据。一种更新颖的方法涉及使用光进行处理。LightMatter 首席执行官尼克·哈里斯 （Nick Harris） 表示，光学设备消除了泄漏效应，从而降低了热量并提高了性能。这种方法特别独特的是，光可以被划分为不同的波长，从而可以优先考虑不同的颜色。
“使用100GHz波长，这是一个非常小的间距，我们可以容纳1000种颜色，”哈里斯说。缺点是激光器不会永远持续下去，因此需要有足够的冗余来使这些系统在其预期的使用寿命内持续使用。
对于更传统的计算，进程节点选项的数量也在增加。晶圆代工厂提供中间节点，无需完全重新设计即可提高性能或功耗。例如，台积电（TSMC）打开了其N4工艺的瓶塞，该工艺将于明年年底进入风险生产。台积电首席执行官魏中瀛在演讲中表示，N5（5nm）和N4中使用的IP将兼容，这使公司能够以最小的重新设计来提高密度和降低功耗。
尽管如此，选项的数量仍然令人眼花缭乱。除了不同的节点数量外，还有不同的工艺选项，以实现低功耗和高性能。最重要的是，不同的衬底材料开始受到关注，包括用于功率晶体管的碳化硅和氮化镓，以及用于低成本、低功耗应用的绝缘体上硅。
所有这些都对用于防止故障的设计规则有很大影响。“如果你正在设计一个小芯片，你不知道它将如何使用或放置，”Mentor的Hogan说。“你不知道它是否会在MCU旁边，所以你必须弄清楚如何以一种深思熟虑的方式做到这一点。你需要保护它免受电磁效应和其他潜在问题的影响。
而且，由于芯片有望在更长的时间内正常运行——就汽车而言，前导节点逻辑可能需要长达 18 年——所有这些都需要在老化的背景下完成。这可能会变得非常复杂，尤其是在多芯片封装中。
Ansys半导体业务部营销副总裁兼首席策略师Vic Kulkarni表示：“您需要关注不同刺激和场景的阈值变化等因素。“你可以对寄存器进行精确分析，但如果 Vdd 没有下降，Vt 也没有下降，那么剩下的余量就不多了。您还需要考虑诸如电气过载之类的事情。晶圆厂不愿意接受这一点。
权衡范围从功耗、性能和成本到服务质量。
“我们过去总是有无损压缩，”Imagination 的 Beets 说。“大约一两年前，我们也推出了有损，这样我们就可以在质量上进行权衡。在GPU中，我们开始看到质量与成本的权衡，有损压缩可以降低质量，这也节省了带宽和功耗。在 GPU 处理中，我们开始看到同样的东西，即可变速率着色。这基本上是当你看视频时，你会说你真正关心的只是脸，你想要完整的细节，所以背景并不重要。游戏本质上是做同样的事情。例如，在赛车游戏中，汽车非常清晰，有很多细节，但其余部分都有运动模糊。
在精度方面也存在权衡。较低的精度可以大大加快处理速度，而稀疏算法可以写得不那么精确，无论是 16 位精度还是 1 位精度。但是，这种精度也可以由硬件和固件控制，并且会对整体系统性能产生重大影响，其中某些功能比其他功能更准确。
结论 在摩尔定律的前 40 年左右，功耗、性能和面积的改进对于大多数应用程序来说已经足够了，并且数据的增长通常可以通过经典扩展来管理。在90nm之后，经典缩放开始显示出压力的迹象。虽然已经很长时间没有注意到了，但它并没有被忽视。
然而，令人惊讶的是，仍然有多少途径可用于大幅提高性能、降低功耗和潜在的成本节约。工程团队正在以新颖有趣的方式进行创新。几十年来对当时看似晦涩难懂的话题或切线的研究现在正在得到回报，还有很多研究正在酝酿中。
]]></content>
  </entry>
  
  <entry>
    <title>STM32高阶应用--使用DFU方案实现固件升级</title>
    <url>/post/mcu/using-DFU-solution-to-update-the-firmware-for-stm32.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>ARM</tag>
      <tag>STM32</tag>
      <tag>DFU</tag>
    </tags>
    <content type="html"><![CDATA[DFU全称为Device Firmware update，是ST官方推出的一个通过USB接口进行IAP升级的方案，同串口ISP一样，他们都集成在了芯片内部的Bootloader区段，可以通过配置boot引脚来启动。（具体可参照ST文档：AN2606）。
什么是 DFU 不过内置DFU的芯片大部分型号都比较新，如果你用的型号没有内置DFU程序，没关系我们也可以通过CubeMX来快速生成和移植一个DFU功能程序到你的Flash中来使用。
DFU方案完整的组件包括单片机DFU Demo代码、PC端升级程序、PC端Demo代码以及相关资料手册等。
通过使用DFU方案，我们可以快速的集成升级功能到开发的产品中，同时还能够快速的开发与之配套的升级程序。
使用CubeMX生成初始工程 由于官方提供的DFU例程并不多，我们很难找到现成的可已使用DFU程序，但是通过CubeMX我们可以很快速的配置和生成DFU的Bootloader，下面我们正式开始。
 新建CubeMX工程  首先选定好IC的型号，进入配置界面，由于只是Bootloader代码所以这里我们只需要配置USB功能和一个做Bootloader触发的引脚就可，其余的时钟等部分一切按照正常方式配置。
设置USB引脚功能  设定USB模式为Device（HS还是FS并不影响DFU的功能，按照应用选择就可）。
开启DFU组件  在MiddleWares中加入USB DFU组件
设置DFU参数
开启DFU组件后，CubeMX的程序设置窗口的MiddleWares中就会出现DFU程序设置按钮。
点开它将APP加载的地址改为0x0800_c000，这个加载地址根据你实际的应用设置，目前我们选择让flash的前三个sector为Bootloader的区域。
第二个全是字段的参数是用来在DFU连接升级软件式传输给软件用来获取Flash结构字符串数据，很好理解这个小协议的内容，点击设置后，下方的CubeMX的参数说明也写的很清晰，这里就不多说了。
当然这些参数也在工程生成后在 usbd_conf.h 和 usbd_dfu_if.c 文件中修改。
最后的设置  最后我们添加一个外部的按键作为触发单片机启动时进入DFU的方式，按键按下后就启动DFU模式，否则直接加载后方APP程序，这里选用PA0引脚，给它设置个User Label 就叫 USER_BTN_GPIO_Port。
修改补全工程  实现 DFU 功能代码  打开 src 目录下的 usbd_dfu_if.c 文件补全其中的功能代码
Flash 解锁
uint16_t MEM_If_Init_HS(void) { HAL_FLASH_Unlock(); return (USBD_OK); } Flash 上锁
uint16_t MEM_If_DeInit_HS(void) { HAL_FLASH_Lock(); return (USBD_OK); } Flash 擦除
static uint32_t GetSector(uint32_t Address) { uint32_t sector = 0; if ((Address &lt; ADDR_FLASH_SECTOR_1) &amp;&amp; (Address &gt;= ADDR_FLASH_SECTOR_0)) { sector = FLASH_SECTOR_0; } ...... } else if ((Address &lt; ADDR_FLASH_SECTOR_23) &amp;&amp; (Address &gt;= ADDR_FLASH_SECTOR_22)) { sector = FLASH_SECTOR_22; } else { sector = FLASH_SECTOR_23; } return sector; } uint16_t MEM_If_Erase_HS(uint32_t Add) { uint32_t startsector = 0; uint32_t sectornb = 0; /* Variable contains Flash operation status */ HAL_StatusTypeDef status; FLASH_EraseInitTypeDef eraseinitstruct; /* Get the number of sector */ startsector = GetSector(Add); eraseinitstruct.TypeErase = FLASH_TYPEERASE_SECTORS; eraseinitstruct.VoltageRange = FLASH_VOLTAGE_RANGE_3; eraseinitstruct.Sector = startsector; eraseinitstruct.NbSectors = 1; status = HAL_FLASHEx_Erase(&amp;eraseinitstruct, &amp;sectornb); if (status != HAL_OK) { return (USBD_FAIL); } return (USBD_OK); } Flash 写入
uint16_t MEM_If_Write_HS(uint8_t *src, uint8_t *dest, uint32_t Len) { uint32_t i = 0; for (i = 0; i &lt; Len; i += 4) { /* Device voltage range supposed to be [2.7V to 3.6V], the operation will be done by byte */ if (HAL_FLASH_Program(FLASH_TYPEPROGRAM_WORD, (uint32_t)(dest + i), *(uint32_t *)(src + i)) == HAL_OK) { /* Check the written value */ if (*(uint32_t *)(src + i) != *(uint32_t *)(dest + i)) { /* Flash content doesn&#39;t match SRAM content */ return (USBD_FAIL); } } else { /* Error occurred while writing data in Flash memory */ return (USBD_FAIL); } } return (USBD_OK); } Flash 读取
uint8_t *MEM_If_Read_HS(uint8_t *src, uint8_t *dest, uint32_t Len) { /* Return a valid address to avoid HardFault */ uint32_t i = 0; uint8_t *psrc = src; for (i = 0; i &lt; Len; i++) { dest[i] = *psrc++; } /* Return a valid address to avoid HardFault */ return (uint8_t *)(dest); } 获取 Flash 擦写时间参数
``c uint16_t MEM_If_GetStatus_HS(uint32_t Add, uint8_t Cmd, uint8_t buffer) { / USER CODE BEGIN 11 */ uint16_t time;
 time = TimingTable[GetSector(Add)]; switch (Cmd) { case DFU_MEDIA_PROGRAM: buffer[1] = (uint8_t)time; buffer[2] = (uint8_t)(time &lt;&lt; 8); buffer[3] = 0; break; case DFU_MEDIA_ERASE: default: buffer[1] = (uint8_t)time; buffer[2] = (uint8_t)(time &lt;&lt; 8); buffer[3] = 0; break; } return (USBD_OK); /* USER CODE END 11 */  }
usbd_dfu_if.h 文件添加的宏定义 ```c /* Define flash address */ // BLANK 1 #define ADDR_FLASH_SECTOR_0 0x08000000 #define ADDR_FLASH_SECTOR_1 0x08004000 #define ADDR_FLASH_SECTOR_2 0x08008000 #define ADDR_FLASH_SECTOR_3 0x0800C000 #define ADDR_FLASH_SECTOR_4 0x08010000 #define ADDR_FLASH_SECTOR_5 0x08020000 #define ADDR_FLASH_SECTOR_6 0x08040000 #define ADDR_FLASH_SECTOR_7 0x08060000 #define ADDR_FLASH_SECTOR_8 0x08080000 #define ADDR_FLASH_SECTOR_9 0x080A0000 #define ADDR_FLASH_SECTOR_10 0x080C0000 #define ADDR_FLASH_SECTOR_11 0x080E0000 // BLANK 2 #define ADDR_FLASH_SECTOR_12 0x08100000 #define ADDR_FLASH_SECTOR_13 0x08104000 #define ADDR_FLASH_SECTOR_14 0x08108000 #define ADDR_FLASH_SECTOR_15 0x0810C000 #define ADDR_FLASH_SECTOR_16 0x08110000 #define ADDR_FLASH_SECTOR_17 0x08120000 #define ADDR_FLASH_SECTOR_18 0x08140000 #define ADDR_FLASH_SECTOR_19 0x08160000 #define ADDR_FLASH_SECTOR_20 0x08180000 #define ADDR_FLASH_SECTOR_21 0x081A0000 #define ADDR_FLASH_SECTOR_22 0x081C0000 #define ADDR_FLASH_SECTOR_23 0x081E0000 /* Flash oprate time from datasheet page 128 */ #define FLASH_SECTOR_16KB_WRITE_ERASE_TIME 500 //500 usb frame,means 500ms #define FLASH_SECTOR_64KB_WRITE_ERASE_TIME 1100 #define FLASH_SECTOR_128KB_WRITE_ERASE_TIME 2000 修改Main文件  首先在main文件前添加几个用于加载APP程序的变量和函数定义
typedef void (*pFunction)(void); pFunction JumpToApplication; uint32_t JumpAddress;1234 然后再 main 函数中加入 外部按键的判断、APP程序加载以及USB DFU初始化功能
int main(void) { /* Reset of all peripherals, Initializes the Flash interface and the Systick. */ HAL_Init(); /* Configure the system clock */ SystemClock_Config(); /* Initialize all configured peripherals */ MX_GPIO_Init(); if (HAL_GPIO_ReadPin(USER_BTN_GPIO_Port, USER_BTN_Pin) == GPIO_PIN_SET) { HAL_GPIO_WritePin(GPIOG, LD3_Pin, GPIO_PIN_SET); // For debug  /* Test if user code is programmed starting from address 0x0800C000 */ if (((*(__IO uint32_t *)USBD_DFU_APP_DEFAULT_ADD) &amp; 0x2FF80000) == 0x20000000) { HAL_GPIO_WritePin(GPIOG, LD4_Pin, GPIO_PIN_SET); // For debug  /* Jump to user application */ JumpAddress = *(__IO uint32_t *)(USBD_DFU_APP_DEFAULT_ADD + 4); JumpToApplication = (pFunction)JumpAddress; /* Reset of all peripherals */ HAL_DeInit(); /* Set interrupt vector to app code */ SCB-&gt;VTOR = USBD_DFU_APP_DEFAULT_ADD; /* Initialize user application&#39;s Stack Pointer */ __set_MSP(*(__IO uint32_t *)USBD_DFU_APP_DEFAULT_ADD); JumpToApplication(); } } MX_USB_DEVICE_Init(); while (1) { } } 编译程序下载进入单片机  使用DfuSe 从ST官网DfuSe的程序安装包，并安装。然后我们按下之前写的触发按键并复位单片机，让单片机初始 USB DFU 功能，这时如果你插着单片机的USB线，系统应该已经识别了。
如果没有右键更新驱动程序，手动指定驱动搜索路径在DfuSe安装目录下的 \Bin\Driver 内。如果直接无法识别USB设备，建议在CubeMx配置完工程后就编译下载测试一下，看看是不是你在移植过程中哪里写错了。
然后我们需要生成一个地址设定在0x0800_c000后的测试程序，就先编写一个 Blink LED 的程序吧，生成bin、hex或S19文件。
然后我们打开DfuSe软件的Dfu file manager来生成DFU软件用的.dfu格式的文件。选择第一项，第二个是用来将.dfu反向变换回来的。
大概的操作已经标在图片上了，操作比较简单就不做详细介绍了，记得把Address的地址改到偏移后的地址上否则下载会出错，其他参数可以不用修改。
然后我们打开DfuSe程序，在Upgrade中选择生成好的blink.dfu文件，勾选校验功能，下载程序。成功后复位单片机，LED开始闪烁，移植成功。
更多 仔细区看看DfuSe的安装目录，里面有DFU的资料文档，还有DFU的工程源代码，可以用来改写自己需要的DFU升级程序。
参考资料 ST官网DfuSe
http://www.stmicroelectronics.com.cn/content/st_com/zh/products/development-tools/software-development-tools/stm32-software-development-tools/stm32-programmers/stsw-stm32080.html ]]></content>
  </entry>
  
  <entry>
    <title>C语言中结构体struct的用法</title>
    <url>/post/programming/usage-of-struct-in-c.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Embedded</tag>
      <tag>Struct</tag>
    </tags>
    <content type="html"><![CDATA[本文简要介绍了c语言中结构体Struct的用法。
定义结构体变量 下面举一个例子来说明怎样定义结构体变量。
struct string { char name[8]; int age; char sex[2]; char depart[20]; float wage1, wage2, wage3, wage4, wage5; }person; 这个例子定义了一个结构名为string的结构体变量person。还可以省略变量名person，做如下定义：
struct string { char name[8]; int age; char sex[2]; char depart[20]; float wage1, wage2, wage3, wage4, wage5; }; struct string person; //定义结构名为string的结构体变量person 定义多个具有相同形式的结构变量：
struct string Liming, Liuqi, ...; 有一种结构体常常出现在函数内部，省略结构名，则称之为无名结构，如下：
struct { char name[8]; int age; char sex[2]; char depart[20]; float wage1, wage2, wage3, wage4, wage5; } Liming, Liuqi; 结构体成员的获取与赋值 结构是一个新的数据类型，结构成员的表示方式为:
结构变量.成员名 如果将&quot;结构变量.成员名&quot;看成一个整体，这样就可以像其他变量那样使用。
下面这个例子定义了一个结构变量stu1，分别给name、age、group赋值，并打印输出。
#include &lt;stdio.h&gt;int main() { struct { char *name; //姓名  int age; //年龄  char group; //所在小组  } stu1; //给结构体成员赋值  stu1.name = &#34;Tom&#34;; stu1.age = 18; stu1.group = &#39;A&#39;; //读取结构体成员的值  printf(&#34;%s的年龄是%d，在%c组\n&#34;, stu1.name, stu1.age, stu1.group); return 0; } 结构体数组 结构体数组就是具有相同结构类型的变量集合，假如要定义一个班级40个同学 的姓名、性别、年龄和住址, 可以定义成一个结构数组。如下所示：
struct { char name[8]; char sex[2]; int age; char addr[40]; }student[40]; 结构体数组成员的访问是以数组元素为结构变量的, 其形式为:
结构数组元素.成员名 例如：
student[0].name student[30].age 结构体指针 结构体指针由一个加在结构变量名前的*操作符来定义，定义一个结构体指针如下：
struct string { char name[8]; char sex[2]; int age; char addr[40]; }*student; 使用结构体指针对结构体成员的访问与结构体变量对结构体成员的访问在表达方式不同。结构体指针对结构体成员的访问方式为：
结构体指针名-&gt;结构体成员 给上面定义的结构体中name和age赋值的语句：
strcpy(student-&gt;name, &#34;acket&#34;); //student-&gt;name就是(*student).name student-&gt;age=18; 需要指出的是结构体指针是指向结构体的一个指针，即结构体中第一个成员的首地址，因此在使用之前应该对结构体指针初始化，即分配整个结构体长度的字节空间：
student=(struct string*)malloc(size of (struct string)); //size of (struct string)是自动求取string结构体的字节长度 malloc()函数定义了一个大小为结构体长度的内存区域，然后将其地址作为结构体指针返回。
位结构 位结构是一种特殊的结构体，位结构定义的一般形式为：
struct 位结构名 { 数据类型 变量名: 整型常数; 数据类型 变量名: 整型常数; }位结构变量; 其中数据类型必须是int（unsigned或signed，但当成员长度为1时, 会被认为是unsigned类型），整型常数必须是0~15的非负整数，表示二进制位个数。变量名是选择项，可以不命名，下面定义了一个位结构：
struct { unsigned incon: 8; /*incon占用低字节 的0~7共8位*/ unsigned txcolor: 4;/*txcolor占用高字节的0~3位共4位*/ unsigned bgcolor: 3;/*bgcolor占用高字节的4~6位共3位*/ unsigned blink: 1; /*blink占用高字节的第7位*/ }ch; 位结构成员的访问与结构体成员的访问相同，访问位结构中的bgcolor成员可写成：
ch.bgcolor 举个例子
struct info { char name[8]; int age; struct addr address; float pay; unsigned state: 1; unsigned pay: 1; }workers; 上面结构体定义了工资的信息，其中有两个只有1位的位结构成员，表示工人的状态以及工资是否已发放。
typedef定义结构体
typedef struct person { int age ; char *name; char *sex; }student; student stu1; //此处可以用student来定义一个结构体变量 typedef的作用就相当于给struct person取了一个别名student。
]]></content>
  </entry>
  
  <entry>
    <title>新手必看的单片机知识</title>
    <url>/post/mcu/knowledge-on-mcu.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>MCS-48</tag>
    </tags>
    <content type="html"><![CDATA[1946年2月15日，第一台电子数字计算机 ENIAC问世，这标志着计算机时代的到来。
前言 ENIAC 是电子管计算机，时钟频率虽然仅有 100 kHz，但能在1s 的时间内完成 5000 次加法运算。与现代的计算机相比，ENIAC有许多不足，但它的问世开创了计算机科学技术的新纪元，对人类的生产和生活方式产生了巨大的影响。
在研制 ENIAC 的过程中，匈牙利籍数学家冯·诺依曼担任研制小组的顾问，并在方案的设计上做出了重要的贡献。
1946年6月，冯·诺依曼又提出了 “程序存储”和“二进制运算”的思想，进一步构建了计算机由运算器、控制器、存储器、输入设备和输出设备组成这一计算机的经典结构。
电子计算机技术的发展，相继经历了电子管计算机、晶体管计算机、集成电路计算机、大规模集成电路计算机和超大规模集成电路计算机五个时代，但是计算机的结构仍然没有突破冯·诺依曼提出的计算机的经典结构框架。
微型计算机的组成及其应用形态 微型计算机的组成 1971 年 1 月，Intel 公司的特德·霍夫在与日本商业通信公司合作研制台式计算器时，将原始方案的十几个芯片压缩成三个集成电路芯片。
其中的两个芯片分别用于存储程序和数据，另一芯片集成了运算器和控制器及一些寄存器， 称为微处理器(即 Intel 4004)。微处理器、存储器加上 I/O 接口电路组成微型计算机。各部分通过地址总线(AB)、数据总线(DB)和控制总线(CB)相连。
微型计算机的应用形态 从应用形态上，微型计算机可以分成三种：多板机(系统机)、单板机和单片机。
 多板机(系统机)  多板机是将微处理器、存储器、I/O 接口电路和总线接口等组装在一块主机板(即微机主板)上，再通过系统总线和其它多块外设适配板卡连接键盘、显示器、打印机、软/硬盘驱动器及光驱等设备。各种适配板卡插在主机板的扩展槽上,并与电源、软/硬盘驱动器及光驱等装在同一机箱内，再配上系统软件,就构成了一台完整的微型计算机系统，简称系统机。
目前人们广泛使用的个人计算机(PC 机)就是典型的多板微型计算机。由于其人机界面好，功能强，软件资源丰富，通常作为办公或家庭的事务处理及科学计算，属于通用计算机，现在已经成为社会各领域中最为通用的工具。
另外，将系统机的机箱进行加固处理，底板设计成无 CPU 的小底板结构，利用底板的扩展槽插入主机板及各种测控板，就构成了一台工业 PC 机。由于其具有人机界面友好和软件资源丰富的优势，工业 PC 机常作为工业测控系统的主机。
单板机  将 CPU 芯片、存储器芯片、I/O 接口芯片和简单的 I/O 设备(小键盘、LED 显示器)等装配在一块印制线路板上，再配上监控程序(固化在 ROM 中),就构成了一台单板微型计算机，简称单板机。典型的产品如 TP801。
单板机的 I/O 设备简单，软件资源少，使用不方便。早期主要用于微型计算机原理的教学及简单的测控系统，现在已很少使用。
单片机  在一片集成电路芯片上集成微处理器、存储器、I/O 接口电路，从而构成了单芯片微型计算机，即单片机。
计算机原始的设计目的是为了提高计算数据的速度和完成海量数据的计算。人们将完成这种任务的计算机称为通用计算机。
随着计算机技术的发展，人们发现了计算机在逻辑处理及工业控制等方面也具有非凡的能力。在控制领域中，人们更多地关心计算机的低成本、小体积、运行的可靠性和控制的灵活性。
特别是智能仪表、智能传感器、智能家电、智能办公设备、汽车及军事电子设备等应用系统要求将计算机嵌入到这些设备中。嵌入到控制系统(或设备)中，实现嵌入式应用的计算机称为嵌入式计算机， 也称为专用计算机。
嵌入式应用的计算机可分为嵌入式微处理器(如 386EX)、嵌入式 DSP 处理器(如 TMS320 系列)、嵌入式微控制器(即单片机，如 80C51 系列)及嵌入式片上系统 SOC。
单片机体积小、价格低、可靠性高，其非凡的嵌入式应用形态对于满足嵌入式应用需求具有独特的优势。
目前，单片机应用技术已经成为电子应用系统设计最为常用的技术手段，学习和掌握单片机应用技术具有极其重要的现实意义。
综上所述，微型计算机技术的发展正趋于两个方向，一是以系统机为代表的通用计算机，致力于提高计算机的运算速度，在实现海量高速数据处理的同时兼顾控制功能；二是以单片机为代表的嵌入式专用计算机，致力于计算机控制功能的片内集成，在满足嵌入式对象的测控需求的同时兼顾数据处理。
单片机的发展过程及产品近况 单片机的发展过程 单片机技术发展十分迅速，产品种类已琳琅满目。纵观整个单片机技术发展过程，可以分为以下三个主要阶段：
单芯片微机形成阶段 1976 年，Intel公司推出了MCS-48系列单片机。该系列单片机早期产品在芯片内集成有：8 位CPU、1K 字节程序存储器(ROM)、64字节数据存储器(RAM)、27 根 I/O 线和1个8 位定时/计数器。
此阶段的主要特点是：在单个芯片内完成了 CPU、存储器、I/O 接口、定时/计数器、中断系统、时钟等部件的集成，但存储器容量较小，寻址范围小(不大于 4K)，无串行接口，指令系统功能不强。
性能完善提高阶段 1980 年，Intel 公司推出 MCS-51 系列单片机。该系列单片机在芯片内集成有：8 位 CPU、4K 字节程序存储器(ROM)、128 字节数据存储器(RAM)、4个 8 位并行接口、1 个全双工串行接口和 2 个 16 位定时/计数器。寻址范围为64 K，并集成有控制功能较强的布尔处理器完成位处理功能。此阶段的主要特点是：结构体系完善，性能已大大提高，面向控制的特点进一步突出。现在，MCS-51 已成为公认的单片机经典机种。
微控制器化阶段 1982 年，Intel 公司推出 MCS-96 系列单片机。该系列单片机在芯片内集成有：16 位 CPU、8K 字节程序存储器(ROM)、232 字节数据存储器(RAM)、 5 个 8 位并行接口、1 个全双工串行接口和 2 个 16 位定时/计数器。寻址范围最大为 64 K。片上还有 8 路 10 位 ADC、1 路 PWM(D/A)输出及高速 I/O 部件。
近年来，许多半导体厂商以 MCS-51 系列单片机的 8051 为内核，将许多测控系统中的接口技术、可靠性技术及先进的存储器技术和工艺技术集成到单片机中，生产出了多种功能强大、使用灵活的新一代 80C51 系列单片机。此阶段的主要特点是：片内面向测控系统的外围电路增强，使单片机可以&ndash;方便灵活地应用于复杂的自动测控系统及设备。因此，“微控制器”的称谓更能反应单片机的本质。
单片机产品近况 随着微电子设计技术及计算机技术的不断发展，单片机产品和技术日新月异。单片机产品近况可以归纳为以下二方面。
一、80C51 系列单片机产品繁多，主流地位已经形成 通用微型计算机计算速度的提高主要体现在 CPU 位数的提高(16 位、32 位乃至 64 位)，而单片机更注重的是产品的可靠性、经济性和嵌入性。所以，单片机 CPU 位数的提高需求并不十分迫切。而多年来的应用实践已经证明， 80C51 的系统结构合理，技术成熟。因此，许多单片机芯片生产厂商倾力于提高 80C51 单片机产品的综合功能，从而形成了 80C51 的主流产品地位。近年来推出的与 80C51 兼容的主要产品有：
 ATMEL 公司融入 Flash 存储器技术推出的 AT89 系列单片机； Philips 公司推出的 80C51、80C552 系列高性能单片机； 华邦公司推出的 W78C51、W77C51 系列高速低价单片机； LG 公司推出的 GMS90/97 系列低压高速单片机； Maxim 公司推出的 DS89C420 高速（50MIPS）单片机； Cygnal 公司推出的 C8051F 系列高速 SOC 单片机等。  由此可见，80C51 已经成为事实上的单片机主流系列，所以本书以 80C51为对象，讲述单片机的原理与接口方法。
二、非 80C51 结构单片机新品不断推出，给用户提供了更为广泛的选择空间在 80C51 及其兼容产品流行的同时，一些单片机芯片生产厂商也推出了一些非 80C51 结构的产品，影响比较大的有：
 Intel 公司推出的 MCS-96 系列 16 位单片机； Microchip 公司推出的 PIC 系列 RISC 结构单片机； TI 公司推出的 MSP430F 系列 16 位低电压、低功耗单片机； ATMEL 公司推出的 AVR 系列 RISC 结构单片机等。  单片机的特点及应用领域、 单片机的特点 控制性能和可靠性高 单片机是为满足工业控制而设计的，所以实时控制功能特别强，其 CPU 可以对 I/O 接口直接进行操作，位操作能力更是其它计算机无法比拟的。另外， 由于 CPU、存储器及 I/O 接口集成在同一芯片内，各部件间的连接紧凑，数据在传送时受到的干扰较小，且不易受环境条件的影响，所以单片机的可靠性非常高。近期推出的单片机产品，内部集成有高速 I/O 接口、ADC、PWM、WDT 等部件，并在低电压、低功耗、串行扩展总线、控制网络总线和开发方式（如在系统编程 ISP）等方面都有了进一步的增强。
体积小、价格低、易于产品化 每片单片机芯片即是一台完整的微型计算机，对于批量大的专用场合，一方面可以在众多的单片机品种间进行匹配选择，同时还可以专门进行芯片设计， 使芯片功能与应用具有良好的对应关系。在单片机产品的引脚封装方面，有的单片机引脚已减少到 8 个或更少，从而使应用系统的印制板减小，接插件减少， 安装简单方便。在现代的各种电子器件中，单片机具有良好的性能价格比。这正是单片机得以广泛应用的重要原因。
单片机的应用领域 由于单片机具有良好的控制性能和灵活的嵌入品质，近年来单片机在各种领域都获得了极为广泛的应用。概要地分成以下几个方面：
智能仪器仪表 单片机用于各种仪器仪表，一方面提高了仪器仪表的使用功能和精度，使仪器仪表智能化，同时还简化了仪器仪表的硬件结构，从而可以方便地完成仪器仪表产品的升级换代。如各种智能电气测量仪表、智能传感器等。
机电一体化产品 机电一体化产品是集机械技术、微电子技术、自动化技术和计算机技术于一体，具有智能化特征的各种机电产品。单片机在机电一体化产品的开发中可以发挥巨大的作用。典型产品如机器人、数控机床、自动包装机、点钞机、医疗设备、打印机、传真机、复印机等。
实时工业控制 单片机还可以用于各种物理量的采集与控制。电流、电压、温度、液位、流量等物理参数的采集和控制均可以利用单片机方便地实现。在这类系统中， 利用单片机作为系统控制器，可以根据被控对象的不同特征采用不同的智能算法，实现期望的控制指标，从而提高生产效率和产品质量。典型应用如电动机转速控制、温度控制、自动生产线等。
分布系统的前端模块 在较复杂的工业系统中，经常要采用分布式测控系统完成大量的分布参数的采集。在这类系统中，采用单片机作为分布式系统的前端采集模块。系统具有运行可靠，数据采集方便灵活，成本低廉等一系列优点。
家用电器 家用电器是单片机的又一重要应用领域，前景十分广阔。如空调器、电冰箱、洗衣机、电饭煲、高档洗浴设备、高档玩具等。另外，在交通领域中，汽车、火车、飞机、航天器等均有单片机的广泛应用。如汽车自动驾驶系统、航天测控系统、黑匣子等。
单片机应用系统开发简介 单片机应用系统的开发 设计单片机应用系统时，在完成硬件系统设计之后，必须配备相应的应用软件。正确无误的硬件设计和良好的软件功能设计是一个实用的单片机应用系统的设计目标。完成这一目标的过程称为单片机应用系统的开发。单片机作为一片集成了微型计算机基本部件的集成电路芯片，与通用微机相比，它自身没有开发功能，必须借助开发机(一种特殊的计算机系统)来完成如下任务：1、排除应用系统的硬件故障和软件错误；2、调试完的程序要固化到单片机内部或外部程序存储器芯片中。
指令的表示形式 指令是让单片机执行某种操作的命令。在单片机内部，指令按一定的顺序以二进制码的形式存放于程序存储器中。二进制码是计算机能够直接执行的机器码(或称目标码)。为了书写、输入和显示方便，人们通常将机器码写成十六进制形式。如二进制码 0000 0100B 可以表示为 04H。04H 所对应的指令的意义是累加器 A 的内容加 1。若写成 INC A，则要清楚得多，这就是该指令的符号表示，称为符号指令。
汇编或编译 符号指令要转换成计算机所能执行的机器码并存入计算机的程序存储器中，这种转换称为汇编。常用的汇编方法有三种，
 一是手工汇编，设计人员对照单片机指令编码表，把每一条符号指令翻译成十六进制数表示的机器码指令， 借助于小键盘送入开发机，然后进行调试，并将调试好的程序写入程序存储器芯片。 二是利用开发机的汇编程序进行汇编。 三是利用通用微型计算机配备的汇编程序进行交叉汇编，然后将目标码传送到开发机中。  另外，还可以采用高级语言(如C51)进行单片机应用程序的设计。在 PC 机中编辑好的高级语言源程序经过编译、连接后形成目标码文件，并传送到开发机中。这种方法具有周期短、移植和修改方便的优点，适合于较复杂系统的开发。
单片机应用系统的传统开发方式 单片机开发系统又称为开发机或仿真器。仿真的目的是利用开发机的资源(CPU、存储器和I/O设备等)来模拟欲开发的单片机应用系统(即目标机) 的 CPU、存储器和I/O操作，并跟踪和观察目标机的运行状态。
仿真可以分为软件模拟仿真和开发机在线仿真两大类。软件模拟仿真成本低，使用方便，但不能进行应用系统硬件的实时调试和故障诊断。下面仅介绍在线仿真方法。
利用独立型仿真器开发 独立型仿真器采用与单片机应用系统相同类型的单片机做成单板机形式， 板上配置 LED 显示器和简易键盘。这种开发系统在没有普通微机系统的支持下，仍能对单片机应用系统进行在线仿真，便于在现场对应用软件进行调试和修改。
另外，这种开发系统还配有串行接口，能与普通微机系统连接。这样， 可以利用普通微机系统配备的组合软件进行源程序的编辑、汇编和联机仿真调试。然后将调试无误的目标程序（即机器码）传送到仿真器，利用仿真器进行程序的固化。
利用非独立型仿真器开发 这种仿真器采用通用微型计算机加仿真器方式构成。仿真器与通用微机间以串行通信的方式连接。这种开发方式必须有微机的支持，利用微机系统配备的组合软件进行源程序的编辑、汇编和仿真调试。有些仿真接口上还备有EPROM 写入插座，可以将开发调试完成的用户应用程序写入 EPROM 芯片。与前一种相比，此种开发方式现场参数的修改和调试不够方便。
以上两种开发方式均是在开发时拔掉目标系统的单片机芯片和程序存储器芯片，插上从开发机上引出的仿真头，即把开发机上的单片机出借给目标机。
仿真调试无误后，拔掉仿真头，再插回单片机芯片，把开发机中调试好的程序固化到 EPROM 芯片中并插到目标机的程序存储器插座上，目标机就可以独立运行了。
单片机开发方式的发展 由于单片机贴片封装形式的广泛采用以及 Flash 存储器技术的迅速发展， 传统的单片机应用系统开发的理念将受到冲击。
采用新的单片机应用系统开发技术可以将单片机先安装到印制线路板上，然后通过 PC 机将程序下载到目标系统。
如：SST 公司推出的 SST89C54 和 SST89C58 芯片分别有 20 KB 和 30 KB 的SuperFlash 存储器，利用这种存储器可以进行高速读/写的特点，能够实现在系统编程(ISP)和在应用编程(IAP)功能。
首先在 PC 机上完成应用程序的编辑、汇编(或编译)和模拟运行，然后实现目标程序的串行下载。
Microchip 公司推出的RISC 结构单片机PIC16F87X 中内置在线调试器ICD功能，该公司还配置了具有 ICSP功能的简单仿真器和烧写器。由于芯片内置了侦测电路逻辑，所以可以不需要额外的硬件仿真器。
通过 PC 机串行电缆(含有完成通信功能的MPLAB-ICD 模块及与目标板连接的 MPLAB-ICD 头)就可以完成对目标系统的仿真调试。
]]></content>
  </entry>
  
  <entry>
    <title>嵌入式开发中的C语言——编译器</title>
    <url>/post/programming/compiler-c-programming-in-embedded-design.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Embedded design</tag>
      <tag>Compiler</tag>
    </tags>
    <content type="html"><![CDATA[如果你和一个优秀的程序员共事，你会发现他对他使用的工具非常熟悉，就像一个画家了解他的画具一样。&mdash; 比尔.盖茨
不能简单的认为是个工具  嵌入式程序开发跟硬件密切相关，需要使用C语言来读写底层寄存器、存取数据、控制硬件等，C语言和硬件之间由编译器来联系，一些C标准不支持的硬件特性操作，由编译器提供。 汇编可以很轻易的读写指定RAM地址、可以将代码段放入指定的Flash地址、可以精确的设置变量在RAM中分布等等，所有这些操作，在深入了解编译器后，也可以使用C语言实现。 C语言标准并非完美，有着数目繁多的未定义行为，这些未定义行为完全由编译器自主决定，了解你所用的编译器对这些未定义行为的处理，是必要的。 嵌入式编译器对调试做了优化，会提供一些工具，可以分析代码性能，查看外设组件等，了解编译器的这些特性有助于提高在线调试的效率。 此外，堆栈操作、代码优化、数据类型的范围等等，都是要深入了解编译器的理由。 如果之前你认为编译器只是个工具，能够编译就好。那么，是时候改变这种思想了。  不能依赖编译器的语义检查 编译器的语义检查很弱小，甚至还会“掩盖”错误。现代的编译器设计是件浩瀚的工程，为了让编译器设计简单一些，目前几乎所有编译器的语义检查都比较弱小。为了获得更快的执行效率，C语言被设计的足够灵活且几乎不进行任何运行时检查，比如数组越界、指针是否合法、运算结果是否溢出等等。这就造成了很多编译正确但执行奇怪的程序。
C语言足够灵活，对于一个数组test[30]，它允许使用像test[-1]这样的形式来快速获取数组首元素所在地址前面的数据；允许将一个常数强制转换为函数指针，使用代码(((void()())0))()来调用位于0地址的函数。C语言给了程序员足够的自由，但也由程序员承担滥用自由带来的责任。
莫名的死机 下面的两个例子都是死循环，如果在不常用分支中出现类似代码，将会造成看似莫名其妙的死机或者重启。
unsigned char i; //例程1  for(i=0;i&lt;256;i++) { //其它代码  } unsigned char i; //例程2  for(i=10;i&gt;=0;i--) { //其它代码  } 对于无符号char类型，表示的范围为0~255，所以无符号char类型变量i永远小于256（第一个for循环无限执行），永远大于等于0（第二个for循环无限执行）。需要说明的是，赋值代码i=256是被C语言允许的，即使这个初值已经超出了变量i可以表示的范围。C语言会千方百计的为程序员创造出错的机会，可见一斑。
不起眼的改变 假如你在if语句后误加了一个分号，可能会完全改变了程序逻辑。编译器也会很配合的帮忙掩盖，甚至连警告都不提示。代码如下：
if(a&gt;b); //这里误加了一个分号  a=b; //这句代码一直被执行 不但如此，编译器还会忽略掉多余的空格符和换行符，就像下面的代码也不会给出足够提示：
if(n&lt;3) return	//这里少加了一个分号 logrec.data=x[0]; logrec.time=x[1]; logrec.code=x[2]; 这段代码的本意是n&lt;3时程序直接返回，由于程序员的失误，return少了一个结束分号。编译器将它翻译成返回表达式logrec.data=x[0]的结果，return后面即使是一个表达式也是C语言允许的。这样当n&gt;=3时，表达式logrec.data=x[0];就不会被执行，给程序埋下了隐患。
难查的数组越界 上文曾提到数组常常是引起程序不稳定的重要因素，程序员往往不经意间就会写数组越界。
一位同事的代码在硬件上运行，一段时间后就会发现LCD显示屏上的一个数字不正常的被改变。经过一段时间的调试，问题被定位到下面的一段代码中：
int SensorData[30]; //其他代码  for(i=30;i&gt;0;i--) { SensorData[i]=…; //其他代码  } 这里声明了拥有30个元素的数组，不幸的是for循环代码中误用了本不存在的数组元素SensorData[30]，但C语言却默许这么使用，并欣然的按照代码改变了数组元素SensorData[30]所在位置的值， SensorData[30]所在的位置原本是一个LCD显示变量，这正是显示屏上的那个值不正常被改变的原因。真庆幸这么轻而易举的发现了这个Bug。
其实很多编译器会对上述代码产生一个警告：赋值超出数组界限。但并非所有程序员都对编译器警告保持足够敏感，况且，编译器也并不能检查出数组越界的所有情况。比如下面的例子：
你在模块A中定义数组：
int SensorData[30]; 在模块B中引用该数组，但由于你引用代码并不规范，这里没有显示声明数组大小，但编译器也允许这么做：
extern int SensorData[]; 这次，编译器不会给出警告信息，因为编译器压根就不知道数组的元素个数。所以，当一个数组声明为具有外部链接，它的大小应该显式声明。
再举一个编译器检查不出数组越界的例子。函数func()的形参是一个数组形式，函数代码简化如下所示：
char * func(char SensorData[30]) { unsigned int 1; for(i=30; i&gt;0; i--) { SensorData[i]=...; //其他代码 	} } 这个给SensorData[30]赋初值的语句，编译器也是不给任何警告的。实际上，编译器是将数组名Sensor隐含的转化为指向数组第一个元素的指针，函数体是使用指针的形式来访问数组的，它当然也不会知道数组元素的个数了。造成这种局面的原因之一是C编译器的作者们认为指针代替数组可以提高程序效率，而且，可以简化编译器的复杂度。
指针和数组是容易给程序造成混乱的，我们有必要仔细的区分它们的不同。其实换一个角度想想，它们也是容易区分的：可以将数组名等同于指针的情况有且只有一处，就是上面例子提到的数组作为函数形参时。其它时候，数组名是数组名，指针是指针。
下面的例子编译器同样检查不出数组越界。
我们常常用数组来缓存通讯中的一帧数据。在通讯中断中将接收的数据保存到数组中，直到一帧数据完全接收后再进行处理。即使定义的数组长度足够长，接收数据的过程中也可能发生数组越界，特别是干扰严重时。
这是由于外界的干扰破坏了数据帧的某些位，对一帧的数据长度判断错误，接收的数据超出数组范围，多余的数据改写与数组相邻的变量，造成系统崩溃。由于中断事件的异步性，这类数组越界编译器无法检查到。
如果局部数组越界，可能引发ARM架构硬件异常。
同事的一个设备用于接收无线传感器的数据，一次软件升级后，发现接收设备工作一段时间后会死机。调试表明ARM7处理器发生了硬件异常，异常处理代码是一段死循环（死机的直接原因）。接收设备有一个硬件模块用于接收无线传感器的整包数据并存在自己的缓冲区中，当硬件模块接收数据完成后，使用外部中断通知设备取数据，外部中断服务程序精简后如下所示：
__irq ExintHandler(void) { unsignedchar DataBuf[50]; GetData(DataBug); //从硬件缓冲区取一帧数据  //其他代码  } 由于存在多个无线传感器近乎同时发送数据的可能加之GetData()函数保护力度不够，数组DataBuf在取数据过程中发生越界。由于数组DataBuf为局部变量，被分配在堆栈中，同在此堆栈中的还有中断发生时的运行环境以及中断返回地址。溢出的数据将这些数据破坏掉，中断返回时PC指针可能变成一个不合法值，硬件异常由此产生。
如果我们精心设计溢出部分的数据，化数据为指令，就可以利用数组越界来修改PC指针的值，使之指向我们希望执行的代码。
1988年，第一个网络蠕虫在一天之内感染了2000到6000台计算机，这个蠕虫程序利用的正是一个标准输入库函数的数组越界Bug。起因是一个标准输入输出库函数gets()，原来设计为从数据流中获取一段文本，遗憾的是，gets()函数没有规定输入文本的长度。
gets()函数内部定义了一个500字节的数组，攻击者发送了大于500字节的数据，利用溢出的数据修改了堆栈中的PC指针，从而获取了系统权限。目前，虽然有更好的库函数来代替gets函数，但gets函数仍然存在着。
神奇的volatile 做嵌入式设备开发，如果不对volatile修饰符具有足够了解，实在是说不过去。volatile是C语言32个关键字中的一个，属于类型限定符，常用的const关键字也属于类型限定符。
volatile限定符用来告诉编译器，该对象的值无任何持久性，不要对它进行任何优化；它迫使编译器每次需要该对象数据内容时都必须读该对象，而不是只读一次数据并将它放在寄存器中以便后续访问之用（这样的优化可以提高系统速度）。
这个特性在嵌入式应用中很有用，比如你的IO口的数据不知道什么时候就会改变，这就要求编译器每次都必须真正的读取该IO端口。这里使用了词语“真正的读”，是因为由于编译器的优化，你的逻辑反应到代码上是对的，但是代码经过编译器翻译后，有可能与你的逻辑不符。
你的代码逻辑可能是每次都会读取IO端口数据，但实际上编译器将代码翻译成汇编时，可能只是读一次IO端口数据并保存到寄存器中，接下来的多次读IO口都是使用寄存器中的值来进行处理。因为读写寄存器是最快的，这样可以优化程序效率。与之类似的，中断里的变量、多线程中的共享变量等都存在这样的问题。
不使用volatile，可能造成运行逻辑错误，但是不必要的使用volatile会造成代码效率低下（编译器不优化volatile限定的变量），因此清楚的知道何处该使用volatile限定符，是一个嵌入式程序员的必修内容。
一个程序模块通常由两个文件组成，源文件和头文件。如果你在源文件定义变量：
unsigned int test; 并在头文件中声明该变量：
extern unsigned long test; 编译器会提示一个语法错误：变量’ test’声明类型不一致。但如果你在源文件定义变量：
volatile unsigned int test; 在头文件中这样声明变量：
extern unsigned int test; /*缺少volatile限定符*/ 编译器却不会给出错误信息（有些编译器仅给出一条警告）。当你在另外一个模块（该模块包含声明变量test的头文件）使用变量test时，它已经不再具有volatile限定，这样很可能造成一些重大错误。比如下面的例子，注意该例子是为了说明volatile限定符而专门构造出的，因为现实中的volatile使用Bug大都隐含，并且难以理解。
在模块A的源文件中，定义变量：
volatile unsigned int TimerCount=0; 该变量用来在一个定时器中断服务程序中进行软件计时：
TimerCount++; 在模块A的头文件中，声明变量：
extern unsigned int TimerCount; //这里漏掉了类型限定符volatile 在模块B中，要使用TimerCount变量进行精确的软件延时：
#include &#34;…A.h&#34; //首先包含模块A的头文件  //其他代码  TimerCount=0; while(TimerCount&lt;=TIMER_VALUE); //延时一段时间(感谢网友chhfish指这里的逻辑错误)  //其他代码 实际上，这是一个死循环。由于模块A头文件中声明变量TimerCount时漏掉了volatile限定符，在模块B中，变量TimerCount是被当作unsigned int类型变量。由于寄存器速度远快于RAM，编译器在使用非volatile限定变量时是先将变量从RAM中拷贝到寄存器中，如果同一个代码块再次用到该变量，就不再从RAM中拷贝数据而是直接使用之前寄存器备份值。
代码while(TimerCount&lt;=TIMER_VALUE)中，变量TimerCount仅第一次执行时被使用，之后都是使用的寄存器备份值，而这个寄存器值一直为0，所以程序无限循环。下面的流程图说明了程序使用限定符volatile和不使用volatile的执行过程。
为了更容易的理解编译器如何处理volatile限定符，这里给出未使用volatile限定符和使用volatile限定符程序的反汇编代码：
 没有使用关键字volatile，在keil MDK V4.54下编译，默认优化级别，如下所示（注意最后两行）：  122: unIdleCount=0; 123: 0x00002E10 E59F11D4 LDR R1,[PC,#0x01D4] 0x00002E14 E3A05000 MOV R5,#key1(0x00000000) 0x00002E18 E1A00005 MOV R0,R5 0x00002E1C E5815000 STR R5,[R1] 124: while(unIdleCount!=200); //延时2S钟  125: 0x00002E20 E35000C8 CMP R0,#0x000000C8 0x00002E24 1AFFFFFD BNE 0x00002E20  使用关键字volatile，在keil MDK V4.54下编译，默认优化级别，如下所示（注意最后三行）：  122: unIdleCount=0; 123: 0x00002E10 E59F01D4 LDR R0,[PC,#0x01D4] 0x00002E14 E3A05000 MOV R5,#key1(0x00000000) 0x00002E18 E5805000 STR R5,[R0] 124: while(unIdleCount!=200); //延时2S钟  125: 0x00002E1C E5901000 LDR R1,[R0] 0x00002E20 E35100C8 CMP R1,#0x000000C8 0x00002E24 1AFFFFFC BNE 0x00002E1C 可以看到，如果没有使用volatile关键字，程序一直比较R0内数据与0xC8是否相等，但R0中的数据是0，所以程序会一直在这里循环比较（死循环）；再看使用了volatile关键字的反汇编代码，程序会先从变量中读出数据放到R1寄存器中，然后再让R1内数据与0xC8相比较，这才是我们C代码的正确逻辑！
局部变量 ARM架构下的编译器会频繁的使用堆栈，堆栈用于存储函数的返回值、AAPCS规定的必须保护的寄存器以及局部变量，包括局部数组、结构体、联合体和C++的类。默认情况下，堆栈的位置、初始值都是由编译器设置，因此需要对编译器的堆栈有一定了解。
从堆栈中分配的局部变量的初值是不确定的，因此需要运行时显式初始化该变量。一旦离开局部变量的作用域，这个变量立即被释放，其它代码也就可以使用它，因此堆栈中的一个内存位置可能对应整个程序的多个变量。
局部变量必须显式初始化，除非你确定知道你要做什么。下面的代码得到的温度值跟预期会有很大差别，因为在使用局部变量sum时，并不能保证它的初值为0。编译器会在第一次运行时清零堆栈区域，这加重了此类Bug的隐蔽性。
由于一旦程序离开局部变量的作用域即被释放，所以下面代码返回指向局部变量的指针是没有实际意义的，该指针指向的区域可能会被其它程序使用，其值会被改变。
char * GetData(void) { char buffer[100]; //局部数组  … return buffer; } 使用外部工具 由于编译器的语义检查比较弱，我们可以使用第三方代码分析工具，使用这些工具来发现潜在的问题，这里介绍其中比较著名的是PC-Lint。
PC-Lint由Gimpel Software公司开发，可以检查C代码的语法和语义并给出潜在的BUG报告。PC-Lint可以显著降低调试时间。
目前公司ARM7和Cortex-M3内核多是使用Keil MDK编译器来开发程序，通过简单配置，PC-Lint可以被集成到MDK上，以便更方便的检查代码。MDK已经提供了PC-Lint的配置模板，所以整个配置过程十分简单，Keil MDK开发套件并不包含PC-Lint程序，在此之前，需要预先安装可用的PC-Lint程序，配置过程如下：
点击菜单Tools&mdash;Set-up PC-Lint… PC-Lint Include Folders：该列表路径下的文件才会被PC-Lint检查，此外，这些路径下的文件内使用#include包含的文件也会被检查； Lint Executable：指定PC-Lint程序的路径 Configuration File：指定配置文件的路径，该配置文件由MDK编译器提供。  菜单Tools&mdash;Lint 文件路径.c/.h 检查当前文件。  菜单Tools&mdash;Lint All C-Source Files 检查所有C源文件。 PC-Lint的输出信息显示在MDK编译器的Build Output窗口中，双击其中的一条信息可以跳转到源文件所在位置。 编译器语义检查的弱小在很大程度上助长了不可靠代码的广泛存在。随着时代的进步，现在越来越多的编译器开发商意识到了语义检查的重要性，编译器的语义检查也越来越强大，比如公司使用的Keil MDK编译器，虽然它的编辑器依然不尽人意，但在其V4.47及以上版本中增加了动态语法检查并加强了语义检查，可以友好的提示更多警告信息。建议经常关注编译器官方网站并将编译器升级到V4.47或以上版本，升级的另一个好处是这些版本的编辑器增加了标识符自动补全功能，可以大大节省编码的时间。  你觉得有意义的代码未必正确 C语言标准特别的规定某些行为是未定义的，编写未定义行为的代码，其输出结果由编译器决定！C标准委员会定义未定义行为的原因如下：    简化标准，并给予实现一定的灵活性，比如不捕捉那些难以诊断的程序错误；
  编译器开发商可以通过未定义行为对语言进行扩展
  C语言的未定义行为，使得C极度高效灵活并且给编译器实现带来了方便，但这并不利于优质嵌入式C程序的编写。因为许多 C 语言中看起来有意义的东西都是未定义的，并且这也容易使你的代码埋下隐患，并且不利于跨编译器移植。Java程序会极力避免未定义行为，并用一系列手段进行运行时检查，使用Java可以相对容易的写出安全代码，但体积庞大效率低下。作为嵌入式程序员，我们需要了解这些未定义行为，利用C语言的灵活性，写出比Java更安全、效率更高的代码来。
常见的未定义行为 自增自减在表达式中连续出现并作用于同一变量或者自增自减在表达式中出现一次，但作用的变量多次出现 自增（++）和自减（--）这一动作发生在表达式的哪个时刻是由编译器决定的，比如：  r = 1 * a[i++] + 2 * a[i++] + 3 * a[i++]; 不同的编译器可能有着不同的汇编代码，可能是先执行i++再进行乘法和加法运行，也可能是先进行加法和乘法运算，再执行i++，因为这句代码在一个表达式中出现了连续的自增并作用于同一变量。更加隐蔽的是自增自减在表达式中出现一次，但作用的变量多次出现，比如：  a[i] = i++; /* 未定义行为 */ 先执行i++再赋值，还是先赋值再执行i++是由编译器决定的，而两种不同的执行顺序的结果差别是巨大的。  函数实参被求值的顺序 函数如果有多个实参，这些实参的求值顺序是由编译器决定的，比如：  printf(&#34;%d %d\n&#34;, ++n, power(2, n)); /* 未定义行为 */ 是先执行++n还是先执行power(2,n)是由编译器决定的。  有符号整数溢出 有符号整数溢出是未定义的行为，编译器决定有符号整数溢出按照哪种方式取值。比如下面代码：  int value1,value2,sum //其它操作  sum=value1+value; /*sum可能发生溢出*/ 有符号数右移、移位的数量是负值或者大于操作数的位数 除数为零 malloc()、calloc()或realloc()分配零字节内存 如何避免C语言未定义行为 代码中引入未定义行为会为代码埋下隐患，防止代码中出现未定义行为是困难的，我们总能不经意间就会在代码中引入未定义行为。但是还是有一些方法可以降低这种事件，总结如下：    了解C语言未定义行为
标准C99附录J.2“未定义行为”列举了C99中的显式未定义行为，通过查看该文档，了解那些行为是未定义的，并在编码中时刻保持警惕；
  寻求工具帮助
编译器警告信息以及PC-Lint等静态检查工具能够发现很多未定义行为并警告，要时刻关注这些工具反馈的信息；
  总结并使用一些编码标准
1）避免构造复杂的自增或者自减表达式，实际上，应该避免构造所有复杂表达式；
  比如a[i] = i++;语句可以改为a[i] = i; i++;这两句代码。
2）只对无符号操作数使用位操作；    必要的运行时检查
检查是否溢出、除数是否为零，申请的内存数量是否为零等等，比如上面的有符号整数溢出例子，可以按照如下方式编写，以消除未定义特性：
  int value1,value2,sum; //其它代码  if((value1&gt;0 &amp;&amp; value2&gt;0 &amp;&amp; value1&gt;(INT_MAX-value2))|| (value1&lt;0 &amp;&amp; value2&lt;0 &amp;&amp; value1&lt;(INT_MIN-value2))) { //处理错误  } else { sum=value1+value2; } 上面的代码是通用的，不依赖于任何CPU架构，但是代码效率很低。如果是有符号数使用补码的CPU架构（目前常见CPU绝大多数都是使用补码），还可以用下面的代码来做溢出检查：
int value1, value2, sum; unsigned int usum = (unsigned int)value1 + value2; if((usum ^ value1) &amp; (usum ^ value2) &amp; INT_MIN) { /*处理溢出情况*/ } else { sum = value1 + value2; } 使用的原理解释一下，因为在加法运算中，操作数value1和value2只有符号相同时，才可能发生溢出，所以我们先将这两个数转换为无符号类型，两个数的和保存在变量usum中。如果发生溢出，则value1、value2和usum的最高位（符号位）一定不同，表达式(usum ^ value1) &amp; (usum ^ value2) 的最高位一定为1，这个表达式位与（&amp;）上INT_MIN是为了将最高位之外的其它位设置为0。    了解你所用的编译器对未定义行为的处理策略
很多引入了未定义行为的程序也能运行良好，这要归功于编译器处理未定义行为的策略。不是你的代码写的正确，而是恰好编译器处理策略跟你需要的逻辑相同。了解编译器的未定义行为处理策略，可以让你更清楚的认识到那些引入了未定义行为程序能够运行良好是多么幸运的事，不然多换几个编译器试试！
以Keil MDK为例，列举常用的处理策略如下：
  1）有符号量的右移是算术移位，即移位时要保证符号位不改变。
2）对于int类的值：超过31位的左移结果为零；无符号值或正的有符号值超过31位的右移结果为零。负的有符号值移位结果为-1。
3）整型数除以零返回零
了解你的编译器 在嵌入式开发过程中，我们需要经常和编译器打交道，只有深入了解编译器，才能用好它，编写更高效代码，更灵活的操作硬件，实现一些高级功能。下面以公司最常用的Keil MDK为例，来描述一下编译器的细节。  编译器的一些小知识  默认情况下，char类型的数据项是无符号的，所以它的取值范围是0～255； 在所有的内部和外部标识符中，大写和小写字符不同； 通常局部变量保存在寄存器中，但当局部变量太多放到栈里的时候，它们总是字对齐的。 压缩类型的自然对齐方式为1。使用关键字__packed来压缩特定结构，将所有有效类型的对齐边界设置为1； 整数以二进制补码形式表示；浮点量按IEEE格式存储； 整数除法的余数的符号于被除数相同，由ISO C90标准得出； 如果整型值被截断为短的有符号整型，则通过放弃适当数目的最高有效位来得到结果。如果原始数是太大的正或负数，对于新的类型，无法保证结果的符号将于原始数相同。 整型数超界不引发异常；像unsigned char test; test=1000;这类是不会报错的； 在严格C中，枚举值必须被表示为整型。例如，必须在‑2147483648 到+2147483647的范围内。但MDK自动使用对象包含enum范围的最小整型来实现（比如char类型），除非使用编译器命令‑‑enum_is_int 来强制将enum的基础类型设为至少和整型一样宽。超出范围的枚举值默认仅产生警告：#66:enumeration value is out of &ldquo;int&rdquo; range； 对于结构体填充，根据定义结构的方式，keil MDK编译器用以下方式的一种来填充结构：  I&gt; 定义为static或者extern的结构用零填充； II&gt; 栈或堆上的结构，例如，用malloc()或者auto定义的结构，使用先前存储在那些存储器位置的任何内容进行填充。不能使用memcmp()来比较以这种方式定义的填充结构！
 编译器不对声明为volatile类型的数据进行优化； __nop()：延时一个指令周期，编译器绝不会优化它。如果硬件支持NOP指令，则该句被替换为NOP指令，如果硬件不支持NOP指令，编译器将它替换为一个等效于NOP的指令，具体指令由编译器自己决定； __align(n)：指示编译器在n 字节边界上对齐变量。对于局部变量，n的值为1、2、4、8； attribute((at(address)))：可以使用此变量属性指定变量的绝对地址； __inline：提示编译器在合理的情况下内联编译C或C++ 函数；  初始化的全局变量和静态变量的初始值被放到了哪里？ 我们程序中的一些全局变量和静态变量在定义时进行了初始化，经过编译器编译后，这些初始值被存放在了代码的哪里？我们举个例子说明：  unsigned int g_unRunFlag=0xA5; static unsigned int s_unCountFlag=0x5A; 我曾做过一个项目，项目中的一个设备需要在线编程，也就是通过协议，将上位机发给设备的数据通过在应用编程（IAP）技术写入到设备的内部Flash中。我将内部Flash做了划分，一小部分运行程序，大部分用来存储上位机发来的数据。随着程序量的增加，在一次更新程序后发现，在线编程之后，设备运行正常，但是重启设备后，运行出现了故障！经过一系列排查，发现故障的原因是一个全局变量的初值被改变了。 这是件很不可思议的事情，你在定义这个变量的时候指定了初始值，当你在第一次使用这个变量时却发现这个初值已经被改掉了！这中间没有对这个变量做任何赋值操作，其它变量也没有任何溢出，并且多次在线调试表明，进入main函数的时候，该变量的初值已经被改为一个恒定值。 要想知道为什么全局变量的初值被改变，就要了解这些初值编译后被放到了二进制文件的哪里。在此之前，需要先了解一点链接原理。 ARM映象文件各组成部分在存储系统中的地址有两种：一种是映象文件位于存储器时（通俗的说就是存储在Flash中的二进制代码）的地址，称为加载地址；一种是映象文件运行时（通俗的说就是给板子上电，开始运行Flash中的程序了）的地址，称为运行时地址。 赋初值的全局变量和静态变量在程序还没运行的时候，初值是被放在Flash中的，这个时候他们的地址称为加载地址，当程序运行后，这些初值会从Flash中拷贝到RAM中，这时候就是运行时地址了。 原来，对于在程序中赋初值的全局变量和静态变量，程序编译后，MDK将这些初值放到Flash中，位于紧靠在可执行代码的后面。在程序进入main函数前，会运行一段库代码，将这部分数据拷贝至相应RAM位置。 由于我的设备程序量不断增加，超过了为设备程序预留的Flash空间，在线编程时，将一部分存储全局变量和静态变量初值的Flash给重新编程了。在重启设备前，初值已经被拷贝到RAM中，所以这个时候程序运行是正常的，但重新上电后，这部分初值实际上是在线编程的数据，自然与初值不同了。  在C代码中使用的变量，编译器将他们分配到RAM的哪里？ 我们会在代码中使用各种变量，比如全局变量、静态变量、局部变量，并且这些变量时由编译器统一管理的，有时候我们需要知道变量用掉了多少RAM，以及这些变量在RAM中的具体位置。 这是一个经常会遇到的事情，举一个例子，程序中的一个变量在运行时总是不正常的被改变，那么有理由怀疑它临近的变量或数组溢出了，溢出的数据更改了这个变量值。要排查掉这个可能性，就必须知道该变量被分配到RAM的哪里、这个位置附近是什么变量，以便针对性的做跟踪。 其实MDK编译器的输出文件中有一个“工程名.map”文件，里面记录了代码、变量、堆栈的存储位置，通过这个文件，可以查看使用的变量被分配到RAM的哪个位置。要生成这个文件，需要在Options for Targer窗口，Listing标签栏下，勾选Linker Listing前的复选框，如下图所示。  默认情况下，栈被分配到RAM的哪个地方？ MDK中，我们只需要在配置文件中定义堆栈大小，编译器会自动在RAM的空闲区域选择一块合适的地方来分配给我们定义的堆栈，这个地方位于RAM的那个地方呢？ 通过查看MAP文件，原来MDK将堆栈放到程序使用到的RAM空间的后面，比如你的RAM空间从0x4000 0000开始，你的程序用掉了0x200字节RAM，那么堆栈空间就从0x4000 0200处开始。 使用了多少堆栈，是否溢出?  有多少RAM会被初始化？ 在进入main()函数之前，MDK会把未初始化的RAM给清零的，我们的RAM可能很大，只使用了其中一小部分，MDK会不会把所有RAM都初始化呢？ 答案是否定的，MDK只是把你的程序用到的RAM以及堆栈RAM给初始化，其它RAM的内容是不管的。如果你要使用绝对地址访问MDK未初始化的RAM，那就要小心翼翼的了，因为这些RAM上电时的内容很可能是随机的，每次上电都不同。  MDK编译器如何设置非零初始化变量？ 对于控制类产品，当系统复位后（非上电复位），可能要求保持住复位前RAM中的数据，用来快速恢复现场，或者不至于因瞬间复位而重启现场设备。而keil mdk在默认情况下，任何形式的复位都会将RAM区的非初始化变量数据清零。 MDK编译程序生成的可执行文件中，每个输出段都最多有三个属性：RO属性、RW属性和ZI属性。对于一个全局变量或静态变量，用const修饰符修饰的变量最可能放在RO属性区，初始化的变量会放在RW属性区，那么剩下的变量就要放到ZI属性区了。 默认情况下，ZI属性区的数据在每次复位后，程序执行main函数内的代码之前，由编译器“自作主张”的初始化为零。所以我们要在C代码中设置一些变量在复位后不被零初始化，那一定不能任由编译器“胡作非为”，我们要用一些规则，约束一下编译器。 分散加载文件对于连接器来说至关重要，在分散加载文件中，使用UNINIT来修饰一个执行节，可以避免编译器对该区节的ZI数据进行零初始化。这是要解决非零初始化变量的关键。 因此我们可以定义一个UNINIT修饰的数据节，然后将希望非零初始化的变量放入这个区域中。于是，就有了第一种方法：   修改分散加载文件，增加一个名为MYRAM的执行节，该执行节起始地址为0x1000A000，长度为0x2000字节（8KB），由UNINIT修饰：  LR_IROM1 0x00000000 0x00080000 { ; load region size_region ER_IROM1 0x00000000 0x00080000 { ; load address = execution address *.o (RESET, +First) *(InRoot$$Sections) .ANY (+RO) } RW_IRAM1 0x10000000 0x0000A000 { ; RW data .ANY (+RW +ZI) } MYRAM 0x1000A000 UNINIT 0x00002000 { .ANY (NO_INIT) } } 那么，如果在程序中有一个数组，你不想让它复位后零初始化，就可以这样来定义变量：  unsigned char plc_eu_backup[32] __attribute__((at(0x1000A000))); 变量属性修饰符__attribute__((at(adde)))用来将变量强制定位到adde所在地址处。由于地址0x1000A000开始的8KB区域ZI变量不会被零初始化，所以位于这一区域的数组plc_eu_backup也就不会被零初始化了。 这种方法的缺点是显而易见的：要程序员手动分配变量的地址。如果非零初始化数据比较多，这将是件难以想象的大工程（以后的维护、增加、修改代码等等）。所以要找到一种办法，让编译器去自动分配这一区域的变量。  分散加载文件同方法1，如果还是定义一个数组，可以用下面方法：  unsigned char plc_eu_backup[32] __attribute__((section(&#34;NO_INIT&#34;),zero_init)); 变量属性修饰符__attribute__((section(“name”),zero_init))用于将变量强制定义到name属性数据节中，zero_init表示将未初始化的变量放到ZI数据节中。因为“NO_INIT”这显性命名的自定义节，具有UNINIT属性。   将一个模块内的非初始化变量都非零初始化
假如该模块名字为test.c，修改分散加载文件如下所示：
  LR_IROM1 0x00000000 0x00080000 { ; load region size_region ER_IROM1 0x00000000 0x00080000 { ; load address = execution address *.o (RESET, +First) *(InRoot$$Sections) } RW_IRAM1 0x10000000 0x0000A000 { ; RW data .ANY (+RW +ZI) } RW_IRAM2 0x1000A000 UNINIT 0x00002000 { test.o (+ZI) } } 在该模块定义时变量时使用如下方法： 这里，变量属性修饰符__attribute__((zero_init))用于将未初始化的变量放到ZI数据节中变量，其实MDK默认情况下，未初始化的变量就是放在ZI数据区的。 ]]></content>
  </entry>
  
  <entry>
    <title>AMD能否借助MI300加速器再次加速</title>
    <url>/post/soc/can-AMD-accelerate-again-with-the-MI300-accelerator.html</url>
    <categories><category>SOC</category>
    </categories>
    <tags>
      <tag>AMD</tag>
      <tag>MI300</tag>
    </tags>
    <content type="html"><![CDATA[ AMD  宣布将于 2023 年 12 月 6 日举办“ Advancing AI ”现场直播活动，AMD董事会主席兼首席执行官苏姿丰博士（Dr. Lisa Su）将携手其他AMD高管、AI生态系统合作伙伴和客户共同探讨AMD产品和软件将如何重塑AI和自适应高性能计算领域。
基本上板上钉钉的是，这场活动中的“聚焦点”，是AMD将推出下一代 AMD Instinct MI300 数据中心 GPU 加速器系列。
总结：
 AMD的 MI300 AI 加速器可能成为该公司未来几年的主要增长动力，使其能够与NVIDIA等公司竞争。 MI300A以及MI300X加速器预计将明显增强AMD的数据中心业务，并有可能产生10亿美元的销售额。 AMD 在数据中心人工智能市场的强势地位，加上对 ROCm 软件生态系统的投资，将进一步支持其增长潜力。  MI300加速器预计成为AMD最快达成10亿美元销售额产品 在2023 财年第三季度财报电话会议上，AMD 管理层预计第四季度数据中心 GPU 收入约为 4 亿美元，2024 年将超过 20 亿美元，全年收入将持续增长。
22财年，AMD在数据中心业务上创造了60亿美元的收入，占集团总收入的25.6%。MI300A和MI300X加速器的出货极大地促进了他们的数据中心业务。Lisa Su表示，MI300 预计将成为公司历史上销售额最快达到 10 亿美元的产品。
MI300A是一款由1460亿个晶体管组成的CPU+GPU加速器，而MI300X则是一款专为数据中心市场设计的纯GPU产品。据透露，AMD有望在未来几周内开始向领先的云和 OEM 客户生产 Instinct MI300X GPU 加速器。此外，Instinct MI300A APU 于 10 月初开始生产发货，以支持 El Capitan Exascale 超级计算机。
MI300系列和NVIDIA H100的AI争夺战 MI300A 和 MI300X 都将成为 AMD 未来几年的重要增长动力。首先，尽管 AMD 的 GPU 产品比 NVIDIA更晚进入市场，但 MI300X 将8个加速器集成到一个平台上，并具有1.5TB HBM3 内存。凭借如此强大的计算能力，MI300X非常适合AI机器学习中的大型语言模型。
业界谈论到AI加速器，NVIDIA是绕不开的话题。
AMD 的 MI300X 使该公司能够与NVIDIA的 H100 GPU 产品竞争。Lisa Su声称MI300X提供5.2TBps的内存带宽，比NVIDIA H100 GPU好1.6倍。
值得注意的是，Lisa Su指的是NVIDIA H100 SXM版本，但NVIDIA同样具有高版本的H100 NVL——通过NVLink桥接2个GPU，提供7.8 TBps的内存带宽——仍然略高于AMD的MI300X。
不过，AMD MI300X的强大，足以满足大型语言模型的计算需求。
数据中心人工智能市场规模巨大，AMD预计今年的潜在市场总额将达到300亿美元，预计到2027年将增长至1500亿美元。
这些都给AMD在此领域留下足够想象的扩展空间。
ROCm 软件生态系统 成功的软件对于人工智能加速器的重要性不可低估。
NVIDIA 的 CUDA 软件已经成功建立了其生态系统，涵盖硬件、软件和外部合作伙伴。同样，AMD 也一直在投资其 ROCm 软件。最新的 ROCm 软件套件完全支持 AMD 的 MI300 加速器。
由于 CUDA 的先发优势，GitHub 上的许多现有代码主要基于 CUDA，为弥补这一差距，AMD 一直在为 AMD GPU 开发 PyTorch/TensorFlow 代码环境。该环境可与 AMD GPU 上基于 CUDA 的代码存储库兼容，从而促进 AMD 生态系统的扩展，并帮助客户更高效地构建机器学习应用程序。
顺应AI计算的浪潮。新推出的 MI300 AI 加速器预计将维持收入增长的高速势头。许多企业优先考虑云和人工智能投资，极大地推动了对加速器的需求。
研究和市场预测 GPU 市场的复合年增长率将达到 29.57%，将从 2021 年的 310 亿美元增至 2028 年的 1900 亿美元。
]]></content>
  </entry>
  
  <entry>
    <title>AMD下一代处理器进化！正式迈入3nm，混合使用三星4nm工艺</title>
    <url>/post/soc/amd-next-generation-chips-will-use-3nm-and-4nm-manufacture-technology.html</url>
    <categories><category>SOC</category>
    </categories>
    <tags>
      <tag>AMD</tag>
      <tag>CPU</tag>
      <tag>GPU</tag>
    </tags>
    <content type="html"><![CDATA[ AMD  这几年的处理器和GPU芯片一直和台积电有着积极的合作，处理器和显卡都已经用上了台积电的5nm工艺。而从最新的报道来看，在下一代处理器，AMD很可能用上台积电的3nm工艺，不过具体是不是Zen 5现在还要打上一个问号，目前来看更大可能是Zen 5C这样的小核心会用上台积电最新的先进工艺。
事实上在之前的AMD路线图中，在下一代Zen 5架构的处理器中，就已经明确表示有Zen 5和Zen 5C，就和当下有Zen 4以及Zen 4C两种架构一样。两者在IP架构部分其实区别并不大，只是规模和尺寸大小，功能部分其实差异不多，和Intel的大小核设计区别还是很大的。而在最新的了解的AMD下一代处理器IP所运用的制程技术中，则包括了台积电N3制程及三星4nm制程，这多少暴露了AMD的设计思路。
过去AMD的路线图中，明确表示Zen 5和Zen 5C会使用4nm和3nm的制程，Zen 5明年就要发布，我们认为赶上台积电N3工艺的可能性不是太大，目前台积电主要是为苹果生产3nm的芯片。所以更可能是Zen 5采用台积电4nm工艺，而更晚发布对能耗要求更高的Zen 5C才会用上台积电的3nm工艺。
先前就有传言表示，AMD在寻求和三星的合作，或许会把部分产能交给三星代工运用其4nm制程技术，但具体规模仍不确定。不过AMD不太可能让三星4nm代工任何重要的IP，所以或许会利用三星4nm进行试产或代工特定I/O晶片。如果是这样，那么未来Zen 5C的主芯片还是采用台积电的3nm，而I/O芯片则会使用三星4nm，类似于目前RDNA 3的设计。
除此之外，Zen 4架构代号为Persephone、Zen 5代号为Nirvana、Zen 6代号为Morpheus。Zen4C代号为Dionysus，而Zen 5C代号则是Prometheus。AMD的Zen 5及Zen 5C核心架构是2024~2025年的重头戏，将运用于代号为Strix Point的笔记本处理器、Granite Ridge的桌机处理器）及Turin服务器处理器等系列的产品上。
无论如何，明年我们会看到Intel和AMD在工艺上的双双进步，Intel的桌面处理器会进入到Intel 4时代，实际也就是Intel自己的7nm工艺；而AMD的新品则会在台积电4nm和3nm之间，届时两家公司的产品在性能部分相信都会有新的进展。而对于AMD用户的好消息是，至少内存和主板都不用更换，就能升级到新一代处理器上！
]]></content>
  </entry>
  
  <entry>
    <title>嵌入式高级工程师10年经验总结</title>
    <url>/post/mcu/summary-of-10-years-of-experience-as-a-senior-embedded-engineer.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>Embedded</tag>
    </tags>
    <content type="html"><![CDATA[本文是一位 嵌入式  高级工程师对10年工作经验的总结。
嵌入式系统的概念 理解“嵌入”的概念 ，主要从三个方面展开。
 从硬件上，“嵌入”将基于CPU的处围器件，整合到CPU芯片内部，比如早期基于X86体系结构下的计算机，CPU只是有运算器和累加器的功能，一切芯片要造外部桥路来扩展实现，象串口之类的都是靠外部的16C550/2的串口控制器芯片实现，而目前的这种串口控制器芯片早已集成到CPU内部，还有PC机有显卡，而多数嵌入式处理器都带有LCD控制器，但其种意义上就相当于显卡。  比较高端的ARM类Intel Xscale架构下的IXP网络处理器CPU内部集成PCI控制器(可配成支持4个PCI从设备或配成自身为CPI从设备);还集成3个NPE网络处理器引擎，其中两个对应于两个MAC地址， 可用于网关交换用，而另外一个NPE网络处理器引擎支持DSL，只要外面再加个PHY芯片即可以实现DSL上网功能。IXP系列最高主频可以达到 1.8G，支持2G内存，1G×10或10G×1的以太网口或Febre channel的光通道。IXP系列应该是目标基于ARM体系统结构下由intel进行整合后成Xscale内核的最高的处理器了。
 从软件上，嵌入就是在定制操作系统内核里将应用一并选入，编译后将内核下载到ROM中。而在定制操作系统内核时所选择的应用程序组件就是完成了软件的“嵌入”，比如Win在内核定制时，会有相应选择，其中就是wordpad,PDF,MediaPlay等等选择，如果我们选择了在CE启动后，就可以在界面中找到这些东西，如果是以前PC上装的windows操作系统，多半的东西都需要我们再装。
  把软件内核或应用文件系统等东西烧到嵌入式系统硬件平台中的ROM中就实现了一个真正的“嵌入”。
  以上的定义是我在6、7年前给嵌入式系统下自话侧重于理解型的定义，书上的定义也有很多，但在“嵌入式”这个领域范围内，谁都不敢说自己的定义是十分确切的，包括那些专家学者们，历为毕竟嵌入式系统是计算机范畴下的一门综合性学科。
嵌入式系统的分层与专业的分类 嵌入式系统分为4层，硬件层、驱动层、操作系统层和应用层。
 硬件层，是整个嵌入式系统的根本，如果现在单片机及接口这块很熟悉，并且能用C和汇编语言来编程的话，从嵌入式系统的硬件层走起来相对容易，硬件层也是驱动层的基础，一个优秀的驱动工程师是要能够看懂硬件的电路图和自行完成CPLD的逻辑设计的，同时还要对操作系统内核及其调度性相当的熟悉的。但硬件平台是基础，增值还要靠软件。  硬件层比较适合于，电子、通信、自动化、机电一体、信息工程类专业的人来搞，需要掌握的专业基础知识有，单片机原理及接口技术、微机原理及接口技术、C语言。
驱动层，这部分比较难，驱动工程师不仅要能看懂电路图还要能对操作系统内核十分的精通，以便其所写的驱动程序在系统调用时，不会独占操作系统时间片，而导致其它任务不能动行，不懂操作系统内核架构和实时调度性，没有良好的驱动编写风格，按大多数书上所说添加的驱动的方式，很多人都能做到，但可能连个初级的 驱动工程师的水平都达不到，这样所写的驱动在应用调用时就如同windows下我们打开一个程序运行后，再打开一个程序时，要不就是中断以前的程序，要不就是等上一会才能运行后来打开的程序。想做个好的驱动人员没有三、四年功底，操作系统内核不研究上几编，不是太容易成功的，但其工资在嵌入式系统四层中可是最高的。  嵌入式的驱动层比较适合于电子、通信、自动化、机电一体、信息工程类专业尤其是计算机偏体系结构类专业的人来搞，除硬件层所具备的基础学科外，还要对数据结构与算法、操作系统原理、编译原理都要十分精通了解。
 操作系统层，对于操作系统层目前可能只能说是简单的移植，而很少有人来自已写操作系统，或者写出缺胳膊少腿的操作系统来，这部分工作大都由驱动工程师来完成。操作系统是负责系统任务的调试、磁盘和文件的管理，而嵌入式系统的实时性十分重要。据说，XP操作系统是微软投入300人用两年时间才搞定的，总时工时是600人年，中科院软件所自己的女娲Hopen操作系统估计也得花遇几百人年才能搞定。因此这部分工作相对来讲没有太大意义。
  应用层，相对来讲较为容易的，如果会在windows下如何进行编程接口函数调用，到操作系统下只是编译和开发环 境有相应的变化而已。如果涉及Jave方面的编程也是如此的。嵌入式系统中涉及算法的由专业算法的人来处理的，不必归结到嵌入式系统范畴内。但如果涉及嵌 入式系统下面嵌入式数据库、基于嵌入式系统的网络编程和基于某此应用层面的协议应用开发(比如基于SIP、H.323、Astrisk)方面又较为复杂， 并且有难度了。
  目标与定位 先有目标，再去定位。
学 ARM  ，从硬件上讲，一方面就是学习接口电路设计，另一方面就是学习汇编和C语言的板级编程。如果从软件上讲，就是要学习基于ARM处理器的操作系统层面 的驱动、移植了。这些对于初学都来说必须明确,要么从硬件着手开始学，要么从操作系统的熟悉到应用开始学，但不管学什么，只要不是纯的操作系统级以上基于 API的应用层的编程，硬件的寄存器类的东西还是要能看懂的，基于板级的汇编和C编程还是要会的。因此针对于嵌入式系统的硬件层和驱动程的人，ARM的接 口电路设计、ARM的C语言和汇编语言编程及调试开发环境还是需要掌握的。
因此对于初学者必然要把握住方向，自己学习嵌入式系统的目标是什么，自己要在那一层面上走。然后再着手学习较好，与ARM相关的嵌入式系统的较为实际的两个层面硬件层和驱动层，不管学好了那一层都会很有前途的。
如果想从嵌入式系统的应用层面的走的话，可能与ARM及其它体系相去较远，要着重研究基嵌入式操作系统的环境应用与相应开发工具链，比如WinCe操作系统下的EVC应用开发(与windows下的VC相类似)，如果想再有突破就往某些音视频类的协议上靠，比如VOIP领域的基于SIP或H.323协议的应用层开发，或是基于嵌入式网络数据库的开发等等。
对于初学者来讲，要量力而行，不要认为驱动层工资高就把它当成方向了，要结合自身特点，嵌入式系统四个层面上那个层面上来讲都是有高人存在，当然高人也对应 的高工资，我是做硬件层的，以前每月工资中个人所得税要被扣上近3千大元，当然我一方面充当工程师的角色，一方面充当主管及人物的角色，两个职位我一个人 干，但上班时间就那些。硬件这方面上可能与我PK的人很少了，才让我拿到那么多的工资。
开发系统选择 很多ARM初学者都希望有一套自己能用的系统，但他们住住会产生一种错误认识就是认为处理器版本越高、性能越高越好，就象很多人认为ARM9与ARM7好， 我想对于初学者在此方面以此入门还应该理智，开发系统的选择最终要看自己往嵌入式系统的那个方向上走，是做驱动开发还是应用，还是做嵌入式系统硬件层设计与板级测试。如果想从操作系统层面或应用层面上走，不管是驱动还是应用，那当然处理器性能越高越好了，但嵌入式系统这个东西自学，有十分大的困难，不是几个月或半年 或是一年二年能搞定的事。
在某种意义上请，ARM7与9的差别就是在某些功能指令集上丰富了些，主频提高一些而已，就比如286和386。对于用户来讲可能觉查不到什么，只能是感觉速度有些快而已。
ARM7比较适合于那些想从硬件层面上走的人，因为ARM7系列处理器内部带MMU的很少，而且比较好控制，就比如S3C44B0来讲，可以很容易将 Cache关了，而且内部接口寄存器很容易看明白，各种接口对于用硬件程序控制或AXD单步命令行指令都可以控制起来，基于51单片机的思想很容易能把他搞懂，就当成个32位的单片机，从而消除很多51工程师想转为嵌入式系统硬件ARM开发工程师的困惑，从而不会被业界某此不是真正懂嵌入式烂公司带到操作 系统层面上去，让他们望而失畏，让业界更加缺少这方面的人才。
而嵌入式系统不管硬件设计还是软件驱动方面都是十分注重接口这部分的，选择平台还要考察一个处理器的外部资源，你接触外部资源越多，越熟悉他们那你以后就业成功的机率就越高，这就是招聘时 所说的有无“相关技能”，因为一个人不可能在短短几年内把所有的处理器都接触一遍，而招聘单位所用的处理器就可能是我们完全没有见过的，就拿台湾数十家小公司(市价几千万)的公司生产的ARM类处理器，也很好用，但这些东西通用性太差，用这些处理器的公司就只能招有相关工作经验的人了，那什么是相关工作经验，在硬件上讲的是外围接口设计，在软件上讲是操作系统方面相关接口驱动及应用开发经验。我从业近十年，2000年ARM出现，我一天始做ARM7,然后 直接跑到了Xscale(这个板本在ARM10-11之间)，一做就是五年，招人面试都不下数百人，在这些方面还是深有体会的。
#3 高级嵌入式系统硬件工程师必备技能
对于硬件来讲有几个方向，就单纯信号来分为数字和模拟，模拟比较难搞，一般需要很长的经验积累，单单一个阻值或容值的精度不够就可能使信号偏差很大。因此年轻人搞的较少，随着技术的发展，出现了模拟电路数字化，比如手机的Modem射频模块，都采用成熟的套片，而当年国际上只有两家公司有此技术，自我感觉模拟功能不太强的人，不太适合搞这个，如果真能搞定到手机的射频模块，只要达到一般程度可能月薪都在15K以上。
另一类就是数字部分了，在大方向上又可分为51/ARM的单片机类，DSP类，FPGA类， 国内FPGA的工程师大多是在IC设计公司从事IP核的前端验证，这部分不搞到门级，前途不太明朗，即使做个IC前端验证工程师，也要搞上几年才能胜任。
DSP硬件接口比较定型，如果不向驱动或是算法上靠拢，前途也不会太大。而ARM单片机类的内容就较多，业界产品占用量大，应用人群广，因此就业空间极 大，而硬件设计最体现水平和水准的就是接口设计这块，这是各个高级硬件工程师相互PK，判定水平高低的依据。而接口设计这块最关键的是看时序，而不是简单的连接，比如PXA255处理器I2C要求速度在100Kbps，如果把一个I2C外围器件，最高还达不到100kbps的与它相接，必然要导致设计的失败。
这样的情况有很多，比如51单片机可以在总线接LCD，但为什么这种LCD就不能挂在ARM的总线上，还有ARM7总线上可以外接个Winband的SD卡控制器，但为什么这种控制器接不到ARM9或是Xscale处理器上，这些都是问题。因此接口并不是一种简单的连接，要看时序，要看参数。
一个优秀的硬件工程师应该能够在没有参考方案的前提下设计出一个在成本和性能上更加优秀的产品，靠现有的方案，也要进行适当的可行性裁剪，但不是胡乱的来，我遇到一个工程师把方案中的5V变1.8V的DC芯片，直接更换成LDO，有时就会把CPU烧上几个。
前几天还有人希望我帮忙把他们以前基于PXA255平台的手持GPS设备做下程序优化，我问了一下情况，地图是存在SD卡中的，而SD卡与PXA255的MMC控制器间采用的SPI接口，因此导致地图读取速度十分的慢，这种情况是设计中严重的缺陷，而不是程序的问题，因此我提了几条建议，让他们更新试下再说。因此想成为一个优秀的工程师，需要对系统整体性的把握和对已有电路的理解，换句话说，给你一套电路图你 终究能看明白多少，看不明白80%以上的话，说明你离优秀的工程师还差得远哪。其次是电路的调试能力和审图能力，但最最基本的能力还是原理图设计PCB绘制，逻辑设计这块。
这是指的硬件设计工程师，从上面的硬件设计工程师中还可以分出ECAD工程师，就是专业的画PCB板的工程师，和EMC设计工程师，帮 人家解决EMC的问题。硬件工程师再往上就是板级测试工程师，就是C语功底很好的硬件工程师，在电路板调试过程中能通过自已编写的测试程序对硬件功能进行 验证。然后再交给基于操作系统级的驱动开发人员。
总之，硬件的内容很多很杂，硬件那方面练成了都会成为一个高手，我时常会给人家做下方案评估，很多高级硬件工程师设计的东西，经常被我一句话否定，因此工程师做到我这种地步，也会得罪些人，但硬件的确会有很多不为人知的东西，让很多高级硬件工程师也摸不到头脑。
那么高级硬件件工程师技术技能都要具备那些东西哪，首先要掌握EDA设计的辅助工具类如Protelor、CAD、PowperPCB、Maplux2、ISE、VDHL语言，要能用到这些工具画图画板做逻辑设计，再有就是接口设计审图能力，再者就是调试能力，如果能走到总体方案设计这块，那就基本上快成为资深工程师了。
硬件是要靠经验，也要靠积累的，正所谓十年磨一剑。
]]></content>
  </entry>
  
  <entry>
    <title>芯片设计中的DRAM</title>
    <url>/post/fpga/DRAM-in-chip-design.html</url>
    <categories><category>FPGA</category>
    </categories>
    <tags>
      <tag>Chip</tag>
      <tag>DRAM</tag>
    </tags>
    <content type="html"><![CDATA[本文将介绍芯片设计中动态随机存取存储器（DRAM）的相关知识，包括其工作原理、分类以及在现代电子设备中的应用。
 DRAM 的基本概念  DRAM（Dynamic Random Access Memory，动态随机存取存储器）是一种用于存储数据的半导体芯片。它的基本工作原理是在一个存储单元中存储一个比特（0 或 1）的信息，并通过刷新机制来保持这些信息的稳定性。DRAM 广泛应用于各种电子设备中，如个人电脑、智能手机等。
DRAM 的工作原理  DRAM 的工作原理相对简单。它由一个存储单元阵列组成，每个存储单元都包含一个存储电容。当一个存储单元被选中时，它的电容中存储的电荷代表数据位（0 或 1）。为了读取或写入数据，DRAM 需要通过行地址和列地址进行寻址。
DRAM 的工作过程中，刷新是关键。由于存储电容会随着时间的推移而泄漏电荷，因此需要定期刷新以保持数据稳定。刷新过程通常是在读取或写入数据之后进行的。
DRAM 的分类  根据不同的应用场景和性能要求，DRAM 分为多种类型。以下是一些常见的 DRAM 类型：
 SDRAM（Synchronous DRAM）：同步 DRAM，用于高速数据传输。SDRAM 使用一个时钟信号来控制数据传输，速度较快。 DDR SDRAM（Double Data Rate SDRAM）：双倍数据速率 SDRAM，可以在每个时钟周期中读取或写入两个数据位。DDR SDRAM 进一步细分为 DDR、DDR2、DDR3 等不同版本，速度逐渐提高。 RDRAM（Rapid I/O DRAM）：快速 I/O DRAM，用于图像处理和视频卡等领域。RDRAM 具有高带宽和低延迟，但功耗较高。 LPDDR（Low Power DDR）：低功耗 DDR，用于移动设备。LPDDR 通过降低功耗来提高电池续航能力。  DRAM 在现代电子设备中的应用  随着科技的不断发展，对存储容量的需求不断增长。DRAM 在现代电子设备中的应用越来越广泛，如：
 个人电脑：DRAM 作为主存储器，用于临时存储操作系统、应用程序和用户数据。 智能手机：DRAM 用于存储操作系统、应用程序和用户数据，以及运行时的缓存。 服务器：DRAM 作为内存，用于支持大量数据处理和高速 I/O。 嵌入式设备：DRAM 用于存储程序代码和数据 ]]></content>
  </entry>
  
  <entry>
    <title>梳理STM32芯片的内部架构</title>
    <url>/post/soc/STM32-chip-internal-architecture.html</url>
    <categories><category>SOC</category>
    </categories>
    <tags>
      <tag>SOC</tag>
      <tag>UART</tag>
    </tags>
    <content type="html"><![CDATA[STM32芯片主要由内核和片上外设组成，STM32F103采用的是Cortex-M3内核，内核由 ARM  公司设计。STM32的芯片生产厂商ST，负责在内核之外设计部件并生产整个芯片。这些内核之外的部件被称为核外外设或片上外设，如 GPIO、USART（串口）、I2C、SPI 等。
 STM32 Internal Architecture  
芯片内部架构示意图 芯片内核与外设之间通过各种总线连接，其中驱动单元有 4 个，被动单元也有 4 个，具体如上图所示。可以把驱动单元理解成是内核部分，被动单元都理解成外设。
ICode 总线 ICode总线是专门用来取指令的，其中的I表示Instruction（指令），指令的意思。写好的程序编译之后都是一条条指令，存放在 FLASH中，内核通过ICode总线读取这些指令来执行程序。
DCode总线 DCode这条总线是用来取数的，其中的D表示Data（数据）。在写程序的时候，数据有常量和变量两种。常量就是固定不变的，用C语言中的const关键字修饰，放到内部FLASH当中。变量是可变的，不管是全局变量还是局部变量都放在内部的SRAM。
系统System总线 我们通常说的寄存器编程，即读写寄存器都是通过系统总线来完成的，系统总线主要是用来访问外设的寄存器。
DMA总线 DMA总线也主要是用来传输数据，这个数据可以是在某个外设的数据寄存器，可以在SRAM，可以在内部FLASH。
因为数据可以被Dcode总线，也可以被DMA总线访问，为了避免访问冲突，在取数的时候需要经过一个总线矩阵来仲裁，决定哪个总线在取数。
内部的闪存存储器Flash 内部的闪存存储器即FLASH，编写好的程序就放在这个地方。内核通过ICode总线来取里面的指令。
内部的SRAM 内部的SRAM，是通常所说的内存，程序中的变量、堆栈等的开销都是基于内部SRAM，内核通过DCode总线来访问它。
FSMC FSMC的英文全称是Flexible static memory controller（灵活的静态的存储器控制器）。通过FSMC可以扩展内存，如外部的SRAM、NAND-FLASH和NORFLASH。但FSMC只能扩展静态的内存，不能是动态的内存，比如就不能用来扩展SDRAM。
AHB 从AHB总线延伸出来的两条APB2和APB1总线是最常见的总线，GPIO、串口、I2C、SPI 这些外设就挂载在这两条总线上。这个是学习STM32的重点，要学会对这些外设编程，去驱动外部的各种设备。
]]></content>
  </entry>
  
  <entry>
    <title>Linux内存管理 | ioremap</title>
    <url>/post/linux/linux-memory-management-ioremap.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Linux</tag>
      <tag>Memory</tag>
      <tag>MMU</tag>
    </tags>
    <content type="html"><![CDATA[ioremap是 Linux  内核中用于将IO物理地址映射到内核虚拟地址空间的函数，对于搭载Linux内核的ARM芯片来说，它通常用于访问芯片内部的寄存器。
ioremap的用法 ioremap函数接受两个参数：映射的起始物理地址和映射的内存区域大小，函数返回一个void类型的指针（虚拟地址）。
void __iomem *addr = ioremap(phys_addr, size); 通过ioremap函数返回的指针，内核就可以访问这片映射的物理区域。
u32 val = readl(addr); val |= (0x1 &lt;&lt; ENABLE_SHIFT); writel(val, addr); 操作完毕后，可以释放映射。
iounmap(addr); ioremap的内部实现 和之前讲过的其他内存分配函数类似，ioremap首先要找到一段空闲的虚拟地址区域，然后建立虚拟地址到物理地址的映射。
ioremap() 的虚拟地址从 vmalloc 区分配，这一点与vmalloc函数的实现一致。
area = get_vm_area_caller(size, VM_IOREMAP, caller); 然后通过修改内核页表的方式将其映射到 I/O 地址空间。
err = ioremap_page_range(addr, addr + size, phys_addr, prot); 与 vmalloc() 不同的是，ioremap() 并不需要通过伙伴系统去分配物理页，因为ioremap() 要映射的目标地址是IO地址，不是物理内存。
]]></content>
  </entry>
  
  <entry>
    <title>芯片设计中的uart模块</title>
    <url>/post/soc/uart-module-in-chip-design.html</url>
    <categories><category>SOC</category>
    </categories>
    <tags>
      <tag>SOC</tag>
      <tag>UART</tag>
    </tags>
    <content type="html"><![CDATA[在芯片设计中，UART（Universal Asynchronous Receiver/Transmitter，通用异步接收/发送器）模块是一个非常重要的外设模块。
UART模块负责处理芯片与外部设备之间的异步串行通信，广泛应用于各种嵌入式系统、微控制器和通信设备中。本文将详细介绍芯片设计中的UART模块及其关键技术。
UART 模块的基本原理 UART 模块主要负责实现异步串行通信，它包括一个发送器（TX）和一个接收器（RX）。发送器将内部并行数据转换为串行数据，并按照一定的时序和速率发送到外部设备；接收器则从外部设备接收串行数据，并将其转换为并行数据，供内部系统使用。
UART 模块的工作原理如下：
 并行数据输入：将内部并行数据输入到 UART 模块。 数据位处理：UART 模块将并行数据的每个位进行处理，如添加起始位、数据位、校验位等。 串行发送：将处理后的数据位按照一定的时序和速率发送给外部设备。 串行接收：从外部设备接收串行数据，并将其转换为并行数据。 数据位处理：UART 模块对接收到的并行数据进行处理，如校验位、数据位、停止位等。 并行数据输出：将处理后的并行数据输出到内部系统。  UART 模块的关键技术  数据位：UART 模块支持不同的数据位，如 5 位、6 位、7 位或 8 位。数据位决定了通信速率和传输效率。 停止位：UART 模块支持不同的停止位，如 1 位、2 位或 3 位。停止位用于标识一个数据帧的结束。 校验位：UART 模块支持不同的校验位，如奇校验、偶校验、高位校验等。校验位用于检测数据传输过程中的错误。 波特率：波特率是指每秒钟传输的位数，它决定了通信速率。UART 模块需要根据外部设备的波特率进行配置。 中断处理：UART 模块支持中断处理，如接收中断、发送中断等。中断处理可以提高系统的实时性和响应速度。 双向通信：UART 模块支持双向通信，既可以发送数据，也可以接收数据。  UART 模块在芯片设计中的应用 在芯片设计中，UART 模块广泛应用于各种嵌入式系统、微控制器和通信设备中。例如，在智能手机、平板电脑、路由器等设备中，UART 模块用于与外部传感器、显示器、Modem 等设备进行通信。此外，UART 模块还可以与其他通信接口（如 I2C、SPI、CAN 等）配合使用，实现更丰富的功能。
UART 模块是芯片设计中的一个重要外设模块，它负责处理异步串行通信。通过掌握 UART 模块的基本原理和关键技术，设计人员可以为芯片提供高效、可靠的通信功能。
]]></content>
  </entry>
  
  <entry>
    <title>通过NAT Server从内网向外网提供服务</title>
    <url>/post/linux/NAT-server-how-to.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Boot</tag>
      <tag>NAT Server</tag>
    </tags>
    <content type="html"><![CDATA[今天给大家介绍一下NAT Server  ，包括NAT Server的原理、工作过程、配置（华为、思科、Juniper）。
什么是 NAT Server NAT（Network Address Translation）服务器是一种网络设备或服务，用于在内部网络和外部网络之间进行地址转换。在网络通信中，每个设备都需要一个唯一的IP地址来进行识别和通信。然而，IPv4地址空间有限，而且经常会出现IP地址不足的情况。为了解决这个问题，引入了NAT技术。
NAT具有“屏蔽”内部主机的作用，将内部网络的私有IP地址转换成公网IP地址，从而在有限的公网IP地址下支持多个内部设备与外部网络通信。这种转换过程隐藏了内部网络的实际IP地址，提高了网络安全性，并减少了对公网IP地址的需求。
然而，有时内网需要向外网提供服务，比如提供WWW服务或FTP服务。这种情况下需要内网的服务器不被“屏蔽”，外网用户可以随时访问内网服务器。这就需要一种机制来允许外部用户访问内网服务器，而不会影响内网其他设备的安全性。
NAT Server（NAT服务器）可以很好地解决这个问题。当外网用户访问内网服务器时，NAT Server通过事先配置好的“公网IP地址+端口号”与“私网IP地址+端口号”之间的映射关系，将服务器的“公网IP地址+端口号”根据映射关系替换成对应的“私网IP地址+端口号”。这样，外网用户的请求就能正确地传递到内网服务器，实现了内网服务器对外提供服务的需求。
NAT Server工作原理 NAT Server的地址转换过程如下：
  在Router上配置NAT Server的转换表项：在网络中的路由器（Router）上配置NAT Server的转换表项。这些表项记录了内网服务器的私网IP地址和端口号与对应的公网IP地址和端口号之间的映射关系。
  外网用户访问内网服务器：当外网用户发起访问请求时，请求会到达路由器。路由器根据该请求的“目的IP地址+端口号”查找NAT Server转换表项，找出对应的“私网IP地址+端口号”。
  替换报文的目的IP地址+端口号：路由器将请求报文中的“目的IP地址+端口号”替换为转换表项中对应的“私网IP地址+端口号”，从而确保报文能够正确地传递给内网服务器。
  内网服务器回应报文：当内网服务器收到外网用户的请求并生成回应报文时，回应报文会发送给路由器。
  查找NAT Server转换表项：路由器根据回应报文的“源IP地址+源端口号”查找NAT Server转换表项，找出对应的“公网IP地址+端口号”。
  替换报文的源IP地址+源端口号：路由器将回应报文中的“源IP地址+源端口号”替换为转换表项中对应的“公网IP地址+端口号”，以确保回应报文能够正确地传递给外网用户。
  通过这个地址转换过程，NAT Server实现了外网用户与内网服务器之间的通信，同时确保内网服务器的私网IP地址和端口号不会被外部用户直接暴露。
NAT Server的地址转换过程（简易拓扑图） NAT Server的地址转换过程可以通过以下简易说明图来表示：
在此简易说明图中，外部用户通过公网IP地址和端口号发起访问请求。请求经过路由器，根据转换表项进行地址转换，将目的IP地址和端口号替换为对应的内网IP地址和端口号。内网服务器处理请求并生成响应，响应经过路由器，根据转换表项进行源地址替换，将源IP地址和端口号替换为对应的公网IP地址和端口号。最终，响应传递给外部用户。
NAT Server的工作原理可以更详细地描述如下：
  配置NAT Server转换表项：在Router上进行配置，将内网服务器的私网IP地址和端口号与公网IP地址和端口号建立映射关系。
  外网用户发起请求：当外网用户通过公网IP地址和端口号发起请求时，请求报文会传递到路由器。
  转换表项查找：路由器根据请求报文中的目的IP地址和端口号查找NAT Server转换表项。
  目的地址替换：路由器使用转换表项中对应的私网IP地址和端口号替换请求报文中的目的IP地址和端口号。
  内网服务器响应：请求报文被路由器转发给内网服务器，内网服务器处理请求并生成响应报文。
  源地址替换：内网服务器的响应报文返回到路由器，路由器根据响应报文中的源IP地址和端口号查找NAT Server转换表项。
  源地址替换：路由器使用转换表项中对应的公网IP地址和端口号替换响应报文中的源IP地址和端口号。
  响应传递给外网用户：经过地址转换后的响应报文通过公网IP地址和端口号传递给外网用户，完成了内网服务器与外网用户之间的通信。
  通过以上步骤，NAT Server实现了内网服务器对外提供服务的需求，同时保护了内网服务器的私网IP地址和端口号，增加了网络安全性。
NAT Server 配置 这里瑞哥提供三个厂商的NAT Server配置：
华为设备配置示例：
 创建NAT地址池：  nat address-group 1 10.0.0.0 255.255.255.0 202.0.0.0 255.255.255.0 创建ACL：  acl number 2001 rule permit tcp source any destination 202.0.0.0 0.0.0.255 创建NAT实例并关联地址池和ACL：  nat instance 1 acl 2001 address-group 1 配置接口并启用NAT Server功能：  interface GigabitEthernet 0/0/1 nat server global 1 应用NAT实例：  interface GigabitEthernet 0/0/1 nat server protocol tcp global 80 inside 10.0.0.10 80 思科设备配置示例：  创建NAT地址池：  ip nat pool NAT_POOL 202.0.0.1 202.0.0.254 netmask 255.255.255.0 创建ACL：  access-list 101 permit tcp any host 202.0.0.10 eq 80 配置NAT实例并关联地址池和ACL：  ip nat inside source list 101 pool NAT_POOL overload 配置接口并启用NAT Server功能：  interface GigabitEthernet0/0 ip nat inside 应用NAT实例：  ip nat inside source static tcp 10.0.0.10 80 202.0.0.10 80 Juniper设备配置示例：  创建NAT地址池：  set security nat pool NAT_POOL address 202.0.0.0/24 创建ACL：  set security nat source rule-set SOURCE_RULE_SET from zone trust set security nat source rule-set SOURCE_RULE_SET to zone untrust set security nat source rule-set SOURCE_RULE_SET rule ALLOW_TCP match source-address any set security nat source rule-set SOURCE_RULE_SET rule ALLOW_TCP match destination-address any set security nat source rule-set SOURCE_RULE_SET rule ALLOW_TCP match application junos-http set security nat source rule-set SOURCE_RULE_SET rule ALLOW_TCP then source-nat pool NAT_POOL 配置接口并启用NAT Server功能：  set security zones security-zone trust interfaces ge-0/0/1 set security zones security-zone untrust interfaces ge-0/0/2 应用NAT实例：  set security nat source rule-set SOURCE_RULE_SET rule ALLOW_TCP then source-nat interface 以上示例仅供参考，实际配置可能因设备型号、固件版本和网络拓扑而有所不同。在进行设备配置时，请根据厂商的官方文档和设备型号，参考相关文档并根据实际情况进行配置。
NAT Server 挑战 NAT Server的使用也存在一些限制和考虑因素。例如，NAT转换表项的数量和管理可能会带来一定的复杂性。此外，如果有大量外部用户同时访问内网服务器，NAT Server可能会面临负载压力和网络拥塞的挑战。因此，在设计和配置NAT Server时，需要综合考虑网络规模、性能需求以及安全性等因素，确保其正常运行和适应实际需求。
总结 综上所述，NAT Server（NAT服务器）是一种用于在内部网络和外部网络之间进行地址转换的设备或服务。它通过建立映射关系，将外部用户的请求转发到内网服务器，并将内网服务器的回应传递回外部用户。以下是关于NAT Server的更详细总结：
  NAT的基本原理：NAT通过将内部网络的私有IP地址转换成公网IP地址，实现了多个内部设备通过有限的公网IP地址与外部网络通信的能力。
  NAT Server的作用：NAT Server充当了内网服务器与外网用户之间的桥梁，允许外部用户访问内网服务器提供的服务。
  地址转换过程：NAT Server的地址转换过程包括配置转换表项和实施转换。
    配置转换表项：在路由器上配置NAT Server的转换表项，记录内网服务器的私网IP地址和端口号与对应的公网IP地址和端口号之间的映射关系。
  外网用户访问内网服务器：外网用户发起访问请求，请求到达路由器，根据目的IP地址和端口号查找转换表项。
  目的地址替换：路由器使用转换表项中的私网IP地址和端口号替换请求报文中的目的IP地址和端口号。
  内网服务器回应：内网服务器生成响应报文，响应报文返回到路由器。
  源地址替换：路由器根据响应报文的源IP地址和端口号查找转换表项，并使用转换表项中的公网IP地址和端口号替换响应报文中的源IP地址和端口号。
  响应传递给外网用户：经过地址转换后的响应报文通过公网IP地址和端口号传递给外网用户。
   增强网络安全性：NAT Server通过隐藏内网服务器的实际IP地址，提高了网络的安全性，阻止外部用户直接访问内网服务器，从而减少了潜在的攻击风险。
  考虑因素：在使用NAT Server时，需要综合考虑网络规模、性能需求和安全性。管理和配置转换表项可能会带来一定的复杂性，同时，大量外部用户访问内网服务器可能导致负载压力和网络拥塞的问题。
  通过使用NAT Server，内网服务器能够提供服务给外部用户，同时保护了内网的隐私和安全性。这为企业和组织提供了一种有效的方式来实现内网与外网之间的双向通信。
]]></content>
  </entry>
  
  <entry>
    <title>C语言的编译过程</title>
    <url>/post/programming/the-compile-process-of-c-languageg.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Compile</tag>
    </tags>
    <content type="html"><![CDATA[C语言的编译链接过程要把我们编写的一个C程序源代码，转换成可以在硬件上运行的程序（可执行代码），需要进行编译和链接。过程图解如下：
本文讲解C语言编译过程中所做的工作，对我们理解头文件、库等的工作过程是有帮助的。而且清楚的了解编译链接过程还对我们在编程时定位错误，以及编程时尽量调动编译器的检测错误会有很大的帮助的。
编译 编译是读取源程序（字符流），对之进行词法和语法的分析，将高级语言指令转换为功能等效的汇编代码，源文件的编译过程包含预处理与编译优化两个主要阶段。
预处理 第一个阶段是预处理阶段，在正式的编译阶段之前进行。预处理阶段将根据已放置在文件中的预处理指令来修改源文件的内容。如#include指令就是一个预处理指令，它把头文件的内容添加到.cpp文件中。这个在编译之前修改源文件的方式提供了很大的灵活性，以适应不同的计算机和操作系统环境的限制。一个环境需要的代码跟另一个环境所需的代码可能有所不同，因为可用的硬件或操作系统是不同的。在许多情况下，可以把用于不同环境的代码放在同一个文件中，再在预处理阶段修改代码，使之适应当前的环境。
主要是以下几方面的处理：
 宏定义指令，如 #define a b  对于这种伪指令，预编译所要做的是将程序中的所有a用b替换，但作为字符串常量的 a则不被替换。还有 #undef，则将取消对某个宏的定义，使以后该串的出现不再被替换。
 条件编译指令，如#ifdef，#ifndef，#else，#elif，#endif等。  这些伪指令的引入使得程序员可以通过定义不同的宏来决定编译程序对哪些代码进行处理。预编译程序将根据有关的文件，将那些不必要的代码过滤掉。
 头文件包含指令，如#include &ldquo;FileName&quot;或者#include 等。  在头文件中一般用伪指令#define定义了大量的宏（最常见的是字符常量），同时包含有各种外部符号的声明。采用头文件的目的主要是为了使某些定义可以供多个不同的C源程序使用。因为在需要用到这些定义的C源程序中，只需加上一条#include语句即可，而不必再在此文件中将这些定义重复一遍。预编译程序将把头文件中的定义统统都加入到它所产生的输出文件中，以供编译程序对之进行处理。包含到c源程序中的头文件可以是系统提供的，这些头文件一般被放在 /usr/include目录下。在程序中#include它们要使用尖括号（&lt; &gt;）。另外开发人员也可以定义自己的头文件，这些文件一般与c源程序放在同一目录下，此时在#include中要用双引号（&quot;&quot;）。
 特殊符号，预编译程序可以识别一些特殊的符号。  例如在源程序中出现的LINE标识将被解释为当前行号（十进制数），FILE则被解释为当前被编译的C源程序的名称。预编译程序对于在源程序中出现的这些串将用合适的值进行替换。
预编译程序所完成的基本上是对源程序的“替代”工作。经过此种替代，生成一个没有宏定义、没有条件编译指令、没有特殊符号的输出文件。这个文件的含义同没有经过预处理的源文件是相同的，但内容有所不同。下一步，此输出文件将作为编译程序的输出而被翻译成为机器指令。
编译、优化 第二个阶段编译、优化阶段，经过预编译得到的输出文件中，只有常量；如数字、字符串、变量的定义，以及c语言的关键字，如main,if,else,for,while,{,}, +,-,*,\等等。
编译程序所要做的工作就是通过词法分析和语法分析，在确认所有的指令都符合语法规则之后，将其翻译成等价的中间代码表示或汇编代码。
优化处理是编译系统中一项比较艰深的技术。它涉及到的问题不仅同编译技术本身有关，而且同机器的硬件环境也有很大的关系。优化一部分是对中间代码的优化。这种优化不依赖于具体的计算机。另一种优化则主要针对目标代码的生成而进行的。
对于前一种优化，主要的工作是删除公共表达式、循环优化（代码外提、强度削弱、变换循环控制条件、已知量的合并等）、复写传播，以及无用赋值的删除，等等。
后一种类型的优化同机器的硬件结构密切相关，最主要的是考虑是如何充分利用机器的各个硬件寄存器存放的有关变量的值，以减少对于内存的访问次数。另外，如何根据机器硬件执行指令的特点（如流水线、RISC、CISC、VLIW等）而对指令进行一些调整使目标代码比较短，执行的效率比较高，也是一个重要的研究课题。
汇编 汇编实际上指把汇编语言代码翻译成目标机器指令的过程。对于被翻译系统处理的每一个C语言源程序，都将最终经过这一处理而得到相应的目标文件。目标文件中所存放的也就是与源程序等效的目标的机器语言代码。目标文件由段组成。通常一个目标文件中至少有两个段：
代码段：该段中所包含的主要是程序的指令。
该段一般是可读和可执行的，但一般却不可写。
数据段：主要存放程序中要用到的各种全局变量或静态的数据。一般数据段都是可读，可写，可执行的。
UNIX环境下主要有三种类型的目标文件：
 可重定位文件  其中包含有适合于其它目标文件链接来创建一个可执行的或者共享的目标文件的代码和数据。
  共享的目标文件 这种文件存放了适合于在两种上下文里链接的代码和数据。第一种是链接程序可把它与其它可重定位文件及共享的目标文件一起处理来创建另一个 目标文件；第二种是动态链接程序将它与另一个可执行文件及其它的共享目标文件结合到一起，创建一个进程映象。
  可执行文件
  它包含了一个可以被操作系统创建一个进程来执行之的文件。汇编程序生成的实际上是第一种类型的目标文件。对于后两种还需要其他的一些处理方能得到，这个就是链接程序的工作了。
链接过程 由汇编程序生成的目标文件并不能立即就被执行，其中可能还有许多没有解决的问题。
例如，某个源文件中的函数可能引用了另一个源文件中定义的某个符号（如变量或者函数调用等）；在程序中可能调用了某个库文件中的函数，等等。所有的这些问题，都需要经链接程序的处理方能得以解决。
链接程序的主要工作就是将有关的目标文件彼此相连接，也即将在一个文件中引用的符号同该符号在另外一个文件中的定义连接起来，使得所有的这些目标文件成为一个能够诶操作系统装入执行的统一整体。
根据开发人员指定的同库函数的链接方式的不同，链接处理可分为两种：
 静态链接  在这种链接方式下，函数的代码将从其所在的静态链接库中被拷贝到最终的可执行程序中。这样该程序在被执行时这些代码将被装入到该进程的虚拟地址空间中。静态链接库实际上是一个目标文件的集合，其中的每个文件含有库中的一个或者一组相关函数的代码。
 动态链接  在此种方式下，函数的代码被放到称作是动态链接库或共享对象的某个目标文件中。链接程序此时所做的，只是在最终的可执行程序中记录下共享对象的名字以及其它少量的登记信息。在此可执行文件被执行时，动态链接库的全部内容将被映射到运行时相应进程的虚地址空间。动态链接程序将根据可执行程序中记录的信息找到相应的函数代码。
对于可执行文件中的函数调用，可分别采用动态链接或静态链接的方法。使用动态链接能够使最终的可执行文件比较短小，并且当共享对象被多个进程使用时能节约一些内存，因为在内存中只需要保存一份此共享对象的代码。但并不是使用动态链接就一定比使用静态链接要优越。在某些情况下动态链接可能带来一些性能上损害。
]]></content>
  </entry>
  
  <entry>
    <title>STM32单片机开发中的RTOS</title>
    <url>/post/mcu/the-rtos-for-STM32-development.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>STM32</tag>
      <tag>RTSO</tag>
    </tags>
    <content type="html"><![CDATA[很多STM32单片机初学者都是从裸机开始的，裸机确实也能开发出好的产品。但是，作为一个嵌入式软件工程师，况且用的并不是51那种低端单片机，如果只会用裸机开发产品，那肯定是不够的。
要从裸机的思维转变到RTOS（Real Time Operating System）的思维，其实需要一个过程，而且开始的一段时间会很痛苦。但过一段时间理解了一些内容，能写一些Demo之后，你会发现其实RTOS也不难。
现在FreeRTOS在CubeMX工具中可以直接配置并使用，相当方便。
为什么需要RTOS 为什么我们需要RTOS？就像最开始学C编程时，老师告诉我们，指针很重要，那时你肯定有一个大的疑问，指针到底有什么好？
心里一直犯嘀咕着：不用指针不一样把程序编出来了？ 现在想想看C语言没了指针，是不是“寸步难行”呢。
回到正题，我们到底为什么需要RTOS？
一般的简单的嵌入式设备的编程思路是下面这样的：
main { {处理事物1}; {处理事物2}; {处理事物3}; ...... ...... {处理事物N}; } isr_server { {处理中断}; } 这是最常见的一种思路，对于简单的系统当然是够用了，但这样的系统实时性很差。
比如“事务1”如果是一个用户输入的检测，当用户输入时，如果程序正在处理事务1下面的那些事务，那么这次用户输入将失效，用户的体验是“这个按键不灵敏，这个机器很慢”，而我们如果把事务放到中断里去处理，虽然改善了实时性但会导致另外一个问题，有可能会引发中断丢失，这个后果有时候比“慢一点”更加严重和恶劣！
又比如事务2是一个只需要1s钟处理一次的任务，那么显然事务2会白白浪费CPU的时间。
改进思路 看到上面裸机开发的局限了吗？
这时，我们可能需要改进我们的编程思路，一般我们会尝试采用“时间片”的方式。这时候编程会变成下面的方式：
main { {事务1的时间片到了则处理事务1}; {事务2的时间片到了则处理事务2}; ...... ...... {事务N的时间片到了则处理事务N}; } time_isr_server { {判断每个事务的时间片是否到来，并进行标记}; } isr_server { {处理中断}; } 可以看到，这种改进后的思路，使得事务的执行时间得到控制，事务只在自己的时间片到来后，才会去执行。但这种方式仍然不能彻底解决“实时性”的问题，因为某个事务的时间片到来后，也不能立即就执行，必须等到当前事务的时间片用完，并且后面的事务时间片没到来，才有机会获得“执行时间”。
这时候我们需要继续改进思路,为了使得某个事务的时间片到来后能立即执行，我们需要在时钟中断里判断完时间片后，改变程序的返回位置，让程序不返回到刚刚被打断的位置，而从最新获得了时间片的事务处开始执行，这样就彻底解决了事务的实时问题。
我们在这个思路上，进行改进，我们需要在每次进入时钟中断前，保存CPU的当前状态和当前事务用到的一些数据，然后我们进入时钟中断进行时间片处理，若发现有新的更紧急的事务的时间片到来了，则我们改变中断的返回的地址，并在CPU中恢复这个更紧急的事务的现场，然后返回中断开始执行这个更紧急的事务。
使用RTOS的好处 上面那段话，对于初学者来说，可能有些不好理解。
事实上，这是因为要实现这个过程是有些复杂和麻烦的，这时候我们就需要找一个操作系统(OS)帮我们做这些事了，如果你能自己用代码实现这个过程，事实上你就在自己写操作系统了。
其实从这里也可也看出，操作系统的原理其实并不那么神秘，只是一些细节你很难做好。我们常见的RTOS基本都是这样的一个操作系统，它能帮你完成这些事情，而且是很优雅的帮你完成！
事实上，RTOS的用处远不止帮你完成这个“事务时间片的处理”，它还能帮你处理各种超时，进行内存管理，完成任务间的通信等。
有了RTOS，程序的层次也更加清晰，给系统添加功能也更方便，这一切在大型项目中越发的明显！
]]></content>
  </entry>
  
  <entry>
    <title>盘点优秀PCB工程师的好习惯</title>
    <url>/post/hardware/the-good-habits-of-excellent-PCB-engineers.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>PCB</tag>
    </tags>
    <content type="html"><![CDATA[在有些人看来，PCB layout工程师的工作会有些枯燥无聊，每天对着板子成千上万条走线，各种各样的封装，重复着拉线的工作&hellip;
事实上，并没有看上去的那么简单！
设计人员需要在各种设计规则之间做出取舍，兼顾性能、工艺、成本等各方面，同时还要注意板子布局的合理整齐。
作为一名优秀的PCB layout工程师，好的工作习惯会使你的设计更合理、性能更好、生产更容易。
下面罗列了PCB layout工程师的7个好习惯，来看看你都占了几个吧！
学会会设计规则 其实现在不光高级的PCB设计软件需要设置布线规则，一些简单易用的PCB工具同样可以进行规则设置。
人脑毕竟不是机器，那就难免会有疏忽有失误。
所以把一些容易忽略的问题设置到规则里面，让电脑帮助我们检查，尽量避免犯一些低级错误。
另外，完善的规则设置能更好的规范后面的工作，所谓磨刀不误砍柴工，板子的规模越复杂规则设置的重要性越突出。
尽可能地执行DRC 尽管在PCB软件上运行DRC功能只需花费很短时间，但在更复杂的设计环境中，只要你在设计过程中始终执行检查便可节省大量时间，这是一个值得保持的好习惯。
每个布线决定都很关键，通过执行DRC可随时提示你那些最重要的布线。
画好原理图 很多工程师都觉得layout工作更重要一些，原理图就是为了生成网表方便PCB做检查用的。
其实，在后续电路调试过程中原理图的作用会更大一些，无论是查找问题还是和同事交流，还是原理图更直观更方便。
另外养成在原理图中做标注的习惯，把各部分电路在layout的时候要注意到的问题标注在原理图上，对自己或者对别人都是一个很好的提醒。
层次化原理图，把不同功能不同模块的电路分成不同的页，这样无论是读图还是以后重复使用都能明显的减少工作量。
优化PCB布局 心急的工程师画完原理图，把网表导入PCB后就迫不及待的把器件放好，开始拉线。
其实一个好的PCB布局能让你后面的拉线工作变得简单，让你的PCB工作的更好。
每一块板子都会有一个信号路径，PCB布局也应该尽量遵循这个信号路径，让信号在板子上可以顺畅的传输，人们都不喜欢走迷宫，信号也一样。
如果原理图是按照模块设计的，PCB也一样可以，按照不同的功能模块可以把板子划分为若干区域。
模拟数字分开，电源信号分开，发热器件和易感器件分开，体积较大的器件不要太靠近板边，注意射频信号的屏蔽等等……
多花一分的时间去优化PCB的布局，就能在拉线的时候节省更多的时间。
多为别人考虑 在进行PCB设计的时候，尽量多考虑一些最终使用者的需求。
比如，如果设计的是一块开发板，那么在进行PCB设计的时候就要考虑放置更多的丝印信息，这样在使用的时候会更方便，不用来回的查找原理图或者找设计人员支持了。
如果设计的是一个量产的产品，那么就要更多的考虑到生产线上会遇到的问题，同类型的器件尽量方向一致，器件间距是否合适，板子的工艺边宽度等等。
这些问题考虑的越早，越不会影响后面的设计，也可以减少后面支持的工作量和改板的次数。
看上去开始设计上用的时间增加了，实际上是减少了自己后续的工作量。
在板子空间允许的情况下，尽量放置更多的测试点，提高板子的可测性，这样在后续调试阶段同样能节省更多的时间，给发现问题提供更多的思路。
反复和客户沟通确认 作为一名优秀的PCB layout工程师，要学会和客户有效沟通。
Layout中一些重要的问题最好和客户反复沟通确认，比如封装的确认。
特别是含有正负极的，三极管，结构连接器的位置，这些将直接影响到后期板卡的安装定位。
细节决定成败 PCB设计是一个细致的工作，需要的就是细心和耐心。刚开始做设计的新手经常犯的错误就是一些细节错误。
器件管脚弄错了，器件封装用错了，管脚顺序画反了等等，有些可以通过飞线来解决，有些可能就让一块板子直接变成了废品。
画封装的时候多检查一遍，投板之前把封装打印出来和实际器件比一下，多看一眼，多检查一遍不是强迫症，只是让这些容易犯的低级错误尽量避免。
]]></content>
  </entry>
  
  <entry>
    <title>用协议分析仪直观理解USB传输的核心概念</title>
    <url>/post/hardware/understand-usb-transition-core-concept-by-using-protocol-analyze.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>USB</tag>
      <tag>Analyzer</tag>
    </tags>
    <content type="html"><![CDATA[本文内容是基于 USB 2.0  。在讲述USB传输前，有必要先了解下USB的几个基本概念。
几个基本概念 本文内容是基于USB 2.0。在讲述USB传输前，有必要先了解下USB的几个基本概念。
USB主机（Host） 每一次传输都是主机发起的，不管是发送数据还是接收数据。
USB设备（Device） 设备会响应主机的请求，每个设备的内部固件中都会存有设备描述符来表明设备的基本信息，比如厂家ID、产品ID、配置数目、接口和端点信息等。
USB枚举 主机识别到有设备接入后，会发起枚举，读取设备的描述符信息后配置设备。
USB配置（Configuration） 一个设备有一个或者多个配置，主机可以通知设备选用哪个配置，但一个设备当前只能有一种生效的配置。
USB接口（Interface） 简单地说，一个接口表示一种功能，比如说这个设备既有虚拟串口功能，也有虚拟网口功能，可能还有大容量存储（U盘）功能。当然一个功能并不都是严格对应一个接口，有些功能可能需要两个以上的接口，这里为了简化描述，暂不深究。
USB端点（Endpoint） 端点简称EP，一个接口配置有一个或者多个端点。端点是主机和设备之间通信的部件，数据是从某个端点发送出去或者接收进来的。端点是有方向的，方向是基于主机侧来定义的，OUT方向是指从主机传出，IN是指传入主机。
USB传输、USB事务与USB包 USB传输由主机发起，任何时刻整个USB体系内仅允许一个数据包在传输。
USB传输有4种类型，控制传输、中断传输、批量传输和同步传输，每种传输有不同的适用场景。
传输由事务构成，事务类型有SETUP事务、DATA IN事务、DATA OUT事务，SETUP事务主要往设备发送控制命令，DATA IN事务主要从设备读取数据，DATA OUT事务主要往设备发送数据。每个事务采用“令牌包”-“数据包”-“握手包”的三段式传输机制（同步传输没有握手包）。
包是USB总线上数据传输的最小单位，其中的PID字段指明了包的类型。令牌包有IN/OUT/SETUP/SOF四种。前三种“令牌包”都含有指定数据包去向或者来源的设备地址和端点，从而保证了只有一个设备对总线上的数据包/令牌包作出响应。“握手包”表示了传输的成功与否。“数据包”承载实际数据。
USB传输、事务、包是从不同层次上去说明一次数据交互的三个概念。一次传输包含多个事务，一个事务包含多个包。直接看一下USB协议分析仪的抓包示例，可能更清楚一些：
控制传输 控制传输是一种可靠的传输，所有USB设备都必须支持的一种传输方式，主机在枚举设备的过程中就是通过端点0进行控制传输。一次控制传输可分为三个阶段：
第一阶段为建立阶段，通过SETUP事务指定了此次控制传输的请求类型；
第二阶段为数据阶段，也有些请求没有数据阶段；
第三阶段为状态阶段，通过一次IN/OUT事务表明请求是否成功完成。
下图是通过USB协议分析仪抓取U盘的某次控制传输，对应的是枚举阶段获取设备描述符：
Control SETUP事务展开图：
Control IN事务展开图：
Control OUT事务展开图：
中断传输 中断传输是一种可靠的传输，主机通过固定的间隔对中断端点进行查询，如果设备有数据则往主机回送数据，否则回送NAK。同样的，如果主机要发送数据，设备没有准备好接收，也会回送NAK。
下图是通过USB协议分析仪抓取的USB camera的某次中断传输（control数据，非图像数据）：
Interrupt IN事务展开图：
批量传输 批量传输是一种可靠的传输，但延迟没有保证，它尽量利用可以利用的带宽来完成传输，适合数据量比较大的传输。高速批量端点的最大包长度为 512。
对于批量输出，如果设备收到的数据包正确，并有足够的空间保存数据，那么设备会返回ACK握手包或NYET握手包（只有高速模式才有NYET握手包，它表示本次数据接收成功，但是没有能力接收下一次传输）。如果设备收到的数据包正确，但是没有足够的空间保存数据：设备返回NAK握手包。主机收到NAK，延时一段时间后，再重新进行批量输出。
对于批量输入，如果设备没有准备好数据，则回送NAK，否则回送数据包。
批量传输由一个或者多个IN / OUT事务组成，下图是抓取的U盘某次批量传输：
Bulk OUT事务展开图：
同步传输 同步传输是一种实时的、不可靠的传输，不支持错误重发机制。高速同步端点的最大包长度为1024。
常规情况下，一个微帧内仅允许一次同步事务传输；但是，高速高带宽端点最多可以在一个微帧内进行三次同步事务传输，传输高达3072字节的数据，这个特性对数据量较大的设备比如USB camera的性能表现有很重要的影响。
下图是抓取的USB Camera的某次同步传输：
Isoch IN事务展开图：
USB包 USB包由SOP（包起始域）、SYNC（同步域）、Packet Content（包内容）、EOP（包结束域）四部分组成，其中SOP、SYNC、EOP为所有包共有的域，Packet Content由PID、地址、帧号、数据、CRC组成，注意这只是一个通用构成，不同类型的包，Packet Content的构成会有一些区别。
USB包按大类分为令牌包、数据包、握手包和帧首包，每个大类里面还有具体类型，比如令牌类有OUT/IN/SETUP等，数据类有DATA0/DATA1等，包的类型由Packet Content中的PID指定。这里不罗列所有类型的包，只抓取几个有代表性的包来看看。
下图是抓取的某个SETUP包的Packet Content：
下图是抓取的某个SOF包的Packet Content：
下图是抓取的某个DATA1包的Packet Content：
USB帧与微帧 USB帧与微帧属于USB传输中时间基准的概念。低速和全速下每个帧时长为1ms，高速下每个帧又分为8个微帧，每个微帧时长为125us。USB 2.0 规范上有详细描述，如下图所示。
在每一个帧（微帧）的起始点，会发送一个SOF包（帧起始包），帧起始包之后可以是输出（OUT）、输入（IN）、建立（SETUP）等令牌包，或者没有包。数据的传输在每个帧（微帧）内进行，如果没有数据要传输，则SOF包发送完毕之后，总线进入空闲状态。
]]></content>
  </entry>
  
  <entry>
    <title>efuse在soc中的重要作用</title>
    <url>/post/soc/the-important-role-of-efuse-in-soc.html</url>
    <categories><category>SOC</category>
    </categories>
    <tags>
      <tag>SOC</tag>
      <tag>Efuse</tag>
    </tags>
    <content type="html"><![CDATA[在现代 SoC 设计中，efuse 是一种非常重要的技术，可以用于保护 SoC 中的敏感信息，防止黑客攻击和未经授权的访问。本文将介绍什么是 efuse，它在 SoC 设计中的应用以及它的优缺点。
什么是 efuse? efuse 是一种可编程的存储器，用于存储 SoC 中的敏感信息，例如密钥、证书、序列号等。与传统的存储器不同，efuse 的编程是一次性的，一旦编程就无法更改。这种特性使得 efuse 非常适合用于存储需要保护的信息，因为它可以防止黑客通过修改存储器中的数据来破解 SoC 的安全性。
efuse 的工作原理是什么？ efuse 通常由两部分组成：编程器和熔丝。编程器用于将数据编程到熔丝中，而熔丝则用于存储数据。当编程器将数据编程到熔丝中时，它会改变熔丝中的物理结构，从而使其不可更改。一旦熔丝被编程，它将永久保存数据，即使 SoC 失去电源，熔丝中的数据也不会丢失。
在 SoC 设计中，efuse 通常被用于以下方面：
  存储加密密钥：在许多安全应用中，加密密钥是必须保护的信息。使用 efuse 可以确保密钥不会被黑客访问或修改。
  存储序列号：每个 SoC 都有一个唯一的序列号，用于标识 SoC。使用 efuse 可以确保序列号不会被修改或伪造。
  存储证书：在安全应用中，证书用于验证 SoC 的身份。使用 efuse 可以确保证书不会被黑客攻击或修改。
  存储配置信息：efuse 还可以用于存储 SoC 的配置信息，例如 CPU 频率、内存大小等。这些信息可以在 SoC 启动时被读取，并根据需要进行更改。
  尽管 efuse 在 SoC 设计中非常有用，但它也有一些缺点：
  一次性编程：由于 efuse 是一次性编程的，因此如果在编程过程中出现错误，则必须丢弃整个 SoC。
  成本：efuse 通常比传统的存储器更昂贵，因此可能会增加 SoC 的成本。
  安全性：尽管 efuse 可以保护 SoC 中的敏感信息，但它本身也可能受到攻击。例如，黑客可以使用高功率的激光器来擦除 efuse 中的数据，或者使用特殊的攻击技术来破解 efuse 的安全性。
  在现代 SoC 设计中，efuse 是一种非常重要的技术，可以保护 SoC 中的敏感信息，防止黑客攻击和未经授权的访问。尽管它有一些缺点，但它仍然是一个非常有用的工具，可以用于保护 SoC 的安全性。
]]></content>
  </entry>
  
  <entry>
    <title>认识电感器的重要作用与特性</title>
    <url>/post/hardware/understand-the-importance-and-feature-of-inductors.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>Inductor</tag>
    </tags>
    <content type="html"><![CDATA[电感器俗称电感，本质上是一个线圈，有空心线圈也有实心线圈，实心线圈有铁芯或者其它材料制成的芯，电感的单位是“H”，简称“亨”。此外，更小的单位是mH，uH，换算方式为1H=1000mH=1000000uH。
电感的常见作用 阻交通直 对于直流电，电感是相当于短路的；而对于交流电，电感是对其有阻碍作用的，交流电的频率越高，电感对它的阻碍作用越大。
变压器 对我们来说最熟悉的电感应用莫过于变压器了，如下图所示为变压器的电路符号。假如左侧线圈匝数为100，右侧匝数为50，如果左侧接220V交流电，那么右侧感应出来的电压为110V，即“匝数比=电压比”而电流却会截然相反；如果左侧流进1A电流，那么右侧会流出2A的电流，即“匝数比=电流的反比”，因为电感只会对电压、电流进行变化，而不能对功率进行变化，如果电压和电流都为正比显然是不合情理的。
RL低通滤波器 所谓低通滤波器是：低频信号可以通过，而高频信号不能通过，电路原理图如下图。输入信号如果是直流电，那么电感相当于一根导线；现在是短路，信号会经过电感，直接输出，而不经过电阻。如果我们逐渐升高电流的频率，由于电感对交流电有阻碍作用，通过电感的信号会慢慢变小，直到达到某一个频率，当高于这个频率之后的电流再也无法通过，这时候就形成了低通滤波器，这个频率就叫做截止频率，公式为 f=R/(2πL)。
RL高通滤波器 高通滤波器的道理和低通的类似，只不过电阻和电感的位置变了，如下图。如果是直流电，会经过电感流回去，这时候如果改变频率，当频率逐渐升高，由于电感对交流电的阻碍作用，当频率达到截止频率时，高频信号不经过电感，而直接把我们需要的高频信号输出。截止频率的计算也是 f=R/(2πL)。
以上列举了一些常用的电感应用，当然电感的作用远远不止这些，以上讲的都是基础，应用的时候考虑的远比以上所说的要多。
十种电感的特性 工字型电感 它的前身是挠线式贴片电感，工字型电感是它们的改良，挡板有效加强储能能力，改变EMI方向和大小，亦可降低RDC。它可以说是讯号通讯电感跟POWER电感的一种妥协。
贴片式的工字型电感主要用于几百kHz至一两MHz的较小型电源切换，如数字相机的LED升压、ADSL等较低频部份的讯号处理或POWER用途。它的Q值有20、30，做为讯号处理颇为适合。RDC比挠线式贴片电感低，作为POWER也是十分好用。当然，很大颗的工字型电感，那肯定是POWER用途了。
工字型电感最大的缺点仍是开磁路，有EMI的问题；另外，噪音的问题比挠线式贴片电感大。
色环电感 色环电感是最简单的棒形电感的加工，主要是用作讯号处理。本身跟棒形电感的特性没有很大的差别，只是多了一些固定物，和加上一些颜色方便分辨感值。因单价算是十分便宜，现时比较不注重体积，以及仍可用插件的电子产品，使用色环电感仍多。
空芯电感 空心电感主要是讯号处理用途，用作共振、接收、发射等。空气可应用在甚高频的产品，故此很多变异要求不太高的产品仍在使用。因为空气不是固定线圈的最佳材料，故此在要求越来越严格的产品趋势上，发展有限。
环形线圈电感 环形线圈电感，是电感理论中很理想的形状。闭磁路，很少EMI的问题，充分利用磁路，容易计算，几乎理论上的好处，全归环形线圈电感。可是，有一个最大的缺点，就是不好挠线，制程多用人工处理。
环形线圈电感最大量的，是用铁粉芯作材料跟树脂等混在一起，使得Air gap均匀分布在铁粉芯内部。
铁粉芯环形线圈电感的优点是环形，但缺点亦是环形。我前面曾说，使用者最喜欢的形状是方形，故此在妥协下环形线圈电感并不是最具优势。
贴片迭层高频电感 贴片迭层高频电感，其实就是空心电感。特性完全相同，不过因为容易固定，可以小型化。
贴片迭层高频电感跟空心电感比较，因为空气不是好的固定物，但空气的相对导磁率是一，在高频很好用，因此找一些相对导磁率是一，又是很好的固定物，那不是很好。
贴片迭层高频电感跟贴片挠线式高频电感的比较，贴片迭层高频电感的Q值不够高是最大的缺点,。
磁棒电感 磁棒电感是空心电感的加强，电感值跟导磁率成正比，塞磁性材料进空心线圈，电感值、Q值等都会大为增加。好处，就自己想象了。如果想不通，或者不想思考，要早点改行喔。磁棒电感是最简单、最基本的电感；30年到100年前，电感有什么应用，它就有什么应用，特性亦是如此。
SMD贴片功率电感 SMD贴片功率电感最主要是强调储能能力，以及LOSS要少。
穿心磁珠 穿心磁珠，就是阻抗器啦，电感是低通组件，可让低频通过，阻挡高频。
贴片磁珠 贴片磁珠就是穿心磁珠的下一代。
贴片高频变压器、插件高频变压器 高频变压器嘛，一般用于开关电源。
原文地址: 认识电感器的重要作用与特性  
]]></content>
  </entry>
  
  <entry>
    <title>常见总线：IIC、IIS、SPI、UART、JTAG、CAN、SDIO、GPIO</title>
    <url>/post/hardware/usual-bus-protocol-introduction.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>IIC</tag>
      <tag>IIS</tag>
      <tag>SPI</tag>
      <tag>UART</tag>
    </tags>
    <content type="html"><![CDATA[本文介绍了常见的总线：IIC、IIS、SPI、UART、JTAG、CAN、SDIO、GPIO。
IIC IIC(Inter－Integrated Circuit)总线是一种由PHILIPS公司开发的两线式串行总线，用于连接微控制器及其外围设备。I2C总线用两条线(SDA和SCL)在总线和装置之间传递信息，在微控制器和外部设备之间进行串行通讯或在主设备和从设备之间的双向数据传送。I2C是OD输出的，大部分I2C都是2线的（时钟和数据），一般用来传输控制信号。
IIS I2S（Inter-IC Sound Bus）是飞利浦公司为数字音频设备之间的音频数据传输而制定的一种总线标准。I2S有3个主要信号：1.串行时钟SCLK，也叫位时钟，即对应数字音频的每一位数据，SCLK有1个脉冲。2.帧时钟LRCK，用于切换左右声道的数据。LRCK为“1”表示正在传输的是左声道的数据，为“0”则表示正在传输的是右声道的数据。3.串行数据SDATA，就是用二进制补码表示的音频数据。有时为了使系统间能够更好地同步，还需要另外传输一个信号MCLK，称为主时钟，也叫系统时钟（Sys Clock）。
SPI SPI(Serial Peripheral Interface：串行外设接口);SPI是Motorola首先在其MC68HCXX系列处理器上定义的。SPI接口主要应用在EEPROM,FLASH,实时时钟,AD转换器,还有数字信号处理器和数字信号解码器之间。SPI接口是以主从方式工作的,这种模式通常有一个主器件和一个或多个从器件,其接口包括以下四种信号：（1）MOSI – 主器件数据输出,从器件数据输入 （2）MISO – 主器件数据输入,从器件数据输出 （3）SCLK – 时钟信号,由主器件产生（4）/SS – 从器件使能信号,由主器件控制。
UART UART(Universal Asynchronous Receiver Transmitter：通用异步收发器)。将由计算机内部传送过来的并行数据转换为输出的串行数据流。将计算机外部来的串行数据转换为字节，供计算机内部使用并行数据的器件使用。在输出的串行数据流中加入奇偶校验位，并对从外部接收的数据流进行奇偶校验。在输出数据流中加入启停标记，并从接收数据流中删除启停标记。处理由键盘或鼠标发出的中断信号（键盘和鼠标也是串行设备）。可以处理计算机与外部串行设备的同步管理问题。有一些比较高档的UART还提供输入输出数据的缓冲区。常用TXD，RXD，/RTS，/CTS。
JTAG JTAG (Joint Test Action Group 联合测试行动小组)是一种国际标准测试协议（IEEE1149.1兼容），主要用于芯片内部测试。标准的JTAG接口是4线：TMS、TCK、TDI、TDO，分别为模式选择、时钟、数据输入和数据输出线。测试复位信号(TRST,一般以低电平有效)一般作为可选的第五个端口信号。一个含有JTAGDebug接口模块的CPU，只要时钟正常，就可以通过JTAG接口访问CPU的内部寄存器和挂在CPU总线上的设备，如FLASH，RAM，内置模块的寄存器，象UART，Timers，GPIO等等的寄存器。
CAN CAN全称为“Controller Area Network”，即控制器局域网，是国际上应用最广泛的现场总线之一。最初，CAN被设计作为汽车环境中的微控制器通讯，在车载各电子控制装置ECU之 间交换信息，形成汽车电子控制网络。比如：发动机管理系统、变速箱控制器、仪表装备、电子主干系统中，均嵌入CAN控制装置。一个由CAN总线构成的单一网络中，理论上可以挂接无数个节点。实际应用中，节点数目受网络硬件的电气特性所限制。例如，当使用Philips P82C250作为CAN收发器时，同一网络中允许挂接110个节点。CAN 可提供高达1Mbit/s的数据传输速率，这使实时控制变得非常容易。另外，硬件的错误检定特性也增强了CAN的抗电磁干扰能力。
SDIO SDIO是SD型的扩展接口，除了可以接SD卡外，还可以接支持SDIO接口的设备，插口的用途不止是插存储卡。支持 SDIO接口的PDA，笔记本电脑等都可以连接象GPS接收器，Wi-Fi或蓝牙适配器，调制解调器，局域网适配器，条型码读取器，FM无线电，电视接收 器，射频身份认证读取器，或者数码相机等等采用SD标准接口的设备。
GPIO GPIO (General Purpose Input Output 通用输入/输出)或总线扩展器利用工业标准I²C、SMBus™或SPI™接口简化了I/O口的扩展。当微控制器或芯片组没有足够的I/O端口，或当系统 需要采用远端串行通信或控制时，GPIO产品能够提供额外的控制和监视功能。
每个GPIO端口可通过软件分别配置成输入或输出。
]]></content>
  </entry>
  
  <entry>
    <title>十年经验的大神谈如何学STM32嵌入式开发</title>
    <url>/post/mcu/how-to-learn-stm32-embedded-development.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>STM32</tag>
      <tag>MCU</tag>
    </tags>
    <content type="html"><![CDATA[本文描述了十年经验的大神谈如何学STM32嵌入式开发
理解嵌入式 从硬件上说 “嵌入”将基于CPU的处围器件，整合到CPU芯片内部，比如早期基于X86体系结构下的计算机，CPU只是有运算器和累加器的功能，一切芯片要造外部桥路来扩展实现，象串口之类的都是靠外部的16C550/2的串口控制器芯片实现，而目前的这种串口控制器芯片早已集成到CPU内部，还有PC机有显卡，而多数嵌入式处理器都带有LCD控制器，但其种意义上就相当于显卡。比较高端的ARM类Intel Xscale架构下的IXP网络处理器CPU内部集成PCI控制器，可配成支持4个PCI从设备或配成自身为CPI从设备;还集成3个NPE网络处理器引擎，其中两个对应于两个MAC地址， 可用于网关交换用，而另外一个NPE网络处理器引擎支持DSL，只要外面再加个PHY芯片即可以实现DSL上网功能。IXP系列最高主频可以达到 1.8G，支持2G内存，1G×10或10G×1的以太网口或Febre channel的光通道。IXP系列应该是目标基于ARM体系统结构下由intel进行整合后成Xscale内核的最高的处理器了。
从软件上说 嵌入就是在定制操作系统内核里将应用一并选入，编译后将内核下载到ROM中。而在定制操作系统内核时所选择的应用程序组 件就是完成了软件的“嵌入”，比如Win在内核定制时，会有相应选择，其中就是wordpad,PDF,MediaPlay等等选择，如果我们选择 了，在CE启动后，就可以在界面中找到这些东西，如果是以前PC上将的windows操作系统，多半的东西都需要我们得新再装。
把软件内核或应用文件系统等东西烧到嵌入式系统硬件平台中的ROM中就实现了一个真正的“嵌入”。
以上的定义是我在6、7年前给嵌入式系统下自话侧重于理解型的定义，书上的定义也有很多，但在“嵌入式”这个领域范围内，谁都不敢说自己的定义是十分确切的，包括那些专家学者们，历为毕竟嵌入式系统是计算机范畴下的一门综合性学科。
嵌入式系统的分层 嵌入式系统分为4层，硬件层、驱动层、操作系统层和应用层。
硬件层 硬件层是整个嵌入式系统的根本，如果现在单片机及接口这块很熟悉，并且能用C和汇编语言来编程的话，从嵌入式系统的硬件层走起来相对容易，硬件层也是驱动层的基础，一个优秀的驱动工程师是要能够看懂硬件的电路图和自行完成CPLD的逻辑设计的，同时还要对操作系统内核及其调度性相当的熟悉的。但硬件平台是基础，增值还要靠软件。
硬件层比较适合于，电子、通信、自动化、机电一体、信息工程类专业的人来搞，需要掌握的专业基础知识有，单片机原理及接口_技术、微机原理及接口_技术、C语言。
驱动层 驱动层这部分比较难，驱动工程师不仅要能看懂电路图还要能对操作系统内核十分的精通，以便其所写的驱动程序在系统调用时，不会独占操作系统时间片，而导致其它任务不能动行，不懂操作系统内核架构和实时调度性，没有良好的驱动编写风格，按大多数书上所说添加的驱动的方式，很多人都能做到，但可能连个初级的 驱动工程师的水平都达不到，这样所写的驱动在应用调用时就如同windows下我们打开一个程序运行后，再打开一个程序时，要不就是中断以前的程序，要不就是等上一会才能运行后来打开的程序。想做个好的驱动人员没有三、四年功底，操作系统内核不研究上几编，不是太容易成功的，但其工资在嵌入式系统四层中可 是最高的。
嵌入式的驱动层比较适合于电子、通信、自动化、机电一体、信息工程类专业尤其是计算机偏体系结构类专业的人来搞，除硬件层所具备的基础学科外，还要对数据结构与算法、操作系统原理、编译原理都要十分精通了解。
操作系统层 对于操作系统层目前可能只能说是简单的移植，而很少有人来自已写操作系统，或者写出缺胳膊少腿的操作系统来，这部分工作大都由驱动工程师来完成。操作系统是负责系统任务的调试、磁盘和文件的管理，而嵌入式系统的实时性十分重要。据说，XP操作系统是微软投入300人用两年时间才搞定的，总时工时是600人年，中科院软件所自己的女娲Hopen操作系统估计也得花遇几百人年才能搞定。因此这部分工作相对来讲没有太大意义。
应用层 应用层相对来讲较为容易的，如果会在windows下如何进行编程接口函数调用，到操作系统下只是编译和开发环 境有相应的变化而已。如果涉及Jave方面的编程也是如此的。嵌入式系统中涉及算法的由专业算法的人来处理的，不必归结到嵌入式系统范畴内。但如果涉及嵌 入式系统下面嵌入式数据库、基于嵌入式系统的网络编程和基于某此应用层面的协议应用开发(比如基于SIP、H.323、Astrisk)方面又较为复杂， 并且有难度了。
从哪里入手嵌入式系统 从硬件上入手ARM 一方面就是学习接口电路设计，另一方面就是学习汇编和C语言的板级编程。如果从软件上讲，就是要学习基于ARM处理器的操作系统层面 的驱动、移植了。这些对于初学都来说必须明确,要么从硬件着手开始学，要么从操作系统的熟悉到应用开始学，但不管学什么，只要不是纯的操作系统级以上基于 API的应用层的编程，硬件的寄存器类的东西还是要能看懂的，基于板级的汇编和C编程还是要会的。因此针对于嵌入式系统的硬件层和驱动程的人，ARM的接 口电路设计、ARM的C语言和汇编语言编程及调试开发环境还是需要掌握的。
因此对于初学者必然要把握住方向，自己学习嵌入式系统的目标是什么，自己要在那一层面上走。然后再着手学习较好，与ARM相关的嵌入式系统的较为实际的两个层面硬件层和驱动层，不管学好了那一层都会很有前途的。
从嵌入式系统的应用层如何入手 可能与ARM及其它体系相去较远，要着重研究基嵌入式操作系统的环境应用与相应开发工具链，比如WinCe操作系统下的EVC应用开发(与windows下的VC相类似)，如果想再有突破就往某些音视频类的协议上靠，比如VOIP领域的基于SIP或H.323协议的应用层开发，或是基于嵌入式网络数据库的开发等等。
对于初学者来讲，要量力而行，不要认为驱动层工资高就把它当成方向了，要结合自身特点，嵌入式系统四个层面上那个层面上来讲都是有高人存在，当然高人也对应 的高工资，我是做硬件层的，以前每月工资中个人所得税要被扣上近3千大元，当然我一方面充当工程师的角色，一方面充当主管及人物的角色，两个职位我一个人 干，但上班时间就那些。硬件这方面上可能与我PK的人很少了，才让我拿到那么多的工资。
芯片的选择 很多ARM初学者都希望有一套自己能用的系统，但他们住住会产生一种错误认识就是认为处理器版本越高、性能越高越好，就象很多人认为ARM9与ARM7好， 我想对于初学者在此方面以此入门还应该理智，开发系统的选择最终要看自己往嵌入式系统的那个方向上走，是做驱动开发还是应用，还是做嵌入式系统硬件层设计与板级测试。如果想从操作系统层面或应用层面上走，不管是驱动还是应用，那当然处理器性能越高越好了，但嵌入式系统这个东西自学，有十分大的困难，不是几个月或半年 或是一年二年能搞定的事。
在某种意义上请，ARM7与9的差别就是在某些功能指令集上丰富了些，主频提高一些而已，就比如286和386。对于用户来讲可能觉查不到什么，只能是感觉速度有些快而已。
ARM7比较适合于那些想从硬件层面上走的人，因为ARM7系列处理器内部带MMU的很少，而且比较好控制，就比如S3C44B0来讲，可以很容易将 Cache关了，而且内部接口寄存器很容易看明白，各种接口对于用硬件程序控制或AXD单步命令行指令都可以控制起来，基于51单片机的思想很容易能把他 搞懂，就当成个32位的单片机，从而消除很多51工程师想转为嵌入式系统硬件ARM开发工程师的困惑，从而不会被业界某此不是真正懂嵌入式烂公司带到操作 系统层面上去，让他们望而失畏，让业界更加缺少这方面的人才。
而嵌入式系统不管硬件设计还是软件驱动方面都是十分注重接口这部分的，选择平台还要考察一个处理器的外部资源，你接触外部资源越多，越熟悉他们那你以后就业成功的机率就越高，这就是招聘时 所说的有无“相关技能”，因为一个人不可能在短短几年内把所有的处理器都接触一遍，而招聘单位所用的处理器就可能是我们完全没有见过的，就拿台湾数十家小公司(市价几千万)的公司生产的ARM类处理器，也很好用，但这些东西通用性太差，用这些处理器的公司就只能招有相关工作经验的人了，那什么是相关工作经 验，在硬件上讲的是外围接口设计，在软件上讲是操作系统方面相关接口驱动及应用开发经验。我从业近十年，2000年ARM出现，我一天始做ARM7,然后 直接跑到了Xscale(这个板本在ARM10-11之间)，一做就是五年，招人面试都不下数百人，在这些方面还是深有体会的。
开发系统的选择，要看自己的未来从来目标方向、要看开发板接口资源、还要看业界的通用性。
成为高级嵌入式系统硬件工程师要具备的技能 就单纯信号来分为数字和模拟，模拟比较难搞，一般需要很长的经验积累，单单一个阻值或容值的精度不够就可能使信号偏差很大。因此年轻人搞的较少，随着技术的发展，出现了模拟电路数字化，比如手机的Modem射频模块，都采用成熟的套片，而当年国际上只有两家公司有此技术，自我感觉模拟功能不太强的人，不太适合搞这个，如果真能搞定到手机的射频模块，只要达到一般程度可能月薪都在15K以上。
一个优秀的硬件工程师应该能够在没有参考方案的前提下设计出一个在成本和性能上更加优秀的产品，靠现有的方案，也要进行适当的可行性裁剪，但不是胡乱的来，我遇到一个工程师把方案中的5V变1.8V的DC芯片，直接更换成LDO，有时就会把CPU烧上几个。
高级硬件件工程师技术技能都要具备那些东西哪，首先要掌握EDA设计的辅助工具类如Protel、ORCAD、PowperPCB、Maplux2、ISE、VDHL语言，要能用到这些工具画图画板做逻辑设计，再有就是接口设计审图能力，再者就是调试能力，如果能走到总体方案设计这块，那就基本上快成为资深工程师了。硬件是要靠经验，也要靠积累的，十年磨一剑，百年磨一针。
]]></content>
  </entry>
  
  <entry>
    <title>STM32怎么选型</title>
    <url>/post/mcu/how-to-select-stm32.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>STM32</tag>
      <tag>MCU</tag>
    </tags>
    <content type="html"><![CDATA[什么是 STM32 STM32，从字面上来理解，ST是意法半导体，M是Microelectronics的缩写，32表示32位，合起来理解，STM32就是指ST公司开发的32位微控制器。在如今的32位控制器当中，STM32可以说是最璀璨的新星，它受宠若娇，大受工程师和市场的青睐，无芯能出其右。
STM32属于一个微控制器，自带了各种常用通信接口，比如USART、I2C、SPI等，可接非常多的传感器，可以控制很多的设备。现实生活中，我们接触到的很多电器产品都有STM32的身影，比如智能手环，微型四轴飞行器，平衡车、移动POST机，智能电饭锅，3D打印机等等。下面我们以最近最为火爆的两个产品来讲解下，一个是手环，一个是飞行器。
现在无人机非常火热，高端的无人机用STM32做不来，但是小型的四轴飞行器用STM32还是绰绰有余的。
STM32 分类 STM32有很多系列，可以满足市场的各种需求，从内核上分有Cortex-M0、M3、M4和M7这几种，每个内核又大概分为主流、高性能和低功耗。具体如下表所示。
单纯从学习的角度出发，可以选择F1和F4，F1代表了基础型，基于Cortex-M3内核，主频为72MHZ，F4代表了高性能，基于Cortex-M4内核，主频180M。之于F1，F4（429系列以上）除了内核不同和主频的提升外，升级的明显特色就是带了LCD控制器和摄像头接口，支持SDRAM，这个区别在项目选型上会被优先考虑。但是从大学教学和用户初学来说，还是首选F1系列，目前在市场上资料最多，产品占有量最多的就是F1系列的STM32。
以STM32F103VET6来讲下STM32的命名方法，具体如下表所示。
更详细的命名方法说明，见下图。
选择合适的 MCU 了解了STM32的分类和命名方法之后，就可以根据项目的具体需求先大概选择哪类内核的MCU，普通应用，不需要接大屏幕的一般选择Cortex-M3内核的F1系列，如果要追求高性能，需要大量的数据运算，且需要外接RGB大屏幕的则选择Cortex-M4内核的F429系列。明确了大方向之后，接下来就是细分选型，先确定引脚，引脚多的功能就多，价格也贵，具体得根据实际项目中需要使用到什么功能，够用就好。确定好了引脚数目之后再选择FLASH大小，相同引脚数的MCU会有不同的FLASH大小可供选择，这个也是根据实际需要选择，程序大的就选择大点的FLASH，要是产品一量产，这些省下来的都是钱啊。有些月出货量以KK（百万数量级）为单位的产品，不仅是MCU，连电阻电容能少用就少用，更甚者连PCB的过孔的多少都有讲究。项目中的元器件的选型有很多学问。
]]></content>
  </entry>
  
  <entry>
    <title>你了解C 和 C++ 标准库吗</title>
    <url>/post/programming/do-you-understand-c-and-c-plus-plus-standard-library.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>C++</tag>
    </tags>
    <content type="html"><![CDATA[本文简要介绍编写 C/C++ 应用程序的领域，标准库的作用以及它是如何在各种操作系统中实现的。
我已经接触 C++ 一段时间了，一开始就让我感到疑惑的是其内部结构：我所使用的内核函数和类从何而来？谁发明了它们？他们是打包在我系统中的某个地方吗？是否存在一份官方的 C++ 手册？
在本文中，我将通过从 C 和 C++ 语言的本质到实际实现来尝试回答这些问题。
C 和 C++ 是如何制订的 当我们谈论 C 和 C++ 时，实际上是指一组定义（程序）语言应该做些什么，如何表现，应该提供哪些功能的规则。C/C++ 的编译器为了处理 C/C++ 编写的源代码必须跟随着这些规则，并生成二进制应用程序。听起来非常接近于 HTML:浏览器遵循着一组指令，所以它们可以以明确的方式来渲染网页。
与 HTML 一样，C 和 C++ 的规则都是理论上的。国际标准化组织(ISO)的一大群人每年都会聚集几次来讨论和定义语言规则。没错，C 和 C++ 是标准化的东西。他们最终都会得到一本官方的叫标准的书，你可以从他们的网站中购买。随着语言的发展新的 papers（指官方的叫标准的书）会被发布，每一次都定义一个新的标准。这就是为什么我们会有不同的 C 和 C++ 版本的原因：C99, C11, C++03, C++11, C++14 等等，数字与出版/发布年份相符。
这些标准都市非常详细和有技术新的文档：我不会把它们当作手册。通常会分为两部分：
  C/C++ 的功能和特性；
  C/C++ 的 API&ndash; 开发人员可以用于他们的 C/C++ 程序的一个类、函数和宏的集合。它也被称为标准库。
  例如，这里有个来自于 C 标准库第一部分的摘选，它定义了 main 函数的结构：
 main 的定义，程序启动时调用的函数。  这是另外一个来自与同样标准的摘录，描述了 CAPI 的成员 &ndash;fmin 函数：
在 math.h 文件中定义 min 函数。  如你所见，几乎没涉及到代码。有人必须阅读标准并将其转换成计算机可以消化的东西。这是工作于编译器和（功能）实现上人们所做的：前者是一种可以读取和处理 C 和 C++ 源文件的工具，后者将标准库转换为代码。我们来深入了解一下。
C 标准库 C 标准库也称为 ISO C 库，是用于完成诸如输入/输出处理、字符串处理、内存管理、数学计算和许多其他操作系统服务等任务的宏、类型和函数的集合。它是在 C 标准中（例如 C11 标准）中定义的。其内容分布在不同的头文件中，比如上面我所提到的 math.h。
C++ 标准库 和 C 标准库的概念类似，但仅针对 C++。C++ 标准库是一组 C++ 模板类，它提供了通用的编程数据结构和函数，如链表、堆、数组、算法、迭代器和任何其他你可以想到的 C++ 组件。C++ 标准库也包含了 C 标准库，并在 C++ 标准中进行了定义（例如 C++ 11 标准）。
实现 C/C++ 标准库 我们从这里开始讨论真正的代码了。从事于标准库实现的开发者阅读官方的 ISO 规范并将其转化为代码。他们必须依赖其操作系统所提供的功能（读/写文件，分配内存，创建线程，&hellip;&hellip;所有这些被称为系统调用），因此每个平台都有其自己的标准库实现。有时它是系统内核的一部分，有时它是作为一个附加组件 - 编译器 - 必须单独下载。
GNU/Linux 版实现 GNU C 库，也称为 glibc, 是 C 标准库的 GNU 项目实现。并非所有的标准 C 函数都可以在 glibc 中找到：大多数数学函数实际上是在 libm 库中实现的，这是一个独立的库。
至今，glibc 是 Linux 上使用最广泛的 C 库。然而，在 90 年代期间，有一段时间里，glibc 有一个竞争对手称为 Linux libc（或者简称 libc），它是由 glibc 1.x 的一个分支产生的。在一段时间里，Linux libc 是许多 Linux 发行版中的标准 C 库。
经过多年的发展，glibc 竟然比 Linux libc 更具优势，并且所有使用它的 Linux 发行版都切换回了 glibc。所以，如果你在你的磁盘中找到一个名为 libc.so.6 的文件，请不要担心：它是现代版的 glibc。为了避免与之前的 Linux libc 版本混淆，版本号增加到了 6（他们无法将其命名为 glibc.so.6：所有Linux库都必须以 lib 前缀打头）。
另一方面，C++ 标准库的实现位于 libstdc++ 或 GNU 标准 C++ 库中。这是一个正在进行的在 GNU/Linux 上实现标准 C++ 库的项目。一般来说，所有常规的 Linux 发行版都默认使用 libstdc++。
Mac 和 iOS 版实现 在 Mac 和 iOS 上，C 标准库的实现是 libSystem 的一部分，libSystem 是位于 /usr/lib/libSystem.dylib 中的核心库。LibSystem 包含其他组件，如数学库、线程库和其他底层实用程序。
关于 C++ 标准库，在 OS X Mavericks（V10.9）之前的 Mac 上，libstdc++ 是默认选项。这在现代的基于 Linux 的系统上可以找到的同样的实现。自 OS X Mavericks 开始，Apple 切换到使用 libc++，这是 LLVM 项目——Mac 官方编译器框架——所引入的 GNU libstdc++ 标准库的替代。
IOS 开发者可以使用 iOS SDK（软件开发工具包）来访问标准库，它是一系列允许创建移动应用程序的工具。
Windows 版实现 在 Windows 上，标准库的实现一直严格限定在 Visual Studio 中，它是微软官方的编译器。他们通常称之为 C/C++ 运行时库（CRT），并且它涵盖了 c/c++ 二者的实现。
在最开始，CRT 被实现为 CRTDLL.DLL 库（我猜，当时没有可用的 C++ 标准库）。从 Windows 95 开始，Microsoft 开始将其迁移到 MSVCRT [版本号] .DLL（MSVCR20.DLL，MSVCR70.DLL 等）之上，据推测也包含 C++ 标准库。在 1997 年，他们决定将文件名简化为 MSVCRT.DLL，这不幸导致了令人讨厌的DLL混乱。这就是为什么从 Visual Studio 7.0 版开始，他们切换回每个版本使用单独的 DLL 了。
Visual Studio 2015 引入了深度的 CRT 重构。C/C++ 标准库的实现迁移到一个新库，Universal C 运行时库 (Universal CRT 或 UCRT)，编译为 UCRTBASE.DLL。UCRT 目前已经成为 Windows 组之一，从 Windows 10 开始作为操作系统的一部分提供。
Android 版实现 Bionic 是 Google 为其 Android 操作系统所编写的 C 标准库实现，它直接在底层使用。第三方开发者可以通过 Android 原生开发工具包（NDK）访问 Bionic，该工具集允许你使用 C 和 C++ 代码编写 Android 应用程序。
在 C++ 端, NDK 提供了很多版本的实现：
  libc++，从从 Lollipop 开始的官方安卓系统和现代 Mac 操作系统都将其作为 C++ 标准库使用。从 NDK 发布 17 版本开始，它将成为 NDK 中唯一可用的 C++ 标准库实现；
  gnustl，libstdc++ 的别名，这两者在 GNU/linux 是同一个库。这个库的已被弃用，它将在 NDK 发布 18 中删除；
  STLport，由 STLport 项目编写的 C++ 标准库的第三方实现，自 2008 年以来一直处于不活跃状态。与 gnustl 一样，STLport 将在 NDK 发布 18 中移除。
  我能使用不同版本的实现代码来替代默认实现吗？ 如果你正在使用资源非常有限的系统，则通常需要引用 C 标准库的不同实现。比如，uClibc-ng, musl libc 和 diet libc 等等，所有这些都适用于嵌入式 Linux 系统的开发，提供更小的二进制文件和更少的内存占用。
C++ 标准库也有不同的实现版本：Apache C++ 标准库，uSTL 以及 EASTL 等等。后面两个实际上仅关注模板部分，而不是完整的库，并且他们是在速度优先的情况下开发的。Apache 版本的库注重的是可移植性。
如果我们脱离了标准库怎么办？ 不使用标准库很简单：只要在你的程序中不引入它们的任何一个头文件，你的工作就完成了。然而，为了让这个操作更有意义一些，你需要通过一些提供的系统调用使用某种方法与操作系统互动。就像我之前说的，这就是标准库中的函数/方法在底层实现的时候所使用的。很可能你也会不得不调用这些方法来与硬件设备交互。
如果对你来说这听起来很让人激动，有些人已经开始在网上尝试在不导入标准库的情况下创建工作流程。因为你依赖于一个特定操作系统所提供的函数，这种方式会丧失可移植性。然而通过使用这种艰难的方式，肯会让你学到更多，而且让你更好的理解当你所做的事情，即使是在使用高级库的时候。
除了知识，当你在嵌入式操作系统上面工作的时候你不会想去引入标准库：因为代码不需要移植，在有限的内存中每个字节都很重要，这会让你更加精准的写代码。另一个使用背景就是 demoscene，在这里人们尽量有限的程序的二进制大小中去保留高质量的音视频——4K仍然不是最小值：一些 demoparties 使用 1K，256 字节，64 字节或者甚至 32 字节来竞争。在那里不允许使用标准库！
]]></content>
  </entry>
  
  <entry>
    <title>一个简单的MCU内存管理模块(附源码)</title>
    <url>/post/mcu/a-simple-mcu-memory-management-module.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>STM32</tag>
      <tag>Memory Management</tag>
    </tags>
    <content type="html"><![CDATA[现在非常多的的MCU性能都还不错，同时用户也会去扩展一些外部RAM，那么如何高效便捷的管理这些内存是一个重要话题。
今天给大家分享一份源码：基于无操作系统的STM32单片机开发，功能强大，可申请到地址空间连续的不同大小的内存空间，且用户接口简单，使用方便。
源码说明 源码包含memory.h 和 memory.c 两个文件（嵌入式C/C++代码的“标配”），其源码中包含重要的注释。
 memory.h文件 ：包含结构体等定义，函数API申明等； memory.c文件 ：是实现内存管理相关API函数的原型。  头文件memory.h 头文件是相关的定义和申请：
#ifndef __MEMORY_H__ #define __MEMORY_H__  #include &#34;stdio.h&#34;#include &#34;string.h&#34;#include &#34;includes.h&#34;//用户使用 typedef struct { void *addr; //申请到的内存的起始地址  uint32_t size; //申请到的内存的大小，按照块大小分配，大于等于申请大小  uint16_t tb; //申请表序号，申请内存时分配，释放内存时使用，用户不使用 }DMEM; //若返回空，则申请失败 DMEM *DynMemGet(uint32_t size); void DynMemPut(DMEM *pDmem); #endif //__MEMORY_H__ 这里的代码比较简单，也是常规的写法，重点是要理解结构体成员的含义。
源文件memory.c 源文件主要就是实现内存管理的函数，源码比较多，这里才分为三部分。
相关的定义 #include &#34;memory.h&#34; #define DMEM_BLOCK_SIZE 256 //内存块大小为256字节 #define DMEM_BLOCK_NUM 20 //内存块个数为20个 #define DMEM_TOTAL_SIZE (DMEM_BLOCK_SIZE*DMEM_BLOCK_NUM) //内存总大小  static uint8_t DMEMORY[DMEM_TOTAL_SIZE]; static DMEM_STATE DMEMS = {0}; typedef enum { DMEM_FREE = 0, DMEM_USED = 1, }DMEM_USED_ITEM; typedef struct { DMEM_USED_ITEM used; //使用状态  uint16_t blk_s; //起始块序号  uint16_t blk_num; //块个数 }DMEM_APPLY; typedef struct { DMEM_USED_ITEM tb_blk[DMEM_BLOCK_NUM]; DMEM tb_user[DMEM_BLOCK_NUM]; //用户申请内存信息  DMEM_APPLY tb_apply[DMEM_BLOCK_NUM]; //系统分配内存信息  uint16_t apply_num; //内存申请表占用数目  uint16_t blk_num; //内存块占用数目 }DMEM_STATE; 内存分配函数DynMemGet DMEM *DynMemGet(uint32_t size) { uint16_t loop = 0; uint16_t find = 0; uint16_t blk_num_want = 0; DMEM * user = NULL; DMEM_APPLY *apply = NULL; //申请内存大小不能为0  if(size == 0) { return NULL; } //申请内存不可超过总内存大小  if(size &gt; DMEM_TOTAL_SIZE) { return NULL; } //申请内存不可超过剩余内存大小  if(size &gt; (DMEM_BLOCK_NUM - DMEMS.blk_num) * DMEM_BLOCK_SIZE) { return NULL; } //申请表必须有空余  if(DMEMS.apply_num &gt;= DMEM_BLOCK_NUM) { return NULL; } //计算所需连续块的个数  blk_num_want = (size + DMEM_BLOCK_SIZE - 1) / DMEM_BLOCK_SIZE; //寻找申请表  for(loop = 0; loop &lt; DMEM_BLOCK_NUM; loop++) { if(DMEMS.tb_apply[loop].used == DMEM_FREE) { apply = &amp;DMEMS.tb_apply[loop]; //申请表已找到  user = &amp;DMEMS.tb_user[loop]; //用户表对应找到  user-&gt;tb = loop; //申请表编号记录  user-&gt;size = blk_num_want * DMEM_BLOCK_SIZE; //分配大小计算  break; } } //没有找到可用申请表，理论上是不会出现此现象的，申请表剩余已在上面校验  if(loop == DMEM_BLOCK_NUM) { return NULL; } //寻找连续内存块  for(loop = 0; loop &lt; DMEM_BLOCK_NUM; loop++) { if(DMEMS.tb_blk[loop] == DMEM_FREE) {//找到第一个空闲内存块  for(find = 1; (find &lt; blk_num_want) &amp;&amp; (loop + find &lt; DMEM_BLOCK_NUM); find ++) {//找到下一个空闲内存块  if(DMEMS.tb_blk[loop + find] != DMEM_FREE) {//发现已使用内存块  break; } } if(find &gt;= blk_num_want) {//寻找到的空闲内存块数目已经够用  user-&gt;addr = DMEMORY + loop * DMEM_BLOCK_SIZE; //计算申请到的内存的地址  apply-&gt;blk_s = loop; //记录申请到的内存块首序号  apply-&gt;blk_num = blk_num_want; //记录申请到的内存块数目  for(find = 0 ; find &lt; apply-&gt;blk_num; find++) { DMEMS.tb_blk[loop + find] = DMEM_USED; } apply-&gt;used = DMEM_USED; //标记申请表已使用  DMEMS.apply_num += 1; DMEMS.blk_num += blk_num_want; return user; } else {//寻找到的空闲内存块不够用，从下一个开始找  loop += find; } } } //搜索整个内存块，未找到大小适合的空间  return NULL; } 内存释放函数DynMemPut void DynMemPut(DMEM *user) { uint16_t loop = 0; //若参数为空，直接返回  if(NULL == user) { return; } //释放内存空间  for(loop = DMEMS.tb_apply[user-&gt;tb].blk_s; loop &lt; DMEMS.tb_apply[user-&gt;tb].blk_s + DMEMS.tb_apply[user-&gt;tb].blk_num; loop++) { DMEMS.tb_blk[loop] = DMEM_FREE; DMEMS.blk_num -= 1; } //释放申请表  DMEMS.tb_apply[user-&gt;tb].used = DMEM_FREE; DMEMS.apply_num -= 1; } 代码中包含注释，注释描述的比较清楚，也比较容易理解。
]]></content>
  </entry>
  
  <entry>
    <title>STM32之GPIO点亮LED</title>
    <url>/post/mcu/STM32-gpio-led.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>STM32</tag>
      <tag>GPIO</tag>
      <tag>LED</tag>
    </tags>
    <content type="html"><![CDATA[我们在基础部分讲了有关GPIO的方面，从这章开始我们进入模块的讲解，从最开始的LED灯到各种传感器模块进行。专栏预计25个章节。后续可能会不定时的增加。
本专栏芯片为STM32F429
对于工程的移植和新建这里不做讲解，对工程建立不懂得，请参考其他博客或者某些教程。
本章使用到的是GPIO的输出功能，GPIO的内容这里不在说明，不理解或者其他原因请参看: https://www.vxbus.com  
硬件设计 本实验以1个LED灯为例，本篇文章主要目的是理解GPIO输出。
LED的正极通过1KΩ与3.3v连接，LED的阴极以单片机的GPIOC的13号引脚相连接。根据电路图，当PC13位输出低电平时，LED灯亮，输出为高时LED熄灭（亮和灭就是两端的电压差，当LED两端同时都是高电平时，没有电压差）。
注：具体连接引脚请根据自己开发板上的电路原理图进行连接。
软件设计 编程步骤 使能GPIO时钟（也就是RCC，这步是非常重要的。具体在那个总线上，请参考数据手册，本专栏芯片为STM32F429）
设置对应于片上外设使用的GPIO工作模式
在应用程序中读取引脚状态、控制引脚输出状态或使用复用功能完成特定功能。
编程要点 使能GPIO时钟。调用函数RCC_AHB1PeriphClockCmd()。不同的外设调用的时钟使能函数可能不一样。
初始化GPIO模式。调用函数GPIO_Init()。
操作GPIO，设置引脚输出状态。调用函数GPIO_SetBits();或GPIO_ResetBits()或GPIO_ToggleBits()。
代码实现 static void LED_Config(void) { GPIO_InitTypeDef GPIO_InitStructure; //GPIO_InitStructure用于存放GPIO的参数  /*开启LED相关的GPIO外设时钟*/ 第一步 RCC_AHB1PeriphClockCmd (RCC_AHB1Periph_GPIOC, ENABLE); //使能GPIOC的时钟  /*选择要控制的GPIO引脚*/ GPIO_InitStructure.GPIO_Pin = GPIO_Pin_13; //设置引脚  *设置引脚模式为输出*/ GPIO_InitStructure.GPIO_Mode = GPIO_Mode_OUT; //设置模式  /*设置引脚速率为2MHz */ GPIO_InitStructure.GPIO_Speed = GPIO_Speed_2MHz; //设置I/O输出速度  /*设置引脚的输出类型为推挽输出*/ GPIO_InitStructure.GPIO_OType = GPIO_OType_PP; //设置输出类型  /*设置引脚为上拉模式*/ GPIO_InitStructure.GPIO_PuPd = GPIO_PuPd_UP; //设置上拉/下拉模式  /*调用库函数，使用上面配置的GPIO_InitStructure初始化GPIO*/ 第二步 GPIO_Init(GPIOC, &amp;GPIO_InitStructure); //根据参数初始化LED的GPIO  GPIO_WriteBit(GPIOC, GPIO_Pin_13, Bit_SET); //将LED默认状态设置为熄灭 } void InitLED(void) { LED_Config(); //配置LED的GPIO } * 函数名称：Contl_lLED * 函数功能：控制LED亮灭 * 输入参数：mode:1-点亮，0-熄灭 * 输出参数：void * 返 回 值：void * 创建日期： *********************************************************************************************************/ void Contl_lLED(u8 mode) { if(mode) { GPIO_WriteBit(GPIOC, GPIO_Pin_13, Bit_RESET); //点亮LED  } else { GPIO_WriteBit(GPIOC, GPIO_Pin_13, Bit_SET); //熄灭LED  } } void LED_ON_OF(u16 cnt) { static u16 time; //time  time++; //计数器的计数值加1  if(time &gt;= cnt) //计数器的计数值大于cnt  { time = 0; //重置计数器的计数值为0  //LED状态取反，实现LED闪烁  GPIO_WriteBit(GPIOC, GPIO_Pin_13, (BitAction)(1 - GPIO_ReadOutputDataBit(GPIOC, GPIO_Pin_13))); } } int main(void) { InitLED(); LED_ON_OF(300); } ]]></content>
  </entry>
  
  <entry>
    <title>简单分析STM32和51的区别</title>
    <url>/post/mcu/difference-between-smt32-and-c51.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>SMT32</tag>
      <tag>C51</tag>
    </tags>
    <content type="html"><![CDATA[分享本文，简单分析STM32与51单片机的区别与取舍之处。
单片微型计算机简称单片机，简单来说就是集CPU（运算、控制）、RAM（数据存储-内存）、ROM（程序存储）、输入输出设备（串口、并口等）和中断系统处于同一芯片的器件，在我们自己的个人电脑中，CPU、RAM、ROM、I/O这些都是单独的芯片，然后这些芯片被安装在一个主板上，这样就构成了我们的PC主板，进而组装成电脑，而单片机只是将这所有的集中在了一个芯片上而已。
51单片机 应用最广泛的8位单片机当然也是初学者们最容易上手学习的单片机，最早由Intel推出，由于其典型的结构和完善的总线专用寄存器的集中管理，众多的逻辑位操作功能及面向控制的丰富的指令系统，堪称为一代“经典”，为以后的其它单片机的发展奠定了基础。
51单片机特性 51单片机之所以成为经典，成为易上手的单片机主要有以下特点：
从内部的硬件到软件有一套完整的按位操作系统，称作位处理器，处理对象不是字或字节而是位。不但能对片内某些特殊功能寄存器的某位进行处理，如传送、置位、清零、测试等，还能进行位的逻辑运算，其功能十分完备，使用起来得心应手。
同时在片内RAM区间还特别开辟了一个双重功能的地址区间，使用极为灵活，这一功能无疑给使用者提供了极大的方便。
乘法和除法指令，这给编程也带来了便利。很多的八位单片机都不具备乘法功能，作乘法时还得编上一段子程序调用，十分不便。
51单片机缺点  AD、EEPROM等功能需要靠扩展，增加了硬件和软件负担 虽然I/O脚使用简单，但高电平时无输出能力，这也是51系列单片机的最大软肋 运行速度过慢，特别是双数据指针，如能改进能给编程带来很大的便利 51保护能力很差，很容易烧坏芯片  51单片机应用范围 目前在教学场合和对性能要求不高的场合大量被采用，使用最多的器件是8051、80C51。
STM32单片 由ST厂商推出的STM32系列单片机，行业的朋友都知道，这是一款性价比超高的系列单片机，应该没有之一，功能及其强大。
其基于专为要求高性能、低成本、低功耗的嵌入式应用专门设计的ARM Cortex-M内核，同时具有一流的外设：1μs的双12位ADC，4兆位/秒的UART，18兆位/秒的SPI等等，在功耗和集成度方面也有不俗的表现，当然和MSP430的功耗比起来是稍微逊色的一些，但这并不影响工程师们对它的热捧程度。
STM32单片机特性 由STM32简单的结构和易用的工具再配合其强大的功能在行业中赫赫有名，其强大的功能主要表现在：
 内核：ARM32位Cortex-M3CPU，最高工作频率72MHz，1.25DMIPS/MHz，单周期乘法和硬件除法 存储器：片上集成32-512KB的Flash存储器。6-64KB的SRAM存储器 时钟、复位和电源管理：2.0-3.6V的电源供电和I/O接口的驱动电压。POR、PDR和可编程的电压探测器（PVD）。4-16MHz的晶振。内嵌出厂前调校的8MHz RC振荡电路。内部40 kHz的RC振荡电路。用于CPU时钟的PLL。带校准用于RTC的32kHz的晶振 调试模式：串行调试（SWD）和JTAG接口。最多高达112个的快速I/O端口、最多多达11个定时器、最多多达13个通信接口。  STM32使用最多的器件：  STM32F103系列 STM32 L1系列 STM32W系列  51单片机和STM32单片机的区别 51单片机是对所有兼容Intel8031指令系统的单片机的统称，这一系列的单片机的始祖是Intel的8031单片机，后来随着flash ROM技术的发展，8031单片机取得了长足的进展成为了应用最广泛的8bit单片机之一，他的代表型号就是ATMEL公司的AT89系列。
STM32单片机则是ST（意法半导体）公司使用arm公司的cortex-M3为核心生产的32bit系列的单片机，他的内部资源（寄存器和外设功能）较8051、AVR和PIC都要多的多，基本上接近于计算机的CPU了，适用于手机、路由器等等。
]]></content>
  </entry>
  
  <entry>
    <title>英伟达再度释放AI“炸弹”</title>
    <url>/post/server/nvidia-launch-gh200-grace-hopper.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>NVIDIA</tag>
      <tag>GH200 Grace Hopper</tag>
    </tags>
    <content type="html"><![CDATA[近日，在计算机图形学顶会SIGGRAPH 2023现场，英伟达再度释放深夜“炸弹”，大模型专用芯片迎来升级版本。
英伟达在会上发布了新一代GH200 Grace Hopper平台，该平台依托于搭载全球首款搭载HBM3e处理器的新型Grace Hopper超级芯片——GH200，专为处理大语言模型、推荐系统、矢量数据库等全球最复杂的生成式AI工作负载而构建。
据悉，GH200芯片将成为世界上第一个配备HBM3e（High Bandwidth Memory 3e）内存的GPU芯片。
与当前一代产品相比，最新版本的GH200超级芯片内存容量增加了3.5倍，带宽增加了3倍；相比最热门的H100芯片，其内存增加1.7倍，传输频宽增加1.5倍。
在当前生成式AI不断激增的需求下，GH200超级芯片的推出，进一步吹响了AI算力之战的号角。
性能更高的GH200芯片 据介绍，GH200 Grace Hopper平台的HBM3e内存比当前HBM3快50%，可提供总计10TB/s的带宽。这使得新平台能够运行比上一版本大3.5倍的模型，同时凭借快3倍的内存带宽提升性能。
同时，该平台采用双配置，包括一个拥有144个Arm Neoverse内核、8 petaflops的AI性能和282GB最新HBM3e内存技术的单个服务器。
英伟达创始人兼首席执行官黄仁勋表示：“为了满足对生成式 AI不断激增的需求，数据中心需要能够满足特定需求的加速计算平台。全新GH200 Grace Hopper超级芯片平台以出色的内存技术和带宽，提高了吞吐量，在不影响性能的情况下可连接多GPU以整合性能，并且具有可以轻松部署到整个数据中心的服务器设计。”
据英伟达公布信息，新平台可以通过 NVIDIA NVLink™ 与其他超级芯片连接，使它们能够协同工作，从而部署当下大型生成式AI模型。这种高速、一致性技术使GPU可以完全访问CPU 内存，在双配置中可提供总计1.2TB的快速内存。
值得注意的是，新平台采用的新款超级芯片GH200与此前发布的H100相比，二者使用同样的GPU，但GH200将同时配备高达141G的内存和72核ARM中央处理器，每秒5TB带宽，内存增加了1.7倍，带宽增加了1.5倍。
新平台和芯片的加持，也让大模型训练的成本得到有效降低。黄仁勋表示，一台服务器可以同时装载两个GH200超级芯片，大型语言模型的推理成本将会大幅降低。
据介绍，投资800万美元Grace Hopper，就相当于8800个价值1亿美元的x86 GPU，意味着成本降低12倍，能耗降低20倍。
英伟达称，GH200已于5月全面投产，基于GH200 Grace Hopper平台的新系统将于2024年第二季度交付。
不过一个关键的问题是，英伟达没有透露超级芯片GH200的价格，这对计算成本高昂的大模型来说尤为重要，H100系列目前售价约为4万美元。
为什么内存对大模型重要 事实上，GH200超级芯片本身并不是一个新产品，而是今年5月在中国台北Computex展上发布的GH200芯片的更新版。
英伟达超大规模和高性能计算副总裁兼总经理伊恩·巴克（Ian Buck）表示：“我们对这款新的GH200感到非常兴奋。HBM3e不仅增加了GPU的容量和内存量，而且速度也更快。”
但为什么GPU内存这么重要？
这是因为随着支撑生成式人工智能应用程序的基础AI模型尺寸的增加，为了能够在不连接独立芯片和系统的情况下运行，大模型需要更大的内存量，以避免性能下降。
拥有更大的内存允许模型保留在单个GPU上，并且不需要多个系统或多个GPU来运行，而额外的内存只会提高 GPU的性能。
目前即使使用英伟达最顶级的H100芯片，有些模型也必须在其他GPU中“分解”模型才能运行。
据英伟达介绍，最新版本GH200配备141GB的HBM3e内存，旨在处理“世界上最复杂的生成式人工智能工作负载，涵盖大型语言模型、推荐系统和矢量数据库”。
对AI领域的影响 伟达的GH200超级芯片和DGX GH200超级计算机是AI领域的重大突破，它们为大规模生成式AI工作负载提供了前所未有的性能和内存空间，使得训练千亿甚至万亿参数的巨型模型成为可能。
这些模型可以在自然语言处理、计算机视觉、推荐系统、图形分析等领域实现更高的精度和效率，为人类解决更复杂的问题提供了强大的工具。
在多位AI从业者看来，当前大模型的训练需求过于迫切，对性能的要求也很高，而GPU的适配和生态转移都需要很长时间，因此目前大家都优先选择英伟达，和其他厂商的测试验证也在进行中。
一场新的算力之战已经拉开帷幕，如果说算力是一个江湖，那么此刻英伟达就是一名绝世高手。
它身怀加速计算的绝技，尤其在AI战场上一骑绝尘，似乎每一次都能精准地踏在浪潮的节奏上。从游戏PC市场、到深度学习的崛起、到云计算的普及、再到生成式AI的降临，英伟达的技术所向披靡。
回头看，英伟达早已超越了GPU本身的概念，AI成为最大的标签，算力的绝世武功撑起了新的万亿帝国。
2022年，英伟达推出了多款重磅产品，分别是基于全新Hopper架构的H100 GPU、CPU和GPU的合体Grace Hopper、两个CPU组合的Grace CPU Superchip，CPU的产品在2023年上市。
其中，设计GPU新架构Hopper时，英伟达增添了一个Transformer引擎，专门为Transformer算法做了硬件优化，加快AI计算的效率。
一位国内芯片从业者直言：“H100出来，其实就是一个新时代了，Grace-Hopper再一个组合，加上高配的互联，完全不给活路，英伟达赢家通吃，AMD、Intel继续苦追。”
同时他也表示：“目前国内一些企业还是在盯着CNN做优化，英伟达已经有Transformer引擎，然后AIGC火热，恰好能做支持。这个眼光，只能佩服他们的科学家们对这个领域深刻的认识。”
一位学术界人士也分析道：“从H100上，包括专用的Transformer引擎以及对FP8格式的支持，可以看到计算硬件在向应用定制的方向前进。Grace CPU说明了整合异构计算系统的重要性。单纯的加速器优化和设计已经不能够满足现在对于计算系统的算力和能效比的要求，需要各个部分的协同优化和设计。”
他还表示，Grace CPU通过提高通信带宽和在CPU和GPU之间建立一致（coherent）的内存模型来解决运算中的瓶颈，这也和学界（近存计算，存内计算）与业界（CXL，CCI等等系统互联协议）一直在关注的方向是一致的。
总而言之，在GPU和CPU的各种排列组合中，英伟达又将算力提升到了新高度。正如黄仁勋所言：“我们正在重新发明计算机，加速计算和人工智能标志着计算正在被重新定义。”
黄仁勋在采访中还提到，数据中心需要用的CPU越来越少，不再是传统上购买数百万个CPU，而是转而购买数百万个GPU。换言之，在他看来，AI算力江湖已经是GPU的主场。
英伟达的野心 事实上，随着ChatGPT引发AI大模型需求热潮，作为加速计算领导者，英伟达今年以来股价累计涨幅已超过210%，近三个月内涨幅就达56%，过去7年股价增长超40倍，目前市值冲破1.1万亿美元。
公开数据显示，英伟达占据全球80%以上的GPU服务器市场份额，同时拥有全球91.4%的企业GPU市场份额。
据投资者服务公司穆迪今年5月份发布的一份研究报告，英伟达在未来几个季度将实现“无与伦比”的收入增长，其数据中心业务的收入将超过竞争对手英特尔和AMD的总和。
但摩根士丹利策略分析师斯坦利（Edward Stanley）在最新报告中称，根据历史背景，英伟达的股价飙升处于“后期”阶段，摩根士丹利认为这标志着 AI 行业的“泡沫”。
GPU持续紧缺下，如今英伟达产品价格已同比上涨超30%，英伟达A800单卡现货近13万元一颗，eBay上H100售价高达4.5万美元。
同时，OpenAI的GPT-4大模型需要至少2.5万张英伟达A100 GPU芯片，而该公司目前至少已拥有1000万颗GPU芯片。
正如黄仁勋常说的，“你GPU买得越多，你越省钱”。主要原因是新的GPU产品能显著提升加速计算，比CPU性能更强、算力更大、功耗更低。
但英伟达的布局还不止于此。
一个现实问题是，高性能的算力也意味着高昂的价格。大模型训练成本动辄成千上百万美元，并不是所有公司都能承受。
而英伟达同时提出了云服务的解决方案NVIDIA AI foundations，黄仁勋表示要做“AI界的台积电”。台积电大大降低了芯片设计公司生产门槛，英伟达也要做代工厂的角色，通过和大模型厂商、云厂商合作提供高性价比的云服务。
在帮助下游企业降低大模型训练成本的同时，英伟达还在逐步参与到上游的产业链升级中。今年，英伟达牵手台积电、ASML、新思，发布了计算光刻库cuLitho。
计算光刻是在芯片设计和制造领域的关键步骤，也是最大的计算负载之一。计算光刻库的技术突破就在于，可以通过部署有大量GPU的DGX AI计算系统对计算光刻进行加速，使其达到原有的基于CPU的计算速度的几十倍，同时降低计算过程的总能耗。
这将有助于晶圆厂缩短原型周期时间、提高产量、减少碳排放，为2nm及更先进的工艺奠定基础，并为曲线掩模、高数值孔径极紫外、亚原子级光刻胶模型等新技术节点所需的新型解决方案和创新技术提供更多可能性。
在多位产业界人士看来，虽然短期内不会影响到下游的应用方面，但是这些上游的研发和升级将长期影响产业的发展，累积形成代际差。
“英伟达在GPU架构的迭代上，一直都有属于自己的发展路径，这几年的发展，也让英伟达跃居AI算力芯片领域的领导者，也因为领先，所以英伟达会思考如何做更多元的布局与行业内的深度合作，这样更能了解行业的需求，比方和台积电等合作便是很好的例子”，某芯片行业专家表示。
当然，英特尔和AMD都已经吹响反攻的号角。
7月，英特尔面向中国市场推出了AI芯片Habana Gaudi 2；6月，AMD推出AI芯片Instinct MI 300X，两者都直接对标英伟达100系列。
目前，在数据中心市场，英伟达和Intel、AMD形成三足鼎立之势。但随着GH200的正式发布，Grace CPU正式登台争角，最应该感到如芒在背的应该是Intel、AMD。虽说大家都知道GH200迟早发布，但等真正发布了，还是有所触动。
围绕着算力的权力游戏还将继续。
引用地址 英伟达再度释放AI“炸弹”  
]]></content>
  </entry>
  
  <entry>
    <title>哪个Linux发行版可以替代Ubuntu</title>
    <url>/post/linux/which-linux-distribution-could-be-alternative-of-ubuntu.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Ubuntu</tag>
      <tag>Fedora</tag>
      <tag>Mint</tag>
      <tag>Debian</tag>
    </tags>
    <content type="html"><![CDATA[在Linux的世界里，Ubuntu是广受欢迎的一个发行版，那么究竟还有哪些Linux的发行版可以和Ubuntu媲美的呢，今天就让我们一起来看看。
Linux Mint 自带音视频解码器，开箱即用，Ubuntu还要下载编解码器才能播放
主要利用免费和开源的编程，对一些限制性的编程，如 MP3、DVD 和 Adobe Flash 进行了豁免。 Linux Mint 对独占编程的考虑很奇怪； 许多 Linux 流通自然排除了限制性编程，因为一些 Linux 拨款的共同目标是坚持自由和开源编程的模型。 它可以通过各种桌面环境进行浏览，包括默认的 Cinnamon 桌面、APT、MATE 和 KDE。
Linux Mint 伴随着大量引入的编程，其中包括 VLC 播放器、Firefox、LibreOffice 等。它允许组织端口利用其防火墙关闭，并且可以访问重做端口选择。 默认的 Linux Mint 桌面环境 CinnamonandMATE 支持多种语言。 通过利用适用于 Linux 的 Wine Windows 相似层编程或虚拟化编程（包括 VMware 或基于内核的虚拟机），它同样可以运行许多用于 Microsoft Windows 的项目。
Debian GNU / Linux 于1993年首次公布。它的创始人Ian Murdock的初始想法是在空闲时间创建一个由数百名志愿者开发的完全非商业项目。当时怀疑论者远远超过乐观主义者，似乎注定要夭折收尾，但实际情况却恰恰相反。 Debian不仅幸存下来，而且还在不到十年的时间里成为了最大的Linux发行版，也是有史以来创建的最大的协作软件项目！
Debian GNU / Linux的成功可以用下面的数字来说明。它由1000多名志愿者开发，它的软件库包含近50,000个二进制包（编译为8个处理器架构），有120个基于Debian的发行版和live CD。这些数字是任何其他基于Linux的操作系统无法比拟的。 Debian主要有三个主要分支（或四个，如果包括增加稳定性的“实验”分支）：“unstable”（也称为“sid”），“testing”和“stable ”。软件包和功能的逐步整合和稳定性，以及项目完善的质量控制机制，使得Debian获得了今天可用的最佳测试和无缺陷发行版之一的声誉。
Fedora Linux 是由 Red Hat 赞助的社区构建发行版，在被 IBM 收购之前，它是世界上最赚钱的开源公司。Red Hat 仍然是开源世界的巨头，为维护整个 Linux 生态系统所依赖的大部分软件和基础设施的开发人员付费。
Red Hat 并不直接开发 Fedora Linux，尽管该公司的一些员工是 Fedora 社区的成员。相反，Red Hat 使用 Fedora Linux 开发自己的独立产品 CentOS 和 Red Hat Enterprise Linux。这两个版本的 Linux 广泛用于企业界、学术机构或任何需要维护自己的服务器的人。
Fedora 提供易于学习的桌面，集成了大多数其他 Linux 发行版之前的最新功能，并内置了 SELinux 等安全工具。
Arch Linux 是在2002年由加拿大计算机科学专业毕业生Judd Vinet在2002年推出的，几年来，它一直是一个为中级和高级Linux用户设计的边缘项目。但是它“滚动更新”，只需要安装一次，然后保持一直更新，不要从头安装新的系统。这都要感谢其强大的包管理器和一个总是最新的软件库。因此，Arch Linux的“发行版”很少，而且现在只限于一个基本的安装光盘，只有在基本系统发生相当大的变化时，才会发行新的安装介质。
Arch Linux除了拥有备受推崇的“滚动发布”更新机制之外，还以其快速和强大的软件包管理器“Pacman”而闻名，能够从源代码安装软件包，并且由于其AUR基础架构，以及经过充分测试的软件包不断增加的软件库。其高度重视的文档，以及卓越的Arch Linux手册，使得一些高级Linux用户可以自行安装和定制分发。用户可以使用的强大工具意味着发行版可以无限定制到最细微的细节，并且没有两个安装可能是相同的。
引用于 哪个Linux发行版可以替代Ubuntu  
]]></content>
  </entry>
  
  <entry>
    <title>Linux 日志管理</title>
    <url>/post/linux/linux-system-log-management.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Log</tag>
    </tags>
    <content type="html"><![CDATA[Linux 日志管理是指对 Linux 系统中产生的各种日志文件进行收集、分析、备份、轮转和删除等操作，以便监控系统的运行状况，诊断和解决问题，提高系统的安全性和性能。
介绍 Linux 系统中有两种主要的日志服务，一种是传统的 rsyslog 服务，它是一个灵活的日志处理器，可以将日志信息发送到不同的目标，如文件、数据库、网络等。另一种是新添加的 systemd-journal 服务，它是一个二进制日志系统，可以存储更多的元数据，如时间戳、主机名、优先级等，并支持日志查询和过滤。
Linux 系统中的日志文件通常存放在 /var/log 目录下，不同的程序和服务会生成不同的日志文件，记录了各种类型的信息，如内核消息、用户登录事件、程序错误等。常见的日志文件及其存放内容如下：
   日志文件 存放内容     /var/log/message 内核消息及各种应用程序的公共日志信息，是 Red Hat Linux 中最常用的日志之一   /var/log/secure 与安全相关的日志信息   /var/log/maillog 与邮件相关的日志信息   /var/log/cron 与定时任务相关的日志信息   /var/log/dmesg 引导过程中的各种事件信息   /var/log/lastlog 每个用户最近一次登录信息   /var/log/wtmp 每个用户登录注销及系统启动和停机事件   /var/log/btmp 失败的、错误的登录尝试及验证事件    Linux 系统中的日志文件会定期进行轮转，即将旧的日志文件重命名并压缩，创建新的日志文件。这样可以避免日志文件占用过多的磁盘空间，并保留一定时间段内的日志记录。日志轮转由 logrotate 命令实现，它根据 /etc/logrotate.conf 和 /etc/logrotate.d/ 目录下的配置文件来执行轮转操作。这些配置文件可以指定轮转周期、轮转次数、轮转方式、轮转后执行的命令等。
 Linux 系统中有多种命令和工具可以用来查看和分析日志文件，例如： tail 命令：用于查看日志文件的最后几行，常用 -f 选项实时监控日志变化。 grep 命令：用于在日志文件中搜索特定的关键字或模式。 who 命令：用于查看当前登录到系统的用户信息。 last 命令：用于查看成功登录到系统的用户记录。 lastlog 命令：用于查看系统中所有用户最近一次登录信息。 lastb 命令：用于查看用户错误的登录列表。 Logcheck 工具：用于分析系统日志并报告异常或重要事件。 Logcheck 工具：用于分析系统日志并报告异常或重要事件。  相关软件包和配置文件 软件包 [root@Demo01 ~]# rpm -qa | grep rsyslog rsyslog-relp-8.24.0-57.el7_9.3.x86_64 rsyslog-libdbi-8.24.0-57.el7_9.3.x86_64 rsyslog-mmnormalize-8.24.0-57.el7_9.3.x86_64 rsyslog-mmjsonparse-8.24.0-57.el7_9.3.x86_64 rsyslog-crypto-8.24.0-57.el7_9.3.x86_64 rsyslog-gnutls-8.24.0-57.el7_9.3.x86_64 rsyslog-snmp-8.24.0-57.el7_9.3.x86_64 rsyslog-kafka-8.24.0-57.el7_9.3.x86_64 rsyslog-mysql-8.24.0-57.el7_9.3.x86_64 rsyslog-mmkubernetes-8.24.0-57.el7_9.3.x86_64 rsyslog-gssapi-8.24.0-57.el7_9.3.x86_64 rsyslog-mmaudit-8.24.0-57.el7_9.3.x86_64 rsyslog-mmsnmptrapd-8.24.0-57.el7_9.3.x86_64 rsyslog-8.24.0-57.el7_9.3.x86_64 rsyslog-pgsql-8.24.0-57.el7_9.3.x86_64 rsyslog-udpspoof-8.24.0-57.el7_9.3.x86_64 rsyslog-elasticsearch-8.24.0-57.el7_9.3.x86_64 rsyslog-doc-8.24.0-57.el7_9.3.noarch 配置文件 /etc/rsyslog.conf #主配置文件 /etc/rsyslog.d/*.conf #辅配置文件 /var/log/ #日志文件存放位置 /usr/sbin/rsyslogd #执行文件 /usr/lib64/rsyslog/ #模块路径 /usr/lib/systemd/system/rsyslog.service #服务单元 [root@Demo01 ~]# grep &#39;####&#39; /etc/rsyslog.conf #### MODULES ####定义模块 #### GLOBAL DIRECTIVES ####定义全局环境 #### RULES #### 定义规则 模块定义 module(load=&#34;imuxsock&#34; # 提供对本地系统日志的支持 SysSock.Use=&#34;off&#34;) # 关闭通过本地日志接口的信息接收功能，日志信息接收通过下面的imjournal模块 module(load=&#34;imjournal&#34; # 提供对systemd日志的访问 StateFile=&#34;imjournal.state&#34;) # 定义状态文件，rsyslog用于记录文件上传进度，避免日志内容混乱 全局环境设置 # 定义工作目录 global(workDirectory=&#34;/var/lib/rsyslog&#34;) # 使用默认的时间戳格式 module(load=&#34;builtin:omfile&#34; Template=&#34;RSYSLOG_TraditionalFileFormat&#34;) # 定义辅助配置文件位置 include(file=&#34;/etc/rsyslog.d/*.conf&#34; mode=&#34;optional&#34;) 规则设置 信息来源.安全级别 处理方式 信息来源 kern：内核相关的日志 user：用户相关的日志 mail：邮件相关的日志 daemon：系统服务相关的日志 lpr：打印相关的日志 cron：计划任务相关的日志 authpriv:认证相关的日志 news：新闻相关的日志 uucp：文件copy相关的日志 local0-local7：自定义相关的日志信息 *： 所有 安全级别 debug: 调试 info: 消息 notice: 注意 warn,warning: 警告 err,error: 错误 crit: 严重级别 alert: 需要立即修改该的信息 emerg,panic: 内核崩溃，系统接近崩溃 *：所有日志级别 none:没有任何级别，也就是不记录日志信息 表达形式 mail.err err+crit+alert+emerg mail.=err err mail.!err 除了err 处理方式 /PATH/FILENAME：将信息储存至 /PATH/FILENAME文件中。注意，如果要系统日志服务把信息储存到文件，该文件必须以 斜线（/） 开头的绝对路径命名之。 USERNAME：将信息送给已登录的用户。 @HOSTNAME：代表使用udp协议将信息转送到远端的日志服务器。 @@hostname：代表使用tcp协议将信息传送到远端的日志服务器 *：将信息传送给所有已登录的用户。 #### RULES #### ########## 日志设备.日志级别 ################## ######### 消息发送位置 ############### # Log all kernel messages to the console. # Logging much else clutters up the screen. #kern.* /dev/console # Log anything (except mail) of level info or higher. # Don&#39;t log private authentication messages! *.info;mail.none;authpriv.none;cron.none /var/log/messages # The authpriv file has restricted access. authpriv.* /var/log/secure # Log all the mail messages in one place. mail.* -/var/log/maillog # Log cron stuff cron.* /var/log/cron # Everybody gets emergency messages *.emerg :omusrmsg:* # Save news errors of level crit and higher in a special file. uucp,news.crit /var/log/spooler # Save boot messages also to boot.log local7.* /var/log/boot.log local2.info /tmp/test.log 日志设备    日志设备.级别 说明     auth -pam(linux中的认证机制) 产生的日志   authpriv -ssh,ftp 等登录信息的验证信息   cron 时间任务相关   kern -内核相关   lpr -打印   mail -邮件   mark(syslog) -rsyslog服务内部的信息,时间标识   news -新闻组   user -用户程序产生的相关信息   uucp -unix to unix copy unix主机之间的相关通信   local 1~7 自定义日志设备文件    日志级别    级别 说明     NONE 什么都不记录   EMERG (紧急) 导致主机系统不可用的情况   ALERT(警告) 必须马上采取解决措施   CRIT (严重) 比较严重的情况   ERR 运行时的错误   WARNING (提醒) 可能影响系统功能的事件   NOTICE(注意) 不会影响系统功能,但是值得注意   INFO 一般信息   DEBUG 调试信息    自下而上,信息记录的越来越少
常用的日志文件 /var/log/boot.log	#系统启动时的日志。 /var/log/dnf.* #dnf软件包管理器相关日志 /var/log/firewalld #防火墙日志 /var/log/lastlog #所有用户最后一次登录信息,需要使用lastlog命令查看 /var/log/maillog #电子邮件系统相关日志 /var/log/messages #整体的系统日志，具体记录范围取决于服务的配置文件 /var/log/wtmp	#记录当前登录和过去登录的用户信息，使用last命令查看 日志格式 [root@Demo01 ~]# tail -n 20 /var/log/messages Jul 1 05:05:41 LAMP dhclient[2115]: bound to 192.168.10.25 -- renewal in 736 seconds. Jul 1 05:05:41 LAMP systemd: Starting Network Manager Script Dispatcher Service... Jul 1 05:05:41 LAMP dbus[777]: [system] Successfully activated service &#39;org.freedesktop.nm_dispatcher&#39; Jul 1 05:05:41 LAMP systemd: Started Network Manager Script Dispatcher Service. DATE TIME HOSTNAME APP（NAME）[PID]: MESSAGES 每一个字段的意义如下说明： DATE：信息发生的日期。 TIME：信息发生的时间。 HOSTNAME：信息发生的主机。 APP：产生信息的软件。 NAME：软件的名称，或是软件组件（Component）的名称。可以省略。 PID：进程标识符 （Process ID）。可以省略。 MESSAGES：信息的内容。 Sep 15 09:03:59 ecs-t6-large-2-linux-20190824103606 systemd-logind: New session 314 of user root. 时间 主机名 子系统名 消息字段 ]]></content>
  </entry>
  
  <entry>
    <title>C++中fmt库的用法</title>
    <url>/post/programming/fmt-lib-usage-in-c-plus-plus.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C++</tag>
      <tag>fmt</tag>
    </tags>
    <content type="html"><![CDATA[本来这篇文章应该接着介绍 memset 的，但是我暂时不想写那个主题。这次就写点新的东西。介绍一下 fmt 库。
介绍与安装 {FMT} 是一个开源格式库，按照作者的说法，是提供快速和安全的 替代 C 的 stdio 和 C++ 的iostreams。
项目地址：https://github.com/fmtlib/fmt
下载最新版的 release 文件即可，将 fmt-10.0.0/include/fmt/core.h include 进来就完成了。其实还可以用 CMake 的，但是今天介绍的重点在语法，所以我就直接单文件 include 了。
据说这个库进入了 C++ 20 当中，不清楚，毕竟我用的还是 C++ 11
用法 最简单的输出就是 print
#define FMT_HEADER_ONLY #include &#34;fmt-10.0.0/include/fmt/core.h&#34; int main() { fmt::print(&#34;Hello fmt!&#34;); } 这样其实和正常的 printf 没有什么区别？C++相对C的最大区别之一就是尽可能地追求typesafe，所以C++从一开始就在寻找替代printf系列函数的解决方案，于是从一开始就有了各种各样的ostream。typesafe是做到了，但是性能低下。三方库 fmt 就是想既解决 typesafe ，也想要一定的性能。
参数替换 类似于 printf 的 % 占位符输出，fmt 使用大括号替代参数。
fmt::print(&#34;Also {}&#34;,&#34;hello fmt!&#34;); 输出结果：
Also hello fmt! 其实这种语法有点类似于 Vue.js 的设计。据说是未来的趋势。。。
另一个有效的函数是 fmt::format，所以上面的输出也可以写成
std::string hello_buffer = fmt::format(&#34;Also {}&#34;,&#34;hello fmt!&#34;); fmt::print(&#34;{}&#34;,hello_buffer); 另外，和 cout 一样，fmt 输出对参数是无关的。
fmt::println(&#34;{}&#34;,4.12); 这样的也是可以正常输出的。
参数格式设计 在大括号内可以对格式进行处理，printf 也有类似的功能，但据说 fmt 的功能更加全面？而且 fmt 利用 format 可以直接处理字符串，这点是 printf 没有的。
但是网上针对这个库的文章很少。。。我也是第一次用，所以只能贴出我整理到的用法了。
大括号的参数分为前后两部分，分别为为位置参数（arg_id）和格式化参数（format_spec）。前者用来显式声明参数在字符串中的位置，后者对值进行一定的格式化转换。（这两个是我翻译的，毕竟官网也没有这俩的中文翻译。。。）
位置参数 官方对位置参数的解释是用正则表达式。。。
replacement_field :: = &#34;{&#34;[arg_id][&#34;:&#34; format_spec] &#34;}&#34; arg_id :: = integer | identifier integer :: = digit + digit :: = &#34;0&#34;...&#34;9&#34; identifier :: = id_start id_continue* id_start :: = &#34;a&#34;...&#34;z&#34; | &#34;A&#34;...&#34;Z&#34; | &#34;_&#34; id_continue :: = id_start | digit 简单解释下吧 从0开始，然后1、2、3，等等
fmt::println(&#34;{0} + {1} = {2}&#34;,2,3,5); //2 + 3 = 5 如果没有指定位置，默认从0往后排
fmt::println(&#34;{} + {} = {}&#34;,2,3,5); //2 + 3 = 5 参数位置与值是一一对应的，所以可以交换顺序
fmt::println(&#34;{1} + {2} = {0}&#34;,5,2,3); //2 + 3 = 5 如果你不想用数字，也可以用fmt::arg指定别名参数
fmt::print(&#34;Hello, {name}! The answer is {number}. Goodbye, {name}.&#34;, fmt::arg(&#34;name&#34;, &#34;World&#34;), fmt::arg(&#34;number&#34;, 42)); //Hello, World! The answer is 42. Goodbye, World. 格式化参数 可选的arg_id放在format_spec的后面，其后是冒号'：'。
]]></content>
  </entry>
  
  <entry>
    <title>浮点数比较问题</title>
    <url>/post/linux/floating-point-comparison-problem.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Linux</tag>
      <tag>Float Point</tag>
    </tags>
    <content type="html"><![CDATA[在C语言中，使用浮点型进行比较可能会出现误差，那么究竟是什么原因呢？
浮点比较出现误差的原因 在C语言中，使用浮点型进行比较可能会出现误差的原因主要有以下几点：
 浮点数舍入误差：由于计算机对浮点数的表示方式是有限的，无法精确表示所有实数。在进行浮点数运算时，会存在舍入误差，这可能导致两个看似相等的浮点数实际上是略微不同的。 浮点数精度限制：浮点数在计算机中以二进制表示，因此只能表示一定范围的实数。对于超出这个范围的数值，浮点数将近似表示，从而引入了误差。 运算顺序和优化：浮点数的运算顺序可能会影响最终结果，特别是当运算涉及到大量的累加操作时。此外，编译器的优化过程也可能对浮点数进行重排或合并，导致结果与预期不符。  解决此问题的方法 为了解决浮点数比较容易出错的问题，可以采取以下措施：
 使用误差范围比较：而不是直接比较两个浮点数是否相等，可以通过定义一个允许的误差范围（例如 epsilon），然后判断两个浮点数之间的差值是否小于该误差范围。 使用整数比较：将浮点数转换为整数的形式，然后进行比较。这种方法可以避免浮点数运算中的舍入误差。但需要注意整数溢出的问题。 避免直接比较浮点数：尽量避免直接使用 == 运算符来比较浮点数是否相等，而是使用其他方式，如比较它们的差值或比例，以减少精度误差的影响。 使用更高精度的数据类型：如果对于高精度的计算要求较高，可以考虑使用库函数提供的更高精度的数据类型，例如 long double 或者自定义的高精度计算库。 注意浮点数的运算顺序和优化：合理安排浮点数的运算顺序，避免大量累加操作的积累误差。同时，可以通过调整编译器的优化选项来控制浮点数运算的行为。  综上所述，使用浮点数进行比较时，要注意浮点数运算的特性，并选择合适的比较方法。根据具体需求，可以采用上述解决办法来减小误差并提高比较的准确性。
使用误差范围方法实现浮点比较的代码 在C语言中，可以使用以下方法来比较浮点数：
 使用差值的绝对值进行比较：  #include &lt;math.h&gt; int compare_float(float a, float b, float epsilon) { if (fabs(a - b) &lt;= epsilon) { return 0; // a 和 b 相等  } else if (a &lt; b) { return -1; // a 小于 b  } else { return 1; // a 大于 b  } } 在上面的示例中，compare_float 函数通过计算两个浮点数 a 和 b 的差的绝对值，并与给定的精度 epsilon 进行比较。如果差的绝对值小于等于 epsilon，则返回0表示两个浮点数相等，否则根据大小关系返回 -1 或 1。
使用 &lt;, &gt;, == 操作符进行比较：  int compare_float(float a, float b, float epsilon) { if (a + epsilon &lt; b) { return -1; // a 小于 b  } else if (a - epsilon &gt; b) { return 1; // a 大于 b  } else { return 0; // a 和 b 相等  } } 上述代码使用 &lt; 和 &gt; 操作符将带有一定误差范围的比较转换为数值的大小比较。
这些方法都需要在比较时指定一个误差范围 epsilon，你可以根据具体情况选择一个适当的值。
请注意，在使用这些方法比较浮点数时，由于浮点数的精度限制，结果可能受到舍入误差的影响。因此，仍然需要谨慎比较浮点数并注意误差范围的选择。
浮点误差范围 epsilon如何确定 确定浮点误差范围 epsilon 的值是一个复杂的问题，因为它取决于许多因素，例如应用的要求、数据的特征以及浮点数运算的性质。下面是几种常见的方法来选择合适的 epsilon 值：
 了解浮点数表示：首先，了解浮点数在计算机中的表示方式和精度限制是很重要的。浮点数由尾数和指数组成，在计算过程中可能会产生舍入误差。这样的了解有助于你理解浮点误差的本质，从而选择一个适当的 epsilon 值。 预估误差：根据你对浮点数操作的预期误差，选择一个合理的 epsilon 值。根据具体应用的需求，确定你对结果精度的要求。例如，如果你需要高精度计算，那么 epsilon 应该设置得更小；如果你可以容忍一定的近似误差，那么可以选择相对较大的 epsilon 值。 观察数据集：观察你的数据集中浮点数的典型差异和范围。根据数据的分布情况来选择一个合适的 epsilon 值。例如，如果数据集中的浮点数差异较小，那么可以选择较小的 epsilon 值。 考虑数值范围：浮点数在不同数量级上可能会有不同的精度要求。当比较较大或较小的浮点数时，可能需要相应地调整 epsilon 的值。例如，对于接近 0 的浮点数，可能需要选择较小的 epsilon 值来确保精度。 实验和测试：通过在你的具体应用场景中运行实验和测试，观察不同 epsilon 值下的结果差异，选择一个最合适的值。可以通过与预期结果进行比较，并评估 epsilon 值对应用的性能和准确性的影响。  需要注意的是，选择 epsilon 值是一个折衷问题，过小的值可能导致计算开销增加，而过大的值可能无法满足精度要求。根据具体情况，在实际应用中可以尝试不同的 epsilon 值，并评估其对结果的影响，以找到最适合你应用的值。
]]></content>
  </entry>
  
  <entry>
    <title>FPGA时序约束--实战篇</title>
    <url>/post/fpga/fpga-timing-constraints.html</url>
    <categories><category>FPGA</category>
    </categories>
    <tags>
      <tag>FPGA</tag>
      <tag>Xilinx</tag>
    </tags>
    <content type="html"><![CDATA[前面几篇文章介绍了“如何写时序约束”和“如何看懂时序约束报告”，这些知识点都是基础，可以知道设计的HDL代码不收敛的位置，但解决时序收敛问题更关键。
 FPGA  时序不收敛，会出现很多随机性问题，上板测试大概率各种跑飞，而且不好调试定位原因，所以在上板测试前，先优化时序，再上板。
今天我们就来唠一唠解决时序不收敛的问题，分享一些常用的解决办法和思路。
模块运行时钟频率 设计模块前，需明确模块运行的最大时钟频率。
不同时钟频率下，对应的时序约束最大延时是不一样的。
比如100MHz时钟下运行的HDL逻辑，比200MHz时钟下的HDL逻辑，支持的组合逻辑层数多。
根据最大时钟频率，来设计HDL代码的层级，时钟频率越高，插入寄存器要更多，增加流水线级数，减少过长的组合逻辑。
HDL代码  HDL代码风格  优先参考FPGA开发软件提供的HDL Template，比如Vivado的language template。
HDL代码逻辑优化  对于复杂的算法代码逻辑，需要结合FPGA并行计算和最小处理单位为bit的特性，对逻辑代码进行优化实现。
明确变量最大的数据位宽。
逻辑代码中，一些软件逻辑实现起来较复杂，尽量简化，删除掉一些不可能出现的情况。
这部分代码逻辑，可能需要重复迭代几遍实现才行。
组合逻辑层数  插入寄存器  将计算逻辑分成多个时钟周期实现，这是常用的时序优化方法，可以减少过多的组合逻辑层数，但会增加延时。
这里以一个多路输入求和计算为例
module sum( input clk, input [15:0] data_A, input [15:0] data_B, input [15:0] data_C, input [15:0] data_D, output [17:0] sum_o); always @(posedge clk) begin sum_o &lt;= data_A + data_B + data_C + data_D; end endmodule 增加寄存器后，改为
module sum( input clk, input [15:0] data_A, input [15:0] data_B, input [15:0] data_C, input [15:0] data_D, output [17:0] sum_o); reg [16:0] sum0, sum1; always @(posedge clk) begin sum0 &lt;= data_A + data_B; sum1 &lt;= data_C + data_D; end always @(posedge clk) begin sum_o &lt;= sum0 + sum1; end endmodule 逻辑展平设计  优化代码中优先级译码电路逻辑，主要出现在IF/ELSE结构语句中，这样逻辑结构被展平，路径延迟得以缩短。
IF ELSE结构语句存在明显的优先级，建议尽量用CASE语句来替代。
防止变量被优化  HDL综合布线软件会根据实际情况，自动优化代码逻辑，可能存在将多个不同寄存器变量合并成一个寄存器变量的情况。
对于不希望被优化的变量，可以在变量定义前，添加（* keep = &ldquo;ture&rdquo; *）
高扇出 高扇出问题，原因是一个寄存器驱动后级数超过了它本身的驱动能力，导致延迟时间过大，不满足时序。
 使用max_fanout  在变量定义前，可以添加(* max_fanout = n *)，来设置变量的最大扇出数，超过这个扇出数，综合软件会自动复制多份变量。
复位信号高扇出  复位信号是常见的高扇出问题，主要解决办法有：
 减少复位信号的使用，能使用使能信号控制的，就用使能信号。 对于大型模块，复位信号可以使用BUFG来驱动复位信号，可以增加复位信号的驱动能力  资源消耗 FPGA器件的整个工程资源消耗，不管是LUT还是BRAM等资源，建议不超过80%。
一旦资源消耗超过80%，在布线综合时，就出现布线资源不够，导致出现布线拥塞，从而出现了时序不收敛的情况。
布线拥塞也分为全局拥塞和局部拥塞，可能是高扇出信号过多，也可能是局部布线资源不够用，导致时序路径过长。
 优化代码逻辑，减少资源消耗。  在资源不够用的情况下，建议检查代码是否可优化，设置的RAM大小是否过大等等。
使用替代资源实现  在FPGA中实现RAM时，可以根据整个资源的使用情况，考虑使用Distributed RAM、URAM等资源来减少BRAM的消耗。
总结 本文分享了时序收敛的一些方法和思路，希望可以给大家带来一点启发。
]]></content>
  </entry>
  
  <entry>
    <title>ZYNQ 读写SD卡</title>
    <url>/post/fpga/read-and-write-sd-card-through-Xilinx-ZYNQ.html</url>
    <categories><category>FPGA</category>
    </categories>
    <tags>
      <tag>FPGA</tag>
      <tag>Xilinx</tag>
      <tag>ZYNQ</tag>
      <tag>SD</tag>
    </tags>
    <content type="html"><![CDATA[SD卡（Secure Digital Card）是一种常用的可移动存储设备，广泛应用于嵌入式系统中。它具有体积小、容量大、读写速度快、易于携带等特点，在数据存储和传输中发挥着重要的作用。
前言 本实验介绍如何使用Xilinx ZYNQ芯片在SD卡上读写文件。
Zynq芯片具有SD卡接口，通过该接口可以实现对SD卡的读写操作。SD卡接口通常是通过SPI（Serial Peripheral Interface）或SDIO（Secure Digital Input Output）协议实现的。SPI协议适用于低速的SD卡读写操作，而SDIO协议则适用于高速的读写操作。
FatFs库 本实验是通过调用FatFs库来对SD卡进行读写。
FatFs是一个开源的文件系统模块，提供了简单而灵活的接口，使嵌入式应用程序能够轻松地读取、写入和管理存储在FAT文件系统中的文件。
FatFs支持FAT12、FAT16和FAT32三种主要的FAT文件系统类型，这些类型广泛应用于各种存储介质，如磁盘、SD卡和USB闪存驱动器等。它被广泛用于嵌入式系统中。
FatFs的特点和功能包括：(1)轻量级和可移植性，它的核心代码非常精简，可以根据系统的需求进行裁剪和配置。它的接口设计独立于底层的存储介质和操作系统，因此可以轻松地移植到不同的平台上。(2)多种API函数，用于打开、关闭、读取、写入和管理文件以及目录操作。(3)支持长文件名。(4)可选的缓存机制，FatFs提供了可选的缓存机制，可以加快对存储介质的访问速度。(5) 可靠性和错误处理。
Vivado工程的编写 我们使用的开发板为ZedBoard。
  本实验使用的Vivado工程延用《ZYNQ 串口打印输出——FPGA Vitis篇》中使用的Vivado工程，大家可以查看该文章来了解Vivado工程的建立。
  修改Vivado工程，勾选SD 0外设。
  我们使用的开发板为ZedBoard，相关SD卡原理图如下图所示。  按照原理图的管脚连接方式，设置好MIO Configuration。
 保存设计，右键点击.bd文件，选择“Generate Output Products…”。
  右键点击.bd文件，选择“Create HDL Wrapper…”。弹出的窗口中选择“Let Vivado manage wrapper and auto-update”，点击“OK”。
  点击Vivado “Flow Navigator”一栏里的“Generate Bitstream”，等待Vivado生成好bit文件后，在菜单栏“File -&gt; Export -&gt; ExportHardware&hellip;”导出硬件信息(.xsa文件)，这里就包含了PS端的配置信息。该步骤如有疑问，可以参考以前的文章《ZYNQ串口打印输出——FPGA Vitis篇》。
  Vitis工程的编写  点击 Vivado 菜单“Tools-&gt; Launch Vitis IDE”，启动 Vitis。 新建 Vitis平台工程。Vitis工程的建立可以参考以前的文章《ZYNQ串口打印输出——FPGA Vitis篇》。 新建 Vitis应用工程，创建一个名为“SD_DEMO_SDK”的工程，工程模板可以选择“Hello World”。 在工程平台的Board Support Package Settings里勾选上xilffs文件系统。注意是“standalone alone”模式下。  工程主要包含两个文件：main.c、bmp.h。  bmp.h里包含了各种不同像素图片的数据头定义。 main.c里包含3个函数：
void genTestImage(u8 * imageSrc); void bmp_write(char * name, char *head_buf, char *data_buf); int main(void); 该工程示例是先通过genTestImage函数生成一张像素为640*480的彩条图片。然后再通过bmp_write函数将图片的数据头（*head_buf）以及图片数据本身（*data_buf）写入SD卡。
 编译工程，将工程下载到硬件板卡上，硬件板卡插上待写入数据的SD卡。
  程序运行完后，串口会打印“sd card write done!”信息。
  开发板断电，将SD卡插入到电脑上的读卡器。可以在文件游览器看到，此时SD卡上多了一个“COLOR.BMP”文件，打开该文件，可以发现正是我们用genTestImage函数生成一张像素为640*480的彩条图片。  实验小结 本实验介绍了如何通过调用FatFs库来加载SD卡、在SD卡上创建文件并写入文件。同理读取SD卡上文件是调用FatFs库的f_read函数。本工程的部分源码见附录A。该工程对应的完整源码可以在公众号输入ZYNQ_SD来获取工程的下载链接，工程采用的是Vivado2021.1版本。
附录 A
int main(void) { FRESULT rc; genTestImage(gImage_640x480); rc = f_mount(&amp;fatfs, &#34;0:/&#34;, 0); if (rc != FR_OK) { return 0 ; } bmp_write(&#34;color.bmp&#34;, (char *)&amp;BMODE_640x480, (char *)&amp;gImage_640x480) ; xil_printf(&#34;sd card write done! \n\r&#34;); return 0; } void genTestImage(u8 * imageSrc) { int total = 0; for (int idxRow = 0; idxRow &lt; 480; idxRow++) { for (int idxCol = 0; idxCol &lt; 640; idxCol++) { if ( idxCol &gt;= 0 &amp;&amp; idxCol &lt; 213) { *(imageSrc + (640*idxRow + idxCol)*3) = 0xFF; *(imageSrc + (640*idxRow + idxCol)*3 + 1) = 0x00; *(imageSrc + (640*idxRow + idxCol)*3 + 2) = 0x00; } else if ( idxCol &gt;= 213 &amp;&amp; idxCol &lt; 426) { *(imageSrc + (640*idxRow + idxCol)*3) = 0x00; *(imageSrc + (640*idxRow + idxCol)*3 + 1) = 0xFF; *(imageSrc + (640*idxRow + idxCol)*3 + 2) = 0x00; } else if ( idxCol &gt;= 426 &amp;&amp; idxCol &lt; 640) { *(imageSrc + (640*idxRow + idxCol)*3) = 0x00; *(imageSrc + (640*idxRow + idxCol)*3 + 1) = 0x00; *(imageSrc + (640*idxRow + idxCol)*3 + 2) = 0xFF; } total++; } } } void bmp_write(char * name, char *head_buf, char *data_buf) { short y,x; short Ximage; short Yimage; u32 iPixelAddr = 0; FRESULT res; unsigned int br; // File R/W count  memset(&amp;Write_line_buf, 0, 1920*3) ; res = f_open(&amp;fil, name, FA_CREATE_ALWAYS | FA_WRITE); if(res != FR_OK) { return ; } res = f_write(&amp;fil, head_buf, 54, &amp;br) ; if(res != FR_OK) { return ; } Ximage=(unsigned short)head_buf[19]*256+head_buf[18]; // bm_width  Yimage=(unsigned short)head_buf[23]*256+head_buf[22]; // bm_height  iPixelAddr = (Yimage-1)*Ximage*3 ; for(y = 0; y &lt; Yimage ; y++) { for(x = 0; x &lt; Ximage; x++) { Write_line_buf[x*3 + 0] = data_buf[x*3 + iPixelAddr + 0] ; Write_line_buf[x*3 + 1] = data_buf[x*3 + iPixelAddr + 1] ; Write_line_buf[x*3 + 2] = data_buf[x*3 + iPixelAddr + 2] ; } res = f_write(&amp;fil, Write_line_buf, Ximage*3, &amp;br) ; if(res != FR_OK) { return ; } iPixelAddr -= Ximage*3; } f_close(&amp;fil); } ]]></content>
  </entry>
  
  <entry>
    <title>手把手教你在嵌入式设备中使用SQLite3</title>
    <url>/post/linux/how-to-use-SQLite3-in-embedded-devices.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Linux</tag>
      <tag>SQLite3</tag>
    </tags>
    <content type="html"><![CDATA[数据库是用来存储和管理数据的专用软件，使得管理数据更加安全，方便和高效。数据库对数据的管理的基本单位是表(table)，在嵌入式linux中有时候它也需要用到数据库，听起来好难，其实就是几个函数，掌握了就好。
常见的数据库 大型数据库(大型机)Oracle(亿级)，中型数据库(分布式超大型)mysql(百万级)，轻型数据库(嵌入式设备)sqlite(万级)，访问数据库使用SQL语句，适用于所有的数据库。
安装SQLite3 有C环境就可以调用sqlite
直接用命令安装 sudo apt-get update sudo apt-get install sqlite3 直接编译源码 将源码拷贝到Ubuntu的非共享目录解压
解压命令：
tar zvxf sqlite-autoconf-3380500.tar.gz 配置
cd sqlite-snapshot-201708031550 ./configure --prefix=/home/gec/sqlite 编译
make 安装
make install SQLite的使用 新建数据库文件
sqlite3 数据库文件的路径 //打开/创建 //比如：sqlite3 first.db 基本操作命令 .exit/.quit -------- 退出数据库命令行 .help -------------- 帮助说明信息 .tables ------------ 查看当前数据库中所有的表 数据库访问的SQL语句 基本语法：
所有的SQL语句都以分号(;)结束 不区分大小写 新建表格 create table 表名(字段名1 字段类型1,字段名2 字段类型2,字段名3 字段类型3,...); 比如： //创建一个stutbl的表，表中有3个字段 //分别是整数类型的学号id,字符串类型的name和整数类型的age create table zhiguoxin(id int,name char[20],age int); //不存在则创建 create table if not exists zhiguoxin(id int,name char[20],age int); //如果希望表中某个字段的内容不重复,可以用unique修饰该字段 create table if not exists zhiguoxin(id int unique,name char[20],age int); 删除表格 drop table 表名; //drop table zhiguoxin; 往表格中插入数据 insert into 表名 values(字段值1,字段值2,字段值3,....); //字段值如果是字符串,必须用&#39;&#39;(单引号)括起来 比如： insert into zhiguoxin values(1001,&#39;刘尧&#39;,18); insert into zhiguoxin values(1002,&#39;聂衍文&#39;,19); insert into zhiguoxin values(1003,&#39;杨佳晨&#39;,20); insert into zhiguoxin values(1004,&#39;冯华阳&#39;,21); 完成插入之后，zhiguoxin 的表格内容如下：
id	name	age 1001	刘尧	18 1002	聂衍文	19 1003	杨佳晨	20 1004	冯华阳	21
查询表中的数据 //查询表中的所有数据
select * from 表名; //select * from zhiguoxin; 查看数据库 可以把first.db数据库文件拷贝至windows下，使用SQLite Developer打开即可看到。SQLite Developer下载地址
https://mydown.yesky.com/pcsoft/443425.html 按条件查找  使用where指定查询条件  select * from zhiguoxin where id=1003;//查询id值为1003的条目 select * from zhiguoxin where age&gt;=19 and age&lt;21; select * from zhiguoxin where age&gt;=19 or age&lt;21; 指定查询的字段  select id,name,age from zhiguoxin;//只查询id,name,age的字段 使用where+like实现模糊查询  select * from zhiguoxin where name like &#39;刘%&#39;;//查找名字以刘开头的条目 使用order by实现查询结果按某个字段的值升序/降序输出  select * from zhiguoxin order by age desc;//按年龄降序排序 select * from zhiguoxin order by id asc; //按id升序排序 删除表中的条目 delete from 表名 where 条件;//删除所有符合条件的条目 比如： delete from zhiguoxin where id=1001; 更新(修改)表中的条目 update 表名 set 字段名1=字段值1,字段名2=字段值2... where 条件;//修改符合条件的条目 比如： update zhiguoxin set age=100 where id=1002; SQLite中字段类型 数字：
int ------- 整型 smallint ---- 短整型 tinyint ----- 微型整数(0~255) bit --------- 0 or 1 float ------ 单精度浮点型 real ------- 双精度浮点型 字符串：
char ---------- 非unicode定长字符串 &lt; 8000 varchar ------- 非unicode变长字符串 &lt; 8000 text ---------- 非unicode变长字符串 &lt; 2^32-1 nchar ---------- unicode定长字符串 &lt; 8000 nvarchar ------- unicode变长字符串 &lt; 8000 ntext ---------- unicode变长字符串 &lt; 2^32-1 SQLite的C语言访问接口 sqlite本身自带C语言访问接口，在C语言的环境下可以直接使用，使用这些接口的代码需要 sqlite的源码编译进可执行程序 或者 编译时链接sqlite的库。
打开 sqlite3_open int sqlite3_open( const char *filename, /* 数据库的文件路径 */ sqlite3 **ppDb /* 输出参数：传出代表打开数据库的句柄 */ ); //成功返回SQLITE_OK,否则打开失败char ---------- 非unicode定长字符串 &lt; 8000 varchar ：非unicode变长字符串 &lt; 8000 text ：非unicode变长字符串 &lt; 2^32-1 nchar：unicode定长字符串 &lt; 8000 nvarchar : unicode变长字符串 &lt; 8000 ntext :unicode变长字符串 &lt; 2^32-1 关闭 sqlite3_close int sqlite3_close(sqlite3 *pDb); //传入要关闭的数据库的句柄 编译方法  直接编译源码  gcc sqlite3.c sqlite_test.c -pthread -ldl -o sqlite_test 链接sqlite3的动态库  gcc sqlite_test.c -pthread -ldl -lsqlite3 -L /home/gec/sqlite/lib -o sqlite_test //如果运行时找不到sqlite3的库，可以将编译出来的库文件拷贝到/usr/lib目录下(cp -r) 执行SQL语句的接口 sqlite3_exec int sqlite3_exec( sqlite3 *pDb, /* 打开的数据库的句柄 */ const char *sql, /* 要执行的SQL语句 */ int (*callback)(void *arg,int col,char **str,char **name), /* 回调函数,处理SQL语句执行返回的结果(查询),一条结果调用一次 arg - exec的第四个参数 col - 本条结果的字段数 str - 记录字段值的数组 name - 记录字段名的数组 回调函数必须返回SQLITE_OK */ void *arg, /* 传递给回调函数的第一个参数 */ char **errmsg /* 错误信息 */ ); //成功返回SQLITE_OK,否则执行失败 几个例子
//连接数据库 int Connection_Sqlite3DataBase() { rc = sqlite3_open(&#34;./face_database/face.db&#34;, &amp;db); if (rc != SQLITE_OK) { fprintf(stderr, &#34;Can&#39;t open database: %s\n&#34;, sqlite3_errmsg(db)); sqlite3_close(db); exit(1); } else printf(&#34;You have opened a sqlite3 database named bind.db successfully!\nCongratulation! Have fun!\n&#34;); return 0; } //将图片插入到数据库 void insert_face_data_toDataBase(const char *name, MByte *face_feature, MInt32 featureSize) { sqlite3_prepare(db, &#34;insert into face_data_table(name,face_feature,feature_size) values (?,?,?);&#34;, -1, &amp;stmt, NULL); sqlite3_bind_text(stmt, 1, name, strlen(name), NULL); sqlite3_bind_blob(stmt, 2, face_feature, featureSize, NULL); sqlite3_bind_int(stmt, 3, featureSize); sqlite3_step(stmt); } ]]></content>
  </entry>
  
  <entry>
    <title>Intel驱动开始默认搜集数据：NVIDIA强制、AMD良心</title>
    <url>/post/news/Intel-driver-starts-to-collect-data-by-default.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Intel</tag>
      <tag>AMD</tag>
      <tag>NVIDIA</tag>
    </tags>
    <content type="html"><![CDATA[Intel最近发布了101.4578 Beta测试版显卡驱动，重点支持Arc锐炫系列，但在常规更新之外，还有一个隐藏点。
在安装过程中，选择典型模式，会出现一个“Compute Improvement Program”(CIP)的新选项，字面意思就是“计算改进项目”，默认勾选。
它和所有类似的改进项目一样，都是用来搜集数据的。
按照Intel的解释，为了改进Arc显卡的性能、功能、使用体验，CIP项目会搜集用户的电脑使用习惯、系统信息、其他设备信息、访问网站(不包含URL链接)等。
其中，使用信息包括：显卡频率、驱动软件使用时长、系统内存占用量、笔记本电池续航时间、即插即用设备等等。
系统信息包括但不限于：设备制造商、CPU型号、内存与显示配置、操作系统版本、软件版本、区域和语言设置、位置与时区等等。
Intel还强调，绝对不会搜集用户姓名、地址、邮箱、手机号等敏感个人信息。
这些操作其实都属于厂商们的常规操作，只是默勾选，确实有点让人感觉不太舒服。
不过，Intel还不算过分的， NVIDIA  最狠，GeForce显卡驱动默认强制开启数据收集功能，而且不可关闭，自定义安装也不行。
AMD会在Adrenalin显卡驱动安装结束时给出选择，不管典型、仅驱动、自定义哪种安装方式，都可以选择开关数据搜集功能。
但不管怎么说，NVIDIA的卡现在就是牛啊，不管游戏卡还是加速卡。
尽管OpenAI CEO之前否认，但业界还是相信他们已经在训练GPT-5大模型，规模将是GPT-4的10倍以上，但这也意味着更烧钱，尤其是用于训练AI的显卡极为稀缺。
全球这么多搞AI大模型的，到底用了多少AI显卡是各家的秘密，很少公开准确数据，GPT-4猜测是在10000-25000张A100显卡上训练的，GPT-5所需的显卡还是迷，马斯克估计的是30000-50000张H100显卡，性能强得多。
除了OpenAI之外，其他公司对高性能AI显卡的需求也居高不下，Meta、谷歌、微软、苹果、特斯拉及马斯克自己都在搞各种AI，预测总需求高达43.2万张H100显卡，价值超过150亿美元。
这还只是国外网友分析的美国科技行业需求，实际上国内的需求不比美国少，即便只能购买特供版的A800、H800加速卡，但这没有妨碍国内公司投身AI大模型，不惜加价抢购AI显卡。
在当前的市场上，只有NVIDIA才能满足AI显卡的需求，AMD及Intel的AI显卡不仅性能、生态上存在问题，而且供货也跟不上，AMD的大杀器MI300X要到年底才能出货，2024年才能大批量上市。
归根到底，这波又是NVIDIA赚麻了，AI显卡的需求将持续到2024年底，这一年半中都是供不应求的情况，H100显卡售价25万元起步，加价的话就难说了，涨幅波动很大。
]]></content>
  </entry>
  
  <entry>
    <title>不让NVIDIA吃独食！AMD下一代Zen5大杀器在路上</title>
    <url>/post/news/AMD-next-generation-zen5-is-on-the-way.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>AMD</tag>
      <tag>Zen5</tag>
      <tag>AI</tag>
      <tag>Intel</tag>
      <tag>NVIDIA</tag>
    </tags>
    <content type="html"><![CDATA[AI硬件市场上，NVIDIA可谓呼风唤雨，旗下的A100、H100加速器炙手可热。
Intel、AMD也都在积极投入相关产品，前者主要是GPU Max系列，后者主要是Instinct MI系列。
不久前，AMD刚刚正式推出了MI300系列加速器，其中MX300X首次将Zen4 CPU、CDNA3 GPU架构合二为一，并集成多达128GB HBM3，MI300A则是纯GPU方案，配备192GB HBM3。
据说还有MI300C、MI300P两种版本，前者是纯CPU架构，后者则是MI300X的精简版，规模砍半。
按照规律，这一代产品发布了，下一代产品肯定已经在积极研发中了，但是能从CEO口中确认下一代的名字，还不多见。
AMD CEO苏姿丰近日表示，AMD持续在AI方面投资，包括下一代MI400系列加速，以及再下一代、再下一代。
苏姿丰还强调，AMD不但有极具竞争力的AI硬件路线图，还会在软件方面做出一些改变。
她没有透露更具体的细节，猜测可能终于要大幅革新AMD ROCm开发框架了，不然永远打不过NVIDIA CUDA。
不出意外的话，MI400系列应该会上Zen5 CPU、CDNA4 GPU两大新架构，既有CPU+GPU融合方案，也有纯GPU方案。
传闻称，AMD正在开发全新的XSwitch高速互连总线技术，对标NVIDIA NVLink，这对于大规模HPC、AI运算来说是至关重要的。
今年AI火爆全球，导致NVIDIA的AI显卡成为香饽饽，需求大涨之下价格也失控了，这几个月不时传出缺货涨价的消息，最夸张的说是H100这样的显卡涨到了50万一块，是原价的2倍。
NVIDIA的AI显卡加价抢购，还有个重要原因是就是市场上没有什么可替代的产品，之前几乎是NVIDIA一家独大，好在下半年AMD的MI300系列AI加速卡就要上市了。
为了跟NVIDIA抢市场，AMD这一波是准备充分了。
在日前的财报会议上，CEO苏姿丰提到他们正在增加AI相关的支出，并且制定了AI战略，在AI硬件芯片及软件开发上下功夫。
针对MI300芯片的产能担忧，苏姿丰提到尽管当前供应链依然吃紧，但他们已经包下了供应链的产能，包括AI芯片不可或缺的台积电CoWos封装及HBM显存等芯片产能。
AMD表示从芯片制造到封装，以及零部件等，MI300系列显卡这次已经确保了充足的产能，在2023年4季度到2024年会大幅扩产，确保满足客户需求。
]]></content>
  </entry>
  
  <entry>
    <title>DDR的工作原理</title>
    <url>/post/hardware/ddr-working-principle.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>DDR</tag>
      <tag>Double Data Rate</tag>
      <tag>SDRAM</tag>
      <tag>DDR4</tag>
      <tag>DDR5</tag>
    </tags>
    <content type="html"><![CDATA[在本专栏中，我们将由浅入深地讲述如何利用FPGA开发DDR接口。首先，我们将回顾DDR协议的基本原理和工作机制；然后介绍FPGA开发DDR接口时需要用到的IP核及使用方法；随后，验证我们开发的接口功能是否正确；最后向大家介绍几种在 FPGA中实用的DDR接口应用方法。
前言 最近几期，我们将通过专栏的方式向大家介绍一个常用的高速接口——DDR接口。DDR（Double Data Rate）是一种常见的内存接口标准，它在计算机系统和其他电子设备中广泛应用，对于数据传输速度的提升起到了至关重要的作用。
DDR的发展历程 SDRAM从发展到现在已经经历了四代，分别是：第一代SDR SDRAM，第二代DDR SDRAM，第三代DDR2 SDRAM，第四代DDR3 SDRAM，现在已经发展到DDR5 SDRAM。
 DDR SDRAM是Double Data Rate Synchronous Dynamic Random Access Memory(双数据率同步动态随机存储器)的简称，为第二代SDRAM标准。其常见标准有DDR 266、DDR 333和DDR 400。其对于SDRAM，主要它允许在时钟脉冲的上升沿和下降沿传输数据，这样不需要提高时钟的频率就能实现双倍的SDRAM速度，例如DDR266内存与PC133 SDRAM内存相比，工作频率同样是133MHz，但在内存带宽上前者比后者高一倍。这种做法相当于把单车道更换为双车道，内存的数据传输性能自然可以翻倍。 DDR2(Double Data Rate 2)SDRAM是由JEDEC(电子设备工程联合委员会)开发的第三代SDRAM内存技术标准，1.8v工作电压，240线接口，提供了相较于DDR SDRAM更高的运行效能与更低的电压，同样采用在时钟的上升/下降延同时进行数据传输的基本方式，但拥有两倍于上一代DDR内存预读取能力(即4bit数据读预取能力)，其常见的频率规范有DDR2 400\533\667\800\1066\1333等，总线频率553MHz的DDR2内存只需133MHz的工作频率 DDR3 SDRAM相比起DDR2具备更低的工作电压(1.5v)，240线接口，支持8bit预读，只需133MHz的工作频率便可实现1066MHz的总线频率。其频率从800MHz起跳，常见频率有DDR3 800\1066\1333\1600\1866\2133等。DDR3是当前流行的内存标准，Intel酷睿i系列(如LGA1156处理器平台)、AMD AM3主板及处理器的平台都是其“支持者”。 DDR4相比DDR3最大的区别有三点：16bit预取机制（DDR3为8bit），同样内核频率下理论速度是DDR3的两倍；更可靠的传输规范，数据可靠性进一步提升；工作电压降为1.2V，更节能。  DDR到DDR5的主要变化，我们可以看到，为了配合整体行业对于性能，容量和省电的不断追求，规范的工作电压越来越低，芯片容量越来越大，IO的速率也越来越高。
除了电压，容量和IO的速率变化之外，上表还列出了Bank，Bank Group，Prefetch和Burst Length的演进，bank数越来越多，到DDR4出现bank group，prefetch也从2n增加到4n，8n。虽然我们说现在DDR4的最大速率是3200MT/s, 但是这是指的DDR4的IO频率，即DDR4和memroy controller之间的接口数据传输速率。那么DRAM是怎么实现用比较低的核心传输频率来满足日益高涨的高速IO传输速率的需求呢？这就是靠prefetch来实现的。
 从DDR开始到DDR3很好理解，Prefetch相当于DRAM core同时修了多条高速公路连到外面的IO口，来解决IO速率比内部核心速率快的问题，IO数据速率跟核心频率的倍数关系就是prefetch。 burst length的长度跟CPU的cache line大小有关。Burst length的长度有可能大于或者等于prefetch。但是如果prefetch的长度大于burst length的长度，就有可能造成数据浪费，因为CPU一次用不了那么多。所以从DDR3到DDR4，如果在保持DDR4内存data lane还是64的前提下，继续采用增加prefetch的方式来提高IO速率的话，一次prefetch取到的数据就会大于一个cache line的大小 （512bits），对于目前的CPU系统，反而会带来性能问题。 DDR4出现了Bank Group,这就是DDR4在不改变prefetch的情况下，能继续提升IO速率的秘密武器。DDR4利用Bank group的interleave，实现IO速率在DDR3基础上进一步提升。  内存原理 从外观上就可以看出来小张的内存条由很多内存颗粒组成。
从内存控制器到内存颗粒内部逻辑，笼统上讲从大到小为：channel＞DIMM＞rank＞chip＞bank＞row/column，如下图：
一个现实的例子是：
在这个例子中，一个i7 CPU支持两个Channel（双通道），每个Channel上可以插俩个DIMM，而每个DIMM由两个rank构成，8个chip组成一个rank。由于现在多数内存颗粒的位宽是8bit，而CPU带宽是64bit，所以经常是8个颗粒可以组成一个rank。所以小张的内存条2R X 8的意思是由2个rank组成，每个rank八个内存颗粒。由于整个内存是4GB，我们可以算出单个内存颗粒是256MB。
这次我们来看看rank和Chip里面有什么，如下图：
这是个DDR3一个Rank的示意图。我们把左边128MB Chip拆开来看，它是由8个Bank组成，每个Bank核心是个一个存储矩阵，就像一个大方格子阵。这个格子阵有很多列（Column）和很多行（Row），这样我们想存取某个格子，只需要告知是哪一行哪一列就行了，这也是为什么内存可以随机存取而硬盘等则是按块存取的原因。
实际上每个格子的存储宽度是内存颗粒（Chip）的位宽，在这里由8个Chip组成一个Rank，而CPU寻址宽度是64bit,所以64/8=8bit，即每个格子是1个字节。选择每个格子也不是简单的两组信号，是由一系列信号组成，以这个2GB DDR3为例：
其引脚按照功能可以分为7类：前3类为电源、地、配置
后4类为：控制信号、时钟信号、地址信号、数据信号
电源、地、配置信号的功能很简单，在此不赘述。DDR4中最重要的信号就是地址信号和数据信号。
如上DDR4芯片有20根地址线（17根Address、2根BA、1根BG），16根数据线。在搞清楚这些信号线的作用以及地址信号为何还有复用功能之前，我们先抛出1个问题。假如我们用20根地址线，16根数据线，设计一款DDR，我们能设计出的DDR寻址容量有多大？
Size（max）=(2^20) * 16 = 2048 KB =2 MB。 但是事实上，该DDR最大容量可以做到1GB，比传统的单线编码寻址容量大了整整512倍，它是如何做到的呢？答案很简单，分时复用。我们把DDR存储空间可以设计成如下样式：
首先将存储空间分成两个大块，分别为BANK GROUP0和BANK GROUP1，再用1根地址线（还剩19根），命名为BG，进行编码。若BG拉高选择BANK GROUP0，拉低选择BANK GROUP1。（当然你也可以划分成4个大块，用2根线进行编码）。
再将1个BANK GROUP区域分成4个BANK小区域，分别命名为BANK0、BANK1、BANK2、BANK3。然后我们挑出2根地址线（还剩余17根）命名为BA0和BA1，为4个小BANK进行地址编码。
此时，我们将DDR内存颗粒划分成了2个BANK GROUP，每个BANK GROUP又分成了4个BANK，共8个BANK区域，分配了3根地址线，分别命名为BG0，BA0，BA1。然后我们还剩余17根信号线，每个BANK又该怎么设计呢？这时候，就要用到分时复用的设计理念了。
剩下的17根线，第一次用来表示行地址，第二次用来表示列地址。即传输2次地址，再传输1次数据，寻址范围最多被扩展为2GB。虽然数据传输速度降低了一半，但是存储空间被扩展了很多倍。这就是改善空间。所以，剩下的17根地址线，留1根用来表示传输地址是否为行地址。过程如下：
 在第1次传输时，行地址选择使能，剩下16根地址线，可以表示行地址范围，可以轻松算出行地址范围为2^16=65536个=64K个。 在第2次传输时，行地址选择禁用，剩下16根地址线，留10根列地址线表示列地址范围，可以轻松表示的列地址范围为2^10=1024个=1K个，剩下6根用来表示读写状态/刷新状态/行使能、等等复用功能。 这样，我们可以把1个BANK划分成64K*1K个=64M个地址编号。 所以1个BANK可以分成64K行，每行1K列，每个存储单元16bit。  最后理一下： 每行可以存储1K *16bit=2KB。每行的存储的容量称为Page Size。
单个BANK共64K行，所以每个BANK存储容量为64K *2KB=128MB。
单个BANK GROUP共4个BANK，每个BANK GROUP存储容量为512MB。
单个DDR4芯片有2个BANK GROUP，故单个DDR4芯片的存储容量为1024MB=1GB。
至此，20根地址线和16根数据线全部分配完成，我们用正向设计的思维方式，为大家讲解了DDR4的存储原理以及接口定义和寻址方式。
但是细心的同学发现一个问题，对于每一个bank，按照正常的10位数据，那么col应该是1024，而现在是128，是什么原因呢？
那么问题又来了，为什么Column Address的寻址能力只有128呢？请继续看下图
在上图中，可以清晰地发现，10bits的Column Address只有7bits用于列地址译码，列地址0,1,2并没有用！列地址0,1,2,这3bits被用于什么功能了？或者是DDR的设计者脑残，故意浪费了这三个bits？在JESD79-3规范中有如下的这个表格：
可以发现，Column Address的A2，A1，A0三位被用于Burst Order功能，并且A3也被用于Burst Type功能。由于一般情况，我们采用的都是顺序读写模式（即{A2,A1,A0}={0,0,0}），所以此时的A3的取值并无直接影响，CA[2:0]的值决定了一次Burst sequence的读写地址顺序。
比如一次Burst Read的时候如果CA[2:0]=3’b001表示低三位从地址1开始读取，CA3=0的时候按顺序读取1，2，3，0，5，6，7，4，CA3=1的时候交错读取1，0，3，2，5，4，7，6。 对于Prefetch而言，正好是8N Prefetch，对于Burst而言对应BL8。BC4其实也是一次BL8的操作，只是丢弃了后一半的数据。
更形象地理解就是对于一个Bank里面的Memory Array，每个Memory Cell可以看作是一个Byte的集合体。CA[9:3]选中一行中的一个特定Byte，再由CA[2:0]选择从这个Byte的哪个位置开始操作。CA3既参与了列地址译码，也决定Burst是连续读取还是交错读取。Prefetch也决定了I/O Frequency和SDRAM Core Frequency之间的关系。
总结 本文主要是针对DDR的原理进行了学习，主要集中在硬件的组成原理，其中涉及到Channel &gt; DIMM &gt; Rank &gt; Chip &gt; Bank &gt; Row/Column，其组成如下图所示
下期预告 在DDR专栏的下期文章里，我们将介绍Xilinx平台下，开发对应DDR接口IP核的具体使用和设置方法。如果觉得我们原创或引用的文章写的还不错，帮忙点赞和推荐吧，谢谢您的关注。
]]></content>
  </entry>
  
  <entry>
    <title>ARMv8架构u-boot启动流程详细分析</title>
    <url>/post/mcu/uboot-boot-process-depth-analysis-based-on-ARMv8.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>ARM</tag>
      <tag>ARMv8</tag>
      <tag>uboot</tag>
    </tags>
    <content type="html"><![CDATA[本文基于 armv8 架构来对 u-boot 进行启动流程分析，u-boot版本为2022-01。
概述 首先引用wiki上的简介：u-boot 是一个主要用于嵌入式系统的引导加载程序，可以支持多种不同的计算机系统结构。
u-boot最先是由德国DENX软件中心团队开发，后续众多有志于开放源码bootloader移植工作的嵌入式开发人员将各个不同系列嵌入式处理器的移植工作不断展开和深入，以支持了更多的嵌入式操作系统的装载与引导。
选择u-boot的理由： 开放源码；支持多种嵌入式操作系统内核的引导，如Linux、NetBSD, VxWorks, QNX, RTEMS, ARTOS, LynxOS, android；支持多个处理器系列，如PowerPC、ARM、x86、MIPS；
较高的可靠性和稳定性；高度灵活的功能设置，适合U-Boot调试、操作系统不同引导要求、产品发布等；
丰富的设备驱动源码，如串口、以太网、SDRAM、FLASH、LCD、NVRAM、EEPROM、RTC、键盘等；
较为丰富的开发调试文档与强大的网络技术支持；
基于以上理由本篇文章对现在主流的armv8架构的u-boot启动流程进行详细分析，以便所有人快速学习和理解u-boot的工作流程。
armv8 u-boot的启动 先看arm官网提供的一张图：
上图详细概括了arm官方推荐的armv8的启动层次结构：
官方将启动分为了BL1，BL2，BL31，BL32，BL33阶段，根据顺序，芯片启动后首先执行BL1阶段代码，接着验签启动BL2，BL2根据具体设计启动BL31或者BL33，BL32只有在有BL31时才可能会存在并被验签加载启动。
armv8分为Secure World和Non-Secure World（Normal World），四种异常级别从高到低分别为EL3，EL2，EL1，EL0。
Secure World就是可以执行可信的firmware和app，比如密码支付，指纹识别等一系列依赖安全保证的服务。Non-Secure World就是我们常见的u-boot，linux，qnx等裸机程序或者操作系统。
EL3具有最高管理权限，负责安全监测和安全模式切换。EL2主要提供了对虚拟化的支持。EL1是一个特权模式，能够执行一些特权指令，用于运行各类操作系统，在安全模式则是可信任OS。EL0是无特权模式，所有APP应用都在EL0。
上图中的BL1，BL2，BL31，BL32，BL33分别对应如下功能：
BL1：是一切信任的根，一般就是固化在ROM中的一段启动加载代码，用于引导bl2，并对bl2进行验签保证可信任执行；
BL2：一般是在flash中的一段可信安全启动代码，它的可信建立在bl1对它的验证，主要完成一些平台相关的初始化，比如对ddr的初始化等，并在完成初始化后寻找BL31或者BL33进行执行；如果找到了BL31则不会继续调用BL33，如果没有BL31则BL33必须有；
BL31：BL31不像BL1和BL2是一次性运行的，它作为最后一道可信任固件存在，在系统运行时通过smc指令陷入EL3调用系统安全服务或者在Secure World和Non-Secure World之间进行切换；在完成BL31初始化后会去寻找BL32或者BL33进行验签后加载执行；
BL32：OPTee OS + 安全app，它是一个可信安全的OS运行在EL1并在EL0启动可信任APP（上述的指纹验证等app），并在Trust OS运行完成后通过smc指令返回BL31，BL31切换到Non-Seucre World继续执行BL33；
BL33：非安全固件，也就是我们常见的UEFI firmware或者u-boot也可能是直接启动Linux kernel；
启动BL1，BL2，BL31，BL32则是一个完整的ATF信任链建立流程（ARM Trusted Firmware），像常见的PSCI（Power State Coordination Interface）功能则是在ATF的BL31上实现；
最后一张图完整展示整个调用流程：
BL2根据是否存在BL31和BL32可选择性的加载不同firmware；
综上所述，可知u-boot是一个运行在非安全世界的bootloader，负责加载各类操作系统，并提供丰富的驱动接口；并根据是否存在安全固件还可以进行不同的boot流程，如下。
u-boot，u-boot-spl，u-boot-tpl的关系：对于一般嵌入式而言只需要一个u-boot作为bootloader即可，但是在小内存，或者有atf的情况下还可以有spl，tpl；
spl：Secondary Program Loader，二级加载器
tpl：Tertiary Program Loader，三级加载器
出现spl和tpl的原因最开始是因为系统sram太小，rom无法在ddr未初始化的情况下一次性把所有代码从flash，emmc，usb等搬运到sram中执行，也或者是flash太小，无法完整放下整个u-boot来进行片上执行。
所以u-boot又定义了spl和tpl，spl和tpl走u-boot完全相同的boot流程，不过在spl和tpl中大多数驱动和功能被去除了，根据需要只保留一部分spl和tpl需要的功能，通过CONFIG_SPL_BUILD和CONFIG_TPL_BUILD控制；
一般只用spl就足够了，spl完成ddr初始化，并完成一些外设驱动初始化，比如usb，emmc，以此从其他外围设备加载u-boot，但是如果对于小系统spl还是太大了，则可以继续加入tpl，tpl只做ddr等的特定初始化保证代码体积极小，以此再次从指定位置加载spl，spl再去加载u-boot。
从目前来看，spl可以取代上图中bl2的位置，或者bl1，根据具体厂商实现来决定，有一些芯片厂商会将spl固化在rom中，使其具有从emmc，usb等设备加载u-boot或者其他固件的能力。
当然在有atf的情况下可以由atf加载u-boot，或者由spl加载atf，atf再去加载u-boot。甚至在快速启动的系统中可以直接由spl启动加载linux等操作系统而跳过启动u-boot；在上图中arm官方只是给出了一个建议的启动信任链，具体实现都需要芯片厂商来决定；
后续分析启动流程中会在具有SPL和TPL的地方拓展它们的分叉执行路径尽量把SPL和TPL的功能也一并分析；
u-boot源码整体结构和一些编译配置方式 编译配置方式 u-boot使用了同Linux一样的编译配置方式，即使用kbuild系统来管理整体代码的配置和编译，通过defconfig来定制各种不同厂商的芯片bootloader二进制程序。编译只需要注意通过环境变量或者命令行参数的方式引入一个交叉编译工具即可：
CROSS_COMPILE：定义交叉编译工具链，可以是aarch64-linux-gnu-，arm-none-eabi-或者ppc-linux-gnu-等等；u-boot有几个配置是需要由对应board配置的。
SYS_ARCH，SYS_CPU，SYS_SOC，SYS_BOARD，SYS_VENDOR，SYS_CONFIG_NAME；一般在board/vendor/board/Kconfig中可全部定义，部分SYS_CPU，SYS_SOC也可以在arch/xxx/Kconfig中定义，根据这几个配置即可确定使用的cpu架构，厂商，板级信息，soc信息。
Makefile会自动根据上述信息进入对应目录组织编译规则，一般如果没有自己对应的这些board信息，需要自己在对应目录建立这些Kconfig和在configs中建立defconfig。
在configs目录中保存了uboot中所有支持的board配置，比如要使用rk3399的evb板的配置信息使用如下方式即可编译出来：
make CROSS_COMPILE=aarch64-linux-gnu- evb-rk3399_defconfig make 如果没有对应的defconfig可以找一个与自己板级信息类似的defconfig生成一个.config，再通过menuconfig来完成自己board的配置，并最后通过savedefconfig保存为自己board的defconfig：
make CROSS_COMPILE=aarch64-linux-gnu- evb-rk3399_defconfig make menuconfig make savedefconfig cp defconfig configs/my_defconfig 下面是evb rk3399的定义：
CONFIG_SYS_ARCH=&#34;arm&#34; CONFIG_SYS_CPU=&#34;armv8&#34; CONFIG_SYS_SOC=&#34;rk3399&#34; CONFIG_SYS_VENDOR=&#34;rockchip&#34; CONFIG_SYS_BOARD=&#34;evb_rk3399&#34; CONFIG_SYS_CONFIG_NAME=&#34;evb_rk3399&#34; 根据CONFIG_SYS_BOARD的定义还会为每个源文件自动包含include/configs/xxxx.h头文件，evb rk3399则是include/configs/evb_rk3399.h头文件。这个头文件可在其中定义board的一些关键配置，系统的ram大小，环境变量的起始地址和大小，GIC基地址，时钟频率，是否开启看门狗等定义，可根据具体需求来定义。
u-boot使用Kconfig和include/configs/xxx.h来灵活的确定u-boot编译流程及最终生成的文件。比如当定义CONFIG_SYS_CPU为&quot;armv8&quot;，CONFIG_SYS_ARCH为&quot;arm&quot;时，即确定了目标架构为armv8会自动根据Makefile进入对应目录进行编译链接。
u-boot源码结构 这里只对一些常用的目录进行说明：
 arch：各种架构的启动初始化流程代码，链接脚本等均在此目录对应的架构中存放； board：包含了大部分厂商的board初始化代码，基本平台化相关的代码都在对应的board目录中，早期的一些board代码在arch/xxx/xxx-mach中，现在基本不会放在arch目录下面了； cmd：包含了大量实用的u-boot命令的实现，比如md，cp，cmp，tftp，fastboot，ext4load等命令的实现，我们也可以在此处添加自己实现的命令； common：包含了u-boot的核心初始化代码，包括board_f，board_r，spl等一系列代码； configs：包含了所有board的配置文件，可直接使用； drivers：大量驱动代码的存放处； dts：编译生成dtb，内嵌dtb到u-boot的编译规则定义目录； env：环境变量功能实现代码； fs：文件系统读写功能的实现，里面包含了各类文件系统的实现； include：所有公用头文件的存放路径； lib：大量通用功能实现，提供给各个模块使用； net：网络相关功能的实现； scripts：编译，配置文件的脚本文件存放处； tools：测试和实用工具的实现，比如mkimage的实现代码在此处；  u-boot armv8链接脚本 在进行源码分析之前，首先看看u-boot的链接脚本，通过链接脚本可以从整体了解一个u-boot的组成，并且可以在启动分析中知道某些逻辑是在完成什么工作。
在armv8中，u-boot使用arch/arm/cpu/armv8/u-boot.lds进行链接。
u-boot-spl和u-boot-tpl使用arch/arm/cpu/armv8/u-boot-spl.lds进行链接，因为每个board的情况可能不同，所以u-boot可以通过Kconfig来自定义u-boot-spl.lds和u-boot-tpl.lds。
u-boot.lds /* SPDX-License-Identifier: GPL-2.0+ */ /* * (C) Copyright 2013 * David Feng &lt;fenghua@phytium.com.cn&gt; * * (C) Copyright 2002 * Gary Jennejohn, DENX Software Engineering, &lt;garyj@denx.de&gt; */ #include &lt;config.h&gt;#include &lt;asm/psci.h&gt; OUTPUT_FORMAT(&#34;elf64-littleaarch64&#34;, &#34;elf64-littleaarch64&#34;, &#34;elf64-littleaarch64&#34;) OUTPUT_ARCH(aarch64) ENTRY(_start) -------------------------------------------------------------------- (1) /* *（1）首先定义了二进制程序的输出格式为&#34;elf64-littleaarch64&#34;， * 架构是&#34;aarch64&#34;，程序入口为&#34;_start&#34;符号； */ SECTIONS { #ifdef CONFIG_ARMV8_SECURE_BASE -------------------------------------------------- (2) /* *（2）ARMV8_SECURE_BASE是u-boot对PSCI的支持，在定义时可以将PSCI的文本段， * 数据段，堆栈段重定向到指定的内存，而不是内嵌到u-boot中。 * 不过一般厂商实现会使用atf方式使其与bootloader分离，这个功能不常用； */ /DISCARD/ : { *(.rela._secure*) } #endif  . = 0x00000000; -------------------------------------------------------------- (3) /* *（3）定义了程序链接的基地址，默认是0，通过配置CONFIG_SYS_TEXT_BASE可修改 * 这个默认值。 */ . = ALIGN(8); .text : { *(.__image_copy_start) --------------------------------------------------- (4) /* *（4）__image_copy_start和__image_copy_end用于定义需要重定向的段， * u-boot是一个分为重定向前初始化和重定向后初始化的bootloader， * 所以此处会定义在完成重定向前初始化后需要搬运到ddr中数据的起始地址和结束地址； * * 大多数时候u-boot是运行在受限的sram或者只读的flash上， * u-boot为了启动流程统一会在ddr未初始化和重定位之前不去访问全局变量， * 但是又为了保证u-boot能够正常读写全局变量，内存，调用各类驱动能力， * 所以u-boot将启动初始化分为了两个部分，重定向前初始化board_f和 * 重定向后初始化 board_r，在重定向之前完成一些必要初始化， * 包括可能的ddr初始化，然后通过__image_copy_start和__image_copy_end * 将u-boot搬运到ddr中，并在ddr中进行重定向后初始化，这个时候的u-boot就可以 * 正常访问全局变量等信息了。 * * 如果想要在board_f过程中读写一些全局变量信息该怎么办呢？ * u-boot通过定义global_data（gd）来完成此功能， * 后续在分析到时会详细讲解实现方式。 */ CPUDIR/start.o (.text*) -------------------------------------------------- (5) /* *（5）定义了链接程序的头部文本段，armv8就是 * arch/arm/cpu/armv8/start.S， * start.S中所有文本段将会链接到此段中并且段入口符号就是_start； */ } /* This needs to come before *(.text*) */ .efi_runtime : { ------------------------------------------------------------ (6) /* *（6）在定义了efi运行时相关支持时才会出现使用的段，一般不用关心； */ __efi_runtime_start = .; *(.text.efi_runtime*) *(.rodata.efi_runtime*) *(.data.efi_runtime*) __efi_runtime_stop = .; } .text_rest : ---------------------------------------------------------------- (7) /* *（7）除了start.o，其他的所有文本段将会链接到此段中； */ { *(.text*) } #ifdef CONFIG_ARMV8_PSCI -------------------------------------------------------- (8) /* *（8）同（2），是PSCI相关功能的支持，一般不会使用； */ .__secure_start : #ifndef CONFIG_ARMV8_SECURE_BASE  ALIGN(CONSTANT(COMMONPAGESIZE)) #endif  { KEEP(*(.__secure_start)) } #ifndef CONFIG_ARMV8_SECURE_BASE #define CONFIG_ARMV8_SECURE_BASE #define __ARMV8_PSCI_STACK_IN_RAM #endif  .secure_text CONFIG_ARMV8_SECURE_BASE : AT(ADDR(.__secure_start) + SIZEOF(.__secure_start)) { *(._secure.text) . = ALIGN(8); __secure_svc_tbl_start = .; KEEP(*(._secure_svc_tbl_entries)) __secure_svc_tbl_end = .; } .secure_data : AT(LOADADDR(.secure_text) + SIZEOF(.secure_text)) { *(._secure.data) } .secure_stack ALIGN(ADDR(.secure_data) + SIZEOF(.secure_data), CONSTANT(COMMONPAGESIZE)) (NOLOAD) : #ifdef __ARMV8_PSCI_STACK_IN_RAM  AT(ADDR(.secure_stack)) #else  AT(LOADADDR(.secure_data) + SIZEOF(.secure_data)) #endif  { KEEP(*(.__secure_stack_start)) . = . + CONFIG_ARMV8_PSCI_NR_CPUS * ARM_PSCI_STACK_SIZE; . = ALIGN(CONSTANT(COMMONPAGESIZE)); KEEP(*(.__secure_stack_end)) } #ifndef __ARMV8_PSCI_STACK_IN_RAM  . = LOADADDR(.secure_stack); #endif  .__secure_end : AT(ADDR(.__secure_end)) { KEEP(*(.__secure_end)) LONG(0x1d1071c); /* Must output something to reset LMA */ } #endif  . = ALIGN(8); .rodata : { *(SORT_BY_ALIGNMENT(SORT_BY_NAME(.rodata*))) } ------------------- (9) /* *（9）所有仅读数据将会在这个段中对齐排序存放好； */ . = ALIGN(8); .data : { -------------------------------------------------------------------- (10) /* *（10）所有数据段将会链接到此段中； */ *(.data*) } . = ALIGN(8); . = .; . = ALIGN(8); .u_boot_list : { ------------------------------------------------------------- (11) /* *（11）u_boot_list段定义了系统中当前支持的所有命令和设备驱动，此段把散落在各个文件中 * 通过U_BOOT_CMD的一系列拓展宏定义的命令和U_BOOT_DRIVER的拓展宏定义的设备驱动收集到一起， * 并按照名字排序存放，以便后续在命令行快速检索到命令并执行和检测注册的设备和设备树匹配 * probe设备驱动初始化；（设备驱动的probe只在定义了dm模块化驱动时有效） */ KEEP(*(SORT(.u_boot_list*))); } . = ALIGN(8); .efi_runtime_rel : { __efi_runtime_rel_start = .; *(.rel*.efi_runtime) *(.rel*.efi_runtime.*) __efi_runtime_rel_stop = .; } . = ALIGN(8); .image_copy_end : { *(.__image_copy_end) } . = ALIGN(8); .rel_dyn_start : -------------------------------------------------------- (12) /* *（12）一般u-boot运行时是根据定义的基地址开始执行，如果加载地址和链接地址 * 不一致则会出现不能执行u-boot的问题。通过一个 * 配置CONFIG_POSITION_INDEPENDENT即可打开地址无关功能， * 此选项会在链接u-boot时添加-PIE参数。此参数会在u-boot ELF文件中 * 生成rela*段，u-boot通过读取此段中表的相对地址值与实际运行时地址值 * 依次遍历进行修复当前所有需要重定向地址，使其可以实现地址无关运行； * 即无论链接基地址如何定义，u-boot也可以在任意ram地址 * 运行（一般需要满足最低4K或者64K地址对齐）； * * 注意此功能只能在sram上实现，因为此功能会在运行时修改文本段数据段中的地址， * 如果此时运行在片上flash，则不能写flash，导致功能失效无法实现地址无关； */ { *(.__rel_dyn_start) } .rela.dyn : { *(.rela*) } .rel_dyn_end : { *(.__rel_dyn_end) } _end = .; . = ALIGN(8); .bss_start : { -------------------------------------------------------- (13) /* *（13）众所周知的bbs段； */ KEEP(*(.__bss_start)); } .bss : { *(.bss*) . = ALIGN(8); } .bss_end : { KEEP(*(.__bss_end)); } /DISCARD/ : { *(.dynsym) } -------------------------------------------- (14) /* *（14）一些在链接时无用需要丢弃的段； */ /DISCARD/ : { *(.dynstr*) } /DISCARD/ : { *(.dynamic*) } /DISCARD/ : { *(.plt*) } /DISCARD/ : { *(.interp*) } /DISCARD/ : { *(.gnu*) } #ifdef CONFIG_LINUX_KERNEL_IMAGE_HEADER ----------------------------------- (15) /* *（15）在efi加载时会很有用，主要在u-boot的二进制头部添加了一些头部信息， * 包括大小端，数据段文本段大小等，以便于efi相关的加载器读取信息， * 此头部信息来自于Linux arm64的Image的头部信息；该头部也不属于u-boot的 * 一部分只是被附加上去的； */ #include &#34;linux-kernel-image-header-vars.h&#34;#endif } u-boot-spl.lds 此链接脚本是标准的spl链接脚本，还包含了u_boot_list段，如果对应自己board不需要命令行或者模块化驱动设备，只作为一个加载器则可以自定义更简略的链接脚本。
/* SPDX-License-Identifier: GPL-2.0+ */ /* * (C) Copyright 2013 * David Feng &lt;fenghua@phytium.com.cn&gt; * * (C) Copyright 2002 * Gary Jennejohn, DENX Software Engineering, &lt;garyj@denx.de&gt; * * (C) Copyright 2010 * Texas Instruments, &lt;www.ti.com&gt; * Aneesh V &lt;aneesh@ti.com&gt; */ MEMORY { .sram : ORIGIN = IMAGE_TEXT_BASE, ---------------------------------------- (1) /* *（1）\&gt;XXX 的形式可以将指定段放入XXX规定的内存中；一般u-boot-spl只有 * 很小的可运行内存块，所以spl中会舍去大量不需要用的段只保留关键的 * 文本段数据段等，并且通过&gt;.sram的形式将不在ddr初始化前用到的段定义到sdram中， * 后续只需在完成ddr初始化后将这些段搬运到ddr中即可，而不需要额外的 * 地址修复逻辑，如下：有一个sram 0x18000-0x19000， * 一个sdram 0x80000000 - 0x90000000， * 那么通过&gt;.sram方式则map文件可能如下： * 0x18000 stext * ... * 0x18100 sdata * ... * 0x80000000 sbss * ... */ LENGTH = IMAGE_MAX_SIZE } MEMORY { .sdram : ORIGIN = CONFIG_SPL_BSS_START_ADDR, LENGTH = CONFIG_SPL_BSS_MAX_SIZE } OUTPUT_FORMAT(&#34;elf64-littleaarch64&#34;, &#34;elf64-littleaarch64&#34;, &#34;elf64-littleaarch64&#34;) OUTPUT_ARCH(aarch64) ENTRY(_start) -------------------------------------------------------------------- (2) /* *（2）同u-boot.lds一致，共用一套逻辑入口_start； */ SECTIONS { .text : { . = ALIGN(8); *(.__image_copy_start) -------------------------------------------------- (3) /* *（3）同样的，如果spl需要重定向则会使用此段定义，大多数情况下spl中会用上重定向； */ CPUDIR/start.o (.text*) *(.text*) } &gt;.sram .rodata : { . = ALIGN(8); *(SORT_BY_ALIGNMENT(SORT_BY_NAME(.rodata*))) } &gt;.sram .data : { . = ALIGN(8); *(.data*) } &gt;.sram #ifdef CONFIG_SPL_RECOVER_DATA_SECTION ---------------------------------------- (4) /* *（4）SPL_RECOVER_DATA_SECTION段用于保存数据段数据， * 一些board在初始化时修改data段数据，并在后续某个阶段 * 从此段中恢复data的原始数据； */ .data_save : { *(.__data_save_start) . = SIZEOF(.data); *(.__data_save_end) } &gt;.sram #endif  .u_boot_list : { . = ALIGN(8); KEEP(*(SORT(.u_boot_list*))); } &gt;.sram .image_copy_end : { . = ALIGN(8); *(.__image_copy_end) } &gt;.sram .end : { . = ALIGN(8); *(.__end) } &gt;.sram _image_binary_end = .; .bss_start (NOLOAD) : { . = ALIGN(8); KEEP(*(.__bss_start)); } &gt;.sdram -------------------------------------------------------------- (5) /* *（5）将bss段数据定义到&gt;.sdram中，即可在初始化ddr后直接对此段地址清零 * 即可使用全局未初始化变量，并且不会带来副作用。 */ .bss (NOLOAD) : { *(.bss*) . = ALIGN(8); } &gt;.sdram .bss_end (NOLOAD) : { KEEP(*(.__bss_end)); } &gt;.sdram /DISCARD/ : { *(.rela*) } /DISCARD/ : { *(.dynsym) } /DISCARD/ : { *(.dynstr*) } /DISCARD/ : { *(.dynamic*) } /DISCARD/ : { *(.plt*) } /DISCARD/ : { *(.interp*) } /DISCARD/ : { *(.gnu*) } } 从上述的链接脚本可以看出，armv8的u-boot的启动是从arch/arm/cpu/armv8/start.S中的_start开始的，并在后续初始化中调用了很多链接脚本中定义的地址符号表。
]]></content>
  </entry>
  
  <entry>
    <title>通俗易懂讲讲 通信原理</title>
    <url>/post/hardware/easy-to-understand-communication-principle.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>Communication Principle</tag>
    </tags>
    <content type="html"><![CDATA[学了通信原理这门课，一开始觉得很难，这里用我自己的学习过程以及对通信系统的了解来说明这些技术的应用。
上面是我画的认为比较完整的通信系统的简单流程图，对此我做一翻解释。
首先日常生活中的信号总是模拟的，我们把这些信号通过滤波等处理，得到带限的信号，这里以基带信号singnal为例子,signal 经过采样保持电路，我们就得到PAM信号，如图
这样的信号就是离散信号了。
离散信号经过量化归属到个档次的幅度中比如我们有2V,4V,6,V,8V四个档次的归类，并且规定1V~3V之间的PAM离散信号就归类到2V的档次中去,一次类推，通过比较给每个PAM信号进行归类，这就是量化。
之后将量化了的信号进行编码，编码是一种认为规定的过程比如我们规定2V用00表示，4V用01表示，6V用10表示，而8V用11来表示,这样就把阶梯信号和二进制信号有了一种对应关系，顺着这种对应关系，我们可以得到刚才量化了的信号的二进制代码，这就是PCM编码得到了可以在存储器中存储的数字信号。
以上从模拟到数字信号的一种转变就是我们常说的A/D转换。至于我们平时要求的转换比特率的求法可以从它的转换过程得出计算方法。一个PAM信号对应一个档次，而一个档次对应几个比特的数字是在编码中体现的，例子中就是一个档次对应两个比特，假设这种对应关系是1对N个比特，对模拟信号的采样率是F,也就是1秒钟有F个PAM信号，这F个PAM信号就要被转换成FN个比特，所以比特率就是FN了。
对于完成转换的数字信号，我们如何处理呢？有的是被放进存储器中存储了，有的是到CPU中进行计算，加密等处理了。
通常为了达到通信目的，我们就要将数字信号传递并且转换成模拟信号，毕竟在生活中模拟信号才是我们可以识别的。
所以我们从存储器中读取数字信号，这些信号是基带信号，不容易传输，经过数字调制系统就可以转换成高频信号而被发送设备以各种形式比如微波，光信号传播出去。发送这些高频信号的速度关系到发送的比特率注意与前面的转换的比特率有不同。假如整个发送端可以发送四中波形A,B,C,D，它们可以分别表示发送了00，01，10，11信号，那么我们就说发送一个符号（即波形）就是发送了两个比特了。由此得到符号率与比特率的关系B=N*D.D是符号率baud/s, B是比特率bit/s, N表示一个符号与N个比特对应。
接收设备将这些信号转换成电信号，通过解调器，就可以还原基带信号，同样可以将它们放进存储器存储，这可以理解成网络视频在我们的电脑上的缓存。缓存中的信号通过解码器，也就是与编码器功能相反的器件将数字序列转换成各种量化的台阶（档次）信号。
最后将台阶信号进行填充恢复，我们就又可以原来的输入的模拟波形了，由此我们完成一次通信。
如果模拟信号不需要数字化，那么我们可以进行模拟调制，同样可以发送出去，这个过程要简单很多。
当然，这里所讲的只是我们学习中所涉及的一些概念，完整的通信系统还有更多要考虑的，这只是我觉得通信过程的关键的骨架问题。
还有几个概念是对它们的理解和总结，希望可以和大家分享。
二进制比特率与信息量中的比特率。 因为我们假定二进制信号是等概率发生的，也就是P=0.5，而信息量的定义是这样的I=-log2(p)bit,通过此式，我们可以计算发送的一个二进制符号的信息量I=-log2(0.5)bit=1 bit,所以我们通常说一个0或者1就是一个比特了。
方波的带宽问题。 由上图我们可以注意到，一个持续时间为T的方波，它的频谱是一个SINC函数，零点带宽是1/T，即时间的倒数。当然，方波的带宽是无限大的，因此这样的波形在现实中是很难实现的，我们只能给方波提供一定的带宽，就是说得到的肯定只能是经过了过滤的波形。
在这里我们可以联系到吉布斯现象。我们可以这样理解：频率越大，就说明变化越快，而方波的转折点处就是一个极快的变化也就是有频带的高频部分构成，而经过带限的滤波之后，高频被滤去，得到的波形在转折点处就变化慢下来，于是在需要变化快的地方（如方波的转折点）变化慢，由此产生吉布斯现象。
升余弦滚降滤波器。 我们知道升余弦滚降滤波器是防止码间串扰而设计的。码间串扰是指各个时间点上发送的符号并非准确的方波，而是在规定的时间内仍有余波，于是对下一个时刻发送的符号产生影响，最后可能因为影响的叠加效果而使后果严重，得到相反的采样结果。注意我们这里讲的码间串扰都是发生在基带频率上的。因此升余弦滚降滤波器也是在基带上的应用。
下图是升余弦滚降滤波器的原理图，上半部分是滤波器的频谱相应图，下半部分是滤波结果在时间域上的波形图。
我们可以这样思考，发送的基带波形是在一定的带限内的，假如说要求发送的符号率是D，那么图下半部分中可知1/2f0=1/D，所以f0=1/(2D), 或者说D=2 f0,由下半图我们可以看出我们发送的符号的频率是2* f0，这串符号在频谱上的表示（上半图）是个带宽为f0的信号，这个就是采样定理中说的当波形用SINC函数来表示时，符号率是该波形的带宽的两倍，也就是升余弦滚降滤波器在r=0的时候的特性。
当然，我们这里表示的只是发送一个符号的波形的带宽，但是我们可以这样想象，一个系统在任何时候发送符号是使用的带宽f0都是固定的，在1时间段内发送的波形的带宽在f0以内，那么我们完全有理由相信在2时间段内发送的波形的带宽必然在f0以内，所以这样可以理解多个符号组成的波形的带宽是在f0以内的。
从下半图我们可以看到，随着r的增加，符号波形在一个周期段以外的衰减就会加快，这里我们就可以看到它对码间串扰的影响会减小，这个就是升余弦滚降滤波器的作用，但是我们必须清楚的看到，符号率是不变的2* f0,而系统的绝对带宽在增加。根据升余弦滚降滤波器的定义我们得到这样一个关系D=2* f0/(1+r)。从以上的分析过程我们可以认为1/2*f0就是发送的数字信号的周期，也就是对于同样周期的信号我们需要不同的带宽，这个带宽就是发送的数字信号的带宽，而与原始的模拟波的带宽无关。
调制的一些想法。 在学习调制的过程中，我一直搞不清什么是调制信号，什么是载波。最后总算明白，原来（一般来讲）调制就是将低频信号（调制信号）携带的信息在另外一个高频的信号（载波）上表现出来，表现的方法可以是改变载波的幅度或者相位或者频率等。当我们看到调制完成的波形是，发现它与载波有不同的幅度或者相位或者频率，从这里的变化我们极可以判断处调制信号有那些信息。载波就是用来携带低频信号要表达的意思的高频信号。之所以用高频是因为在一般情况下高频信号便于传输。
以上是我在学习通信原理中觉得关键要明白的只是点，这样知识才可以融会贯通。
]]></content>
  </entry>
  
  <entry>
    <title>C语言while(1) 和 for ( ; ; )的区别</title>
    <url>/post/programming/difference-while-1-and-for-loop.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Embedded</tag>
    </tags>
    <content type="html"><![CDATA[while(1) 和 for(;;) 它们不都是无限循环吗，作用应该一样啊，它们到底有什么区别？
要回答这个问题，其实你各自编写一段while(1) 和 for(;;)的代码，编译对比一下代码大小和汇编文件，你就大概知道了。
while(1)和for(;;)语法表达 这里先说一下while(1)和for(;;)语法表达式。
while语法表达 while (表达式) { 语句 } 其中：
 表达式：是循环条件 语句：为循环体。  while语句的语义是：计算表达式的值，当值为真(非0)时， 执行循环体语句。其执行过程可用下图表示：
for语法表达 for(表达式1; 表达式2; 表达式3) { 语句 } 它的执行过程如下：
先求解表达式1 求解表达式2 若其值为真（非0），则执行for语句中指定的内嵌语句，然后执行下面第3）步； 若其值为假（0），则结束循环，转到第5）步。
求解表达式3 转回上面第2）步继续执行。 循环结束，执行for语句下面的一个语句。 执行过程可用下图表示：
while(1)和for(;;)异同点 这里先说一下结论，然后再验证验证结论。
相同点 作用和效果都一样：都是实现无限循环的功能。
不同点 while(1)：其中括号里面是一个条件，程序会判断真假。而括号里面的“1”永远是一个“真值”。
其中，每一次循环，编译器都要判断常量1是不是等于零。
for(;;)：这两个;;空语句，编译器一般会优化掉的，直接进入死循环。
根据上面的描述，你可能会觉得：while(1) 比 for(;;) 要做更多事，汇编代码更多，代码量也更大。
但事实是这样吗？下面验证一下。
验证while(1)和for(;;)差异 我们编写分别两个文件for.c和while.c，然后分别生成汇编代码，看下情况。
源代码 while.c：
for.c：
生成汇编 我们这里使用gcc编译器生成汇编，执行命令如下：
while汇编代码：
for汇编代码：
你会发现，除了文件名不同，其余都相同。
当然，这里额外说一下，不同代码、不同编译器，以及不同优化等级，可能最终结果有所差异。
]]></content>
  </entry>
  
  <entry>
    <title>状态机的三种实现方法</title>
    <url>/post/programming/three-implementation-methods-of-state-machine.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>State Machine</tag>
    </tags>
    <content type="html"><![CDATA[这次我们一起来学习C语言实现状态机的三种方法解析。
状态机的实现无非就是 3 个要素：状态、事件、响应。转换成具体的行为就 3 句话。
 发生了什么事？ 现在系统处在什么状态？ 在这样的状态下发生了这样的事，系统要干什么？  用 C 语言实现状态机主要有 3 种方法：switch—case 法、表格驱动法、函数指针法。
switch—case 法 状态用 switch—case 组织起来， 将事件也用switch—case 组织起来， 然后让其中一个 switch—case 整体插入到另一个 switch—case 的每一个 case 项中 。
「程序清单 List4 ：」 switch (StateVal) { case S0: switch (EvntID) { case E1: action_S0_E1(); /*S0 状态下 E1 事件的响应 */ StateVal = new state value; /*状态迁移，不迁移则没有此行 */ break; case E2: action_S0_E2(); /*S0 状态下 E2 事件的响应 */ StateVal = new state value; break; ... ... case Em: action_S0_Em(); /*S0 状态下 Em 事件的响应 */ StateVal = new state value; break; default: break; } break; case S1: ... ... break; ... ... case Sn: ... ... break; default: break; } 上面的伪代码示例只是通用的情况，实际应用远没有这么复杂。虽然一个系统中事件可能有很多种，但在实际应用中，许多事件可能对某个状态是没有意义的。
例如在程序清单 List4中，如果 E2、······ Em 对处在 S0 状态下的系统没有意义，那么在 S0 的 case 下有关事件E2、······ Em 的代码根本没有必要写,状态 S0 只需要考虑事件 E1 的处理就行了。
既然是两个 switch—case 之间的嵌套， 那么就有一个谁嵌套谁的问题， 所以说 switch—case法有两种写法：状态嵌套事件和事件嵌套状态。这两种写法都可以， 各有利弊， 至于到底选用哪种方式就留给设计人员根据具体情况自行决断吧。
关于 switch—case 法还有最后一点要说明， 因为 switch—case 的原理是从上到下挨个比较，越靠后，查找耗费的时间就越长，所以要注意状态和事件在各自的 switch 语句中的安排顺序，不推荐程序清单 List4 那样按顺序号排布的方式。出现频率高或者实时性要求高的状态和事件的位置应该尽量靠前。
表格驱动法 如果说 switch—case 法是线性的，那么表格驱动法则是平面的。表格驱动法的实质就是将状态和事件之间的关系固化到一张二维表格里，把事件当做纵轴，把状态当做横轴，交点[Sn , Em]则是系统在 Sn 状态下对事件 Em 的响应。
如图 4， 我把表格中的 Node_SnEm 叫做状态机节点， 状态机节点 Node_SnEm 是系统在 Sn状态下对事件 Em 的响应。这里所说的响应包含两个方面：输出动作和状态迁移。状态机节点一般是一个类似程序清单 List5 中的结构体变量 。
struct fsm_node { void (*fpAction)(void* pEvnt); INT8U u8NxtStat; }; 程序清单 List5 中的这个结构体有两个成员：fpAction 和 u8NxtStat。fpAction 是一个函数指针， 指向一个形式为 void func(void * pEvnt)的函数， func 这个函数是对状态转移中动作序列的标准化封装。
也就是说， 状态机在状态迁移的时候， 不管输出多少个动作、操作多少个变量、调用多少个函数，这些行为统统放到函数 func 中去做。
把动作封装好了之后，再把封装函数 func 的地址交给函数指针 fpAction，这样，想要输出动作，只需要调用函数指针 fpAction 就行了。
再看看上面的 func 函数，会发现函数有一个形参 pEvnt，这是一个类型为 void * 的指针， 在程序实际运行时指向一个能存储事件的变量，通过这个指针我们就能获知关于事件的全部信息，这个形参是很有必要的。事件一般包括两个属性：事件的类型和事件的内容。
例如一次按键事件，我们不仅要知道这是一个按键事件，还要知道按下的到底是哪个键。事件的类型和状态机当前的状态可以让我们在图 4 的表格中迅速定位，确定该调用哪个动作封装函数， 但是动作封装函数要正确响应事件还需要知道事件的内容是什么， 这也就是形参pEvnt 的意义。
由于事件的多样性，存储事件内容的数据格式不一定一样，所以就把 pEvnt 定义成了 void * 型，以增加灵活性。有关 fpAction 的最后一个问题：如果事件 Em 对状态 Sn 没有意义，那么状态机节点Node_SnEm 中的 fpAction 该怎么办？我的答案是：那就让它指向一个空函数呗！前面不是说过么，什么也不干也叫响应。
u8NxtStat 存储的是状态机的一个状态值。我们知道， 状态机响应事件要输出动作， 也就是调用函数指针 fpAction 所指向的那个封装函数， 函数调用完毕后程序返回主调函数， 状态机对事件的响应就算结束了， 下一步就要考虑状态迁移的问题了。
可能要保持本状态不变， 也可能要迁移到一个新的状态，该如何抉择呢？u8NxtStat 存储的状态就是状态机想要的答案！
图 4 的这张表格反映在 C 语言代码里就是一个二维数组，第 1 维就是状态机的状态，第 2维就是统一分类的事件，而数组的元素则是程序清单 List5 中的结构体常量。如果程序中使用表格驱动法，还需要注意一些特别的事项。要将状态当做表格的横轴，那么就要求状态值集合必须满足以下条件：
(1) 该集合是一个递增的等差整数数列
(2) 该数列初值为 0
(3) 该数列等差值为 1
“事件” 作为纵轴，其特点和要求与用来做横轴的“状态” 完全一致。在 C 语言提供的数据类型中， 没有比枚举更符合以上要求的可选项了， 极力推荐将状态集合和事件类型集合做成枚举常量。表格驱动法的优点：调用接口统一 ，定位快速。
表格驱动法屏蔽了不同状态下处理各个事件的差异性，因此可以将处理过程中的共性部分提炼出来，做成标准统一的框架式代码，形成统一的调用接口。根据程序清单 List5 中的状态机节点结构体，做成的框架代码如程序清单 List6 所示。
表格驱动法查找目标实际上就是一次二维数组的寻址操作，所以它的平均效率要远高于switch—case 法。
###「程序清单 List6 ：」
extern struct fsm_node g_arFsmDrvTbl[][]; /*状态机驱动表格*/ INT8U u8CurStat = 0; /*状态暂存*/ INT8U u8EvntTyp = 0; /*事件类型暂存*/ void* pEvnt = NULL; /*事件变量地址暂存*/ struct fsm_node stNodeTmp = {NULL, 0}; /*状态机节点暂存*/ u8CurStat = get_cur_state(); /*读取当前状态*/ u8EvntTyp = get_cur_evnt_typ(); /*读取当前触发事件类型*/ pEvnt = (void*)get_cur_evnt_ptr(); /*读取事件变量地址*/ stNodeTmp = g_arFsmDrvTbl[u8CurStat ][u8EvntTyp ];/*定位状态机节点*/ stNodeTmp.fpAction(pEvnt ); /*动作响应*/ set_cur_state(stNodeTmp.u8NxtStat); /*状态迁移*/ ..... 表格驱动法好则好矣，但用它写出来的程序还有点儿小问题，我们先来看看按照表格驱动法写出来的程序有什么特点 。
前面说过，表格驱动法可以把状态机调度的部分做成标准统一的框架代码，这个框架适用性极强， 不管用状态机来实现什么样的应用， 框架代码都不需要做改动， 我们只需要根据实际应用场合规划好状态转换图，然后将图中的各个要素(状态、事件、动作、迁移，有关“条件”要素一会儿再说)用代码实现就行了，我把这部分代码称作应用代码。
在应用代码的.c 文件中， 你会看到一个声明为 const 的二维数组， 也就是图 4 所示的状态驱动表格， 还会看到许多彼此之间毫无关联的函数， 也就是前面提到的动作封装函数。这样的一份代码， 如果手头上没有一张状态转换图， 让谁看了也会一头雾水， 这样的格式直接带来了代码可读性差的问题。
如果我们想给状态机再添加一个状态，反映到代码上就是给驱动表格再加一列内容，同时也要新添加若干个动作封装函数。如果驱动表格很大， 做这些工作是很费事儿的， 而且容易出错。如果不小心在数组中填错了位置， 那么程序跑起来就和设计者的意图南辕北辙了，
远没有在 switch—case 法中改动来得方便、安全。上面说的只是小瑕疵， 其实最让我不爽的是表格驱动法不能使用Extended State Machine(对这个词组还有印象吧？)！Extended State Machine 的最大特点就是状态机响应事件之前先判断条件，根据判定结果选择执行哪些动作，转向哪个状态。
也就是说，系统在状态 Sn 下发生了事件 Em 后，转向的状态不一定是唯一的，这种灵活性是 Extended State Machine 的最有价值的优点。
回过头来看看程序清单 List5 中给出的状态机节点结构体，如果系统在状态 Sn 下发生了事件 Em， 状态机执行完 fpAction 所给出的动作响应之后， 必须转到 u8NxtStat 指定的状态。
表格驱动法的这个特性直接杜绝了 Extended State Machine 在表格驱动法中应用的可能性， 所以表格驱动法的代码实现中不存在“条件” 这个状态机要素。ESM，你是如此的优秀，我怎么舍得抛弃你 ？！
再看图 4 所示的表格驱动法示例图，如果我们把表格中的代表事件的纵轴去掉，只留下代表状态的横轴，将一列合并成一格，前文提到的问题是不是能得到解决呢？不错！这就是失传江湖多年的《葵花宝典》 ——阉割版表格驱动法 ！！
阉割版表格驱动法，又名压缩表格驱动法，一维状态表格与事件 switch—case 的合体。压缩表格驱动法使用了一维数组作为驱动表格，数组的下标即是状态机的各个状态。
表格中的元素叫做压缩状态机节点， 节点的主要内容还是一个指向动作封装函数的函数指针， 只不过这个动作封装函数不是为某个特定事件准备的， 而是对所有的事件都有效的。
节点中不再强制指定状态机输出动作完毕后所转向的状态， 而是让动作封装函数返回一个状态， 并把这个状态作为状态机新的状态。
压缩表格驱动法的这个特点， 完美的解决了 Extended State Machine 不能在表格驱动法中使用的问题 。
程序清单 List7 中的示例代码包含了压缩状态机节点结构体和状态机调用的框架代码。
「程序清单 List7：」 struct fsm_node /*压缩状态机节点结构体*/ { INT8U (*fpAction)(void* pEvnt); /*事件处理函数指针*/ INT8U u8StatChk; /*状态校验*/ }; ...... u8CurStat = get_cur_state(); /*读取当前状态*/ ...... if(stNodeTmp.u8StatChk == u8CurStat ) { u8CurStat = stNodeTmp.fpAction(pEvnt ); /*事件处理*/ set_cur_state(u8CurStat ); /*状态迁移*/ } else { state_crash(u8CurStat ); /*非法状态处理*/ } ..... 对照程序清单 List5，就会发现程序清单 List7 中 struct fsm_node 结构体的改动之处。首先， fpAction 所指向函数的函数形式变了，动作封装函数 func 的模样成了这样的了：
INT8U func(void * pEvnt); 现在的动作封装函数 func 是要返回类型为 INT8U 的返回值的，这个返回值就是状态机要转向的状态， 也就是说， 压缩表格驱动法中的状态机节点不负责状态机新状态的确定， 而把这项任务交给了动作封装函数 func， func 返回哪个状态， 状态机就转向哪个状态。
新状态由原来的常量变成了现在的变量，自然要灵活许多。上面说到现在的动作封装函数 func 要对当前发生的所有的事件都要负责， 那么 func 怎么会知道到底是哪个事件触发了它呢？看一下 func 的形参 void * pEvnt 。
在程序清单 List5 中我们提到过，这个形参是用来向动作封装函数传递事件内容的，但是从前文的叙述中我们知道， pEvnt 所指向的内存包含了事件的所有信息， 包括事件类型和事件内容 ， 所以通过形参 pEvnt ， 动作封装函数 func 照样可以知道事件的类型。
程序清单 List7 中 struct fsm_node 结构体还有一个成员 u8StatChk ， 这里面存储的是状态机 的一个状态，干什么用的呢？玩 C 语言数组的人都知道，要严防数组寻址越界。
要知道，压缩表格驱动法的驱动表格是一个以状态值为下标的一维数组， 数组元素里面最重要的部分就是一个个动作封装函数的地址。
函数地址在单片机看来无非就是一段二进制数据， 和内存中其它的二进制数据没什么两样，不管程序往单片机 PC 寄存器里塞什么值，单片机都没意见。假设程序由于某种意外而改动了存储状态机当前状态的变量，使变量值变成了一个非法状态。
再发生事件时， 程序就会用这个非法的状态值在驱动表格中寻址， 这时候就会发生内存泄露，程序拿泄露内存中的未知数据当函数地址跳转，不跑飞才怪！
为了防止这种现象的发生， 压缩状态机节点结构体中又添加了成员 u8StatChk 。u8StatChk中存储的是压缩状态机节点在一维驱动表格的位置， 例如某节点是表格中的第 7 个元素， 那么这个节点的成员 u8StatChk 值就是 6。
看一下程序清单 List7 中的框架代码示例， 程序在引用函数指针 fpAction 之前， 先检查当前状态和当前节点成员 u8CurStat 的值是否一致，一致则认为状态合法，事件正常响应，如果不一致，则认为当前状态非法，转至意外处理，最大限度保证程序运行的安全。当然，如果泄露内存中的数据恰好和 u8CurStat 一致，那么这种方法真的就回天乏力了。
还有一个方法也可以防止状态机跑飞，如果状态变量是枚举，那么框架代码就可以获知状态值的最大值， 在调用动作封装函数之前判断一下当前状态值是否在合法的范围之内， 同样能保证状态机的安全运行。
压缩表格驱动法中动作封装函数的定义形式我们已经知道了，函数里面到底是什么样子的呢？程序清单 List8 是一个标准的示例。
「程序清单List8：」 INT8U action_S0(void* pEvnt) { INT8U u8NxtStat = 0; INT8U u8EvntTyp = get_evnt_typ(pEvnt); switch(u8EvntTyp ) { case E1: action_S0_E1(); /*事件 E1 的动作响应*/ u8NxtStat = new state value; /*状态迁移，不迁移也必须有本行*/ break; ...... case Em: action_S0_Em(); /*事件 Em 的动作响应*/ u8NxtStat = new state value; /*状态迁移，不迁移也必须有本行*/ break; default: ; /*不相关事件处理*/ break; } return u8NxtStat ; /*返回新状态*/ } 从程序清单 List8 可以看出， 动作封装函数其实就是事件 switch—case 的具体实现。函数根据形参 pEvnt 获知事件类型， 并根据事件类型选择动作响应， 确定状态机迁移状态， 最后将新的状态作为执行结果返回给框架代码。
有了这样的动作封装函数， Extended State Machine 的应用就可以完全不受限制了！到此，有关压缩表格驱动法的介绍就结束了。
个人认为压缩表格驱动法是相当优秀的，它既有表格驱动法的简洁、高效、标准，又有 switch—case 法的直白、灵活、多变，相互取长补短，相得益彰。
函数指针法 上面说过，用 C 语言实现状态机主要有 3 种方法(switch—case 法、表格驱动法、函数指针法)， 其中函数指针法是最难理解的， 它的实质就是把动作封装函数的函数地址作为状态来看待。不过，有了之前压缩表格驱动法的铺垫，函数指针法就变得好理解了，因为两者本质上是相同的。
压缩表格驱动法的实质就是一个整数值(状态机的一个状态)到一个函数地址(动作封装函数)的一对一映射， 压缩表格驱动法的驱动表格就是全部映射关系的直接载体。在驱动表格中通过状态值就能找到函数地址，通过函数地址同样能反向找到状态值。
我们用一个全局的整型变量来记录状态值，然后再查驱动表格找函数地址，那干脆直接用一个全局的函数指针来记录状态得了，还费那劳什子劲干吗？！这就是函数指针法的前世今生。
用函数指针法写出来的动作封装函数和程序清单 List8 的示例函数是很相近的， 只不过函数的返回值不再是整型的状态值， 而是下一个动作封装函数的函数地址， 函数返回后， 框架代码再把这个函数地址存储到全局函数指针变量中。
相比压缩表格驱动法，在函数指针法中状态机的安全运行是个大问题，我们很难找出一种机制来检查全局函数指针变量中的函数地址是不是合法值。如果放任不管， 一旦函数指针变量中的数据被篡改，程序跑飞几乎就不可避免了。
小节 有关状态机的东西说了那么多，相信大家都已经感受到了这种工具的优越性，状态机真的是太好用了！其实我们至始至终讲的都是有限状态机(Finite State Machine 现在知道为什么前面的代码中老是有 fsm 这个缩写了吧！)， 还有一种比有限状态机更 NB 更复杂的状态机， 那就是层次状态机(Hierarchical State Machine 一般简写为 HSM)。
通俗的说，系统中只存在一个状态机的叫做有限状态机，同时存在多个状态机的叫做层次状态机(其实这样解释层次状态机有些不严谨， 并行状态机也有多个状态机， 但层次状态机各个状态机之间是上下级关系，而并行状态机各个状态机之间是平级关系)。
层次状态机是一种父状态机包含子状态机的多状态机结构，里面包含了许多与面向对象相似的思想， 所以它的功能也要比有限状态机更加强大， 当一个问题用有限状态机解决起来有些吃力的时候， 就需要层次状态机出马了。
层次状态机理论我理解得也不透彻， 就不在这里班门弄斧了，大家可以找一些有关状态机理论的专业书籍来读一读。要掌握状态机编程，理解状态机(主要指有限状态机)只是第一步，也是最简单的一步，更重要的技能是能用状态机这个工具去分析解剖实际问题：划分状态、 提取事件、 确定转换关系、规定动作等等，形成一张完整的状态转换图，最后还要对转换图进行优化，达到最佳。
把实际问题变成了状态转换图， 工作的一大半就算完成了， 这个是具有架构师气质的任务，剩下的问题就是按照状态图编程写代码了，这个是具有代码工特色的工作。
]]></content>
  </entry>
  
  <entry>
    <title>Linux系统内核概述</title>
    <url>/post/linux/linux-share-file-folder-and-time-synchronization.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>NFS</tag>
      <tag>NTP</tag>
    </tags>
    <content type="html"><![CDATA[本文讲解了主从服务器创建共享目录以及主从服务器实现时钟同步。
目标：主从服务器创建共享目录。 安装并启动NFS 安装：yum install -y nfs-utils systemctl enable rpcbind #网络服务,负责在客户端和服务端之间建立联系。 systemctl enable nfs-server systemctl start rpcbind systemctl start nfs-server NFS服务端创建共享目录 所有服务器均创建目录：mkdir -p /opt/gao/test/file 修改配置文件：vi /etc/exports /opt/gao/test/file/ *(insecure,rw,sync,no_root_squash) :wq 重启NFS服务:systemctl restart nfs-server 查看配置路径键入：exportfs NFS客户端配置 查看主服务器可挂载目录：showmount -e 主服务器IP 修改文件：vi /etc/fsta 主服务器IP:/opt/gao/test/file /opt/gao/test/file/ nfs defaults,_netdev 0 0 :wq 挂载目录：mount -t nfs 主服务器IP:/opt/gao/test/file /opt/gao/test/file/ 测试连通性 任意一台服务器的/opt/gao/test/file目录下创建文件，去其他服务相同目录查看。
目标：主从服务器实现时钟同步。 部署NTP服务 查看ntp和ntpdate安装情况：rpm -qa | grep ntp 安装ntp：yum -y install ntp 安装ntpdate：yum -y install ntpdate 设置时区：cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 配置NTP服务端 vim /etc/ntp.conf #注释以下内容 restrict default nomodify notrap nopeer noquery restrict ::1 # 新增下面内容 # 备注eg:191.169.6.156服务端所在网段为191.169.6.0 restrict default kod nomodify notrap nopeer noquery restrict -6 default kod nomodify notrap nopeer noquery restrict -6 ::1 restrict 191.169.6.0(服务端所在网段) mask 服务端子网掩码 server 127.127.1.0 prefer fudge 127.127.1.0 stratum 10 #执行命令 启动服务：service ntpd start 开机启动：chkconfig ntpd on 查看同步状态：ntpstat 配置NTP客户端 vim /etc/ntp.conf # 注释下面内容： restrict default nomodify notrap nopeer noquery restrict ::1 #新增下面内容： restrict default kod nomodify notrap nopeer noquery restrict -6 default kod nomodify notrap nopeer noquery restrict -6 ::1 server 191.169.6.156 preferservice ntpd stop chkconfig ntpd off 配置定时同步时间 crontab -e 输入：*/2 * * * * /usr/sbin/ntpdate NTP服务端IP &gt;&gt; /dev/null 硬件时钟与系统时钟同步：hwclock -w 各服务器键入date验证：date 原文连接： Linux共享目录和时钟同步  
]]></content>
  </entry>
  
  <entry>
    <title>find使用xargs和exec执行效率比较</title>
    <url>/post/linux/comparison-of-execution-efficiency-between-find-xargs-and-exec.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Find</tag>
      <tag>xargs</tag>
      <tag>exec</tag>
    </tags>
    <content type="html"><![CDATA[在linux上测试在使用find命令进行批量操作时，xargs和exec两种方式那个效率更高。
目的 在linux上测试在使用find命令进行批量操作时，xargs和exec两种方式那个效率更高。
实验 实验准备 批量创建一批文件，用来做测试使用
# 创建100个文件 [root@localhost a]# touch file{1..100} [root@localhost a]# ls file1 file13 file18 file22 file27 file31 file36 file40 file45 file5 file54 file59 file63 file68 file72 file77 file81 file86 file90 file95 file10 file14 file19 file23 file28 file32 file37 file41 file46 file50 file55 file6 file64 file69 file73 file78 file82 file87 file91 file96 file100 file15 file2 file24 file29 file33 file38 file42 file47 file51 file56 file60 file65 file7 file74 file79 file83 file88 file92 file97 file11 file16 file20 file25 file3 file34 file39 file43 file48 file52 file57 file61 file66 file70 file75 file8 file84 file89 file93 file98 file12 file17 file21 file26 file30 file35 file4 file44 file49 file53 file58 file62 file67 file71 file76 file80 file85 file9 file94 file99 # 修改前50个文件的文件属主和属组为jin [root@localhost a]# chown jin:jin file{1..50} [root@localhost a]# ll |head -10 total 0 -rw-r--r--. 1 jin jin 0 Jul 19 11:02 file1 -rw-r--r--. 1 jin jin 0 Jul 19 11:02 file10 -rw-r--r--. 1 root root 0 Jul 19 11:02 file100 -rw-r--r--. 1 jin jin 0 Jul 19 11:02 file11 -rw-r--r--. 1 jin jin 0 Jul 19 11:02 file12 -rw-r--r--. 1 jin jin 0 Jul 19 11:02 file13 -rw-r--r--. 1 jin jin 0 Jul 19 11:02 file14 -rw-r--r--. 1 jin jin 0 Jul 19 11:02 file15 -rw-r--r--. 1 jin jin 0 Jul 19 11:02 file16 time命令 time命令用来统计一个命令执行使用的时间
语法：time + 执行的命令
实例：
[root@localhost a]# time ls file1 file13 file18 file22 file27 file31 file36 file40 file45 file5 file54 file59 file63 file68 file72 file77 file81 file86 file90 file95 file10 file14 file19 file23 file28 file32 file37 file41 file46 file50 file55 file6 file64 file69 file73 file78 file82 file87 file91 file96 file100 file15 file2 file24 file29 file33 file38 file42 file47 file51 file56 file60 file65 file7 file74 file79 file83 file88 file92 file97 file11 file16 file20 file25 file3 file34 file39 file43 file48 file52 file57 file61 file66 file70 file75 file8 file84 file89 file93 file98 file12 file17 file21 file26 file30 file35 file4 file44 file49 file53 file58 file62 file67 file71 file76 file80 file85 file9 file94 file99 real 0m0.006s user 0m0.002s sys 0m0.004s xargs测试 #删除当前目录下文件属主为jin的文件 [root@localhost a]# time find ./ -user jin |xargs rm -rf  real 0m0.006s user 0m0.001s sys 0m0.005s [root@localhost a]# ls file100 file53 file56 file59 file62 file65 file68 file71 file74 file77 file80 file83 file86 file89 file92 file95 file98 file51 file54 file57 file60 file63 file66 file69 file72 file75 file78 file81 file84 file87 file90 file93 file96 file99 file52 file55 file58 file61 file64 file67 file70 file73 file76 file79 file82 file85 file88 file91 file94 file97 可以看到使用管道配置xargs查找并删除文件属主为jin的文件一共用时0.006s,前50个文件已经被删除
exec测试 #创建file1...file50文件 [root@localhost a]# touch file{1..50} [root@localhost a]# ls file1 file13 file18 file22 file27 file31 file36 file40 file45 file5 file54 file59 file63 file68 file72 file77 file81 file86 file90 file95 file10 file14 file19 file23 file28 file32 file37 file41 file46 file50 file55 file6 file64 file69 file73 file78 file82 file87 file91 file96 file100 file15 file2 file24 file29 file33 file38 file42 file47 file51 file56 file60 file65 file7 file74 file79 file83 file88 file92 file97 file11 file16 file20 file25 file3 file34 file39 file43 file48 file52 file57 file61 file66 file70 file75 file8 file84 file89 file93 file98 file12 file17 file21 file26 file30 file35 file4 file44 file49 file53 file58 file62 file67 file71 file76 file80 file85 file9 file94 file99 #修改file1...file50这50个文件的属主和属组为jin [root@localhost a]# chown jin:jin file{1..50} [root@localhost a]# time find ./ -user jin |wc -l 50 real 0m0.032s user 0m0.002s sys 0m0.003s #使用-exec删除匹配到到文件 [root@localhost a]# time find /root/a -user jin -exec rm -rf {} \; real 0m0.057s user 0m0.018s sys 0m0.032s [root@localhost a]# ls file100 file53 file56 file59 file62 file65 file68 file71 file74 file77 file80 file83 file86 file89 file92 file95 file98 file51 file54 file57 file60 file63 file66 file69 file72 file75 file78 file81 file84 file87 file90 file93 file96 file99 file52 file55 file58 file61 file64 file67 file70 file73 file76 file79 file82 file85 file88 file91 file94 file97 可以看到使用exec查找并删除文件属主为jin的文件一共用时0.057s,前50个文件已经被删除.
结论 在使用find查找文件并准备做批量操作时，xargs的效率比exec的效率更高效
彩蛋 使用rm命令直接删除效率更高
[root@localhost a]# touch file{1..50} [root@localhost a]# ls file1 file13 file18 file22 file27 file31 file36 file40 file45 file5 file54 file59 file63 file68 file72 file77 file81 file86 file90 file95 file10 file14 file19 file23 file28 file32 file37 file41 file46 file50 file55 file6 file64 file69 file73 file78 file82 file87 file91 file96 file100 file15 file2 file24 file29 file33 file38 file42 file47 file51 file56 file60 file65 file7 file74 file79 file83 file88 file92 file97 file11 file16 file20 file25 file3 file34 file39 file43 file48 file52 file57 file61 file66 file70 file75 file8 file84 file89 file93 file98 file12 file17 file21 file26 file30 file35 file4 file44 file49 file53 file58 file62 file67 file71 file76 file80 file85 file9 file94 file99 [root@localhost a]# time rm -rf file{1..50} real 0m0.003s user 0m0.001s sys 0m0.002s [root@localhost a]# ls file100 file53 file56 file59 file62 file65 file68 file71 file74 file77 file80 file83 file86 file89 file92 file95 file98 file51 file54 file57 file60 file63 file66 file69 file72 file75 file78 file81 file84 file87 file90 file93 file96 file99 file52 file55 file58 file61 file64 file67 file70 file73 file76 file79 file82 file85 file88 file91 file94 file97 ]]></content>
  </entry>
  
  <entry>
    <title>PCB线路设计制作术语</title>
    <url>/post/hardware/terminology-of-PCB-circuit-design-and-fabrication.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>PCB</tag>
      <tag>Layout</tag>
    </tags>
    <content type="html"><![CDATA[本文讲解了PCB线路设计制作术语。
1、Annular Ring 孔环
指绕接通孔壁外平贴在板面上的铜环而言。在内层板上此孔环常以十字桥与外面大地相连，且更常当成线路的端点或过站。在外层板上除了当成线路的过站之外，也可当成零件脚插焊用的焊垫。与此字同义的尚有 Pad(配圈)、 Land (独立点)等。
2、Artwork 底片
在电路板工业中，此字常指的是黑白底片而言。至于棕色的“偶氮片”(Diazo Film)则另用 Phototool 以名之。PCB 所用的底片可分为“原始底片”Master Artwork 以及翻照后的“工作底片”Working Artwork 等。
3、Basic Grid 基本方格
指电路板在设计时，其导体布局定位所着落的纵横格子。早期的格距为 100 mil，目前由于细线密线的盛行，基本格距已再缩小到 50 mil。
4、Blind Via Hole 盲导孔
指复杂的多层板中，部份导通孔因只需某几层之互连，故刻意不完全钻透，若其中有一孔口是连接在外层板的孔环上，这种如杯状死胡同的特殊孔，称之为“盲孔”(Blind Hole)。
5、Block Diagram 电路系统块图
将组装板及所需的各种零组件，在设计图上以正方或长方形的空框加以框出， 且用各种电性符号，对其各框的关系逐一联络，使组成有系统的架构图。
6、Bomb Sight 弹标
原指轰炸机投弹的瞄准幕。PCB 在底片制作时，为对准起见也在各角落设置这种上下两层对准用的靶标，其更精确之正式名称应叫做Photographers'　Target。
7、Break-away panel 可断开板
指许多面积较小的电路板，为了在下游装配线上的插件、放件、焊接等作业的方便起见，在 PCB 制程中，特将之并合在一个大板上，以进行各种加工。完工时再以跳刀方式，在各独立小板之间进行局部切外形(Routing)断开，但却保留足够强度的数枚“连片”(Tie Bar 或Break-away Tab)，且在连片与板边间再连钻几个小孔；或上下各切 V 形槽口，以利组装制程完毕后，还能将各板折断分开。这种小板子联合组装方式，将来会愈来愈多， IC卡即是一例。
8、Buried Via Hole 埋导孔
指多层板之局部导通孔，当其埋在多层板内部层间成为“内通孔”，且未与外层板“连通”者，称为埋导孔或简称埋孔。
9、Bus Bar 汇电杆
多指电镀槽上的阴极或阳极杆本身，或其连接之电缆而言。另在“制程中”的电路板，其金手指外缘接近板边处，原有一条连通用的导线(镀金操作时须被遮盖)，再另以一小窄片(皆为节省金量故需尽量减小其面积)与各手指相连，此种导电用的连线亦称 Bus Bar。而在各单独手指与 Bus Bar 相连之小片则称Shooting Bar。在板子完成切外形时，二者都会一并切掉。
10、CAD电脑辅助设计
Computer Aided Design，是利用特殊软体及硬体，对电路板以数位化进行布局(Layout)，并以光学绘图机将数位资料转制成原始底片。此种 CAD对电路板的制前工程，远比人工方式更为精确及方便。
11、Center-to-Center Spacing 中心间距
指板面上任何两导体其中心到中心的标示距离(Nominal Distance)而言。若连续排列的各导体，而各自宽度及间距又都相同时(如金手指的排列)，则此“中心到中心的间距”又称为节距(Pitch)。
12、Clearance 余地、余隙、空环
指多层板之各内层上，若不欲其导体面与通孔之孔壁连通时，则可将通孔周围的铜箔蚀掉而形成空环，特称为“空环”。又外层板面上所印的绿漆与各孔环之间的距离也称为 Clearance 。不过由于目前板面线路密度愈渐提高，使得这种绿漆原有的余地也被紧逼到几近于无了。
13、Component Hole 零件孔
指板子上零件脚插装的通孔，这种脚孔的孔径平均在 40 mil 左右。现在SMT盛行之后，大孔径的插孔已逐渐减少，只剩下少数连接器的金针孔还需要插焊，其余多数 SMD 零件都已改采表面粘装了。
14、Component Side 组件面
早期在电路板全采通孔插装的时代，零件一定是要装在板子的正面，故又称其正面为“组件面”。板子的反面因只供波焊的锡波通过，故又称为“焊锡面”(Soldering Side) 。目前 SMT 的板类两面都要粘装零件，故已无所谓“组件面“或“焊锡面”了，只能称为正面或反面。通常正面会印有该电子机器的制造厂商名称，而电路板制造厂的 UL 代字与生产日期，则可加在板子的反面。
15、Conductor Spacing 导体间距
指电路板面的某一导体，自其边缘到另一最近导体的边缘，其间所涵盖绝缘底材面的跨距，即谓之导体间距，或俗称为间距。又，Conductor 是电路板上各种形式金属导体的泛称。
16、Contact Area 接触电阻
在电路板上是专指金手指与连接器之接触点，当电流通过时所呈现的电阻之谓。为了减少金属表面氧化物的生成，通常阳性的金手指部份，及连接器的阴性卡夹子皆需镀以金属，以抑抵其“接载电阻”的发生。其他电器品的插头挤入插座中，或导针与其接座间也都有接触电阻存在。
17、Corner Mark 板角标记
电路板底片上，常在四个角落处留下特殊的标记做为板子的实际边界。若将此等标记的内缘连线，即为完工板轮廓外围(Contour)的界线。
18、Counterboring 定深扩孔，埋头孔
电路板可用螺丝锁紧固定在机器中，这种匹配的非导通孔(NPTH)，其孔口须做可容纳螺帽的“扩孔”，使整个螺丝能沉入埋入板面内，以减少在外表所造成的妨碍。
19、Crosshatching 十字交叉区
电路板面上某些大面积导体区，为了与板面及绿漆之间都得到更好的附着力起见，常将感部份铜面转掉，而留下多条纵横交叉的十字线，如网球拍的结构一样，如此将可化解掉大面积铜箔，因热膨胀而存在的浮离危机。其蚀刻所得十字图形称为 Crosshatch，而这种改善的做法则称为 Crosshatching。
20、Countersinking 锥型扩孔，喇叭孔
是另一种锁紧用的螺丝孔，多用在木工家俱上，较少出现精密电子工业中。
21、Crossection Area 截面积
电路板上线路截面积的大小，会直接影响其载流能力，故设计时即应首先列入见，常将感部份铜面转掉，而留下多条纵横交叉的十字线，如网球拍的结构一样，如此将可化解掉大面积铜箔，因热膨胀而存在的浮离危机。其蚀刻所得十字图形称为 Crosshatch，而这种改善的做法则称为 Crosshatching。
22、Current-Carrying Capability 载流能力
指板子上的导线，在指定的情况下能够连续通过最大的电流强度(安培)，而尚不致引起电路板在电性及机械性质上的劣化 (Degradation)，此最大电流的安培数，即为该线路的“载流能力”。
23、Datum Reference 基准参考
在 PCB 制造及检验的过程中，为了能将底片图形在板面上得以正确定位起见,特选定某一点、线,或孔面做为其图形的基准参考，称为 Datum Point，Datum Line，或称 Datum Level(Plane)，亦称 Datum Hole。
24、Dummy Land 假焊垫
组装时为了牵就既有零件的高度，某些零件肚子下的板面需加以垫高，使点胶能拥有更好的接着力，一般可利用电路板的蚀刻技术，刻意在该处留下不接脚不通电而只做垫高用的“假铜垫”，谓之 Dummy Land。不过有时板面上因设计不良，会出现大面积无铜层的底材面，分布着少许的通孔或线路。为了避免该等独立导体在镀铜时过度的电流集中，而发生各种缺失起见，也可增加一些无功能的假垫或假线，在电镀时分摊掉一些电流，让少许独立导体的电流密度不至太高，这些铜面亦称为 Dummy Conductors。
25、Edge Spacing板边空地
指由板边到距其“最近导体线路”之间的空地，此段空地的目的是在避免因导体太靠近板边，而可能与机器其他部份发生短路的问题，美国UL之安全认证，对此项目特别讲究。一般板材之白边分层等缺点不可渗入此“边地”宽度的一半。
26、Edge-Board contact板边金手指
是整片板子对外联络的出口，通常多设板边上下对称的两面上，可插接于所匹配的板边连接器中。
27、Fan Out Wiring／Fan in Wiring扇出布线／扇入布线
指QFP四周焊垫所引出的线路与通孔等导体，使焊妥零件能与电路板完成互连的工作。由于矩形焊垫排列非常紧密，故其对外联络必须利用矩垫方圈内或矩垫方圈外的空地，以扇形方式布线，谓之“扇出”或“扇入”。更轻薄短小的密集PCB，可在外层多安置一些焊垫以承接较多零件，而将互连所需的布线藏到下一层去。其不同层次间焊垫与引线的衔接，是以垫内的盲孔直接连通，无须再做扇出扇入式布线，目前许多高功能小型无线电话的手机板，即采此种新式的叠层与布线法。
28、Fiducial Mark 光学靶标，基准讯号
在板面上为了下游组装，方便其视觉辅助系统作业起见，常大型IC于板面组装位置各焊垫外缘的空地上，在其右上及左下各加一个三角的“光学靶标”，以协助放置机进行光学定位，便是一例。而PCB制程为了底片与板面在方位上的对准，也常加有两枚以上的基准记号。
29、Fillet内圆填角
指两平面或两直线，在其垂直交点处所补填的弧形物而言。在电路板中常指零件引脚之焊点，或板面T形或L形线路其交点等之内圆填补，以增强该处的机械强及电流流通的方便。
30、Film 底片
指已有线路图形的软片而言。通常厚度有7mil及4mil两种，其感光的药膜有黑白的卤化银，及棕色或其他颜色的偶氮化合物，此词亦称为Artwork。
31、Fine Line 细线
按目前的技术水准，孔间四条线或平均线宽在5～6mil以下者，称为细线。
32、Fine Pitch密脚距，密线距，密垫距
凡脚距(Lead Pitch)等于或小于 0.635mm(25mil)者，称为密距。
33、Finger 手指（板边连续排列接点）
在电路板上为能使整片组装板的功能得以对外联络起见，可采用板边“阳式“的镀金连续接点，以插夹在另一系统”阴式“连续的承接器上，使能达到系统间相互连通的目的。Finger的正式名称是“Edge-Board Contact&quot;。
34、Finishing 终饰、终修
指各种制成品在外观上的最后修饰或修整工作，使产品更具美观、保护，及质感的目的。Metal Finishing特指金属零件或制品，其外表上为加强防蚀功能及观而特别加做的处理层而言，如各种电镀层、阳极处理皮膜、有机物或无机物之涂装等，皆属之。
35、Form-to-List 布线说明清单
是一种指示各种布线体系的书面说明清单。
36、Gerber Date，Gerber File 格博档案
是美商 Gerber 公司专为电路板面线路图形与孔位，所发展一系列完整的软体档案。设计者或买板子的公司，可将某一料号的全部图形资料转变成 Gerber File(正式学名是“RS 274 格式”)，经由Modem 直接传送到 PCB 制造者手中，然后从其自备的 CAM 中输出，再配合雷射绘图机(Laser Plotter)的运作下，而得到钻孔、测试、线路底片、绿漆底片…甚至下游组装等具体作业资料，使得 PCB制造者可立即从事打样或生产，节省许多沟通及等待的时间。此种电路板“制前工程”各种资料的电脑软体，目前全球业界中皆以 Gerber File为标准作业。此外尚有 IPC-D-350D 另一套软体的开发，但目前仍未见广用。
37、Grid 标准格
指电路板布线图形时的基本经纬方格而言，早期长宽格距各为 100 mil，那是以“积体电路”(IC)引脚的脚距为参考而定的，目前密集组装已使得此种Grid 再逼近到 50 mil 甚至 25 mil。座落在格子交点上则称为 On Grid。
38、Ground Plane Clearance 接地空环
“积体电路器”不管是传统 IC 或是 VLSI ，其接地脚或电压脚，与其接地层(GND)或接电压层(Vcc)的脚孔接通后，再以“一字桥”或“十字桥”与外面的大铜面进行互连。至于穿层而过完全不接大铜面的通孔，则必须取消任何桥梁而与外地隔绝。又为了避免因受热而变形起见，通孔与大铜面之间必须留出膨胀所需的伸缩空环(Clearance Ring，即图中之白环)。因而可从已知引脚所接连的层次，即可判断出到底是 GND 或 Vcc 了。一般通孔制作若各站管理不善的话，将会发生“粉红圈”，但此种粉红圈只应出现在空环(Clearance Ring)以内的孔环(Annular Ring)上，而不应该越过空环任凭其渗透到大地上，那样就太过份了。
39、Ground plane(or Earth Plane) 接地层
是属于多层板内层的一种板面，通常多层板的一层线路层，需要搭配一层大铜面的接地层，以当成众多零件公共回路的接地、遮蔽(Shielding) 、以及散热(Heatsinking)之用。以传统 TTL 逻辑双排脚的 IC 为例，从其正面(背面)观看时，以其一端之缺口记号朝上，其左边即为第一只脚(通常在第一脚旁的本体也会打上一个小凹陷或白点作为识别)，按顺序数到该排的最后一脚即为“接地脚”。再按反时针方向数到另一排最后一脚，就是要接电压层(Power Plane)的引脚。
40、Hole Density 孔数密度
指板子在单位面积中所钻的孔数而言。
41、Indexing Hole 基准孔、参考孔
指电路板于制造中在板角或板边先行钻出某些工具孔，以当成其他影像转移、钻孔、或切外形，以及压合制程的基本参考点，称为 Indexing Hole。其他尚有 Indexing Edge、Slot、Notch 等类似术语。
42、Inspection Overlay 套检底片
是采用半透明的线路阴片或阳片(如 Diazo之棕片、绿片或蓝片等)，可用以套准在板面上做为对照目检的工具，此法可用于“首批试产品”(First Article)之目检用途。
43、Key 钥槽，电键
前者在电路板上是指金手指区某一位置的开槽缺口，目的是为了与另一具阴性连接器得以匹配，在插接时不致弄反的一种防呆设计，称为 Keying Slot。后者是指有弹簧接点的密封触控式按键，可做为电讯的快速接通及跳开之用。
44、Land 孔环焊垫、表面(方型)焊垫
早期尚未推出 SMT 之前，传统零件以其脚插孔焊接时，其外层板面的孔环,除须做为导电互连之中继站(Terminal)外，尚可与引脚形成强固的锥形焊点。后来表面粘装盛行,所改采的板面方型焊垫亦称为 Land。此字似可译为“焊环”或“配圈”或“焊垫”，但若译成“兰岛”或“鸡眼”则未免太离谱了。
45、Landless Hole 无环通孔
指某些密集组装的板子，由于板面需布置许多线路及粘装零件的方型焊垫，所剩的空地已经很少。有时对已不再用于外层接线或插焊，如仅做为层间导电用的导孔(Via Hole)时，则可将其孔环去掉，而挪出更多的空间用以布线，此种只有内层孔环而无外层孔环的通孔，特称为 Landless Hole。
46、Laser Photogenerator(LPG)，Laser Photoplotter 雷射曝光机
直接用雷射的单束平行光再配合电脑的操控，用以曝制生产 PCB 的原始底片(Master Artwork)，以代替早期用手工制作的原始大型贴片(Tape-up),及再缩制而成的原始底片。此种原始底片的运送非常麻烦,一旦因温湿度发生变化,则会导致成品板尺寸的差异，精密板子的品质必将大受影响。如今已可自客户处直接取得磁碟资料，配合雷射之扫瞄曝光即可得到精良的底片，对电路板的生产及品质都大有助益。
47、Lay Out 布线、布局
指电路板在设计时，各层次中各零件的安排，以及导线的走向、通孔的位置等整体的布局称为 Lay Out。
48、Layer to Layer Spacing 层间距离
是指多层板两铜箔导体层之间的距离，或指绝缘介质的厚度而言。通常为了消除板面相邻线路所产生的杂讯起见，其层次间距中的介质要愈薄愈好，使所感应产生的杂讯得以导入接地层之中。但如何避免因介质太薄而引发的漏电，及保持必须的平坦度，则又是另两项不易克服的难题。
49、Master Drawing 主图
是指电路板制造上各种规格的主要参考，也记载板子各部尺寸及特殊的要求，即俗称的“蓝图”，是品检的重要依据。所谓一切都要“照图施工”，除非在授权者签字认可的进一步资料(或电报或传真等)中可更改主图外，主图的权威规定是不容回避的。其优先度(Priority)虽比订单及特别资料要低，但却比各种成文的“规范”(Specs)及习惯做法都要重要。
50、Metal Halide Lamp 金属卤素灯
碘是卤素中的一种，碘在高温下容易由固体直接“升华”成为气体。在以钨丝发光体的白炽灯泡内，若将碘充入其中，则在高温中会形成碘气。此种碘气能够捕捉已蒸发的钨原子而起化学反应，将令钨原子再重行沉落回聚到钨丝上，如此将可大幅减少钨丝的消耗，而增加灯泡的寿命。并且还可加强其电流效率而增强亮度。一般多用于汽车的前灯、摄影、制片与晒版感光等所需之光源。这种碘气白炽灯也是一种不连续光谱的光源，其能量多集中在紫外区的 410～430 nm 的光谱带中,如同汞气灯一样，也不能随意加以开关。但却可在不工作时改用较低的能量，维持暂时不灭的休工状态，以备下次再使用时，将可得到瞬间的立即反应。
51、Mil 英丝
是一种微小的长度单位，即千分之一英吋【0.001 in】之谓。电路板工业中常用以表达“厚度”。此字在机械业界原译为“英丝”或简称为“丝”，且亦行之有年，系最基本的行话。不过一些早期美商“安培电子”的PCB从业人员，不明就里也未加深究，竟将之与另一公制微长度单位的“条”(即10微米) 混为一谈。流传至今已使得大部份业界甚至下游组装业界，在二十年的以讹传讹下，早已根深蒂固积非成是即使想改正也很不容易了。最让人不解的是，连金手指镀金层厚度的微吋(m-in)，也不分青红皂白一律称之为“条”，实乃莫名其妙之极。反而大陆的PCB界都还用法正确。此外若三个字母全大写成MIL时，则为“美军”Military的简写，常用于美军规范(如MIL -P-13949H,或MIL-P-55110D)与美军标准(如MIL-STD-202 等)之书面或口语中。
52、Minimum Electrical Spacing 电性间距下限，最窄电性间距
指两导体之间，在某一规定电压下，欲避免其间介质发生崩溃(Break down) ，或欲防止发生电晕(Corona)起见，其最起码应具有的距离谓之“下限间距”。
53、Mounting Hole 安装孔
为电路板上一种无导电功能的独立大孔，系将组装板锁牢在机体架构上而用的。这种做为机械用途的孔，称为“安装孔”。此词也指将较重的零件以螺丝锁在板子上用的机械孔而言。
54、Mounting Hole组装孔，机装孔
是用螺丝或其他金属扣件，将组装板锁牢固定在机器底座或外壳的工具孔，为直径 160mil左右的大孔。此种组装孔早期均采两面大型孔环与孔铜壁之PTH，后为防止孔壁在波焊中沾锡而影响螺丝穿过起见，新式设计特将大孔改成“非镀通孔”(在PTH之前予以遮盖或镀铜之后再钻二次孔) ，而于周围环宽上另做数个小型通孔以强化孔环在板面的固着强度。由于NPTH十分麻烦，近来SMT板上也有将大孔只改回PTH者，其两面孔环多半不相同，常将焊接面的大环取消而改成几个独立的小环，或改成马蹄形不完整的大环，或扩充面积成异形大铜面，兼做为接地之用。
55、Negative 负片，钻尖第一面外缘变窄
是指各种底片上(如黑白软片、棕色软片及玻璃底片等)，导体线路的图案是以透明区呈现，而无导体之基材部份则呈现为暗区(即软片上的黑色或棕色部份) ，以阻止紫外光的透过。此种底片谓之负片。又，此字亦指钻头之钻尖，其两个第一面外缘因不当重磨而变窄的情形。
56、Non-Circular Land 非圆形孔环焊垫
早期电路板上的零件皆以通孔插装为主，在填孔焊锡后完成互连(Interconnection)的功能。某些体积较大或重量较重的零件，为使在板面上的焊接强度更好起见，刻意将其孔外之环形焊垫变大，以强化焊环的附着力，及形成较大的锥状焊点。此种大号的焊垫在单面板上尤为常见。
57、Pad Master圆垫底片
是早期客户供应的各原始底片之一种，指仅有“孔位”的黑白“正片”。其中每一个黑色圆垫中心都有小点留白，是做为“程式打带机”寻找准确孔位之用。该Pad Master完成孔位程式带制作之后，还要将每一圆垫中心的留白点，以人工方式予以涂黑再翻成负片，即成为绿漆底片。如今设计者已将板子上各种所需的“诸元与尺度”都做成Gerber File的磁片，直接输入到CAM及雷射绘图机中，即可得到所需的底片，不但节省人力而且品质也大幅提升。附图即为新式Pad Master底片的一角，是两枚大型IC所接插座的孔位。
58、Pad焊垫，圆垫
此字在电路板最原始的意思，是指零件引脚在板子上的焊接基地。早期通孔插装时代，系表示外层板面上的孔环。1985年后的SMT时代，此字亦指板面上的方形焊垫。不过此字亦常被引伸到其他相关的方面，如内层板面上尚未钻孔成为孔环的各圆点或小圆盘，业界也通常叫做Pad；此字可与Land通用。
59、Panel制程板
是指在各站制程中所流通的待制板。其一片Panel中可能含有好几片“成品板“(Board)。此等”制程板“的大小，在每站中也不一定相同，如压合站之Panel板面可能很，大但为了适应钻孔机的每一钻轴作业起见，只好裁成一半或四分之一的Panel Size。当成品板的面积很小时，其每一Panel中则可排入多片的Board。通常Panel Size愈大则生产愈经济。
60、Pattern板面图形
常指电路板面的导体图形或非导体图形而言，当然对底片或蓝图上的线路图案，也可称为Pattern。
61、Photographic Film感光成像之底片
是指电路板上线路图案的原始载体，也就是俗称的“底片”(Art Work)。常用的有Mylar式软片及玻璃板之硬片。其遮光图案的薄膜材质，有黑色的卤化银(Silver halid)及棕色的偶氮化合物(Diazo)。前者几乎可挡住各种光线，后者只能挡住550nm以下的紫外光。而波长在550nm以上的可见光，对干膜已经不会发生感光作用，故其工作区可采用黄光照明，比起卤化银黑白底片只能在暗红光下作业，的确要方便得多了。
62、Photoplotter， Plotter光学绘图机
是以移动性多股单束光之曝光法，代替传统固定点状光源之瞬间全面性曝光法。在数位化及电脑辅助之设计下，PCB设计者可将原始之孔环、焊垫、布线及尺寸等精密资料，输入电脑在Gerber File系统下，收纳于一片磁片之内。电路板生产者得到磁片后，即可利用CAM及光学绘图机的运作而得到尺寸精准的底片，免于运送中造成底片的变形。由于普通光源式的Photoplotter缺点甚多，故已遭淘汰。现在业界已一律使用雷射光源做为绘图机。已成为商品者有平台式(Flat Bed)、内圆筒式(Inner drum)、外圆筒式(Outer Drum)，及单独区域式等不同成像方式的机种。其等亦各有优缺点，是现代PCB厂必备的工具。也可用于其他感光成像的工作领域，如LCD、PCM等工业中。
63、Phototool底片
一般多指偶氮棕片(Diazo film)，可在黄色照明下工作，比起只能在红光下工作的黑白卤化银底片要方便一些。
64、Pin接脚，插梢，插针
指电路板孔中所插装的镀锡零件脚，或镀金之插针等。可做为机械支持及导电互连用处，是早期电路板插孔组装的媒介物。其纵横之间距(Pitch)早期大多公定为100 mil，以做为电路板及各种零件制造的依据。
65、Pitch跨距，脚距，垫距，线距
Pitch纯粹是指板面两“单元”中心间之远近距离，PCB业美式表达常用mil pitch，即指两焊垫中心线间的跨距mil而言。 Pitch与Spacing不同，后者通常是指两导体间的“隔离板面”，是面积而非长度。
66、Plotting标绘
以机械方式将X、Y之众多座标数据在平面座标系统中，描绘成实际线路图的作业过程，便称为Plot或Plotting。目前底片的制作已放弃早期的徒手贴图(Tape up)，而改用“光学绘图”方式完成底片，不但节省人力，而且品质更好。
67、Polarizing Slot偏槽
指板边金手指区的开槽，一般故意将开槽的位置放偏，以避免因左右对称而可能插反，此种为确保正确插接而加开的方向槽，亦称为Keying Slot。
68、Process Camera制程用照像机
是做底片(Artwork)放大、缩小，或从贴片(Tape up)直接照像而得到底片的专用相机。其组成有三大件直立于可移动的轨道上且彼此平行，即图中右端的原始贴片或母片架、镜头，以及左端待成像的子片架等。这是早期生产底片的方式，目前已进步到数位化，自客户取得的磁碟，经由电脑软体及电射绘图机的工作下，即可直接得到原始底片，已无须再用到照相机了。
69、Production Master生产底片
指1：1可直接用以生电路板的原寸底片而言，至于各项诸元的尺寸与公差，则须另列于主图上 (Master Drawing亦即蓝图)。
70、Reference Dimension参考尺度
参考尺寸仅供参考资料用的尺度，因未设公差故不能当成正式施工及品检的根据。
71、Reference Edge参考边缘
指板边板角上某导体之一个边缘，可做为全板尺寸的量测参考用，有时也指某一特殊鉴别记号而言。
72、Register Mark对准用标记
指底片上或板面上，各边框或各角落所设定的特殊标记，用以检查本层或各层之间的对准情形，图示者即为两种常用的对准标记。其中同心圆形者可在多层板每层的板边或板角处，依序摆设不同直径的圆环，等压合后只要检查所“扫出”(即铣出)立体同心圆之套准情形，即可判断其层间对准度的好坏。
73、Registration对准度
电路板面各种导体之实际位置，与原始底片或原始设计之原定位置，其两者之间逼近的程度，谓之“ Registration”。大陆业界译为“重合度”。“对准度”可指某一板面的导体与其底片之对准程度；或指多层板之“层间对准度” (Layer to Layer Registration)，皆为PCB的重要品质。
74、Revision修正版，改订版
指规范或产品设计之修正版本或版次，通常是在其代号之后加上大写的英文字母做为修订顺序之表示。
75、Schemetic Diagram电路概略图
利用各种符号、电性连接、零件外形等，所画成的系统线路布局概要图。
76、Secondary Side第二面
此即电路板早期原有术语之“焊锡面” (Solder Side)。因早期在插孔焊接零件时，所有零件都装在第一面 (或称Component Side;组件面)，第二面则只做为波焊接触用途，故称为焊锡面。待近年来因SMT表面粘装兴起，其正反两面都装有很多零件，故不宜再续称为焊锡面，而以“第二面”较恰当。
77、Slot, Slotting槽口，开槽
指 PCB板边或板内某处，为配合组装之需求，而须进行“开槽”以做为匹配，谓之槽口。在金手指板边者，也称为“偏槽”或“定位槽”(Polarising Slot or Locating Slot)，是故意开偏以避免金手指阴式接头的插反。
78、Solder Dam锡堤
指焊点周围由绿漆厚度所形成的堤岸，可防止高温中熔锡流动所造成之短路，通常以干膜式的防焊膜较易形成 Solder Dam。
79、Solder Plug锡塞，锡柱
指在波焊中涌入镀通孔内的焊锡，冷却后即留在孔中成为导体的一部份，称为“锡塞”。若孔中已有插接的零件脚时，则锡塞还具有“焊接点”的功用。至于目前一般不再用于插接，而只做互连目的之 PTH，则多已改成直径在20 mil以下的小孔，称之为导通孔 (Via Hole)。此等小孔的两端都已盖满或塞满绿漆，阻止助焊剂及熔锡的进入，这种导通孔当然就不会再有 Solder Plug了。
80、Solder Side焊锡面
早期电路板组装完全以通孔插装为主流，板子正面(即零组件面)常用来插装零件，其布线多按“板横”方向排列。板子反面则用以配合引脚通过波焊机的锡波，故称为“焊接面”，此面线路常按“板长”方向布线，以顺从锡波之流动。此词之其他称呼尚有 Secondary Side， Far Side等。
81、Spacing间距
指两平行导体间其绝缘空地之宽度而言，通常将“间距”与“线路”二者合称为“线对”(Line Pair)。
82、Span跨距
指两特殊目标点之间所涵盖的宽度，或某一目标点与参考点之间的距离。
83、Spur底片图形边缘突出
指底片上的透明区或黑暗区的线路图形，当其边缘解像不良发生模糊不清时，常出现不当的突出点，称为Spur。
84、Step and Repeat逐次重复曝光
面积很小的电路板为了生产方便起见，在底片制作阶段常将同一图案重复排列成较大的底片。系使用一种特殊的 Step and Repect 式曝光机，将同一小型图案逐次局部曝光再并连成为一个大底片，再用以进行量产。
85、Supported Hole(金属)支助通孔
指正常的镀通孔(PTH)，即具有金属孔壁的钻孔。一般都省略前面的“支持性”字眼。原义是指可导电及提供引脚焊接用途的通孔。
86、Tab接点，金手指
在电路板上是指板边系列接点的金手指而言，为一种非正式的说法。
87、Tape Up Master原始手贴片
早期电路板之底片，并非使用 CAD/CAM及雷射绘图机所制作，而是采各种专用的黑色“贴件” (如线路、圆垫、金手指等尺寸齐全之专用品，以Bishop之产品最为广用)，在方眼纸上以手工贴成最原始的“贴片”(Tape Up Master)，再用照相机缩照成第一代的原始底片 (Master Artwork)。十余年前日本有许多电路板的手贴片工作，即以空运来往台湾寻求代工。近年来由于电脑的发达与精准，早已取代手工的做法了。
88、Terminal Clearance端子空环，端子让环
在内层板之接地(Ground)或电压(Power)两层大铜面上，当“镀通孔”欲从内层板中穿过而又不欲连接时，则可先将孔位处的铜面蚀掉，而留出较大的圆形空地，则当PTH铜孔壁完成时，其外围自然会出现一围“空环”。另外在外层板面上加印绿漆时，各待焊之孔环周围也要让出“环状空地”，避免绿漆沾污焊环甚至进孔。这两种“空环”也可称为“Terminal Clearance”。
89、Terminal端子
广义上所说的“端子”，是指做为电性连接的各种装置或零件。电路板上的狭义用法是指内外层的各种孔环(Annumlar Ring)而言。同义词尚有Pad、Land、Terminal Area、 Terminal Pad、 Solder Pad等。
90、Thermal Relief散热式镂空
不管是在内外层板上的大铜面，其连续完整的面积皆不可过大，以免板子在高温中(如焊接)，因板材与铜皮之间膨胀系数的差异而造成板翘、浮离，或起泡等毛病。一般可在大铜面上采“网球拍”式的镂空，以减少热冲击。此词亦称为 Halfonning或Crosshatching等。UL规定在其认证的“黄卡”中，需要登载在板子上最大铜面的直径，即是一种安全的考虑。
91、Thermal Via导热孔，散热孔
是分布在高功率(如5W以上)大型零件 (如CPU或其他驱动IC)腹底板面上的通孔，此等通孔不具导电互连功能只做散热用途。有时还会与较大的铜面连接，以增加直接散热的效果。此等散热孔对 Z方向热应力具有舒缓的作用。精密Daught Card的 8 层小板，或在某些BGA双面板上，就常有这种格点排列的散热孔，与两面镀金的“散热座”等设计。
92、Throwing Power分布力
当电镀进行时，因处在阴极的工作物受其外形的影响，造成“原始电流分布” (Primary Current Distribution)的高低不均，而出现镀层厚度的差异。此时口在槽液中添加各种有机助剂(如光泽剂、整平剂、润湿剂等)，使阴极表面原有之高电流区域，在各种有机物的影响下，对原本快速增厚的镀层有一种减缓作用，从而得以拉近与低电流区域在镀厚上的差异。这种槽液中有机添加剂对阴极镀厚分布的改善能力，称为槽液的“分布力”，是一种需高度配合的复杂实验结果。当湿式电解制程为阳极处理时，则此“分布力”一词也适用于挂在阳极的工作物。如铝件的阳极处理，就是常见的例子。
93、Thermo-Via导热孔
指电路板上之大型 IC 等高功率零件，在工作中会发生多量的热能，组装板必须要将此额外的热量予以排散，以免损及该电子设备的寿命。其中一种简单的散热方法，就是利用表面粘装大型 IC的底座板材空地，刻意另加制作PTH，将大型IC所发的热，直接引至板子背面的大铜面上，以进行散热。此种专用于传热而不导电的通孔，称为 Thermo-Via。
94、Tie Bar分流条
在电路板工业中是指板面经蚀刻得到独立线路后，若还需再做进一步电镀时，须预先加设导电的路径才能继续进行。例如于金手指区的铜面上，再进行镀镍镀金时，只能靠特别留下来的 Bus Bar( 汇流条)及 Tie Bar 去接通来自阴极杆的电流。此临时导电用的两种“工具线路”，在板子完工后均将自板边予以切除。
95、Tooling Feature工具标的物
是指电路板在各种制作及组制过程中，用以定位、对准、参考之各种标志物。如工具孔、参考点、裁切点、参考线、定位孔、定位槽、对准记号等，总称为“工具用标的物”。
96、Trace线路、导线
指电路板上一般导线或线路而言，通常并不包括通孔、大地，焊垫及孔环等。原文中当成“线路”用的术语尚有Track、Line、 Line Run、Conductor等。
97、Trim Line裁切线
电路板成品的外围，在切外型时所应遵循的边界线称为 Trim Line。
98、True Position真位
指电路板孔位或板面各种标的物(Feature)，其等在设计上所坐落的理论位置，称为真位。但由于各种图形转移以及机械加工制程等，不免都隐藏着误差公差，不可能每片都很准确。当板子在完工时，只要“标的”仍处于真位所要求圆面积的半径公差范围内(True Position Tolerance)，而不影响组装及终端功能时，则其品质即可允收。
99、Unsupported Hole非镀通孔
指不做导通或插装零件用途，又无镀铜孔壁之钻孔而言，通常此等NPTH孔径多半很大，如 125 mil之锁螺丝孔即是。
100、Via Hole导通孔
指电路板上只做为导电互连用途，而不再插焊零件脚之 PTH 而言。此等导通孔有贯穿全板的“全通导孔”(Through Via Hole)、有只接通至板面而未全部贯穿的“盲导孔”(Blind Via Hole)、有不与板面接通却埋藏在板材内部之“埋通孔”(Buried Via Hole)等。此等复杂的局部通孔，是以逐次连续压合法(Sequential Lamination) 所制作完成的。此词也常简称为“Via”。
101、Voltage Plane Clearance电压层的空环
当镀通孔须穿过多层板之内藏电压层，而不欲与之接触时，可在电压层的铜面上先行蚀刻出圆形空地，压合后再于此稍大的空地上钻出较小的孔，并继续完成PTH。此时其管状孔铜壁与电压层大铜面之间，即有一圈空环存在而得以绝缘，称之为Clearance。
102、Voltage Plane电压层
是指电路板上驱动各种零件工作所需的电压，可藉由板面一种公共铜导体区予以供给，或多层板中以一个层次做为电压层，如四层板的两内层之一就是电压层(如5V或 12V)，一般以Vcc符号表示。另一层是接地层 (Groung Plane)。通常多层板的电压层除供给零件所需的电压外，也兼做散热 (Heat Sinking)与屏障(Shielding)之功能。
103、Wiring Pattern布线图形
指电路板设计上之“布线”图形，与Circuitry Pattern、 Line Run Pattern等同义。
104、Working Master工作母片
指比例为1：1大小，能用于电路板生产的底片，并可直接再翻制成生产线上的实际使用的底片，这种原始底片称之 Working Master。CAD Computer Aided Design ; 电脑辅助设计CAE Computer Aided Engineering ; 电脑辅助工程CAM Computer Aided Manufacturing ; 电脑辅助制造MLB Multilayer Board ; 多层板 (指PCB的多层板)PCB Printed Circuit Board; 印刷电路板(亦做PWB，其中间为Wiring，不过目前已更简称为 Printed Board。大陆术语为“印制电路板”)SMOBC Solder Mask Over Bare Copper ; 绿漆直接印于裸铜板上 (即喷锡板)。
]]></content>
  </entry>
  
  <entry>
    <title>Marauder-高效缓存和预取加速手机APP</title>
    <url>/post/linux/synergized-caching-and-prefetching-for-low-risk-mobile-app-acceleration.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Android</tag>
      <tag>Marauder</tag>
      <tag>Mobile App</tag>
    </tags>
    <content type="html"><![CDATA[本次解读的文章来自MobiSys‘21，研究如何高效加速移动应用程序响应，研究人员来自UCLA、密歇根大学以及普林斯顿大学。
背景&amp;问题 移动应用程序已成为移动用户访问互联网服务的主要媒介，占智能手机用户关注时间的80%以上，手机应用成功的关键是较低的响应时间和用户感知的延迟。Android官方给出的报告显示用户对仅仅100毫秒量级的延迟反应消极，如果响应时间超过2-3秒，他们会放弃交互甚至删除应用。 鉴于移动应用程序性能的重要性，许多工作都致力于提高它们的响应能力。很多研究认为网络传输延迟是导致高响应时间的主要原因，本文也基于此。目前，有两种主要的技术来减轻网络延迟对应用响应的负面影响：缓存和预取。原则上，两都非常有效，特别是考虑到用户在与应用程序交互时表现出的重复模式。然而，每一种都有基本的缺点，这些缺点限制了它们在实践中的使用和有效性。
动机 实验设置   实验负载：论文收集75个各种类别的Android App，关注其中的50个（使用流行的OkHttp缓存库）；
  用户交互模拟：论文使用了人形应用测试框架Humanoid app测试框架，它采用深度神经网络从实际用户轨迹中学习交互模式；
  运行设置：对每个应用程序考虑默认的APK，以及嵌入Marauder的变体两种情况，在Google Pixel 4和Samsung Galaxy Note 9上运行；随机选择每个应用程序的5个用户交互轨迹，并以𝛿分钟为间隔进行应用。根据之前对用户-应用程序交互的研究，论文考虑10分钟到1天的𝛿值；如果未说明，默认值为𝛿 = 60𝑚𝑖𝑛𝑠。实验过程网络环境包括家庭WiFi和LTE网络；
  性能基准：本文主要的性能指标是用户响应时间IRT（interaction response time），即用户执行屏幕点击以触发交互的时间与交互的最终屏幕完全呈现的时间之间的时间。（具体测量方法详见论文介绍）；
  相关结论  现在的手机APP交互太慢：  图 3显示应用程序和跟踪的交互响应时间 (IRT) 分布，IRT 值的中位数和第 90 个百分位数在 WiFi 网络上分别为 1.6 和 3.7 秒，在 LTE 网络上跃升至 2.9 和 6.7 秒。因此，交互响应时间经常超过用户愿意容忍的 2-3 秒。 网络延迟是关键因素：  移动应用程序的响应时间取决于内容获取过程中产生的网络延迟，以及在APK中解析/呈现该内容和其他代码的客户端计算延迟。对于每个交互，论文比较了有和没有网络延迟的IRT。如图4所示，网络延迟分别占WiFi和LTE中值交互IRT的38%和64%。
现有优化存在局限：  上述实验中，应用程序采用默认运行模式，应用程序的APK或源服务器指定的任何缓存或预取都会被采用。然而，响应时间仍然过长。
缓存的问题：现有的缓存要求开发人员为他们服务的每个资源显式设置一个TTL。然而，设置这样的TTL是困难的，因为每个资源的理想TTL随时间而变化。论文的实验中，50%资源的理想TTLs的标准偏差是2小时，在这种情况下，开发人员面临着权衡；
预取的问题：应用程序对预取的支持通常选择获取大量内容的通用策略，其中大部分内容没有被使用。因此，尽管有潜在的加速，实际上预取在资源使用方面是非常浪费的。这种浪费会导致较高的通信成本，并且还会影响IRT加速，尤其是在带宽受限的设置中，其中明确请求的资源必须与不必要预取的资源竞争；
设计 Marauder是一个移动应用程序加速框架，其目标是同时利用缓存和预取的能力，尽量回避它们的风险和局限性。Marauder的关键思想是使用明智的预取来最大化已经缓存的对象的效用(即缓存命中)，然后使用这些缓存的对象来指导即时预取(即在当前交互期间)。
观察 观察一：论文发现为给定交互提取的文本文件（即 JSON、HTML、JavaScript、CSS 和 XML）直接嵌入了该交互所需的大多数非文本资源的列表，94%提取的非文本资源的URL可以从以前提取的文本文件中获得。所以，当应用程序解析和执行文本文件时，可以直接从应用程序的缓存中发出对任何引用文件的预取请求。这样，文本文件的早期解析和执行延迟会与被引用的非文本文件的网络获取延迟重叠。而且，这种JIT(just-in-time)的预取的风险会很低因为它只考虑直接列在文件中的资源，该文件被显式地请求并且将要被解析；
观察二：论文观察到缓存资源的内容通常保持不变，尽管相应的 TTL 已过期（这发生在47% 的资源中），这表明现有缓存TTL 设置过于保守。所以可以通过预取即将到期的资源，在它们没有改变的情况下延长它们的TTL(从而提高它们的命中率)；
观察三：论文发现给定文本文件引用的文件集通常在很长一段时间内保持稳定，即使文本内容发生变化也是如此。例如，中间文本文件的引用文件集在4小时内保持不变，尽管50%的文本文件仅在20分钟内保持不变。将此条件放宽到只有90%的引用文件未更改，将中位持续时间增加到9小时。所以可以通过在验证/更新不可缓存的文本文件并随后解析该文本文件时，对该文本文件所引用的文件发出预取请求，减少条件检查所带来的延迟。。
后台操作   Cache Refresher：刷新缓存资源，以提高整体缓存命中率。对于缓存中具有非零TTL的每个资源(即，不包括标记为非缓存的资源)，Marauder添加一个计时器事件，该事件在到期时检查资源的内容是否没有改变，以及其TTL是否可以延长。按照上面的观察二，Marauder对文本和非文本文件执行不同的TTL扩展过程；
  JIT Prefetcher：促进文本文件引用的资源的在线预取。每当一个文本文件被添加到应用程序缓存时(即使它被标记为无缓存), Marauder 都会异步生成一个工作线程来解析相应文本文件的正文以搜索引用的URL。开发人员使用各种正则表达式和 LinkedIn URL 检测器库静态分析文本文件，以查找所有类似于 URL 的字符串；
  运行流程 在用户交互期间，应用程序发出的请求正常访问缓存存在三种潜在的情况，每种情况都需要使用 Marauder 的不同工作流程。
  对于第一次请求文本文件(即，它不在缓存中，甚至过期)，或者任何请求非文本文件但在应用程序缓存中未命中的请求，Marauder会立即通过网络发出请求。收到响应后，Marauder将内容发送到应用程序，将其添加到缓存中，如果它是文本文件，则开始后台任务以提取引用的资源；
  对于在应用程序缓存中命中的文本文件请求(根据缓存库的默认命中标准)，Marauder用相应的内容响应应用程序，并立即对该文本文件引用的所有文件发出异步预取请求(使用离线生成的列表)。预取请求首先通过应用程序缓存，确保已经缓存的资源不会被重新下载。为了发出预取请求，Marauder首先填充动态查询参数的值；
  对于在应用程序缓存中未命中但与标记为无缓存的条目相关的文本文件请求，Marauder会发出一个对文本文件的请求，然后发出对其所有被引用子节点的预取请求。如果文本文件在某些预取资源之前到达，Marauder会小心地将应用程序显式发出的后续请求排队，这些请求已经有一个未完成的预取请求。通过这种方式，Marauder避免了重复请求和带宽浪费；一旦相应的预取响应到达，队列中的请求就会得到服务；
  实验 应用程序加速 图14 说明了与当前应用程序所采用的默认缓存和预取策略相比，Marauder能够降低交互响应时间(IRT)。例如，在LTE网络上，Marauder 将一半的应用程序的IRT提高了 19.8-27.4%（或 0.58-0.81 秒）；一半的应用程序的第 90 个百分位 IRT 改进为 29.7-43.5%（或 0.87-1.27 秒）。由于服务器的网络延迟较低，Marauder 在 WiFi 上的收益中位数和 90% 分别下降到 16.9-23.1% 和 26.1-33.2%。图 14 还显示，当用户会话之间的时间增加时，Marauder 的改进更加明显（即是前文的参数𝛿）。例如，在 LTE 上，随着𝛿 从 20 分钟增加到 4 小时，一半的应用程序的IRT 改进从 19.8% 增长到 24.4%。
Marauder性能深入分析  每个设计的效率：分别分析了JIT预取和Cache Refreshing的效果，后台缓存刷新以提高已缓存资源的命中率是 Marauder 收益最大的地方，在所考虑的 𝛿 值的中位数处提供 13.3-16.1% 的加速。相比之下，即时预取可提供 3.4-8.6% 的中值加速； 互动案例的测试：Marauder 优化的有效性受目标特定交互中的加载模式的影响。为了更好地理解这些关系，实验分析了当前应用程序的交互，并确定了影响 Marauder 提供的加速幅度的三种主要模式；  和先进方案对比 论文将 Marauder 与三种加速方法进行了比较：Paloma预取系统，以及应用程序支持的最激进和保守的预取策略。
总结 论文提出了一种移动应用程序加速系统Marauder，它综合利用缓存和预取技术，优化了TTL设置不当、缓存过时内容以及预取浪费带宽问题。同时，文章通过分析大量实验数据，得到了一些关键观察。相关实验设计非常巧妙值得学习。对缓存和预取这两种操作系统经典设计在应用程序加速领域做了深入分析，但是设计本身并不复杂。此外，从实现上来看，Marauder只是用上述优化的版本替换了大多数应用程序所依赖的缓存库，可以立即部署。
源代码和实验数据访问 https://github.com/muralisr/marauder  
The End
致谢
感谢本次论文解读者，来自华东师范大学的博士生李文通，主要研究方向为跨设备资源共享、移动计算。
 论文下载地址  
]]></content>
  </entry>
  
  <entry>
    <title>Nvidia 3060显卡 CUDA环境搭建</title>
    <url>/post/linux/how-to-setup-CUDA-environment-for-nvidia-3060.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Nvidia</tag>
      <tag>Ubuntu 22.04</tag>
      <tag>Cuda11.6</tag>
      <tag>Cudnn8.8</tag>
      <tag>Nouveau</tag>
    </tags>
    <content type="html"><![CDATA[本文详细记录了如何在Ubuntu 22.04上部署基于NVIDIA 510的CUDA。
写在前面 工作中遇到，简单整理 理解不足小伙伴帮忙指正 对每个人而言，真正的职责只有一个：找到自我。然后在心中坚守其一生，全心全意，永不停息。所有其它的路都是不完整的，是人的逃避方式，是对大众理想的懦弱回归，是随波逐流，是对内心的恐惧 ——赫尔曼·黑塞《德米安》
当前系统环境 系统环境
┌──[root@test]-[~] └─$hostnamectl Static hostname: test Icon name: computer-desktop Chassis: desktop Machine ID: addc7ca21ef24518a9465c499eb3c8b7 Boot ID: 14aa59cc6960431c95d328684b521844 Operating System: Ubuntu 22.04.2 LTS Kernel: Linux 5.19.0-43-generic Architecture: x86-64 Hardware Vendor: Micro-Star International Co., Ltd. Hardware Model: MS-7C83 显卡版本
┌──[root@test]-[~] └─$lspci -vnn | grep VGA 01:00.0 VGA compatible controller [0300]: NVIDIA Corporation GA106 [GeForce RTX 3060 Lite Hash Rate] [10de:2504] (rev a1) (prog-if 00 [VGA controller]) ┌──[root@test]-[~] └─$ 安装 NVIDIA 驱动程序，在安装之前，需要禁用 Nouveau 驱动程序。
Nouveau 是一个开源的NVIDIA显卡驱动程序，它由社区开发和维护。它可以在Linux系统上替代NVIDIA官方驱动程序，但它的性能和功能可能不如官方驱动程序。
如果使用 Nouveau 驱动程序，您可能无法使用NVIDIA的高级功能，如CUDA和深度学习库。如果您需要使用这些功能，建议安装NVIDIA官方驱动程序。
禁用 Nouveau 驱动程序
┌──[root@test]-[~] └─$sudo vim /etc/modprobe.d/blacklist-nouveau.conf ┌──[root@test]-[~] └─$cat /etc/modprobe.d/blacklist-nouveau.conf blacklist nouveau options nouveau modeset=0 ┌──[root@test]-[~] └─$sudo update-initramfs -u update-initramfs: Generating /boot/initrd.img-5.19.0-43-generic 没有输出说明操作成功
┌──[root@test]-[~] └─$reboot ┌──[root@test]-[~] └─$lsmod | grep nouveau ┌──[root@test]-[~] └─$ 安装Nvidia驱动 这里的版本 nvidia-driver-510 要和后面安装 cuda 的版本一样
如果之前安装过卸载驱动
# 查看显卡型号 lspci -vnn | grep VGA # 卸载旧驱动 sudo apt-get remove --purge nvidia* 离线安装
如果离线环境需要手动安装,下载驱动：https://www.nvidia.com/Download/index.aspx?lang=en-us
# 给run文件可执行权限  sudo chmod a+x NVIDIA-Linux-x86_64-515.86.01.run # 安装  sudo ./NVIDIA-Linux-x86_64-440.64.run -no-x-check -no-nouveau-check -no-opengl-files # -no-x-check：安装驱动时关闭X服务 # -no-nouveau-check：安装驱动时禁用nouveau # -no-opengl-files：只安装驱动文件，不安装OpenGL文件 非离线安装
非离线环境使用包管理工具安装，下面的选择这一种,选择安装驱动版本
┌──[root@test]-[~] └─$ubuntu-drivers devices == /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0 == modalias : pci:v000010DEd00002504sv00001462sd0000397Dbc03sc00i00 vendor : NVIDIA Corporation model : GA106 [GeForce RTX 3060 Lite Hash Rate] driver : nvidia-driver-530-open - distro non-free driver : nvidia-driver-470 - distro non-free driver : nvidia-driver-525-open - third-party non-free driver : nvidia-driver-535 - third-party non-free driver : nvidia-driver-520 - third-party non-free driver : nvidia-driver-510 - distro non-free driver : nvidia-driver-525 - third-party non-free driver : nvidia-driver-515-server - distro non-free driver : nvidia-driver-535-open - third-party non-free recommended driver : nvidia-driver-530 - third-party non-free driver : nvidia-driver-470-server - distro non-free driver : nvidia-driver-515-open - distro non-free driver : nvidia-driver-525-server - distro non-free driver : nvidia-driver-515 - third-party non-free driver : xserver-xorg-video-nouveau - distro free builtin ┌──[root@test]-[~] └─$ 安装
┌──[root@test]-[~] └─$sudo apt install nvidia-driver-510 -y 重启机器
┌──[root@test]-[~] └─$reboot 查看安装是否成功，对应版本信息
┌──[root@test]-[~] └─$nvidia-smi Thu Jun 15 11:49:43 2023 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 510.108.03 Driver Version: 510.108.03 CUDA Version: 11.6 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 NVIDIA GeForce ... Off | 00000000:01:00.0 On | N/A | | 0% 38C P8 16W / 170W | 172MiB / 12288MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | 0 N/A N/A 1386 G /usr/lib/xorg/Xorg 60MiB | | 0 N/A N/A 1650 G /usr/bin/gnome-shell 109MiB | +-----------------------------------------------------------------------------+ ┌──[root@test]-[~] └─$cat /proc/driver/nvidia/version NVRM version: NVIDIA UNIX x86_64 Kernel Module 510.108.03 Thu Oct 20 05:10:45 UTC 2022 GCC version: gcc version 11.3.0 (Ubuntu 11.3.0-1ubuntu1~22.04.1) ┌──[root@test]-[~] └─$ 安装Cuda CUDA是NVIDIA提供的一种并行计算平台和编程模型，旨在利用GPU的并行计算能力加速计算密集型应用程序。
CUDA包括CUDA驱动程序和CUDA Toolkit。支持多种编程语言，包括C、C++、Fortran和Python等。
 CUDA驱动程序是GPU和操作系统之间的接口. CUDA Toolkit则包括编译器、库和工具，用于开发CUDA应用程序。  如果以前安装过，卸载
sudo /usr/local/cuda-11.6/bin/cuda-uninstaller sudo rm -rf /usr/local/cuda-11.6 sudo: /usr/local/cuda-11.8/bin/uninstall_cuda_8.0.pl: command not found ┌──[root@test]-[~] └─$sudo /usr/local/cuda-11.6/bin/ bin2c cuda-gdbserver ncu nsys-ui nv-nsight-cu-cli computeprof cuda-memcheck ncu-ui nvcc nvprof compute-sanitizer cuda-uninstaller nsight_ee_plugins_manage.sh __nvcc_device_query nvprune crt/ cu++filt nsight-sys nvdisasm nvvp cudafe++ cuobjdump nsys nvlink ptxas cuda-gdb fatbinary nsys-exporter nv-nsight-cu ┌──[root@test]-[~] └─$sudo /usr/local/cuda-11.6/bin/cuda-uninstaller 在输出的终端 UI页面，空格选择全部，选择完成，卸载完成之后重新安装
┌──[root@test]-[~] └─$sudo /usr/local/cuda-11.6/bin/cuda-uninstaller Successfully uninstalled ┌──[root@test]-[~] └─$sudo rm -rf /usr/local/cuda-11.6 官网安装包下载
 https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=22.04&target_type=runfile_local  
┌──[root@test]-[~] └─$chmod +x cuda_* 这里cuda 选择 cuda_11.6.0_510.39.01_linux.run, 510 对应的版本
┌──[root@test]-[~] └─$ll cuda* -rwxr-xr-x 1 root root 3488951771 1月 11 2022 cuda_11.6.0_510.39.01_linux.run* -rwxr-xr-x 1 root root 3490450898 5月 5 2022 cuda_11.7.0_515.43.04_linux.run* -rwxr-xr-x 1 root root 4317456991 4月 17 23:04 cuda_12.1.1_530.30.02_linux.run* -rwxr-xr-x 1 root root 853 5月 17 19:52 cuda_log.log* -rw-r--r-- 1 root root 2472241638 7月 29 2021 cuda-repo-ubuntu2004-11-4-local_11.4.1-470.57.02-1_amd64.deb -rw-r--r-- 1 root root 2699477842 5月 5 2022 cuda-repo-ubuntu2204-11-7-local_11.7.0-515.43.04-1_amd64.deb ┌──[root@test]-[~] └─$ ┌──[root@test]-[~] └─$sudo ./cuda_12.1.1_530.30.02_linux.run 上面我们已经安装了驱动，所以不需要选择，直接安装 cuda 相关的就可以，安装成功输出
┌──[root@test]-[~] └─$sudo ./cuda_11.6.0_510.39.01_linux.run =========== = Summary = =========== Driver: Not Selected Toolkit: Installed in /usr/local/cuda-11.6/ Please make sure that - PATH includes /usr/local/cuda-11.6/bin - LD_LIBRARY_PATH includes /usr/local/cuda-11.6/lib64, or, add /usr/local/cuda-11.6/lib64 to /etc/ld.so.conf and run ldconfig as root To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-11.6/bin ***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 510.00 is required for CUDA 11.6 functionality to work. To install the driver using this installer, run the following command, replacing &lt;CudaInstaller&gt; with the name of this run file: sudo &lt;CudaInstaller&gt;.run --silent --driver Logfile is /var/log/cuda-installer.log 添加对应环境变量
┌──[root@test]-[/b1205] └─$echo $LD_LIBRARY_PATH /usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64 ┌──[root@test]-[/b1205] └─$echo $PATH /usr/local/cuda-11.6/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin ┌──[root@test]-[/b1205] └─$ 安装 cuDNN cuDNN 是NVIDIA提供的一个用于深度神经网络的加速库，它可以优化卷积、池化、归一化等操作，使得在GPU上运行深度神经网络的速度得到了大幅度提升。cuDNN需要与CUDA配合使用，因此在安装cuDNN之前，需要先安装相应版本的CUDA。
 https://developer.nvidia.com/rdp/cudnn-download  
这里需要注册账户登录一下,然后在这里下载
 https://developer.nvidia.com/rdp/cudnn-archive  
选择cuda对应的版本
┌──[root@test]-[~] └─$ls cudnn* cudnn-local-repo-ubuntu2204-8.8.1.3_1.0-1_amd64.deb sudo dpkg -i cudnn-local-repo-ubuntu2204-8.8.1.3_1.0-1_amd64.deb sudo cp /var/cudnn-local-repo-*/cudnn-local-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudoapt-get install libcudnn8=8.8.1.3-1+cuda1 sudo apt-get install libcudnn8-dev=8.8.1.3-1+cuda1 sudo apt-get install libcudnn8-samples=8.8.1.3-1+cuda1 确实安装是否成功 ┌──[root@test]-[~] └─$nvcc -V &amp;&amp; nvidia-smi nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2021 NVIDIA Corporation Built on Fri_Dec_17_18:16:03_PST_2021 Cuda compilation tools, release 11.6, V11.6.55 Build cuda_11.6.r11.6/compiler.30794723_0 Thu Jun 15 14:42:58 2023 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 510.108.03 Driver Version: 510.108.03 CUDA Version: 11.6 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 NVIDIA GeForce ... Off | 00000000:01:00.0 On | N/A | | 0% 51C P8 21W / 170W | 105MiB / 12288MiB | 12% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | 0 N/A N/A 1386 G /usr/lib/xorg/Xorg 81MiB | | 0 N/A N/A 1650 G /usr/bin/gnome-shell 22MiB | +-----------------------------------------------------------------------------+ ┌──[root@test]-[~] └─$ 编写测试脚本测试
(py39) test@test:~/code/Face$ cat cuda_vim.py import numpy as np import time from numba import cuda @cuda.jit def increment_kernel(array): idx = cuda.grid(1) if idx &lt; array.size: array[idx] += 1 def main(): n = 1000000000 a = np.zeros(n, dtype=np.int32) threads_per_block = 1024 blocks_per_grid = (n + threads_per_block - 1) // threads_per_block start = time.time() increment_kernel[blocks_per_grid, threads_per_block](a) end = time.time() print(&#34;Time taken: &#34;, end - start) if __name__ == &#34;__main__&#34;: while True: main() (py39) test@test:~/code/Face$ Every 2.0s: nvidia-smi test: Thu Jun 15 14:44:47 2023 Thu Jun 15 14:44:47 2023 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 510.108.03 Driver Version: 510.108.03 CUDA Version: 11.6 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 NVIDIA GeForce ... Off | 00000000:01:00.0 On | N/A | | 0% 55C P2 51W / 170W | 4025MiB / 12288MiB | 22% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | 0 N/A N/A 1386 G /usr/lib/xorg/Xorg 81MiB | | 0 N/A N/A 1650 G /usr/bin/gnome-shell 22MiB | | 0 N/A N/A 32031 C python 3917MiB | +-----------------------------------------------------------------------------+ 遇到的问题 安装530高版本报下面的错：
┌──[root@test]-[~] └─$sudo ./cuda_12.1.1_530.30.02_linux.run Error! Could not locate dkms.conf file. File: /var/lib/dkms/nvidia-fs/2.15.3/source/dkms.conf does not exist. cat: /var/log/nvidia/.uninstallManifests/kernelobjects-components/uninstallManifest-nvidia_fs: No such file or directory make: *** No rule to make target &#39;uninstall&#39;. Stop. Error! DKMS tree already contains: nvidia-fs-2.15.3 You cannot add the same module/version combo more than once. =========== = Summary = =========== Driver: Not Selected Toolkit: Installed in /usr/local/cuda-12.1/ Please make sure that - PATH includes /usr/local/cuda-12.1/bin - LD_LIBRARY_PATH includes /usr/local/cuda-12.1/lib64, or, add /usr/local/cuda-12.1/lib64 to /etc/ld.so.conf and run ldconfig as root To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-12.1/bin To uninstall the kernel objects, run ko-uninstaller in /usr/local/kernelobjects/bin ***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 530.00 is required for CUDA 12.1 functionality to work. To install the driver using this installer, run the following command, replacing &lt;CudaInstaller&gt; with the name of this run file: sudo &lt;CudaInstaller&gt;.run --silent --driver Logfile is /var/log/cuda-installer.log ┌──[root@test]-[~] └─$ 解决办法，换了低版本的510
运行 nvvp 报错
┌──[root@test]-[~] └─$nvvp Nvvp: Cannot open display: WARNING: An illegal reflective access operation has occurred WARNING: Illegal reflective access by org.eclipse.osgi.storage.FrameworkExtensionInstaller (file:/usr/local/cuda-11.6/libnvvp/plugins/org.eclipse.osgi_3.10.1.v20140909-1633.jar) to method java.net.URLClassLoader.addURL(java.net.URL) WARNING: Please consider reporting this to the maintainers of org.eclipse.osgi.storage.FrameworkExtensionInstaller WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations WARNING: All illegal access operations will be denied in a future release Nvvp: Cannot open display: Nvvp: An error has occurred. See the log file /usr/local/cuda-11.6/libnvvp/configuration/1686795694122.log. ┌──[root@test]-[~] └─$ ssh 环境不行，需要做桌面环境
在桌面环境执行，报错
Gtk-Message: 09:10:26.571: Failed to load module &#34;canberra-gtk-module&#34; 安装下面的安装包
┌──[root@test]-[~] └─$sudo apt-get install libcanberra-gtk-module nvidia-driver-XXX-open 版本安装报错
nvidia-driver-530-open 是一个在发行版的非自由存储库中提供的NVIDIA驱动程序，它是由发行版的维护者维护的。这意味着它是与发行版的其余部分紧密集成的，并且由发行版的维护者提供支持和更新。
nvidia-driver-530 是一个第三方非自由驱动程序，它不是由发行版的维护者维护的。相反，它是由NVIDIA公司提供的，并且可能需要手动安装和配置。由于它不是由发行版的维护者提供的，因此您可能无法获得与发行版集成和支持相同的级别。
nvidia-driver-530-open是更受支持和更集成的选择，而nvidia-driver-530则需要更多的手动配置和支持。
nvidia-driver-530-open : Depends: libnvidia-gl-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: nvidia-dkms-530-open (&lt;= 530.41.03-1) Depends: nvidia-dkms-530-open (&gt;= 530.41.03) Depends: nvidia-kernel-common-530 (&lt;= 530.41.03-1) but it is not going to be installed Depends: nvidia-kernel-common-530 (&gt;= 530.41.03) but it is not going to be installed Depends: nvidia-kernel-source-530-open (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: libnvidia-compute-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: libnvidia-extra-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: nvidia-compute-utils-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: libnvidia-decode-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: libnvidia-encode-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: nvidia-utils-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: xserver-xorg-video-nvidia-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: libnvidia-cfg1-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Depends: libnvidia-fbc1-530 (= 530.41.03-0ubuntu0.22.04.2) but it is not going to be installed Recommends: libnvidia-compute-530:i386 (= 530.41.03-0ubuntu0.22.04.2) Recommends: libnvidia-decode-530:i386 (= 530.41.03-0ubuntu0.22.04.2) Recommends: libnvidia-encode-530:i386 (= 530.41.03-0ubuntu0.22.04.2) Recommends: libnvidia-fbc1-530:i386 (= 530.41.03-0ubuntu0.22.04.2) Recommends: libnvidia-gl-530:i386 (= 530.41.03-0ubuntu0.22.04.2) E: Unable to correct problems, you have held broken packages. 解决办法，下面的方式进行了尝试，未解决。换了不带 open 的版本
更新你的软件包列表和已安装的软件包：
sudo apt update sudo apt upgrade 尝试使用以下命令来修复可能存在的损坏软件包：
sudo apt --fix-broken install 使用以下命令来清理系统中已经安装的软件包的缓存：
sudo apt clean 尝试使用以下命令来删除已经损坏的软件包并重新安装
sudo apt remove nvidia-driver-530-open sudo apt autoremove sudo apt install nvidia-driver-530-open 博文部分内容参考 © 文中涉及参考链接内容版权归原作者所有，如有侵权请告知，这是一个开源项目，如果你认可它，不要吝啬星星哦 :)
 https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html  
 https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#id8  
 https://blog.51cto.com/u_4029519/5909904  
© 2018-2023 liruilonger@gmail.com , All rights reserved. 保持署名-非商用-相同方式共享(CC BY-NC-SA 4.0)
]]></content>
  </entry>
  
  <entry>
    <title>最古老的Linux之一：活了30年仍在运行</title>
    <url>/post/linux/Slackware-Linux-30th-anniversary.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Slackware</tag>
    </tags>
    <content type="html"><![CDATA[Slackware不是第一个 Linux  发行版，但它仍然是迄今为止最古老的且仍在运行的Linux发行版之一。本周，Slackware Linux将迎来其30周年生日。
Slackware Linux以简单、稳定和安全著称，Slackware Linux主要由Slackware团队维护和开发，该团队由Slackware的创建者Patrick Volkerding领导。Slackware Linux的安装和使用相对较为繁琐，需要手动配置和安装软件包。但它也因此提供了更高的定制性和灵活性，用户可以根据自己的需求自由选择软件版本和配置。Slackware Linux的软件包管理方式较为独特，采用tar包和脚本的方式进行管理和安装。用户需要手动下载和安装所需的软件包，然后进行配置和编译。尽管相对于其他现代Linux发行版，Slackware Linux的界面和功能较为简单，但它的稳定性和安全性仍然吸引着一些用户。此外，Slackware Linux还支持多种硬件平台，包括x86、x64、ARM等。
Slackware 1.0版本发布于1993年7月16日，当前最新的版本Slackware 15则在2021年进入测试阶段，并于去年初正式发布。与其他发行版相似，Slackware最初源自开发者对其他Linux发行版的不满，Debian比Slackware还要年轻一点。其实更早之前，MCC Interim Linux可以说是针对普通用户的第一个发行版，它的第一个候选版本0.97版本在1991年内核诞生几个月后就出现了，但是Interim缺乏许多今天已经具备的特性，例如包管理器。接着其他几个发行版紧随其后，特别是SLS（Softlanding Linux 系统）很快就激发了它的两个后代。正如已故的Debian Linux创始人Ian Murdock在1993年最初的声明中提到，他对SLS的不满激发了对Debian创造。
Slackware Linux 最初是一个修复和改进SLS的项目，Slackware团队迄今为止仍在对其进行维护，不得不说团队成功地完成了它们最初的使命。目前Slackware Linux存在三种变体，同名形式仍然是x86-32系统，而Slackware64是面向64位x86设备的发行版，此外还有Arm64版本。
令人惊讶的是，今天Slackware 15的安装界面与上世纪90年代并无不同，没有诸如图形引导之类的东西，看上去俨然似软件“古董”。它启动到登录提示符，然后您需要手动运行setup程序，并使用90年代DOS风格的文本模式菜单来勾选您想要安装的组件。默认情况下，它没有配置图形登录界面，甚至没有配置普通用户帐户，您需要键入startx并启动桌面，并预配置AMD Radeon显卡驱动程序，准备好连接到无线网络等等。
Slackware 15并不是您想象中的那种轻量级的Linux发行版，运行完整更新将会填满您的16GB根分区。它具有在线存储库、自动依赖性解析以及您期望的那些21世纪发行版中拥有的花里胡哨的功能。
尽管如此，今天的Slackware Linux实际上是一个名符其实的现代发行版，使用它的时候，不要因其过于简单的文本安装模式和、缺乏图形桌面等细节修饰而觉得自己仍活在上个世纪。我们无法确定Slackware的风格是否源于传统，亦或是有意为之（也许是为了吓跑烦人的新手），当然，也可能两者兼有之。如今，它比Alpine Linux或是Arch Linux等更年轻的发行版更容易安装，想起来就像BSD一样，哦，它也是无systemd的（即system daemon，是linux下的一种init软件）。
]]></content>
  </entry>
  
  <entry>
    <title>嵌入式网络接口该怎么设计</title>
    <url>/post/hardware/how-to-design-embedded-network-interface.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>Network</tag>
      <tag>Linux</tag>
      <tag>SOC</tag>
      <tag>MAC</tag>
    </tags>
    <content type="html"><![CDATA[本篇文章是关于嵌入式网络接口的一些知识介绍。
嵌入式网络简介 嵌入式下的网络硬件接口 提起网络，我们一般想到的硬件就是“网卡”，现在网卡已经是通过一个芯片来完成了，嵌入式网络硬件分为两部分：MAC和PHY，大家都是通过看数据手册来判断一款SOC是否支持网络，如果一款芯片数据手册说自己支持网络，一般都是说的这款SOC内置MAC，MAC类似I2C控制器、SPI控制器一样的外设。
但是光有MAC还不能直接驱动网络，还需要另外一个芯片：PHY，因此对于内置MAC的SOC，其外部必须搭配一个PHY芯片。内部没有MAC的SOC芯片，就需要使用外置的MAC+PHY一体芯片了，这里就要牵扯出常见的两个嵌入式网络硬件方案了。
SOC内部没有网络MAC外设 对于内部没有MAC的SOC芯片，可以使用外置 MAC+PHY一体的网络芯片来实现网络功能。比如三星linux开发板里面用的最多的DM9000，DM9000对SOC提供了一个SRAM接口，SOC会以SRAM的方式操作DM9000。
有些外置的网络芯片更强大，内部甚至集成了硬件TCP/IP协议栈，对外提供一个SPI接口，比如W5500。这个一般用于单片机领域，单片机通过SPI接口与W5500进行通信，由于W5500内置了硬件TCP/IP协议栈，因此单片机就不需要移植软件协议栈，直接通过SPI来操作W5500，简化了单片机联网方案。
这种方案的优点就是让不支持网络的SOC能够另辟蹊径，实现网络功能，但是缺点就是网络效率不高，因为一般芯片内置的MAC会有网络加速引擎，比如网络专用DMA，网络处理效率会很高。而且此类芯片网速都不快，基本就是10/100M。另外，相比PHY芯片而言，此类芯片的成本也比较高，可选择比较少。
SOC与外部MAC+PHY芯片的连接如图1-1所示：
图1-1 主控SOC与外置MAC+PHY芯片连接
SOC内部集成网络MAC外设 我们一般说某个SOC支持网络，说的就是他内部集成网络MAC外设，此时我们还需要外接一个网络PHY芯片。。
目前几乎所有支持网络的SOC都是内置MAC外设，比如STM32F4/F7/H7系列、NXP的I.MX系列，内部集成网络MAC的优点如下：
1）内部MAC外设会有专用的加速模块，比如专用的DMA，加速网速数据的处理。
2）网速快，可以支持10/100/1000M网速。
3）外接PHY可选择性多，成本低。
内部的MAC外设会通过MII或者RMII接口来连接外部的PHY芯片，MII/RMII接口用来传输网络数据。另外主控需要配置或读取PHY芯片，也就是读写PHY的内部寄存器，所以还需要一个控制接口，叫做MIDO，MDIO很类似IIC，也是两根线，一根数据线叫做MDIO，一根时钟线叫做MDC。
SOC内部MAC外设与外部PHY芯片的连接如图1-2所示：
图1-2 内部MAC与外部PHY之间的连接
大家在做项目的时候，如果要用到网络功能，强烈建议大家选择内部带有网络MAC外设的主控SOC！I.MX6ULL就有两个10M/100M的网络MAC外设，正点原子ALPHA开发板板载了两颗PHY芯片，型号为LAN8720。因此，本章节只讲解SOC内部MAC+外置PHY芯片这种方案。
MII/RMII接口 前面我们说了，内部MAC通过MII/RMII接口来与外部的PHY芯片连接，完成网络数据传输，本节我们就来学习一下什么是MII和RMII接口。
MII接口 MII全称是Media Independent Interface，直译过来就是介质独立接口，它是IEEE-802.3定义的以太网标准接口，MII接口用于以太网MAC连接PHY芯片，连接示意图如图1-3所示：
图1-3 MII接口
MII接口一共有16根信号线，含义如下：
 TX_CLK：发送时钟，如果网速为100M的话时钟频率为25MHz，10M网速的话时钟频率为2.5MHz，此时钟由PHY产生并发送给MAC。 TX_EN：发送使能信号。 TX_ER：发送错误信号，高电平有效，表示TX_ER有效期内传输的数据无效。10Mpbs网速下TX_ER不起作用。 TXD[3:0]：发送数据信号线，一共4根。 RXD[3:0]：接收数据信号线，一共4根。 RX_CLK：接收时钟信号，如果网速为100M的话时钟频率为25MHz，10M网速的话时钟频率为2.5MHz，RX_CLK也是由PHY产生的。 RX_ER：接收错误信号，高电平有效，表示RX_ER有效期内传输的数据无效。10Mpbs网速下RX_ER不起作用。 RX_DV：接收数据有效，作用类似TX_EN。 CRS：载波侦听信号。 COL：冲突检测信号。  MII接口的缺点就是所需信号线太多，这还没有算MDIO和MDC这两根管理接口的数据线，因此MII接口使用已经越来越少了。
RMII接口 RMII全称是Reduced Media Independent Interface，翻译过来就是精简的介质独立接口，也就是MII接口的精简版本。RMII接口只需要7根数据线，相比MII直接减少了9根，极大的方便了板子布线，RMII接口连接PHY芯片的示意图如图1-4所示：
图1-4 RMII接口
 TX_EN：发送使能信号。 TXD[1:0]：发送数据信号线，一共2根。 RXD[1:0]：接收数据信号线，一共2根。 CRS_DV：相当于MII接口中的RX_DV和CRS这两个信号的混合。 REF_CLK：参考时钟，由外部时钟源提供， 频率为50MHz。这里与MII不同，MII的接收和发送时钟是独立分开的，而且都是由PHY芯片提供的。 除了MII和RMII以外，还有其他接口，比如GMII、RGMII、SMII、SMII等，关于其他接口基本都是大同小异的，这里就不做讲解了。正点原子ALPAH开发板上的两个网口都是采用RMII接口来连接MAC与外部PHY芯片。  MDIO接口 MDIO全称是Management Data Input/Output，直译过来就是管理数据输入输出接口，是一个简单的两线串行接口，一根MDIO数据线，一根MDC时钟线。驱动程序可以通过MDIO和MDC这两根线访问PHY芯片的任意一个寄存器。MDIO接口支持多达32个PHY。同一时刻内只能对一个PHY进行操作，那么如何区分这32个PHY芯片呢？和IIC一样，使用
器件地址即可。同一MDIO接口下的所有PHY芯片，其器件地址不能冲突，必须保证唯一，具体器件地址值要查阅相应的PHY数据手册。
因此，MAC和外部PHY芯片进行连接的时候主要是MII/RMII和MDIO接口，另外可能还需要复位、中断等其他引脚。
RJ45接口 网络设备是通过网线连接起来的，插入网线的叫做RJ45座，如图1-5所示：
图1-5 RJ45座子
RJ45座要与PHY芯片连接在一起，但是中间需要一个网络变压器，网络变压器用于隔离以及滤波等，网络变压器也是一个芯片，外形一般如图1-6所示：
图1-6 网络变压器
但是现在很多RJ45座子内部已经集成了网络变压器，比如最常用的HR911105A就是内置网络变压器的RJ45座。内置网络变压器的RJ45座和不内置的引脚一样，但是一般不内置的RJ45座会短一点。
因此，大家在画板的时候一定要考虑你所使用的RJ45座是否内置网络变压器，如果不内置的话就要自行添加网络变压器部分电路！同理，如果你所设计的硬件是需要内置网络变压器的RJ45座，肯定不能随便焊接一个不内置变压器的RJ45座，否则网络工作不正常！
RJ45座子上一般有两个灯，一个黄色(橙色)，一个绿色，绿色亮的话表示网络连接正常，黄色闪烁的话说明当前正在进行网络通信。这两个灯由PHY芯片控制，PHY芯片会有两个引脚来连接RJ45座上的这两个灯。内部MAC+外部PHY+RJ45座(内置网络变压器)就组成了一个完整的嵌入式网络接口硬件，如图1-7所示：
图1-7 嵌入式网络硬件接口示意图
PHY芯片基础知识 PHY是IEEE 802.3规定的一个标准模块，前面说了，SOC可以对PHY进行配置或者读取PHY相关状态，这个就需要PHY内部寄存器去实现。PHY芯片寄存器地址空间为5位，地址 0~31共32个寄存器，IEEE定义了0~15这16个寄存器的功能，16~31这16个寄存器由厂商自行实现。
也就是说不管你用的哪个厂家的PHY芯片，其中0~15这16个寄存器是一模一样的。仅靠这16个寄存器是完全可以驱动起PHY芯片的，至少能保证基本的网络数据通信，因此 Linux  内核有通用PHY驱动，按道理来讲，不管你使用的哪个厂家的PHY芯片，都可以使用Linux的这个通用PHY驱动来验证网络工作是否正常。
事实上在实际开发中可能会遇到一些其他的问题导致Linux内核的通用PHY驱动工作不正常，这个时候就需要驱动开发人员去调试了。但是，随着现在的PHY芯片性能越来越强大，32个寄存器可能满足不了厂商的需求，因此很多厂商采用分页技术来扩展寄存器地址空间，以求定义更多的寄存器。
这些多出来的寄存器可以用于实现厂商特有的一些技术，因此Linux内核的通用PHY驱动就无法驱动这些特色功能了，这个时候就需要PHY厂商提供相应的驱动源码了，所以大家也会在Linux内核里面看到很多具体的PHY芯片驱动源码。
不管你的PHY芯片有多少特色功能，按道理来讲，Linux内核的通用PHY驱动是绝对可以让你这PHY芯片实现基本的网络通信，因此大家也不用担心更换PHY芯片以后网络驱动编写是不是会很复杂。
IEEE802.3协议英文原版中的 “22.2.4 Management functions”章节，此章节对PHY的前16个寄存器功能进行了规定，如图1-8所示：
图1-8 IEEE规定的前16个寄存器
关于这16个寄存器的内容协议里面也进行了详细的讲解，这里就不分析了。大家可以找个具体的PHY芯片数据手册对比看一下，比如百M网络最常用的LAN8720A这个PHY，大家可以看一下LAN8720前面几个寄存器结构是否和图1-8中的一样。
关于嵌入式Linux的网络接口设计就讲到这里。
]]></content>
  </entry>
  
  <entry>
    <title>Linux 超级漂亮的 Shell</title>
    <url>/post/linux/beautiful-linux-shell.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Shell</tag>
    </tags>
    <content type="html"><![CDATA[Linux/Unix 提供了很多种 Shell，为什么要这么多 Shell？
zsh 介绍 Linux shell 那我问你，你同类型的衣服怎么有那么多件？花色，质地还不一样。写程序比买衣服复杂多了，而且程序员往往负责把复杂的事情搞简单，简单的事情搞复杂。牛程序员看到不爽的 Shell，就会自己重新写一套，慢慢形成了一些标准，常用的 Shell 有这么几种，sh、bash、csh 等，想知道你的系统有几种 shell，可以通过以下命令查看：
cat/etc/shells 显示如下：
zsh 简介 Zsh 是一个 Linux 下强大的 shell, 由于大多数 Linux 产品安装，以及默认使用bash shell, 但是丝毫不影响极客们对 zsh 的热衷, 几乎每一款 Linux 产品都包含有 zsh，通常可以用 apt-get、urpmi 或 yum 等包管理器进行安装
Zsh 具有以下主要功能
 开箱即用、可编程的命令行补全功能可以帮助用户输入各种参数以及选项 在用户启动的所有 shell 中共享命令历史 通过扩展的文件通配符，可以不利用外部命令达到 find 命令一般展开文件名 改进的变量与数组处理 在缓冲区中编辑多行命令 多种兼容模式，例如使用 /bin/sh 运行时可以伪装成 Bourne shell 可以定制呈现形式的提示符；包括在屏幕右端显示信息，并在键入长命令时自动隐藏 可加载的模块，提供其他各种支持：完整的 TCP 与 Unix 域套接字控制，FTP 客户端与扩充过的数学函数 完全可定制化  zsh 与 oh-my-zsh 终极配置 之前是因为看到这篇文章：终极 Shell——Zsh 才选择使用 zsh，被它的自动完成、补全功能吸引了。官网：http://www.zsh.org
选择 oh-my-zsh, oh-my-zsh 是基于 zsh 的功能做了一个扩展，方便的插件管理、主题自定义，以及漂亮的自动完成效果。
在 Github 上找关于 zsh 的项目时发现的，试用了一下觉得很方便，不用像上面文章里面提到的那么复杂，配置一些插件的名称即可使用相应的功能。
官网：https://github.com/robbyrussell/oh-my-zsh
安装 zsh 安装 zsh 对于一般的 Ubuntu 系统，配置好正确的源之后，就能直接键入以下命令安装：
sudo apt-get install zsh 配置 zsh zsh的配置是一门大学问，这里不赘述，直接给出一个配置文件，大家可以下载后放入 zsh 配置文档直接使用。（我的一个法国朋友手配的，相当顺手）
把.zshrc拷贝到相应用户的home目录即可(也可以把你的bash的配置文件(~/.bash_prorile 或者 ~/.profile 等) 给拷贝到zsh的配置文件~/.zshrc里，因为zsh兼容bash)
取代bash，设为默认shell sudo usermod -s /bin/zsh username 或者
chsh -s /bin/zsh chsh -s `whichzsh` 如果要切换回去 bash：
chsh -s /bin/bash 当然你实在不愿意把 zsh 当成默认的 shell, 而又想使用它, 那么你可以每次进入是都使用zsh进入, 而输入exit退出
安装oh-my-zsh 直接用 zsh 会很麻烦，因为 zsh 功能很强大但是太复杂，所以需要 oh-my-zsh 来将它简单化
直接用 git 从 github 上面下载包 git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh 备份已有的 zshrc, 替换 zshrc cp ~/.zshrc ~/.zshrc.orig cp~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 直接使用脚本安装 cd oh-my-zsh/tools ./install.sh 你可以直接直接使用如下命令安装
sh -c &#34;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&#34; sh -c &#34;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&#34; 其本质就是下载并执行了 github 上的 install.sh 脚本, 该脚本位于oh-my-zsh/tools/install.sh
配置主题 oh-my-zsh 集成了大量的主题, 位于oh-my-zsh/theme
配置主题, 可以通过修改~/.zshrc中的环境变量ZSH_THEME来完成
ZSH_THEME=&#34;agnoster&#34; # (this is one of the fanc yones) 如果你觉得主题太多你可以选择使用随机模式, 来由系统随机选择
ZSH_THEME=&#34;random&#34;#(...please let it be pie... please be some pie..) 详细的主题信息, 可以参见 zsh 主题介绍
配置插件 修改～/.zshrc中plugins
plugins=(gitbundlerosxrakeruby)
详细的插件信息, 可以参见 zsh 插件 Plugins 介绍
更新 oh-my-zsh 默认情况下, 您将被提示检查每几周的升级. 如果你想我 ZSH 自动升级本身没有提示你, 修改 ~/.zshrc
disable_update_prompt=true 禁用自动升级, 修改~/.zshrc disable_auto_update=true 当然你也可以选择手动更新 如果你想在任何时间点升级（也许有人刚刚发布了一个新的插件，你不想等待一个星期？) 你只需要运行：
upgrade_oh_my_zsh
卸载 oh-my-zsh 如果你想卸载oh-my-zsh, 只需要执行uninstall_oh_my_zsh zsh， 从命令行运行，这将删除本身和恢复你以前的 bash 或者 zsh 配置。
]]></content>
  </entry>
  
  <entry>
    <title>如何在Linux中搭建DNS服务</title>
    <url>/post/linux/dns-server-configuration-in-linux.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>DNS</tag>
    </tags>
    <content type="html"><![CDATA[要在Linux系统上搭建DNS服务，你可以按照以下步骤进行操作：
安装BIND软件包 sudo yum install bind bind-utils 配置主DNS服务器 打开/etc/named.conf文件，编辑DNS服务器的配置。根据你的域名和网络环境，修改以下示例配置为适当的值：
options { listen-on port 53 { any; }; allow-query { any; }; recursion yes; }; zone &#34;example.com&#34; IN { type master; file &#34;/var/named/example.com.zone&#34;; allow-update { none; }; }; 创建主DNS区域文件 创建一个区域文件以存储DNS记录。在/var/named/目录下创建一个名为example.com.zone的文件，并添加相应的DNS记录。示例：
$TTL 86400 @ IN SOA ns1.example.com. root.example.com. ( 2018010101 ; Serial 3600 ; Refresh 1800 ; Retry 604800 ; Expire 86400 ; Minimum TTL ) @ IN NS ns1.example.com. @ IN A 192.168.1.10 www IN A 192.168.1.20 配置反向解析 打开/etc/named.conf文件，并添加反向解析配置。示例：
zone &#34;1.168.192.in-addr.arpa&#34; IN { type master; file &#34;/var/named/1.168.192.zone&#34;; allow-update { none; }; }; 创建反向解析区域文件 在/var/named/目录下创建一个名为1.168.192.zone的文件，用于反向解析。添加以下内容：
$TTL 86400 @ IN SOA ns1.example.com. root.example.com. ( 2018010101 ; Serial 3600 ; Refresh 1800 ; Retry 604800 ; Expire 86400 ; Minimum TTL ) @ IN NS ns1.example.com. 10 IN PTR example.com. 20 IN PTR www.example.com. 设置防火墙规则 如果您的防火墙处于启用状态，请确保允许DNS流量通过
sudo firewall-cmd --add-service=dns --permanent sudo firewall-cmd --reload 启动并启用DNS服务 sudo systemctl start named sudo systemctl enable named 现在，你的Linux系统上的DNS服务器就已经搭建完成了。您可以在其他设备上将DNS服务器设置为您的CentOS主机的IP地址，以使用该DNS服务器进行域名解析。
请注意，在实际生产环境中，你可能需要更复杂的配置来满足网络需求，例如添加其他区域或配置转发等。
DNS原理及解析流程 DNS是互联网中用于将域名解析为IP地址的系统。它充当了一个分布式数据库，将人类可读的域名映射到计算机可理解的IP地址。
DNS的解析流程如下：
 用户在浏览器中输入一个域名，比如www.example.com 操作系统首先会检查本地缓存（称为本地DNS缓存），看是否已经有该域名的解析结果。如果有，则直接返回并跳至第8步。如果没有，继续进行后续步骤。 操作系统向预配置的本地DNS服务器发送一个DNS查询请求。这个本地DNS服务器通常由用户的ISP（互联网服务提供商）或者自定义的DNS服务器提供。 本地DNS服务器收到查询请求后，首先检查自己的缓存，如果存在对应的域名解析结果，直接返回给操作系统。如果没有，则继续进行后续步骤。 本地DNS服务器根据域名的顶级域（TLD）来选择合适的根域名服务器（Root DNS Server）发送查询请求。根域名服务器负责管理顶级域名服务器的地址信息。 根域名服务器返回给本地DNS服务器一个顶级域名服务器的地址。 本地DNS服务器再次向顶级域名服务器发送查询请求。顶级域名服务器负责管理对应顶级域下的权威域名服务器（Authoritative DNS Server）的地址信息。 本地DNS服务器收到权威域名服务器的地址后，向权威域名服务器发送最终的查询请求。 权威域名服务器收到查询请求后，在自己的数据中查找该域名的解析结果。 如果权威域名服务器找到了该域名的解析结果，它将返回给本地DNS服务器。 本地DNS服务器收到解析结果后，会将其缓存下来，并将解析结果返回给操作系统。 操作系统将解析结果传递给应用程序，例如浏览器。 应用程序利用解析结果中的IP地址与服务器建立连接，并完成后续的通信过程。 整个DNS解析流程可能涉及多次查询和响应，但由于DNS系统的分布式结构和缓存机制，大部分解析结果可以从本地DNS缓存或者本地DNS服务器的缓存中获取，从而提高解析速度和减轻DNS服务器的负载压力。  需要注意的是，DNS解析并非一次性完成的，DNS记录可能会发生变化，因此在某些情况下，需要等待DNS记录的刷新时间（TTL）过期后才能获取到最新的解析结果。
原文连接: 如何在Linux中搭建DNS服务  
]]></content>
  </entry>
  
  <entry>
    <title>取代C++？谷歌开源编程语言Carbon</title>
    <url>/post/programming/google-open-source-programming-language-carbon.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>Google</tag>
      <tag>C++</tag>
      <tag>Carbon</tag>
    </tags>
    <content type="html"><![CDATA[号称替代C++，谷歌发布新的编程语言，已经过去了一年。去年7月，在多伦多举办的CppNorth大会上，谷歌宣布正式开源内部打造的编程语言Carbon，并称他是C++的继任者。
谷歌的工程师认为呢，尽管C++仍然是性能关键性软件的主流编程语言，并且拥有庞大且不断增长的代码库。但同时呢，也存在着应用性较差，掌握难度大以及由于语言功能过于丰富而导致的混乱的问题。
所以呢，他们决定自己开发一门语言来代替C++，于是呢，这个速度更快，并且可以和C++代码互相操作的新语言就应运而生了，Carbon编程语言已经在GitHub上开源了。
其实呢，Google在编程语言方面确实还挺强的，之前开源的go long呢，目前已经是使用非常广泛的一个编程语言了，但是这次Carbon能否延续Go语言的传奇？目前下结论呢，还为时尚早，毕竟上一个号称代替C++的 Rust  语言目前混的并不咋滴。
在谈到为何要替代 C++ 时，谷歌工程师Carruth表示，C++作为长期以来构建性能关键应用的首选语言，它自身的很多问题困扰着现代开发人员。C++积累了数十年的技术负债，带有的很多过时实践都是其前身C语言的一部分。C++ 的维护者优先考虑向后兼容，以便继续支持广泛使用的项目，例如Linux及其包管理生态系统等。
此外，C++语言的发展也受到了官僚委员会程序的阻碍，该程序以标准化而非设计为导向。这种做法导致很难添加新功能。C++在很大程度上处于一个隔绝的开发过程，其中可能经过数年才会做出一些重要决定。
因此，Carruth希望通过更开放的社区主导环境来构建Carbon语言，并已开源。到2023年7月中旬，该项目已在GitHub上获得30.8k的Stars。
Carbon的设计理念和特性 谷歌希望在2022年年底推出Carbon的核心工作版本，即v0.1。Carbon将建立在现代编程原则的基础上，包含一个泛型系统，使开发人员不再需要为每个实例检查和再核对代码。
C++ 语言中亟需的一个特性是内存安全。内存访问 bug是安全漏洞的罪魁祸首之一，Carbon 设计人员将探索追踪未初始化状态的更好方法、设计支持动态边界检查的 API和惯用语，并构建全面的默认debug构建模式。随着时间的推移，设计人员还计划构建一个安全的Carbon子集。
Carbon语言将支持以下功能：  性能关键型软件； 软件和语言演变； 易于阅读、理解和编写的代码； 实用的安全和测试机制； 快速且可扩展的开发； 现代操作系统平台、硬件架构和环境； 与现有C++代码的互操作性和迁移  同时，Carbon语言的亮点包括如下：  Introducer关键字和简单语法； 函数输入参数为只读值； 指针提供间接访问和变体； 使用表达式命名类型； 软件包为root命名空间； 通过包名导入APIs； 用显式对象参数来声明方法； 单继承、默认使用最终类； 强大且经过定义检查的泛型； 类型显式地实现接口。  Carbon设计团队将着手创建一个内置包管理器，这在C++中非常欠缺。此外，团队还计划编写一些将C++代码迁移到Carbon代码的工具。下图左为C++代码，右为Carbon编写的相同函数：
为何不大力发展Rust语言呢？ 有人或许会问了：最近有专门为解决内存安全性能应用的需求而构建的Rust语言，为何不直接使用它呢？Carruth对此表示，如果Rust适合你，就继续使用。但是，将C++的生态系统转移到Rust非常困难。
相比之下，Carbon是建立在已有C++生态系统之上，适合那些已经拥有大量C++代码库的开发人员，这些库很难转换到Rust。
目前 Carbon 语言的代码已完全开源。Chandler 表示，虽然 Carbon 诞生自谷歌内部，且目前的项目负责人主要（不完全）由谷歌员工组成，但它的目标是要成为一个 “独立且由社区驱动的开源项目”。
如果你对 Carbon 感兴趣，可以下载源代码并在自己的设备上进行试验，或者通过 Compiler Explorer 直接在浏览器中体验 Carbon 编程语言。
对于 Carbon 项目，有开发者透露了一些背景信息：2020 年 2 月，C++ 标准委员会就 “破坏 ABI 兼容性以保证性能” 提案进行了投票，这项工作主要由谷歌员工推动，但最终投票没有通过。因此，许多谷歌员工已经停止参与 C++ 的标准化工作，并辞去他们在委员会中的正式职务，clang 的开发工作也大大放缓。基于这些背景，再结合谷歌对 Carbon 设定的目标，这名开发者认为，谷歌确实希望把 Carbon 打造成替代 C++ 的语言。
]]></content>
  </entry>
  
  <entry>
    <title>RS422/485接口电路设计要点</title>
    <url>/post/hardware/design-points-of-rs422-485-circuit.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>UART</tag>
      <tag>RS422</tag>
      <tag>RS485</tag>
    </tags>
    <content type="html"><![CDATA[RS-422标准全称是“平衡电压数字接口电路的电气特性”，它定义了接口电路的特性。
实际上还有一根信号地线，共5根线。由于接收器采用高输入阻抗和发送驱动器比RS232更强的驱动能力，故允许在相同传输线上连接多个接收节点，最多可接10个节点。一个主设备（Master），其余为从设备（Slave），从设备之间不能通信，所以RS-422支持点对多的双向通信。接收器输入阻抗为4k，故发端最大负载能力是10&amp;TImes;4k+100Ω（终接电阻）。
 RS-422和RS-485电路  原理基本相同，都是以差动方式发送和接收，不需要数字地线。差动工作是同速率条件下传输距离远的根本原因，这正是二者与RS232的根本区别，因为RS232是单端输入输出，双工工作时至少需要数字地线。发送线和接收线三条线（异步传输），还可以加其它控制线完成同步等功能。
RS-422通过两对双绞线可以全双工工作收发互不影响，而RS485只能半双工工作，发收不能同时进行，但它只需要一对双绞线。RS422和RS485在19kpbs下能传输1200米。用新型收发器线路上可连接台设备。
典型的RS422接口电路 图 1 典型的RS422接口电路
典型的RS485接口电路 图 2 典型的RS485接口电路
图 3 全双工RS485接口电路拓扑
设计要点   接口保护用途的TVS管D1-8，通常选择最大反向工作电压VRWM为5.0V的双向TVS管，如Diodes SMBJ5.0CA。注：这里可以选择耐压更高的TVS元件。
  DI和RO引脚都使用10k电阻上拉，是为防止误触发，产生误动作，因为“UART以一个前导“0”触发一次接收动作”。
  图 1所示，差分接收器的端接电阻一般取值120 Ω，来源于通常RS422/485传输线所用的特征阻抗约为120 Ω。图 3所示的RS485多点应用中，若在SCH&amp;PCB设计时不清楚后期现场布线中哪两个设备距离最远，可在所有差分接收端都预留120 Ω端接电阻，以便后期现场应用时通过拨码开关选择性接入。
  由于RS422/485差分接收器的特性是，VIA - VIB的绝对值必须大于200 mV，否则无法正确识别高低电平。所以，图 1所示，当使用3.3V电源时，故障安全偏置电阻R5和R6最大取值为930 Ω；当使用5.0V电源时，R5和R6最大取值为1440 Ω。
  说明：故障安全偏置电阻，是为了解决“总线空闲、开路或短路”情况下，接收端状态不确定的问题。由于RS422只支持点对点应用，且故障安全偏置电阻只需要在接收端使用，所以图 1和图 2电路，R3-4不是必要的，R5-6和R12-15是必要的。注：如果R12/R13在发送端已经有，那么在接收端就不是必要的。
 图 1所示，在RS422点对点应用中，两端的差分接收器都需要120 Ω并联端接电阻。图 3所示，在RS485多点应用中，只需在最远的两点接收端使用120 Ω并联端接电阻，中间各支路不需要。
  图 2和图 3所示，各支路的A&amp;B引脚和Z&amp;Y引脚都串联0R电阻，当某路故障时将RS485总线拉低时，逐一断开电阻，方便排查故障。
  SCH&amp;PCB设计时，两个设备间的RS422/485通信线，除了两对差分线外，至少需要一根地线，防止共模电压超出规定的范围而导致通信故障。
  有选择的情况下，RS422/485通信电缆中，信号线不应与电源线并行或尽量远离电源线，若无法避免，信号线最好使用带屏蔽的双绞线。且现场布线，采用菊花链拓扑，不采用星形或环形拓扑，以免因反射等因素导致通信错误。
  原文地址： RS422/485接口电路设计要点  
]]></content>
  </entry>
  
  <entry>
    <title>5款超强大的FPGA开发板</title>
    <url>/post/fpga/5-ultra-powerful-fpga-development-boards.html</url>
    <categories><category>FPGA</category>
    </categories>
    <tags>
      <tag>FPGA</tag>
      <tag>Xilinx</tag>
      <tag>Microsemi</tag>
      <tag>Stratix 10</tag>
    </tags>
    <content type="html"><![CDATA[随着人工智能、深度学习在市场越来越受欢迎，除了GPU、众多独角兽公司的AI专用芯片，FPGA同样是深度学习的热门平台之一。本文将给大家介绍5款强大到不可思议的FPGA开发板，当然价格也是高的离谱，肯能对于大多数工程师来说，这些属于求而不得的高端“玩具”。
RTG4开发套件 RTG4-DEV-KIT是Microsemi公司的产品，当然目前的话已经被Microchip收购，这是一套为高端的客户提供的评估和开发平台，主要用于数据传输，串行连接，总线接口等高密度高性能FPGA的高速设计等应用 。
该开发板采用RT4G150器件，采用陶瓷封装，提供150,000个逻辑元件，具有1,657个引脚，下图是RTG4-DEV-KIT开发板的外设接口功能图。
RTG4开发套件主要包括的硬件功能如下：
 两个1GB DDR3同步动态随机存取存储器(SDRAM) 2GB SPI Flash PCI Express Gen1 接口1个 PCIe x4 接口 一对SMA连接器，用于测试全双工SERDES通道 两个带有HPC/LPC引脚排列的FMC连接器，用于扩展 用于10/100/1000以太网的RJ45接口 USB micro-AB连接器 SPI，GPIO的接口 FTDI编程器接口用于编程外部SPI Flash JTAG编程接口 用于应用程序编程和调试的RVI接口 Flashpro编程接口 用于调试的嵌入式跟踪宏(ETM)单元接口 用于用户应用的双列直插式封装(DIP)开关 按钮开关和LED 电流测量测试点  RTG4-DEV-KIT开发板的硬件框图
从硬件框图上也能看到RTG4-DEV-KIT复杂的电源管理系统，12V的DC直流供电，通过DCDC/以及LDO分配到各个功能部分的供电。
英特尔Stratix 10开发套件 Intel Stratix 10开发套件是包含各类软硬件的完整设计环境，用于评估Stratix 10 FPGA的功能。该套件可用于通过符合PCI-SIG的开发板来开发和测试PCI Express 3.0设计。使用这些开发板可开发和测试由DDR4、DDR3、QDR IV和RLDRAM III存储器组成的存储器子系统。通过使用FPGA夹层卡 (FMC) 连接器与FMC夹层卡连接，还可以开发模块化和可扩展设计。该套件支持JESD204B、Serial RapidIO、10Gbps以太网 (10GbE)、SONET、通用公共无线电接口 (CPRI)、OBSAI等诸多协议。
英特尔Stratix 10开发套件硬件框图
开发板板载的主要FPGA是Intel公司的Stratix 10系列产品，相比前一代产品成本提供2X性能和超低功耗，具有几个开创性的创新如新型的HyperFlex™和架构，能满足日益增长的带宽和处理性能，从而满足功率预算。嵌入硬件系统基于四核64位ARM Cortex-A53，采用Intel 14-nm Tri-Gate (FinFET)技术和混合性3D片上系统(SiP)技术，单片核多达550万和逻辑单元，多达96个全双工收发器，数据速率高达28.3Gbps，主要用在计算和存储，网络设备，光传输网络，广播，军用雷达，医疗设备，测试和测量以及5G无线设备，ASIC原型。
ADS8-V1 评估板 确切的说，ADS8-V1 评估板并不是一块专为FPGA评估的板卡，而是为了支持ADI公司高速数据转换，当连接到指定的 ADI 高速 ADC 评估板时，ADS8-V1 可用作数据采集板。ADS8-V1 上的 FPGA 设计用于支持最高速 JESD204B 模数转换器，可充当数据接收器，同时 ADC 为数据发射器。
ADS8-V1EBZ接口外设如下：
 Xilinx Kintex Ultrascale XCKU040-3FFVA1156E FPGA 一(1)个FMC +连接器 一(1)个FMC +连接器支持二十(20)个16Gbps收发器 DDR4 SDRAM 简单的USB 3.0端口接口  ADI强大的数据采集评估板可以应用于航空航天和防务、电子监控和对抗、仪器仪表和测量、通信测试设备、信号发生器(通过射频传输音频)、5G领域等。
REFLEX CES XpressVUP-LP9P REFLEX CES XpressVUP-LP9P是基于Virtex Ultrascale + VU9P FPGA的低配置PCIe网络处理FPGA板，专为HPC等网络应用而设计。该板提供2组DDR4，2组QDR2 +存储器和2个QSFP28网箱，用于多个10GbE / 40GbE / 100GbE网络解决方案。其主要的功能包括了：PCIe Gen3 x16、Xilinx Virtex UltraScale + VU9P FPGA、板载两个DDR4和两个QDR2 +独立组、两个QSFP28光纤笼用于多网络解决方案、具有16个通道，8 Gb/s链路速率的PCIe接口(Gen3)等。
XpressVUP-LP9P技术规格 FPGA和配置模块  Xilinx Virtex UltraScale + 16nm FPGA：XCVU9P-L2FLGB2104E(生产) XCVU9P-L2FLGB2104E(生产) 2,6 M系统逻辑单元 270 Mb UltraRAM(UltraScale +提供高密度，双端口，同步存储器模块) 用于外部Xilinx USB电缆的JTAG连接器 双四SPI(x8)配置模式的2x Nor Flash  通讯接口  PCI Express x16(第1,2或3代) 2 x QSFP28四光纤笼(2 x 4 XCVR：每条链路28 Gb/ s)，支持10GbE / 40GbE / 100GbE QSFP28模块支持的其他协议  存储  板载DDR4,2x组64位+ 4位ECC，总共8GB 板载QDR-II +，2x存储区，18位，总共144Mbits  功率  最大100W 提供定制散热器  其他资源  板载可编程PLL振荡器(Si5345)，高度灵活和可配置的时钟发生器。 板载高精度振荡器为精确时间协议(PTP)以太网提供时钟精确20MHz-0.05ppm，同步协议标准化IEEE 1588 一个用于PPS(每秒脉冲)的同轴连接器，允许多个电子部件同步  REFLEX CES XpressVUP-LP9P硬件框图
值得一提的是，XpressVUP在POWER9 CPU主机处理器(IBM)上支持CAPI 2.0，并且还支持IBM SNAP框架，只需很少的FPGA专业知识，SNAP框架允许应用工程师在服务器环境中快速创建基于FPGA的加速程序。它使用IBM CAPI 2.0接口，该接口可在标准PCIe物理通道上运行，但具有CPU和FPGA之间较低延迟和一致内存共享的优势。
Digilent NetFPGA-SUME NetFPGA-SUME是Digilent，剑桥大学和斯坦福大学之间的合作项目，是高性能和高密度网络设计的理想平台。
NetFPGA-SUME采用赛灵思Virtex-7 690T FPGA，支持30个13.1 GHz GTH收发器，四个SFP + 10Gb/s端口，五个独立的高速存储器组，由500MHz QDRII +和1866MT / s DDR3 SoDIMM器件构建，以及一个八通道第三代PCIe，可提供超大的吞吐量，并可支持大量高速数据流FPGA架构和存储器件，其它功能包括在FMC和QTH扩展连接器以及SATA端口上共展示20个收发器。
NetFPGA-SUME的主要任务是为学生，研究人员和开发人员提供最先进的网络平台，无论是学习基础知识还是创建新的硬件和软件应用程序，该板可轻松支持四个10Gb/s以太网端口上的同时线速处理，并可在板上操作和处理数据。
Digilent NetFPGA-SUME特征：  Xilinx Virtex-7 XC7V690T FFG1761-3 Xilinx CPLD XC2C512用于FPGA配置 PCIe Gen3 x8(8Gbps /通道) 两个512Mbits Micron StrataFlash(PC28F512G18A) 编程：赛灵思Vivado 设计套件 三个x36 72Mbits QDR II SRAM(CY7C25652KV18-500BZC) 两个4GB DDR3 SODIMM(MT8KTF51264Hz-1G9E1) 用于JTAG编程和调试的Micro USB连接器(与UART接口共享) 一根Micro USB线用于编程/ UART QTH连接器(8个RocketIO GTH收发器) 四个SFP +接口(4个RocketIO GTH收发器)，支持10Gbps 两个SATA-III端口 用户LED和按钮 一个HPC FMC连接器(10个RocketIO GTH收发器) 一个Pmod端口  总结 FPGA的强大还是在于其超灵活的可编程能力，随着人工智能越来越受市场的喜爱，无论是GPU还是专用的AI芯片都不可能像FPGA这样便于新进入这个领域的企业折腾、创新，带着这种与生俱来的优势，相信FPGA的春天还很漫长。
原文连接: 5款超强大的FPGA开发板  
]]></content>
  </entry>
  
  <entry>
    <title>10道经典的嵌入式C语言题目</title>
    <url>/post/programming/ten-classical-embedded-c-language-examination-questions.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Embedded</tag>
      <tag>Struct</tag>
    </tags>
    <content type="html"><![CDATA[10个C语言面试题，涉及指针、进程、运算、结构体、函数、内存，看看你能做出几个
gets()函数 问：请找出下面代码里的问题：
#include&lt;stdio.h&gt; int main(void) { char buff[10]; memset(buff,0,sizeof(buff)); gets(buff); printf(&#34;\nThe buffer entered is [%s]\n&#34;,buff); return 0; } 答：上面代码里的问题在于函数gets()的使用，这个函数从stdin接收一个字符串而不检查它所复制的缓存的容积，这可能会导致缓存溢出。这里推荐使用标准函数fgets()代替。
strcpy()函数 问：下面是一个简单的密码保护功能，你能在不知道密码的情况下将其破解吗？
#include&lt;stdio.h&gt;  int main(int argc, char *argv[]) { int flag = 0; char passwd[10]; memset(passwd,0,sizeof(passwd)); strcpy(passwd, argv[1]); if(0 == strcmp(&#34;LinuxGeek&#34;, passwd)) { flag = 1; } if(flag) { printf(&#34;\nPassword cracked \n&#34;); } else { printf(&#34;\nIncorrect passwd \n&#34;); } return 0; } 答：破解上述加密的关键在于利用攻破strcpy()函数的漏洞。所以用户在向“passwd”缓存输入随机密码的时候并没有提前检查“passwd”的容量是否足够。
所以，如果用户输入一个足够造成缓存溢出并且重写“flag”变量默认值所存在位置的内存的长“密码”，即使这个密码无法通过验证，flag验证位也变成了非零，也就可以获得被保护的数据了。例如：
$ ./psswd aaaaaaaaaaaaa Password cracked 虽然上面的密码并不正确，但我们仍然可以通过缓存溢出绕开密码安全保护。
要避免这样的问题，建议使用 strncpy()函数。
作者注：最近的编译器会在内部检测栈溢出的可能，所以这样往栈里存储变量很难出现栈溢出。在我的gcc里默认就是这样，所以我不得不使用编译命令‘-fno-stack-protector’来实现上述方案。
main()的返回类型 问：下面的代码能 编译通过吗？如果能，它有什么潜在的问题吗？
#include&lt;stdio.h&gt;  void main(void) { char *ptr = (char*)malloc(10); if(NULL == ptr) { printf(&#34;\nMalloc failed \n&#34;); return; } else { // Do some processing  free(ptr); } return; } 答：因为main()方法的返回类型，这段代码的错误在大多数编译器里会被当作警告。
main()的返回类型应该是“int”而不是“void”。因为“int”返回类型会让程序返回状态值。这点非常重要，特别当程序是作为依赖于程序成功运行的脚本的一部分运行时。
内存泄露 问：下面的代码会导致内存泄漏吗？
#include&lt;stdio.h&gt;  void main(void) { char *ptr = (char*)malloc(10); if(NULL == ptr) { printf(&#34;\nMalloc failed \n&#34;); return; } else { // Do some processing  } return; } 答：尽管上面的代码并没有释放分配给“ptr”的内存，但并不会在程序退出后导致内存泄漏。在程序结束后，所有这个程序分配的内存都会自动被处理掉。
但如果上面的代码处于一个“while循环”中，那将会导致严重的内存泄漏问题！
提示：如果你想知道更多关于内存泄漏的知识和内存泄漏检测工具，可以来看看我们在Valgrind上的文章。
free()函数 问：下面的程序会在用户输入’freeze’的时候出问题，而’zebra’则不会，为什么？
#include&lt;stdio.h&gt;  int main(int argc, char *argv[]) { char *ptr = (char*)malloc(10); if(NULL == ptr) { printf(&#34;\nMalloc failed \n&#34;); return -1; } else if(argc == 1) { printf(&#34;\nUsage \n&#34;); } else { memset(ptr, 0, 10); strncpy(ptr, argv[1], 9); while(*ptr != &#39;z&#39;) { if(*ptr == &#39;&#39;) break; else ptr++; } if(*ptr == &#39;z&#39;) { printf(&#34;\nString contains &#39;z&#39;\n&#34;); // Do some more processing  } free(ptr); } return 0; } 答：这里的问题在于，代码会（通过增加“ptr”）修改while循环里“ptr”存储的地址。当输入“zebra”时，while循环会在执行前被终止，因此传给free()的变量就是传给malloc()的地址。
但在“freeze”时，“ptr”存储的地址会在while循环里被修改，因此导致传给free()的地址出错，也就导致了seg-fault或者崩溃。
使用_exit退出 问：在下面的代码中，atexit()并没有被调用，为什么？
#include&lt;stdio.h&gt;  void func(void) { printf(&#34;\nCleanup function called \n&#34;); return; } int main(void) { int i = 0; atexit(func); for(;i&lt;0xffffff;i++); _exit(0); } 这是因为_exit()函数的使用，该函数并没有调用atexit()等函数清理。如果使用atexit()就应当使用exit()或者“return”与之相配合。
void*和C结构体 问：你能设计一个能接受任何类型的参数并返回interger（整数）结果的函数吗？
答：如下：
int func(void *ptr) 如果这个函数的参数超过一个，那么这个函数应该由一个结构体来调用，这个结构体可以由需要传递参数来填充。
* 和 ++ 操作 问：下面的操作会输出什么？为什么？
#include&lt;stdio.h&gt;  int main(void) { char *ptr = &#34;Linux&#34;; printf(&#34;\n[%c] \n&#34;,*ptr++); printf(&#34;\n[%c] \n&#34;,*ptr); return 0; } 答：输出结果应该是这样：
[L]
[i]
因为“++”和“ * ” 的优先权一样，所以“ * ptr++ ”相当于 “ * (ptr++) ”。即应该先执行 ptr++，然后才是 * ptr，所以操作结果是“L”。第二个结果是“i”。
问：修改代码片段 问：下面的代码段有错，你能指出来吗？
#include&lt;stdio.h&gt;  int main(void) { char *ptr = &#34;Linux&#34;; *ptr = &#39;T&#39;; printf(&#34;\n[%s] \n&#34;, ptr); return 0; } 答：这是因为，通过 * ptr = ‘T’，会改变内存中代码段（只读代码）“Linux”的第一个字母。这个操作是无效的，因此会造成segment-fault或者崩溃。
返回本地变量的地址 问：下面代码有问题吗？如果有，该怎么修改？
#include&lt;stdio.h&gt;  int* inc(int val) { int a = val; a++; return &amp;a; } int main(void) { int a = 10; int *val = inc(a); printf(&#34;\nIncremented value is equal to [%d] \n&#34;, *val); return 0; } 答：尽管上面的程序有时候能够正常运行，但是在“inc()”中存在严重的漏洞。这个函数返回本地变量的地址。因为本地变量的生命周期就是“inc()”的生命周期，所以在inc结束后，使用本地变量会发生不好的结果。这可以通过将main()中变量“a”的地址来避免，这样以后还可以修改这个地址存储的值。
]]></content>
  </entry>
  
  <entry>
    <title>Linux操作系统学习——启动</title>
    <url>/post/linux/linux-operating-system-study-boot.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Boot</tag>
    </tags>
    <content type="html"><![CDATA[Linux操作系统内核是服务端学习的根基，也是提高编程能力、源码阅读能力和进阶知识学习能力的重要部分，本文开始将记录Linux操作系统中的各个部分源码学习历程。
前言 关于如何学习源码，个人觉得可以从以下角度入手，有效地提高阅读和学习的效率。（学习语言就不说了，这是基本功。学习IDE推荐Source Insight或者Visual Studio，网站源码阅读推荐woboq）
理解代码的组织结构。 以Linux源码举例，首先你得知道操作系统分为哪几个部分，他们单独做了什么功能，如何进行配合完成更为具体的功能。建立整体的印象有助于后续深入学习的时候方便理解，毕竟代码是用的不是看的，理解他的作用有利于理解为什么要这么做。
深入各个模块学习 模块接口： 这里推荐微软的画图工具visio或者思维导图xmind，用其画图可以将各个模块的接口列出，并绘制各个模块之间的关系，通过了解接口可以清楚各个模块之间的关系，即绘制模块组织图
工作流程： 通过上面一步得到各模块间的关系，然后实际用断点或log等方式看一看整体的工作流程，在模块组织图的基础上绘制程序流程图
模块粘合层： 我们的代码有很多都是用来粘合代码的，比如中间件（middleware）、Promises 模式、回调（Callback）、代理委托、依赖注入等。这些代码模块间的粘合技术是非常重要的，因为它们会把本来平铺直述的代码给分裂开来，让你不容易看明白它们的关系。这些可以作为程序流程图的补充，让其中本来无法顺畅衔接的地方变得通畅无阻。
模块具体实现： 这是最难得地方，涉及到大量具体源码的学习。深入细节容易迷失在细节的海洋里，因此需要有一些重点去关注，将非重点的内容省略。通过学习绘制模块具体架构图和模块的算法时序图，可以帮助你更好的掌握源码的精髓。
需要关注的包括 代码逻辑。 代码有两种逻辑，一种是业务逻辑，这种逻辑是真正的业务处理逻辑；另一种是控制逻辑，这种逻辑只是用控制程序流转的，不是业务逻辑。比如：flag 之类的控制变量，多线程处理的代码，异步控制的代码，远程通讯的代码，对象序列化反序列化的代码等。这两种逻辑你要分开，很多代码之所以混乱就是把这两种逻辑混在一起了。
重要的算法。 一般来说，我们的代码里会有很多重要的算法，我说的并不一定是什么排序或是搜索算法，可能会是一些其它的核心算法，比如一些索引表的算法，全局唯一 ID 的算法、信息推荐的算法、统计算法、通读算法（如 Gossip）等。这些比较核心的算法可能会非常难读，但它们往往是最有技术含量的部分。
底层交互。 有一些代码是和底层系统的交互，一般来说是和操作系统或是 JVM 的交互。因此，读这些代码通常需要一定的底层技术知识，不然，很难读懂。
可以忽略的包括 出错处理。 根据二八原则，20% 的代码是正常的逻辑，80% 的代码是在处理各种错误，所以，你在读代码的时候，完全可以把处理错误的代码全部删除掉，这样就会留下比较干净和简单的正常逻辑的代码。排除干扰因素，可以更高效地读代码。
数据处理。 只要你认真观察，就会发现，我们好多代码就是在那里倒腾数据。比如 DAO、DTO，比如 JSON、XML，这些代码冗长无聊，不是主要逻辑，可以不理。
忽略过多的实现细节。 在第一遍阅读源码时，已弄懂整体流程为主，至于具体的实现细节先简单的理清处过一遍，不用过于纠结。当梳理清楚全部的框架逻辑后，第二遍再深入的学习研究各个模块的实现，此时应该解决第一遍中的疑惑。第三遍可以跳出代码的实现，来看Linux的设计思路、编程艺术和演进之路。
重在实践。 Linux的代码都是可以调试的，看很多遍也许不如跟着调试走一遍，然后再自己修改修改做一些小测试。
传授知识。 当你能将知识讲述给别人听，并让别人听懂时，你已经可以自豪的说洞悉了这些知识。所以不妨从一个小的例子开始自说自话，看能不能自圆其说，甚至写成博客、做成PPT给大家讲解。
说了一大堆的废话，下面就正式开始操作系统的深入学习记录之旅了。
混沌初开 本文分析从按下电源键到加载BIOS以及后续bootloader的整个过程。犹如盘古开天辟地一般，该过程将混沌的操作系统世界分为清晰的内核态和用户态，并经历从实模式到保护模式的变化。这里先简单介绍一下名词，便于后续理解。
实模式（Real Mode)：又名 Real Address Mode，在此模式下地址访问的是真实地内存地址所在位置。在此模式下，可以使用20位（1MB）的地址空间，软件可以不受限制的操作所有地址的空间和IO设备。
保护模式（Protected Mode)：又名 Protected Virtual Address Mode，采用虚拟内存、页等机制对内存进行了保护，比起实模式更为安全可靠，同时也增加了灵活性和扩展性。
从启动电源到BIOS 当我们按下电源键，主板会发向电源组发出信号，接收到信号后，电源会提供合适的电压给计算机。当主板收到电源正常启动的信号后，主板会启动CPU。CPU重置所有寄存器数据，并设置初始化数据，这个初始化数据在X86架构里如下所示：
1IP 0xfff0 2CS selector 0xf000 3CS base 0xffff0000 4IP/EIP (Instruction Pointer) : 指令指针寄存器，记录将要执行的指令在代码段内的偏移地址 5CS（Code Segment Register）：代码段寄存器，指向CPU当前执行代码在内存中的区域（定义了存放代码的存储器的起始地址） 实模式采取内存段来管理 0 - 0xFFFFF的这1M内存空间，但是由于只有16位寄存器，所以最大地址只能表示为0xFFFFF（64KB)，因此不得不采取将内存按段划分为64KB的方式来充分利用1M空间。也就是上所示的，采取段选择子 + 偏移量的表示法。这种方法在保护模式中对于页的设计上也沿用了下来，可谓祖传的智慧了。具体的计算公式如下所示：
1PhysicalAddress = Segment Selector * 16 + Offset 该部分由硬件完成，通过计算访问0XFFFF0，如果该位置没有可执行代码则计算机无法启动。如果有，则执行该部分代码，这里也就是我们故事的开始，BIOS程序了。
BIOS到BootLoader BIOS执行程序存储在ROM中，起始位置为0XFFFF0，当CS:IP指向该位置时，BIOS开始执行。BIOS主要包括以下内存映射：
10x00000000 - 0x000003FF - Real Mode Interrupt Vector Table 20x00000400 - 0x000004FF - BIOS Data Area 30x00000500 - 0x00007BFF - Unused 40x00007C00 - 0x00007DFF - Our Bootloader 50x00007E00 - 0x0009FFFF - Unused 60x000A0000 - 0x000BFFFF - Video RAM (VRAM) Memory 70x000B0000 - 0x000B7777 - Monochrome Video Memory 80x000B8000 - 0x000BFFFF - Color Video Memory 90x000C0000 - 0x000C7FFF - Video ROM BIOS 100x000C8000 - 0x000EFFFF - BIOS Shadow Area 110x000F0000 - 0x000FFFFF - System BIOS 12 其中最重要的莫过于中断向量表和中断服务程序。BIOS程序在内存最开始的位置（0x00000）用1 KB的内存空间（0x00000～0x003FF）构建中断向量表，在紧挨着它的位置用256字节的内存空间构建BIOS数据区（0x00400～0x004FF），并在大约57 KB以后的位置（0x0E05B）加载了8 KB左右的与中断向量表相应的若干中断服务程序。中断向量表中有256个中断向量，每个中断向量占4字节，其中两个字节是CS的值，两个字节是IP的值。每个中断向量都指向一个具体的中断服务程序。
BIOS程序会选择一个启动设备，并将控制权转交给启动扇区中的代码。主要工作即使用中断向量和中断服务程序完成BootLoader的加载，最终将boot.img加载至0X7C00的位置启动。Linux内核通过Boot Protocol定义如何实现该引导程序，有如GRUB 2和syslinux等具体实现方式，这里仅介绍GRUB2。
BootLoader的工作 boot.img由boot.S编译而成，512字节，安装在启动盘的第一个扇区，即MBR。由于空间有限，其代码十分简单，仅仅是起到一个引导的作用，指向后续的核心镜像文件，即core.img。core.img包括很多重要的部分，如lzma_decompress.img、diskboot.img、kernel.img等，结构如下图。
整个加载流程如下：
1、boot.img加载core.img的第一个扇区，即diskboot.img，对应代码为diskboot.S
2、diskboot.img加载core.img的其他部分模块，先是解压缩程序 lzma_decompress.img，再往下是 kernel.img，最后是各个模块 module 对应的映像。这里需要注意，它不是 Linux 的内核，而是 grub 的内核。注意，lzma_decompress.img 对应的代码是 startup_raw.S，本来 kernel.img 是压缩过的，现在执行的时候，需要解压缩。
3、加载完core之后，启动grub_main函数。
4、grub_main函数初始化控制台，计算模块基地址，设置 root 设备，读取 grub 配置文件，加载模块。最后，将 GRUB 置于 normal 模式，在这个模式中，grub_normal_execute (from grub-core/normal/main.c) 将被调用以完成最后的准备工作，然后显示一个菜单列出所用可用的操作系统。当某个操作系统被选择之后，grub_menu_execute_entry 开始执行，它将调用 GRUB 的 boot 命令，来引导被选中的操作系统。
 在这之前，我们所有遇到过的程序都非常非常小，完全可以在实模式下运行，但是随着我们加载的东西越来越大，实模式这 1M 的地址空间实在放不下了，所以在真正的解压缩之前，lzma_decompress.img 做了一个重要的决定，就是调用 real_to_prot，切换到保护模式，这样就能在更大的寻址空间里面，加载更多的东西。
开机时的16位实模式与内核启动的main函数执行需要的32位保护模式之间有很大的差距，这个差距谁来填补？head.S做的就是这项工作。就像 kernel boot protocol 所描述的，引导程序必须填充 kernel setup header （位于 kernel setup code 偏移 0x01f1 处） 的必要字段，这些均在head.S中定义。在这期间，head程序打开A20，打开pe、pg，废弃旧的、16位的中断响应机制，建立新的32位的IDT……这些工作都做完了，计算机已经处在32位的保护模式状态了，调用32位内核的一切条件已经准备完毕，这时顺理成章地调用main函数。后面的操作就可以用32位编译的main函数完成，从而正式启动内核，进入波澜壮阔的Linux内核操作系统之中。
总结 本文介绍了从按下电源开关至加载完毕BootLoader的整个过程，后续将继续分析从实模式进入保护模式，从而启动内核创建0号、1号、2号进程的整个过程。
]]></content>
  </entry>
  
  <entry>
    <title>Linux三剑客（grep,sed,awk）</title>
    <url>/post/linux/linux-three-musketeers.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Grep</tag>
      <tag>Sed</tag>
      <tag>Awk</tag>
    </tags>
    <content type="html"><![CDATA[在Linux系统中，awk、grep、sed等命令被广泛用于文本处理。它们是非常强大的命令行工具，可以用于搜索、替换、过滤、排序等多种操作。
本文将介绍这些命令的基本用法和示例，帮助读者更好地了解它们的功能和用法。
grep命令 grep是一种非常常见的文本搜索工具，它可以搜索指定字符串在一个或多个文件中出现的行，并将结果输出到标准输出。它的语法格式如下：
grep [OPTIONS] PATTERN [FILE...] 其中，OPTIONS表示选项，PATTERN表示要搜索的模式，FILE表示要搜索的文件名。
下面是一些grep命令的常用选项：
 -i：忽略大小写 -v：显示不匹配的行 -n：显示行号 -c：显示匹配行的数量 -r：递归搜索子目录 -e：搜索多个模式  下面是一些grep命令的实例：
在文件中搜索指定字符串 grep &#34;hello&#34; file.txt 在文件中搜索多个字符串 grep -e &#34;hello&#34; -e &#34;world&#34; file.txt 在文件中搜索并显示匹配行号 grep -n &#34;hello&#34; file.txt 在文件中搜索并显示不匹配的行 grep -v &#34;hello&#34; file.txt 在目录中递归搜索指定字符串 grep -r &#34;hello&#34; directory/ sed命令 sed是一种流编辑器，它可以执行各种文本操作，如替换、删除、插入等。它的语法格式如下：
sed [OPTIONS] COMMAND [FILE...] 其中，OPTIONS表示选项，COMMAND表示要执行的sed命令，FILE表示要处理的文件名。
下面是一些常用的sed命令：
 s：替换指定模式 d：删除指定行 i：插入指定字符串 c：替换指定行 y：字符转换 p：打印匹配的行  下面是一些sed命令的实例：
替换文件中的指定字符串 sed &#39;s/hello/world/&#39; file.txt 删除文件中的指定行 sed &#39;3d&#39; file.txt 在文件中指定行后插入指定字符串 sed &#39;2i\hello world&#39; file.txt 替换文件中指定行的内容 sed &#39;3c\hello world&#39; file.txt awk命令 awk是一种文本处理工具，它可以用于格式化、过滤、计算等操作。它的语法格式如下：
awk [OPTIONS] &#39;PATTERN { ACTION }&#39; [FILE...] 其中，OPTIONS表示选项，PATTERN表示要匹配的模式，ACTION表示要执行的操作，FILE表示要处理的文件名。
下面是一些常用的awk命令：
 print：打印指定内容 if：条件判断 for：循环结构 sum：计算指定  下面是一些awk命令的实例：
打印文件中的所有行 awk &#39;{print}&#39; file.txt 打印文件中第二列的内容 awk &#39;{print $2}&#39; file.txt 计算文件中所有数字的总和 awk &#39;{sum += $1} END {print sum}&#39; file.txt 打印文件中包含指定字符串的行 awk &#39;/hello/ {print}&#39; file.txt 在文件中指定列后面添加指定字符串 awk &#39;{$3 = $3 &#34;hello&#34;} {print}&#39; file.txt 以上是grep、sed、awk命令的基本语法和示例。这些命令可以通过选项和参数进行进一步定制和扩展。例如，grep命令可以通过-i选项忽略大小写，-r选项递归搜索子目录，-n选项显示行号等。
在实际应用中，这些命令通常会被结合使用。例如，可以使用grep命令搜索指定字符串，然后使用sed命令进行替换，最后使用awk命令进行计算和格式化。
此外，这些命令也可以通过管道符号（|）进行连接。例如，可以使用grep命令搜索指定字符串，然后将结果通过管道符号传递给sed命令进行替换，最后将结果再次通过管道符号传递给awk命令进行计算和格式化。
总之，grep、sed、awk等命令是Linux系统中非常重要和常用的文本处理工具。熟练掌握它们的基本语法和用法，可以大大提高文本处理的效率和质量。
]]></content>
  </entry>
  
  <entry>
    <title>如何在 Linux 中配置 IPv4 和 IPv6 地址</title>
    <url>/post/linux/how-to-configure-ipv4-and-ipv6.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>IPv4, IPv6</tag>
    </tags>
    <content type="html"><![CDATA[IPv4和IPv6是Internet上常用的两种IP地址协议。在Linux系统中，您可以通过配置网络接口来设置IPv4和IPv6地址。本文将详细介绍如何在Linux中配置IPv4和IPv6地址。
步骤 1：确定网络接口 在开始配置IP地址之前，您需要确定要配置的网络接口。执行以下命令来列出当前系统上的网络接口：
ifconfig -a 该命令将显示所有可用的网络接口及其相关信息。确定要配置的网络接口的名称，例如eth0或enp0s3。
步骤 2：配置 IPv4 地址 ###临时配置
要临时配置IPv4地址，可以使用ifconfig命令。执行以下命令来设置IPv4地址：
sudo ifconfig &lt;interface&gt; &lt;ipv4_address&gt; netmask &lt;netmask&gt; 将替换为要配置的网络接口的名称，&lt;ipv4_address&gt;替换为您要分配的IPv4地址，替换为子网掩码。
例如，要将IP地址为192.168.1.10，子网掩码为255.255.255.0的IPv4地址分配给eth0接口，执行以下命令：
sudo ifconfig eth0 192.168.1.10 netmask 255.255.255.0 永久配置 要永久配置IPv4地址，您需要编辑网络接口的配置文件。执行以下命令来打开配置文件：
sudo nano /etc/network/interfaces 在文件中找到要配置的接口部分，添加以下行：
auto &lt;interface&gt; iface &lt;interface&gt; inet static address &lt;ipv4_address&gt; netmask &lt;netmask&gt; gateway &lt;gateway_address&gt; 将替换为要配置的网络接口的名称，&lt;ipv4_address&gt;替换为您要分配的IPv4地址，替换为子网掩码，&lt;gateway_address&gt;替换为网关地址。
保存文件并关闭文本编辑器。然后，执行以下命令以使更改生效：
sudo systemctl restart networking 现在，您的Linux系统将使用配置的IPv4地址。
步骤 3：配置 IPv6 地址 临时配置 要临时配置IPv6地址，可以使用ifconfig命令。执行以下命令来设置IPv6地址：
sudo ifconfig &lt;interface&gt; inet6 add &lt;ipv6_address&gt;/&lt;prefix_length&gt; 将替换为要配置的网络接口的名称，&lt;ipv6_address&gt;替换为您要分配的IPv6地址，&lt;prefix_length&gt;替换为前缀长度。
例如，要将IPv6地址为2001:0db8:85a3:0000:0000:8a2e:0370:7334，前缀长度为64的IPv6地址分配给eth0接口，执行以下命令：
sudo ifconfig eth0 inet6 add 2001:0db8:85a3:0000:0000:8a2e:0370:7334/64 永久配置 要永久配置IPv6地址，您需要编辑网络接口的配置文件。执行以下命令来打开配置文件：
sudo nano /etc/network/interfaces 在文件中找到要配置的接口部分，添加以下行：
iface &lt;interface&gt; inet6 static address &lt;ipv6_address&gt;/&lt;prefix_length&gt; 将替换为要配置的网络接口的名称，&lt;ipv6_address&gt;替换为您要分配的IPv6地址，&lt;prefix_length&gt;替换为前缀长度。
保存文件并关闭文本编辑器。然后，执行以下命令以使更改生效：
sudo systemctl restart networking 现在，您的Linux系统将使用配置的IPv6地址。
步骤 4：验证配置 要验证IPv4和IPv6地址的配置是否成功，可以执行以下命令来查看网络接口的IP地址信息：
ifconfig &lt;interface&gt; 将&lt;interface&gt;替换为您配置的网络接口的名称。该命令将显示指定接口的IP地址信息，包括IPv4和IPv6地址。 结论 通过本文的指导，您已经学会了在Linux中配置IPv4和IPv6地址的详细步骤。根据您的网络需求，您可以临时或永久地配置这些地址。
具体的配置方式可能因Linux发行版和版本而有所不同。本文提供了一般的配置方法，但如果您的系统有特定的要求或网络环境，请参考相关文档或咨询系统管理员。
]]></content>
  </entry>
  
  <entry>
    <title>风河携手三星推进软件定义汽车演进</title>
    <url>/post/news/wind-river-and-samsung-drive-the-evolution-of-software-defined-vehicles.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Wind River</tag>
      <tag>Samsung</tag>
      <tag>SNV</tag>
    </tags>
    <content type="html"><![CDATA[领先的关键任务智能系统软件提供商风河公司宣布与三星电子系统LSI业务部建立新的合作关系。双方将致力于加速软件定义汽车的发展，开发高质量车载信息娱乐解决方案（IVI）、座舱监控和高级驾驶辅助系统。
汽车工业正在向软件定义汽车演进，越来越多的功能和特性都将由软件来驱动，并能快速简便地进行更新。确保开发人员拥有卓越的工具、流程和结构，有效实现软件的创建、测试与更新，这对整个行业来说皆属最高优先事项。
为了加速迭代演进，风河将基于三星Exynos Auto V920芯片组向客户提供自己的软件技术，创建一整套完全集成化的汽车软件与硬件解决方案，其中的核心是Wind River Helix™ Virtualization Platform（虚拟化平台）。这是一套获得安全认证的多核、多操作系统平台，支持最终用户融合不同安全性要求的运行时环境，包括VxWorks®实时操作系统(RTOS)、Linux和Android。
要设计和开发互联自动驾驶电动汽车，必须采用新的软件定义方法，以及高性能计算系统。我们与三星携手合作，支持OEM厂商和Tier 1供应商继承和发展过去三十多年来在航空航天与国防、工业、医疗和电信等诸多领域所积累的技术和经验，构建对未来软件定义车辆至关重要的软件系统，满足多种不同层次的关键性认证要求。
Exynos Auto V920是我们最新的5nm汽用处理器，提供强大的智能化性能和更高水平的车内体验，让汽车拥有更高的安全性。这套系统能够以高效节能的方式在多个虚拟机上同时运行多个应用，从而满足了行业的低功耗需求。通过与风河公司的密切合作，我们能够加强业界领先的IVI开发工作，并通过风河领先的运行时环境进一步扩展到多个安全关键领域。
]]></content>
  </entry>
  
  <entry>
    <title>英特尔宣布，出售设备公司股份</title>
    <url>/post/news/intel-announces-sale-of-stake-IMS.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Intel</tag>
      <tag>IMS</tag>
      <tag>Bain Capital</tag>
    </tags>
    <content type="html"><![CDATA[英特尔公司今天宣布，已同意将其 IMS Nanofabrication GmbH (“IMS”) 业务约 20% 的股份出售给 Bain Capital Special Situations（“贝恩资本”）处理的一项交易中，IMS 的估值约为 43 亿美元。
该交易预计将于 2023 年第三季度完成。IMS 将作为独立子公司运营，并继续由首席执行官 Elmar Platzgummer 博士领导。
英特尔方面透露：“考虑到估值水平和投资水平，这将成为我们有史以来最好的收购之一。”
自 2015 年发明多电子束技术并推出首款商用多光束掩模写入器以来，总部位于奥地利维也纳的 IMS 一直是先进技术节点多光束掩模写入领域的行业领导者。英特尔最初于 2009 年投资 IMS，并最终于 2015 年收购了该业务。自收购以来，IMS 为英特尔带来了显著的投资回报，同时将其员工和生产能力增长了四倍，并交付了另外三代产品。
如今，随着 EUV 技术在前沿技术中得到广泛采用，创建高级 EUV（极紫外光刻）掩模所需的多光束掩模写入工具已成为半导体制造生态系统中越来越重要的组成部分。这项投资将使 IMS 能够通过加速创新和实现更深入的跨行业合作来抓住多光束掩模写入工具的重要市场机会。
企业发展高级副总裁 Matt Poirier 表示：“光刻技术的进步对于推动半导体行业的持续进步至关重要，而掩模写入在行业向新图案技术（例如高数值孔径 EUV）过渡中发挥着核心作用。”在英特尔。“贝恩资本的投资和合作将为 IMS 提供更大的独立性，并带来战略视角，帮助加速下一阶段的光刻技术创新，最终使整个生态系统受益。”
Platzgummer 表示：“我们很高兴能获得贝恩资本这一宝贵的合作伙伴，贝恩资本在与企业合作推动增长和价值创造方面拥有悠久的历史。随着 EUV 变得更加普遍和高效，他们与我们一样坚信 IMS 面临着有意义的机遇。High-NA EUV 在本世纪下半叶从开发转向大批量制造。我们期待扩大我们的能力，为世界上最大的芯片生产商提供支持，他们依靠我们的技术来生产当前和下一代半导体产品。
贝恩资本 (Bain Capital) 合伙人 Marvin Larbi-Yeboa 表示：“作为半导体制造和纳米技术行业新兴技术的全球领导者和创新者，我们相信 IMS 处于有利地位，能够利用随着芯片产能增加而带来的有吸引力的长期有利因素在线并建立其领先的竞争地位、技术差异化和尖端的产品能力。”
贝恩资本董事总经理 Will Tetler 补充道：“我们期待与 IMS 卓越的管理团队和英特尔合作，利用我们深厚的行业经验和价值创造能力，通过进一步投资支持业务的长期增长战略其领先的技术和产品组合使 IMS 能够扩大其竞争市场地位。”
]]></content>
  </entry>
  
  <entry>
    <title>STM32的完整启动流程分析</title>
    <url>/post/mcu/STM32-whole-boot-up-process-analysis.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>STM32</tag>
      <tag>boot up</tag>
      <tag>process</tag>
    </tags>
    <content type="html"><![CDATA[关于STM32的启动流程，网上有的资料在讨论几种boot模式，有的在回答启动文件的内容，在查阅了很多资料后，本文给出一个比较全面的总结和回答。
根据boot引脚决定三种启动模式 复位后，在 SYSCLK 的第四个上升沿锁存 BOOT 引脚的值。BOOT0 为专用引脚，而 BOOT1 则与 GPIO 引脚共用。一旦完成对 BOOT1 的采样，相应 GPIO 引脚即进入空闲状态，可用于其它用途。BOOT0与BOOT1引脚的不同值指向了三种启动方式：
  从主Flash启动。主Flash指的是STM32的内置Flash。选择该启动模式后，内置Flash的起始地址将被重映射到0x00000000地址，代码将在该处开始执行。一般我们使用JTAG或者SWD模式下载调试程序时，就是下载到这里面，重启后也直接从这启动。
  从系统存储器启动。系统储存器指的是STM32的内置ROM，选择该启动模式后，内置ROM的起始地址将被重映射到0x00000000地址，代码在此处开始运行。ROM中有一段出厂预置的代码，这段代码起到一个桥的作用，允许外部通过UART/CAN或USB等将代码写入STM32的内置Flash中。这段代码也被称为ISP(In System Programing)代码，这种烧录代码的方式也被称为ISP烧录。关于ISP、ICP和IAP之间的区别将在后续章节中介绍。
  从嵌入式SRAM中启动。显然，该方法是在STM32的内置SRAM中启动，选择该启动模式后，内置SRAM的起始地址将被重映射到0x00000000地址，代码在此处开始运行。这种模式由于烧录程序过程中不需要擦写Flash，因此速度较快，适合调试，但是掉电丢失。
  总结：上面的每一种启动方式我都描述了“xxx的起始地址被重映射到了0x00000000地址，从而代码从xxx开始启动”，如下图是STM32F4xx中文参考手册中的图，可以看到类似的表述。同时，在下图中也展示了STM32F4xx中统一编址下，各内存的地址分配，注意一点，即使相应的内存被映射到了0x00000000起始的地址，通过其原来地址依然是可以访问的。
启动后bootloader做了什么？ 根据BOOT引脚确定了启动方式后，处理器进行的第二大步就是开始从0x00000000地址处开始执行代码，而该处存放的代码正是bootloader。
bootloader，也可以叫启动文件，无论性能高下，结构简繁，价格贵贱，每一种微控制器(处理器)都必须有启动文件，启动文件的作用便是负责执行微控制器从“复位”到“开始执行main函数”中间这段时间(称为启动过程)所必须进行的工作。最为常见的51，AVR或MSP430等微控制器当然也有对应启动文件，但开发环境往往自动完整地提供了这个启动文件，不需要开发人员再行干预启动过程，只需要从main函数开始进行应用程序的设计即可。同样，STM32微控制器，无论是keiluvision4还是IAR EWARM开发环境，ST公司都提供了现成的直接可用的启动文件。
网上有很多资料分析了STM32的启动文件的内容，在此我只进行简单的表述。启动文件中首先会定义堆栈，定义中断/异常向量表，而其中只实现了复位的异常处理函数Reset_Handler，该函数内容如下(STM32F4XX，IAR编译器)，可以看到其主要执行了SystemInit和__iar_program_start两个函数，其主要功能除了初始化时钟，FPU等，还会执行一个重要功能，那就是内存的搬移、初始化操作。 这是我想重点介绍的内容，同时也会回答一个疑问，就是如果从Flash启动的话，代码究竟是运行在哪儿的？在我之前接触ARM9、CortexA系列的时候，一般都是把代码搬到内部的SRAM或者外部DDR中执行的，STM32是如何呢？答案下一小节揭晓。
bootloader中对内存的搬移和初始化 本节针对程序在内置Flash中启动的情况进行分析。
我们知道烧录的镜像文件中包含只读代码段.text，已初始化数据段.data和未初始化的或者初始化为0的数据段.bss。代码段由于是只读的，所以是可以一直放在Flash中，CPU通过总线去读取代码执行就OK，但是.data段和.bss段由于会涉及读写为了，为了更高的读写效率是要一定搬到RAM中执行的，因此bootloader会执行很重要的一步，就是会在RAM中初始化.data和.bss段，搬移或清空相应内存区域。
因此我们知道，当启动方式选择的是从内置Flash启动的时候，代码依旧是在Flash中执行，而数据则会被拷贝到内部SRAM中，该过程是由bootloader完成的。bootloader在完成这些流程之后，就会将代码交给main函数开始执行用户代码。
  现在让我们思考一个问题，PC机在运行程序的时候将程序从外存（硬盘）中，调入到RAM中运行，CPU从RAM中读取程序和数据；而单片机的程序则是固化在Flash中，CPU运行时直接从Flash中读取程序，从RAM中读取数据，那么PC机能从Flash之类的存储介质中直接读代码执行吗？
  答案是不行。因为x86构架的CPU是基于冯.诺依曼体系的，即数据和程序存储在一起，而且PC机的RAM资源相当丰富，从几十M到几百M甚至是几个G，客观上能够承受大量的程序数据。但是单片机的构架大多是哈弗体系的，即程序和数据分开存储，而且单片的片内RAM资源是相当有限的，内部的RAM过大会带来成本的大幅度提高。
  ISP、IAP、ICP三种烧录方式 虽然这个小节稍稍偏题，但是由于上面在3中启动方式中介绍过了ISP烧录，因此一并在此介绍剩下的两种烧录方式。
  ICP(In Circuit Programing)。在电路编程，可通过CPU的Debug Access Port 烧录代码，比如ARM Cortex的Debug Interface主要是SWD(Serial Wire Debug)或JTAG(Joint Test Action Group)；
  ISP(In System Programing)。在系统编程，可借助MCU厂商预置的Bootloader 实现通过板载UART或USB接口烧录代码。
  IAP(In Applicating Programing)。在应用编程，由开发者实现Bootloader功能，比如STM32存储映射Code分区中的Flash本是存储用户应用程序的区间（上电从此处执行用户代码），开发者可以将自己实现的Bootloader存放到Flash区间，MCU上电启动先执行用户的Bootloader代码，该代码可为用户应用程序的下载、校验、增量/补丁更新、升级、恢复等提供支持，如果用户代码提供了网络访问功能，IAP 还能通过无线网络下载更新代码，实现OTA空中升级功能。
  IAP和ISP 的区别。
   ISP程序一般是芯片厂家提供的。IAP一般是用户自己编写的 ISP一般支持的烧录方式有限，只有串口等。IAP就比较灵活，可以灵活的使用各种通信协议烧录 isp一般需要芯片进行一些硬件上的操作才行，IAP全部工作由程序完成，不需要去现场 isp一般只需要按格式将升级文件通过串口发送就可以。IAP的话控制相对麻烦，如果是OTA的话还需要编写后台的。 注意，这里介绍的bootloader功能显然跟之前介绍的启动文件bootloader有所区别，其目的是为了能接受外部镜像进行烧录，而不是为了运行普通用户程序。 ]]></content>
  </entry>
  
  <entry>
    <title>什么是大数据时代</title>
    <url>/post/news/what-is-the-era-of-big-data.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Big Data</tag>
    </tags>
    <content type="html"><![CDATA[最早提出&quot;大数据&quot;时代到来的是全球知名咨询公司麦肯锡，麦肯锡称:&ldquo;数据，已经渗透到当今每一个行业和业务职能领域，成为重要的生产因素。
人们对于海量数据的挖掘和运用，预示着新一波生产率增长和消费者盈余浪潮的到来。&rdquo; &ldquo;大数据&quot;在物理学、生物学、环境生态学等领域以及军事、金融、通讯等行业存在已有时日，却因为近年来互联网和信息行业的发展而引起人们关注。简单来说：大量数据 + 云计算 = 大数据时代
大数据特征 ###数据量大(Volume)
第一个特征是数据量大。大数据的起始计量单位至少是P(1000个T)、E(100万个T)或Z(10亿个T)。
类型繁多(Variety) 第二个特征是数据类型繁多。包括网络日志、音频、视频、图片、地理位置信息等等，多类型的数据对数据的处理能力提出了更高的要求。
价值密度低(Value) 第三个特征是数据价值密度相对较低。如随着物联网的广泛应用，信息感知无处不在，信息海量，但价值密度较低，如何通过强大的机器算法更迅速地完成数据的价值&quot;提纯&rdquo;，是大数据时代亟待解决的难题。
速度快、时效高(Velocity) 第四个特征是处理速度快，时效性要求高。这是大数据区分于传统数据挖掘最显著的特征。
既有的技术架构和路线，已经无法高效处理如此海量的数据，而对于相关组织来说，如果投入巨大采集的信息无法通过及时处理反馈有效信息，那将是得不偿失的。可以说，大数据时代对人类的数据驾驭能力提出了新的挑战，也为人们获得更为深刻、全面的洞察能力提供了前所未有的空间与潜力。
那么数据生活距离我们遥远吗？ 正相反，数据与我们日常生活的联系从未如此紧密过，从没有像今天如此活跃，具体的记录着人类与世界。从最初的计算机，摄像头到家用计算机，智能手机，再到大数据和人工智能，我们不断升级采集和利用数据的方式。而现在，从一辆车的每日碳排放量统计到全球气温的检测，从预测个人在网上喜好分析到总统选举时投票趋势的预测，我们都可以做到。
数据将人与人，人与世界连接起来，构成一张繁密的网络，每个人都在影响世界，又在被他人影响着。传统的统计方法已经无法处理这种相互影响的数据，这么办？答案是让机器自己来处理数据，从数据中习得知识。
这便是当代人工智能的本质。与传统的数据记录定义不同，这种数据是有“生命”的。它更像是我们身体的一种自然延伸：聆听我们的声音，拓宽我们的视野，加深我们的记忆，甚至组成一个以数据形式存在的“我”。
生活中的大数据很多，以下是几个例子：  互联网搜索：每天有数百万的搜索请求，包含了大量的关键字和查询信息。通过分析这些数据，搜索引擎可以优化搜索算法，提高搜索结果的准确性。 电子商务：在线购物网站产生了大量的数据，包括用户浏览、购买、评论、评分等信息。通过分析这些数据，商家可以更好地了解消费者需求，优化产品和服务。 社交媒体：社交媒体如Facebook、Twitter、微信等产生了海量的数据，包括用户关系、兴趣爱好、社交网络等。通过分析这些数据，企业可以了解消费者的行为和需求，优化宣传和营销策略。 医疗健康：医疗领域的大数据可以帮助医生更好地诊断疾病、预测疾病风险、优化治疗方案等。例如，通过分析患者的基因组数据，可以提前预测某些疾病的发作可能性，及时采取干预措施。 交通运输：现代交通系统中产生了大量的数据，包括车辆位置、速度、路况、交通流量等。通过分析这些数据，交通运输管理者可以更好地规划交通、提高交通效率，优化城市交通管理。  大数据的利与弊可以概括为以下几点： 利：   提供更准确的信息：大数据可以提供海量、多样化、实时的数据，帮助企业和政府更好地了解市场、用户需求、社会趋势等，从而做出更准确的决策。
  优化产品和服务：通过分析大数据，企业可以了解消费者的需求和习惯，优化产品和服务，提高用户满意度和忠诚度。
  提高效率和生产力：大数据可以优化生产流程、提高生产效率，让企业更快地响应市场变化，提高生产力。
  弊：   隐私问题：大数据涵盖了大量的个人信息和数据，如果这些数据被不法分子获取，就会造成极大的隐私泄露风险。
  误导性：大数据中有时会出现伪相关关系，需要进行深入的数据分析和挖掘，否则可能会引起误导。
  质量问题：大数据中可能包含有误的、不准确的数据，这会影响到对数据的分析和应用。
  技术门槛高：大数据的处理需要高级的技术和工具，这会导致技术门槛较高，对于一些小型企业和普通用户来说比较困难。
  总之，大数据虽然带来了很多的机遇和优势，但也面临着一些挑战和风险，需要我们在使用大数据时保持警惕和谨慎。
]]></content>
  </entry>
  
  <entry>
    <title>Linux内核中使用的C语言技巧</title>
    <url>/post/programming/c-language-tricks-used-in-the-linux-kernel.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Embedded</tag>
      <tag>Struct</tag>
    </tags>
    <content type="html"><![CDATA[下面是Linux内核中常常使用到的C语言技巧，比较实用，小伙伴们学起来！注意需要GCC编译器才支持这些特性。
typeof的使用 下面是我们常用的返回最大值宏定义，这个写法存在一些问题。
#define max(a,b) ((a) &gt; (b) ? (a) : (b)) 如果a传入i++，b传入j++，那么这个比较大小就会出错。例如：
#define max(a,b) ((a)&gt;(b)?(a):(b))  int x = 1, y = 2; printf(&#34;max=%d\n&#34;, max(x++, y++)); printf(&#34;x = %d, y = %d\n&#34;, x, y); 上面代码输出：max=2，x=2，y=4，结果是错误。为修改此宏，可以定义一个变量将a和b的值分别赋给该变量，并将该变量作为参数传递给max宏进行比较。在GNU C语言中，可以使用以下代码实现：
#define max(a,b) ({ \ int _a = (a); \  int _b = (b); \ _a &gt; _b ? _a : _b; }) 如果不知道具体的数据类型，可以使用typeof类转换宏，Linux内核中的例子：
#define max(a, b) ({ \ typeof(a) _a = (a); \ typeof(b) _b = (b); \ (void) (&amp;_a == &amp;_b); \ _a &gt; _b ? _a : _b; })  typeof(a) _a = (a):定义一个a类型的变量_a，将a赋值给_a typeof(b) _b = (b):定义一个b类型的变量_b，将b赋值给_b (void) (&amp;_a == &amp;_b):判断两个数的类型是否相同，如果不相同，会抛出一个警告。因为a和b的类型不一样，其指针类型也会不一样，两个不一样的指针类型进行比较操作，会抛出警告。  typeof用法举例：
//typeof的参数可以是表达式或类型  //参数是类型 typeof(int *) a,b;//等价于：int *a,*b;  //参数是表达式 int foo(); typeof(foo()) var;//声明了int类型的var变量，因为表达式foo()是int类型的。由于表达式不会被执行，所以不会调用foo函数。 柔性数组 柔性数组，也称为零长数组，主要用于变长结构体。因此，它有时被称为变长数组。使用方法是在结构体的末尾声明一个长度为0的数组，从而使该结构体具有可变长度。对于编译器来说，长度为0的数组不占用空间，因为数组名本身只是一个偏移量，代表了一个不可修改的地址常量符号。
结构体中定义零长数组：
&lt;mm/percpu.c&gt; struct pcpu_chunk { struct list_head list; unsigned long populated[]; /* 变长数组 */ }; 数据结构最后一个元素被定义为零长度数组，不占结构体空间。这样，我们可以根据对象大小动态地分配结构的大小。
struct line { int length; char contents[0]; }; struct line *thisline = malloc(sizeof(struct line) + this_length); thisline-&gt;length = this_length; 如上例所示，struct line数据结构定义了一个int length变量和一个变长数组contents[0]，这个struct line数据结构的大小只包含int类型的大小，不包含contents的大小，也就是sizeof (struct line) = sizeof (int)。
创建结构体对象时，可根据实际的需要指定这个可变长数组的长度，并分配相应的空间，如上述实例代码分配了this_length 字节的内存，并且可以通过contents[index]来访问第index个地址的数据。
case范围 GNU C语言支持指定一个case的范围作为一个标签，如：
case low ...high: case &#39;A&#39; ...&#39;Z&#39;: 这里low到high表示一个区间范围，在ASCII字符代码中也非常有用。下面是Linux内核中的代码例子。
&lt;arch/x86/platform/uv/tlb_uv.c&gt; static int local_atoi(const char *name){ int val = 0; for (;; name++) { switch (*name) { case &#39;0&#39; ...&#39;9&#39;: val = 10*val+(*name-&#39;0&#39;); break; default: return val; } } } 另外，还可以用整形数来表示范围，但是这里需要注意在“&hellip;”两边有空格，否则编译会出错。
&lt;drivers/usb/gadget/udc/at91_udc.c&gt; static int at91sam9261_udc_init(struct at91_udc *udc){ for (i = 0; i &lt; NUM_ENDPOINTS; i++) { ep = &amp;udc-&gt;ep[i]; switch (i) { case 0: ep-&gt;maxpacket = 8; break; case 1 ... 3: ep-&gt;maxpacket = 64; break; case 4 ... 5: ep-&gt;maxpacket = 256; break; } } } 标号元素 GNU C语言可以通过指定索引或结构体成员名来初始化，不必按照原来的固定顺序进行初始化。
结构体成员的初始化在 Linux 内核中经常使用，如在设备驱动中初始化file_operations数据结构：
&lt;drivers/char/mem.c&gt; static const struct file_operations zero_fops = { .llseek = zero_lseek, .read = new_sync_read, .write = write_zero, .read_iter = read_iter_zero, .aio_write = aio_write_zero, .mmap = mmap_zero, }; 如上述代码中的zero_fops的成员llseek初始化为zero_lseek函数，read成员初始化为new_sync_read函数，依次类推。当file_operations数据结构的定义发生变化时，这种初始化方法依然能保证已知元素的正确性，对于未初始化成员的值为0或者NULL。
可变参数宏 在GNU C语言中，宏可以接受可变数目的参数，主要用在输出函数里。例如：
&lt;include/linux/printk.h&gt; #define pr_debug(fmt, ...) \ dynamic_pr_debug(fmt, ##__VA_ARGS__) “&hellip;”代表一个可以变化的参数表，“VA_ARGS”是编译器保留字段，预处理时把参数传递给宏。当宏的调用展开时，实际参数就传递给dynamic_pr_debug函数了。
UL 的使用 在Linux内核代码中，我们经常会看到一些数字的定义使用了UL后缀修饰。
数字常量会被隐形定义为int类型，两个int类型相加的结果可能会发生溢出。
因此使用UL强制把int类型数据转换为unsigned long类型，这是为了保证运算过程不会因为int的位数不同而导致溢出。
 1 ：表示有符号整型数字1 UL：表示无符号长整型数字1 ]]></content>
  </entry>
  
  <entry>
    <title>单片机基础概念：指令、数位、字节、存储器、总线</title>
    <url>/post/mcu/basic-concept-of-micro-processor-unit.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>ROM</tag>
      <tag>BUS</tag>
      <tag>Data Bit</tag>
    </tags>
    <content type="html"><![CDATA[本文介绍单片机基础概念：指令、数位、字节、存储器、总线
执行指令 我们来思考一个问题，当我们在编程器中把一条指令写进单片机内部，然后取下单片机，单片机就可以执行这条指令。
那么这条指令一定保存在单片机的某个地方，并且这个地方在单片机掉电后依然可以保持这条指令不会丢失，这是个什么地方呢？这个地方就是单片机内部的只读存储器即ROM(READ ONLY MEMORY)。
为什么称它为只读存储器呢？刚才我们不是明明把两个数字写进去了吗？原来在89C51中的ROM是一种电可擦除的ROM，称为FLASH ROM，刚才我们是用的编程器，在特殊的条件下由外部设备对ROM进行写的操作，在单片机正常工作条件下，只能从那面读，不能把数据写进去，所以我们还是把它称为ROM。
数的本质和物理现象 我们知道，计算机可以进行数学运算，这令我们非常难以理解，它们只是一些电子元器件，怎么可以进行数学运算呢？
我们人类做数学题如37+45是这样做的，先在纸上写37，然后在下面写45，然后大脑运算最后写出结果，运算的原材料是37和45，结果是82都是写在纸上的，计算机中又是放在什么地方呢？
为了解决这个问题，先让我们做一个实验：这里有一盏灯，我们知道灯要么亮，要么不亮，就有两种状态，我们可以用‘0’和‘1’来代替这两种状态：规定亮为‘1’、不亮为‘0’。
现在放上三盏灯，一共有几种状态呢？我们列表来看一下：000 / 001 / 010 / 011 / 100 / 101 / 110 / 111。我们来看，这个000 / 001 / 101 不就是我们学过的的二进制数吗？本来，灯的亮和灭只是一种物理现象，可当我们把它们按一定的顺序排好后，灯的亮和灭就代表了数字了。让我们再抽象一步，灯为什么会亮呢？是因为输出电路输出高电平，给灯通了电。因此，灯亮和灭就可以用电路的输出是高电平还是低电平来替代了。这样，数字就和电平的高、低联系上了。
数位的含义 通过上面的实验我们已经知道：一盏灯亮或者说一根线的电平的高低，可以代表两种状态：0和1，实际上这就是一个二进制位。
因此我们就把一根线称之为一“位”，用BIT表示。
一根线可以表示0和1，两根线可以表达00 / 01 / 10 / 11四种状态，也就是可以表达0~3，而三根可以表达0~7，计算机中通常用8根线放在一起，同时计数，就可以表示0~255一共256种状态。
这8根线或者8位就称之为一个字节(BYTE)。
存储器的构造 存储器就是用来存放数据的地方。它是利用电平的高低来存放数据的，也就是说，它存放的实际上是电平的高、低，而不是我们所习惯认为的1234这样的数字，这样，我们的一个谜团就解开了。
一个存储器就象一个个的小抽屉，一个小抽屉里有八个小格子，每个小格子就是用来存放“电荷”的，电荷通过与它相连的电线传进来或释放掉。至于电荷在小格子里是怎样存的，就不用我们操心了，你可以把电线想象成水管，小格子里的电荷就象是水，那就好理解了。存储器中的每个小抽屉就是一个放数据的地方，我们称之为一个“单元”。
有了这么一个构造，我们就可以开始存放数据了，想要放进一个数据12，也就是00001100，我们只要把第二号和第三号小格子里存满电荷，而其它小格子里的电荷给放掉就行了。
可问题出来了，一个存储器有好多单元，线是并联的，在放入电荷的时候，会将电荷放入所有的单元中，而释放电荷的时候，会把每个单元中的电荷都放掉。这样的话，不管存储器有多少个单元，都只能放同一个数，这当然不是我们所希望的。因此，要在结构上稍作变化。
需要在每个单元上有个控制线，想要把数据放进哪个单元，就把一个信号给这个单元的控制线，这个控制线就把开关打开，这样电荷就可以自由流动了。而其它单元控制线上没有信号，所以开关不打开，不会受到影响。
这样，只要控制不同单元的控制线，就可以向各单元写入不同的数据了。同样，如果要从某个单元中取数据，也只要打开相应的控制开关就行了。
存储器的译码 那么，我们怎样来控制各个单元的控制线呢？这个还不简单，把每个单元的控制线都引到集成电路的外面不就行了吗？
事情可没那么简单，一片27512存储器中有65536个单元，把每根线都引出来，这个集成电路就得有6万多个脚？不行，怎么办？要想法减少线的数量。
有一种方法称这为译码，简单介绍一下：一根线可以代表2种状态，2根线可以代表4种状态，3根线可以代表8种，256种状态又需要几根线代表？8根线，所以65536种状态我们只需要16根线就可以代表了。
存储器的选片概念 至此，译码的问题解决了，让我们再来关注另外一个问题。送入每个单元的八根线是用从什么地方来的呢？它就是从计算机上接过来的，一般地，这八根线除了接一个存储器之外，还要接其它的器件。
这样问题就出来了，这八根线既然不是存储器和计算机之间专用的，如果总是将某个单元接在这八根线上，就有问题出现了：比如这个存储器单元中的数值是0FFH另一个存储器的单元是00H，那么这根线到底是处于高电平，还是低电平？怎样分辨？
办法很简单，当外面的线接到集成电路的引脚进来后，不直接接到各单元去，中间再加一组开关就行了。平时我们让开关打开着，如果确实是要向这个存储器中写入数据，或要从存储器中读出数据，再让开关接通就行了。
这组开关由三根引线选择：读控制端、写控制端和片选端。要将数据写入片中，先选中该片，然后发出写信号，开关就合上了，并将传过来的数据(电荷)写入片中。如果要读，先选中该片，然后发出读信号，开关合上，数据就被送出去了。
读和写信号同时还接入到另一个存储器，但是由于片选端不同，所以虽有读或写信号，但没有片选信号，所以另一个存储器不会“误会”而开门，造成冲突。那么会不同时选中两片芯片呢？
只要是设计好的系统就不会，因为它是由计算控制的，而不是我们人来控制的，如果真的出现同时出现选中两片的情况，那就是电路出了故障了，这不在我们的讨论之列。
总线概念 从上面的介绍中我们已经看到，用来传递数据的八根线并不是专用的，而是很多器件大家共用的。
所以我们称之为数据总线，总线英文名为BUS，总即公交车道，谁也可以走。而十六根地址线也是连在一起的，称之为地址总线。
]]></content>
  </entry>
  
  <entry>
    <title>CPU、MPU、MCU和SOC的简介</title>
    <url>/post/mcu/introduction-of-cpu-mpu-mcu-soc.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>CPU</tag>
      <tag>MPU</tag>
      <tag>MCU</tag>
      <tag>SOC</tag>
    </tags>
    <content type="html"><![CDATA[在嵌入式开发中，我们会经常看到或接触一些专业术语，例如CPU、MPU、MCU和SOC等，并且这些专业术语出现的频率也是非常之高，在面试中也常常会作为提问的知识点，下面我们就来看一下他们之间的特点和区别。
CPU CPU是Central Processing Unit的缩写，计算机的运算控制核心就是CPU。CPU是由运算器、控制器和寄存器及相应的总线构成。众所周知的三级流水线：取址、译码、执行的对象就是CPU，CPU从存储器或高速缓冲存储器中取出指令，放入指令寄存器，并对指令译码，然后执行指令。而计算机的可编程性其实就是指对CPU的编程。
MPU MPU是Micro Processor Unit的缩写，指微处理器（这里要注意不是微控制器，很多人会把微处理器和微控制器混淆），微处理器通常代表功能强大的CPU（可理解为增强型的CPU），这种芯片往往是计算机和高端系统的核心CPU。例如嵌入式开发者最熟悉的 ARM  的Cortex-A芯片，他们都属于MPU。
MCU MCU是Micro Control Unit的缩写，指微控制器。随着大规模集成电路的出现及发展，把计算机的CPU、RAM、ROM、定时器和输入输出I/O引脚集成在一个芯片上，比如51，STC、Cortex-M这些芯片，它们的内部除了CPU外还包含了RAM和ROM，可直接添加简单的器件（电阻，电容）等构成最小系统就可以运行代码了。而像ARM（Cortex-A系列）直接放代码是运行不了的，因为它本质上只是增强版的CPU，必须添加相应的RAM和ROM。
SOC SOC是System on Chip的缩写，指的是片上系统。可以这样对比来看：MCU只是芯片级的芯片，而SOC是系统级的芯片，它集成了MCU和MPU的优点，即拥有内置RAM和ROM的同时又像MPU那样强大，它可以存放并运行系统级别的代码，也就是说可以运行操作系统（以Linux OS为主）
另外，SOPC也是一个值得了解的概念，与上述几项概念相比，SOPC的出现频率并不是那么高，但这并不影响它的重要性。SOPC是System On a Programmable Chip的缩写，即 可编程片上系统，SOPC与MCU、MPU、SOC最明显的区别在于：可更改硬件配置，也就是说自己构造芯片。
举个例子说明便于理解，单片机的硬件配置是固化好了的， 我们能够编程修改的就是软件配置，本来是串口通信功能，通过修改代码变成AD采样功能，也就是说硬件配置是固定了的，我们只能通过修改软件来选择其中的一项或多项功能；而SOPC可以修改硬件配置信息使其成为相应的芯片，可以是MCU，也可以是SOC。
结语 在嵌入式开发中，接触频率较多的一般是MCU和SOC，而现在STM32也几乎成为了MCU的代名词，SOC目前则以Cortex-A系列为主，开发难度也有所差异，对于嵌入式从业者来说，弄清楚这些专业概念是必备的。
]]></content>
  </entry>
  
  <entry>
    <title>嵌入式C语言之结构体封装函数</title>
    <url>/post/programming/embedded-c-programming-language-struct-pack-function.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Embedded</tag>
      <tag>Struct</tag>
    </tags>
    <content type="html"><![CDATA[在嵌入式系统中，结构体封装函数可以用于对于嵌入式硬件资源进行抽象和封装，从而提高软件的可维护性和可移植性。结构体封装函数通常包含数据和行为，并提供了对数据的访问和操作方法。
比如可以将硬件驱动函数封装在结构体中，方便对外提供统一的API接口，同时也便于代码的移植和扩展。另外，结构体封装函数还可以用于实现状态机、任务调度等复杂的系统功能。
在C语言中，结构体不仅可以封装数据，还可以封装函数指针。这种方式可以用于实现回调函数、状态机等，提高代码的复用性和可维护性。特别是在嵌入式当中，应用是非常多的。
结构体封装函数的作用  将函数指针和参数打包成一个结构体，实现了代码的模块化和可复用性。 在结构体中可以定义多个函数指针，实现了对函数的分类管理和调用。 结构体可以作为函数的参数或返回值，传递和返回函数指针和参数。  结构体封装函数的应用  回调函数：将函数指针和参数打包成一个结构体，传递给API函数，在API函数内部执行该函数。 状态机：将每个状态对应的处理函数封装成一个结构体，根据当前状态调用相应的处理函数。 事件驱动：将事件处理函数封装成一个结构体，通过事件触发调用相应的处理函数。 线程池：将任务处理函数封装成一个结构体，加入任务队列后由线程池调用执行  结构体封装函数的好处  更好的隐藏实现细节：结构体封装函数使得函数的实现细节被封装在结构体内部，只有结构体暴露给外部的函数指针，实现了良好的封装和信息隐藏。 更加灵活的函数调用：函数指针可以被动态修改，从而实现动态的函数调用。例如，在状态机中，根据不同的状态，可以将相应的处理函数指针赋值给一个函数指针变量，从而实现状态的转换和函数的调用。 更加方便的扩展性：结构体封装函数可以轻松地添加新的函数指针，从而扩展功能。在需要添加新功能时，只需要定义一个新的函数指针，并添加到结构体中，就可以实现功能的扩展，而不需要修改原有的代码。 更加通用的代码：结构体封装函数可以使用于各种不同的编程范式，例如面向对象编程（OOP）和函数式编程（FP），从而实现通用的代码。例如，在OOP中，结构体可以被看作是一个对象，函数指针可以被看作是对象的方法，从而实现OOP编程的思想。 更加易于维护：结构体封装函数使得代码更加清晰、易于维护和修改。由于函数指针的定义和使用都在结构体内部，因此修改或调整代码时，只需要修改结构体中的函数指针定义或调用方式，而不需要修改其他部分的代码，从而使得代码更加健壮、易于维护和修改 模块化：通过结构体封装函数，可以将多个函数和数据结构组合成一个模块，以便于模块化设计和维护。这种方法可以将代码的复杂性分解到不同的模块中，降低了代码的耦合性，提高了代码的可读性和可维护性。 代码复用：结构体封装的函数可以通过传递结构体的方式重用同一个函数。这种方式可以大大减少代码量，提高代码的复用性和可维护性。 可扩展性：当需要增加新的功能时，只需增加新的函数和数据结构，而不需要修改现有代码。这种方式可以大大减少代码的修改和调试时间，提高代码的可扩展性和可维护性。 保护数据：通过结构体封装函数，可以将数据和函数封装在一个结构体中，防止外部代码对数据的非法访问和修改。 提高安全性：将函数和数据封装在一个结构体中，可以防止其他函数对数据的非法操作，从而提高程序的安全性。  举例1 /* 定义封装函数结构体由外部调用*/ typedef struct { int x; int y; void (*move_up)(int steps); void (*move_down)(int steps); void (*move_left)(int steps); void (*move_right)(int steps); } Point; // 定义结构体中的函数 void move_up(int steps) { // 向上移动steps个单位  // ... } void move_down(int steps) { // 向下移动steps个单位  // ... } void move_left(int steps) { // 向左移动steps个单位  // ... } void move_right(int steps) { // 向右移动steps个单位  // ... } int main() { // 初始化结构体  Point point = { .x = 0, .y = 0, .move_up = move_up, .move_down = move_down, .move_left = move_left, .move_right = move_right }; // 调用结构体中的函数  point.move_up(10); point.move_right(5); return 0; } 在上面的示例代码中，我们定义了一个结构体Point，其中包含了两个整型变量x和y，以及四个函数指针move_up、move_down、move_left和move_right。每个函数指针指向一个移动函数，用于在平面坐标系中移动点的位置。通过使用结构体封装函数，我们可以将函数和数据封装在一起，方便地进行操作和管理。
在main()函数中，我们首先通过初始化的方式，将结构体中的成员变量和函数指针初始化。然后，我们使用结构体中的函数指针，调用了move_up()和move_right()函数，分别将点向上移动10个单位和向右移动5个单位。
值得注意的是，在实际应用中，我们需要根据实际情况修改函数的实现，以及结构体中的成员变量和函数指针的数量和类型。同时避免滥用。
举例2 typedef struct { void (*init)(void); void (*write)(uint8_t data); uint8_t (*read)(void); } spi_t; void spi_init(void) { /* SPI初始化代码 */ } void spi_write(uint8_t data) { /* SPI写入数据 */ } uint8_t spi_read(void) { /* SPI读取数据 */ } int main(void) { spi_t spi = {spi_init, spi_write, spi_read}; spi.init(); spi.write(0xAA); uint8_t data = spi.read(); return 0; } 在举例2这个例子中，我们定义了一个spi_t类型的结构体，它包含了三个成员函数指针，分别对应SPI总线的初始化、写入和读取操作。在main函数中，我们定义了一个spi结构体变量，并且初始化它的函数指针成员。接下来，我们通过spi结构体变量的函数指针成员，分别调用了SPI总线的初始化、写入和读取操作。
使用结构体封装函数可以使代码更加清晰明了，减少了代码的冗余和重复，同时也方便代码的扩展和维护。
举例3 假设我们需要控制一个LED灯的亮度，可以使用PWM（脉冲宽度调制）技术来实现。为了方便控制，我们可以使用一个结构体来封装控制LED灯的函数和变量。
typedef struct { uint8_t duty_cycle; // 占空比  void (*set_duty_cycle)(uint8_t duty_cycle); // 设置占空比的函数指针  void (*start)(void); // 启动PWM输出的函数指针  void (*stop)(void); // 停止PWM输出的函数指针 } pwm_control_t; // 设置占空比 void set_duty_cycle(uint8_t duty_cycle) { // 设置占空比的代码 } // 启动PWM输出 void start_pwm(void) { // 启动PWM输出的代码 } // 停止PWM输出 void stop_pwm(void) { // 停止PWM输出的代码 } int main(void) { pwm_control_t pwm; pwm.duty_cycle = 50; // 设置占空比为50%  pwm.set_duty_cycle = set_duty_cycle; pwm.start = start_pwm; pwm.stop = stop_pwm; pwm.set_duty_cycle(pwm.duty_cycle); // 设置占空比  pwm.start(); // 启动PWM输出  while (1) { // 循环执行其他任务  } } 在上面的代码中，我们定义了一个名为pwm_control_t的结构体，其中包含了一个占空比成员变量duty_cycle和三个函数指针set_duty_cycle、start和stop。set_duty_cycle函数用于设置占空比，start函数用于启动PWM输出，stop函数用于停止PWM输出。
在main函数中，我们创建了一个pwm_control_t类型的结构体变量pwm，并分别给结构体的成员变量和函数指针赋值。接着，我们调用了set_duty_cycle和start函数来设置占空比和启动PWM输出。
结构体封装函数的好处在于，我们可以通过创建不同的结构体变量来控制多个LED灯，而且不同的LED灯可以使用不同的PWM参数。此外，如果需要修改PWM输出的实现方式，只需要修改start和stop函数即可，而不需要修改每个LED灯。
]]></content>
  </entry>
  
  <entry>
    <title>Linux驱动IO篇——mmap操作</title>
    <url>/post/linux/linux-io-device-driver-mmap-operation.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Device Driver</tag>
      <tag>mmap</tag>
      <tag>IO</tag>
    </tags>
    <content type="html"><![CDATA[平时我们写Linux驱动和用户空间交互时，都是通过copy_from_user把用户空间传过来的数据进行拷贝，为什么要这么做呢？
前言 因为用户空间是不能直接内核空间数据的，他们映射的是不同的地址空间，只能先将数据拷贝过来，然后再操作。
如果用户空间需要传几MB的数据给内核，那么原来的拷贝方式显然效率特别低，也不太现实，那怎么办呢？
想想，之所以要拷贝是因为用户空间不能直接访问内核空间，那如果可以直接访问内核空间的buffer，是不是就解决了。
简单来说，就是让一块物理内存拥有两份映射，即拥有两个虚拟地址，一个在内核空间，一个在用户空间。关系如下：
通过mmap映射就可以实现。
应用层 应用层代码很简单，主要就是通过mmap系统调用进行映射，然后就可以对返回的地址进行操作。
char * buf; /* 1. 打开文件 */ fd = open(&#34;/dev/hello&#34;, O_RDWR); if (fd == -1) { printf(&#34;can not open file /dev/hello\n&#34;); return -1; } /* 2. mmap * MAP_SHARED : 多个APP都调用mmap映射同一块内存时, 对内存的修改大家都可以看到。 * 就是说多个APP、驱动程序实际上访问的都是同一块内存 * MAP_PRIVATE : 创建一个copy on write的私有映射。 * 当APP对该内存进行修改时，其他程序是看不到这些修改的。 * 就是当APP写内存时, 内核会先创建一个拷贝给这个APP, * 这个拷贝是这个APP私有的, 其他APP、驱动无法访问。 */ buf = mmap(NULL, 1024*8, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); mmap的第一个参数是想要映射的起始地址，通常设置为NULL，表示由内核来决定该起始地址。
第二参数是要映射的内存空间的大小。
第三个参数PROT_READ | PROT_WRITE表示映射后的空间是可读可写的。
第四个参数可填MAP_SHARED或MAP_PRIVATE：
 MAP_SHARED：多个APP都调用mmap映射同一块内存时, 对内存的修改大家都可以看到。就是说多个APP、驱动程序实际上访问的都是同一块内存。 MAP_PRIVATE：创建一个copy on write的私有映射。当APP对该内存进行修改时，其他程序是看不到这些修改的。就是当APP写内存时, 内核会先创建一个拷贝给这个APP，这个拷贝是这个APP私有的, 其他APP、驱动无法访问。  驱动层 驱动层主要是实现mmap接口，而mmap接口的实现，主要是调用了remap_pfn_range函数，函数原型如下：
int remap_pfn_range( struct vm_area_struct *vma, unsigned long addr, unsigned long pfn, unsigned long size, pgprot_t prot); vma：描述一片映射区域的结构体指针 addr：要映射的虚拟地址起始地址 pfn：物理内存所对应的页框号，就是将物理地址除以页大小得到的值 size：映射的大小 prot：该内存区域的访问权限
驱动主要步骤：
  使用kmalloc或者kzalloc函数分配一块内存kernel_buf，因为这样分配的内存物理地址是连续的，mmap后应用层会对这一个基地址去访问这块内存。
  实现mmap函数
  static int hello_drv_mmap(struct file *file, struct vm_area_struct *vma) { /* 获得物理地址 */ unsigned long phy = virt_to_phys(kernel_buf);//kernel_buf是内核空间分配的一块虚拟地址空间  /* 设置属性：cache, buffer*/ vma-&gt;vm_page_prot = pgprot_writecombine(vma-&gt;vm_page_prot); /* map */ if(remap_pfn_range(vma, vma-&gt;vm_start, phy&gt;&gt;PAGE_SHFIT, vma-&gt;vm_end - vma-&gt;start, vma-&gt;vm_page_prot)){ printk(&#34;mmap remap_pfn_range failed\n&#34;); return -ENOBUFS; } return 0; } static struct file_operations my_fops = { .mmap = hello_drv_mmap, };  通过virt_to_phys将虚拟地址转为物理地址，这里的kernel_buf是内核空间的一块虚拟地址空间 设置属性：不使用cache，使用buffer 映射：通过remap_pfn_range函数映射，phy&raquo;PAGE_SHIFT其实就是按page映射，除了这个参数，其他的起始地址、大小和权限都可以由用户在系统调用函数中指定。  当应用层调用mmap后，就会调用到驱动层的mmap函数，最终应用层的虚拟地址和驱动中的物理地址就建立了映射关系，应用层也就可以直接访问驱动的buffer了。
]]></content>
  </entry>
  
  <entry>
    <title>Linux下SPI驱动详解</title>
    <url>/post/linux/linux-spi-device-driver-detailed-explanation.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Linux</tag>
      <tag>SPI</tag>
      <tag>Device Driver</tag>
    </tags>
    <content type="html"><![CDATA[SPI，是英语Serial Peripheral interface的缩写，顾名思义就是串行外围设备接口。
SPI总线 SPI总线概述 SPI是Motorola首先在其MC68HCXX系列处理器上定义的。SPI接口主要应用在 EEPROM，FLASH，实时时钟，AD转换器，还有数字信号处理器和数字信号解码器之间。SPI，是一种高速的，全双工，同步的通信总线，并且在芯片的管脚上只占用四根线，节约了芯片的管脚，同时为PCB的布局上节省空间，提供方便，正是出于这种简单易用的特性，现在越来越多的芯片集成了这种通信协议。SPI总线的构成及信号类型如图1-1所示：
 MOSI – 主设备数据输出，从设备数据输入 对应MOSI master output slave input MISO – 主设备数据输入，从设备数据输出 对应MISO master input slave output CLK – 时钟信号，由主设备产生 nCS – 从设备使能信号，由主设备控制  图1-1 SPI总线模型
SPI总线时序 SPI接口在Master控制下产生的从设备使能信号和时钟信号，两个双向移位寄存器按位传输进行数据交换，传输数据高位在前（MSB first），低位在后。如下图所示，在CLK的下降沿上数据改变，上升沿一位数据被存入移位寄存器。
图1-2 spi传输时序图
在一个SPI时钟周期内，会完成如下操作：（1）Master通过MOSI线发送1位数据，同时Slave通过MOSI线读取这1位数据；（2）Slave通过MISO线发送1位数据，同时Master通过MISO线读取这1位数据。Master和Slave各有一个移位寄存器，如图1-3所示，而且这两个移位寄存器连接成环状。依照CLK的变化，数据以MSB first的方式依次移出Master寄存器和Slave寄存器，并且依次移入Slave寄存器和Master寄存器。当寄存器中的内容全部移出时，相当于完成了两个寄存器内容的交换。
SPI总线传输模式 SPI总线传输一共有4种模式，这4种模式分别由时钟极性(CPOL，Clock Polarity)和时钟相位(CPHA，Clock Phase)来定义，其中CPOL参数规定了SCK时钟信号空闲状态的电平，CPHA规定了数据是在SCK时钟的上升沿被采样还是下降沿被采样。这四种模式的时序图如下图1-4所示：
 模式0：CPOL= 0，CPHA=0。CLK串行时钟线空闲是为低电平，数据在SCK时钟的上升沿被采样，数据在CLK时钟的下降沿切换 模式1：CPOL= 0，CPHA=1。CLK串行时钟线空闲是为低电平，数据在SCK时钟的下降沿被采样，数据在CLK时钟的上升沿切换 模式2：CPOL= 1，CPHA=0。CLK串行时钟线空闲是为高电平，数据在SCK时钟的下降沿被采样，数据在CLK时钟的上升沿切换 模式3：CPOL= 1，CPHA=1。CLK串行时钟线空闲是为高电平，数据在SCK时钟的上升沿被采样，数据在CLK时钟的下降沿切换 其中比较常用的模式是模式0和模式3。为了更清晰的描述SPI总线的时序，下面展现了模式0下的SPI时序图1-5：  图1-5 mode0下的SPI时序图
SPI总线的优缺点  在点对点的通信中，SPI接口不需要进行寻址操作，且为全双工通信，显得简单高效。 SPI接口没有指定的流控制，没有应答机制确认是否接收到数据。  Linux SPI 框架 软件架构 Linux系统对spi设备具有很好的支持，linux系统下的spi驱动程序从逻辑上可以分为3个部分：
 spi核心（SPI Core）：SPI Core是Linux内核用来维护和管理spi的核心部分，SPI Core提供操作接口函数，允许一个spi master，spi driver和spi device初始化时在SPI Core中进行注册，以及退出时进行注销。 spi控制器驱动（SPI Master Driver）：SPI Master针对不同类型的spi控制器硬件，实现spi总线的硬件访问操作。SPI Master通过接口函数向SPI Core注册一个控制器。 spi设备驱动（SPI Device Driver）：SPI Driver是对应于spi设备端的驱动程序，通过接口函数向SPI Core进行注册，SPI Driver的作用是将spi设备挂接到spi总线上；Linux的软件架构图如图2-1所示：  图2-1 spi软件架构图
初始化及退出流程 注册spi控制器 注册spi控制器到内核分为两个阶段：第一个阶段，使用spi_alloc_master,分配一个spi_master的空间，具体流程如图2-2所示：
第二阶段，使用spi_register_master将第一阶段分配的spi_master注册到内核中，具体流程如2-3所示：
注销spi控制器 spi控制器注销的流程如图2-4所示：
关键数据结构 spi_device struct spi_device { struct device dev; /*spi控制器对应的device结构 struct spi_master *master; /*设备使用的master结构，挂在哪个主控制器下*/ u32 max_speed_hz; /*通讯时钟最大频率*/ u8 chip_select; /*片选号，每个master支持多个spi_device */ u8 mode; #define SPI_CPHA 0x01 /* clock phase */#define SPI_CPOL 0x02 /* clock polarity */#define SPI_MODE_0 (0|0) /* (original MicroWire) */#define SPI_MODE_1 (0|SPI_CPHA) #define SPI_MODE_2 (SPI_CPOL|0) #define SPI_MODE_3 (SPI_CPOL|SPI_CPHA) #define SPI_CS_HIGH 0x04 /* chipselect active high? */#define SPI_LSB_FIRST 0x08 /* per-word bits-on-wire */#define SPI_3WIRE 0x10 /* SI/SO signals shared */#define SPI_LOOP 0x20 /* loopback mode */#define SPI_NO_CS 0x40 /* 1 dev/bus, no chipselect */#define SPI_READY 0x80 /* slave pulls low to pause */ u8 bits_per_word; /*每个字长的比特数，默认是8*/ int irq; void *controller_state; /*控制器状态*/ void *controller_data; /*控制器数据*/ char modalias[SPI_NAME_SIZE]; /* 设备驱动的名字 */ int cs_gpio; /* chip select gpio */ /* * likely need more hooks for more protocol options affecting how * the controller talks to each chip, like: * - memory packing (12 bit samples into low bits, others zeroed) * - priority * - drop chipselect after each word * - chipselect delays * - ... */ }; spi_device代表一个外围spi设备，由master controller driver注册完成后扫描BSP中注册设备产生的设备链表并向spi_bus注册产生。在内核中，每个spi_device代表一个物理的spi设备。
spi_driver struct spi_driver { const struct spi_device_id *id_table; /*支持的spi_device设备表*/ int (*probe)(struct spi_device *spi); int (*remove)(struct spi_device *spi); void (*shutdown)(struct spi_device *spi); int (*suspend)(struct spi_device *spi, pm_message_t mesg); int (*resume)(struct spi_device *spi); struct device_driver driver; }; spi_driver代表一个SPI protocol drivers，即外设驱动
struct spi_master struct spi_master { struct device dev; /*spi控制器对应的device结构*/ struct list_head list; /*链表 /* other than negative (== assign one dynamically), bus_num is fully * board-specific. usually that simplifies to being SOC-specific. * example: one SOC has three SPI controllers, numbered 0..2, * and one board&#39;s schematics might show it using SPI-2. software * would normally use bus_num=2 for that controller. */ s16 bus_num; /*总线（或控制器编号）*/ /* chipselects will be integral to many controllers; some others * might use board-specific GPIOs. */ u16 num_chipselect; /*片选数量*/ /* some SPI controllers pose alignment requirements on DMAable * buffers; let protocol drivers know about these requirements. */ u16 dma_alignment; /* spi_device.mode flags understood by this controller driver */ u16 mode_bits; /* master支持的设备模式 */ /* bitmask of supported bits_per_word for transfers */ u32 bits_per_word_mask; /* other constraints relevant to this driver */ u16 flags; /*用于限定某些限制条件的标志位 #define SPI_MASTER_HALF_DUPLEX BIT(0) /* can&#39;t do full duplex */ #define SPI_MASTER_NO_RX BIT(1) /* can&#39;t do buffer read */#define SPI_MASTER_NO_TX BIT(2) /* can&#39;t do buffer write */ /* lock and mutex for SPI bus locking */ spinlock_t bus_lock_spinlock; struct mutex bus_lock_mutex; /* flag indicating that the SPI bus is locked for exclusive use */ bool bus_lock_flag; /* Setup mode and clock, etc (spi driver may call many times). * * IMPORTANT: this may be called when transfers to another * device are active. DO NOT UPDATE SHARED REGISTERS in ways * which could break those transfers. */ int (*setup)(struct spi_device *spi); /*根据spi设备更新硬件配置。设置spi工作模式、时钟等*/ /* bidirectional bulk transfers * * + The transfer() method may not sleep; its main role is * just to add the message to the queue. * + For now there&#39;s no remove-from-queue operation, or * any other request management * + To a given spi_device, message queueing is pure fifo * * + The master&#39;s main job is to process its message queue, * selecting a chip then transferring data * + If there are multiple spi_device children, the i/o queue * arbitration algorithm is unspecified (round robin, fifo, * priority, reservations, preemption, etc) * * + Chipselect stays active during the entire message * (unless modified by spi_transfer.cs_change != 0). * + The message transfers use clock and SPI mode parameters * previously established by setup() for this device */ int (*transfer)(struct spi_device *spi, struct spi_message *mesg); /*添加消息到队列的方法，此函数不可睡眠。它的职责是安排发生的传送并且调用注册的回调函数complete()*/ /* called on release() to free memory provided by spi_master */ void (*cleanup)(struct spi_device *spi);/*cleanup函数会在spidev_release函数中被调用，spidev_release被登记为spi dev的release函数。*/ /* * These hooks are for drivers that want to use the generic * master transfer queueing mechanism. If these are used, the * transfer() function above must NOT be specified by the driver. * Over time we expect SPI drivers to be phased over to this API. */ bool queued; struct kthread_worker kworker; /*用于管理数据传输消息队列的工作队列线程*/ struct task_struct *kworker_task; struct kthread_work pump_messages; /*具体实现数据传输队列的工作队列*/ spinlock_t queue_lock; struct list_head queue; /*该控制器的消息队列，所有等待传输的队列挂在该链表下*/ struct spi_message *cur_msg;/*当前正在处理的消息队列*/ bool busy; /忙状态*/ bool running; /*正在跑*/ bool rt; int (*prepare_transfer_hardware)(struct spi_master *master); /*回调函数，正式发起传输前会被调用，用于准备硬件资源*/ int (*transfer_one_message)(struct spi_master *master, struct spi_message *mesg); /*单个消息的原子传输回调函数，队列中每个消息都会回调一次该回调来完成传输工作*/ int (*unprepare_transfer_hardware)(struct spi_master *master); /*清理回调函数*/ /* gpio chip select */ int *cs_gpios; }; spi_master代表一个spi控制器。
struct spi_message 和spi_transfer 要完成和SPI设备的数据传输工作，我们还需要另外两个数据结构：spi_message和spi_transfer。
spi_message包含了一个的spi_transfer结构序列，一旦控制器接收了一个spi_message，其中的spi_transfer应该按顺序被发送，并且不能被其它spi_message打断，所以我们认为spi_message就是一次SPI数据交换的原子操作。下面我们看看这两个数据结构的定义：
struct spi_message ：
struct spi_message { struct list_head transfers; /*spi_transfer链表队列，此次消息的传输段队列，一个消息可以包含多个传输段。*/ struct spi_device *spi; /*传输的目的设备*/ unsigned is_dma_mapped:1; /*如果为真，此次调用提供dma和cpu虚拟地址。*/ /* REVISIT: we might want a flag affecting the behavior of the * last transfer ... allowing things like &#34;read 16 bit length L&#34; * immediately followed by &#34;read L bytes&#34;. Basically imposing * a specific message scheduling algorithm. * * Some controller drivers (message-at-a-time queue processing) * could provide that as their default scheduling algorithm. But * others (with multi-message pipelines) could need a flag to * tell them about such special cases. */ /* completion is reported through a callback */ void (*complete)(void *context);/*异步调用完成后的回调函数*/ void *context; /*回调函数的参数*/ unsigned actual_length; /*实际传输的长度*/ int status; /*该消息的发送结果，成功被置0，否则是一个负的错误码。*/ /* for optional use by whatever driver currently owns the * spi_message ... between calls to spi_async and then later * complete(), that&#39;s the spi_master controller driver. */ struct list_head queue; void *state; }; 链表字段queue用于把该结构挂在代表控制器的spi_master结构的queue字段上，控制器上可以同时被加入多个spi_message进行排队。另一个链表字段transfers则用于链接挂在本message下的spi_tranfer结构。complete回调函数则会在该message下的所有spi_transfer都被传输完成时被调用，以便通知协议驱动处理接收到的数据以及准备下一批需要发送的数据。我们再来看看spi_transfer结构：spi_transfer
struct spi_transfer { /* it&#39;s ok if tx_buf == rx_buf (right?) * for MicroWire, one buffer must be null * buffers must work with dma_*map_single() calls, unless * spi_message.is_dma_mapped reports a pre-existing mapping */ const void *tx_buf; /*发送缓冲区*/ void *rx_buf; /*接收缓冲区*/ unsigned len; /*缓冲区长度，tx和rx的大小（字节数）。指它们各自的大小*/ dma_addr_t tx_dma; /*tx的dma地址*/ dma_addr_t rx_dma; /*rx的dma地址*/ unsigned cs_change:1; /*当前spi_transfer发送完成之后重新片选*/ u8 bits_per_word; /*每个字长的比特数，0代表使用spi_device中的默认值8*/ u16 delay_usecs; /*发送完成一个spi_transfer后的延时时间，此次传输结束和片选改变之间的延时，之后就会启动另一个传输或者结束整个消息*/ u32 speed_hz; /*通信时钟。如果是0，使用默认值*/ #ifdef CONFIG_SPI_LOMBO  struct lombo_spi_operate_para *esop; #endif  struct list_head transfer_list; /*用于链接到spi_message，用来连接的双向链接节点*/ }; 首先，transfer_list链表字段用于把该transfer挂在一个spi_message结构中，tx_buf和rx_buf提供了非dma模式下的数据缓冲区地址，len则是需要传输数据的长度，tx_dma和rx_dma则给出了dma模式下的缓冲区地址。原则来讲，spi_transfer才是传输的最小单位，之所以又引进了spi_message进行打包，我觉得原因是：有时候希望往spi设备的多个不连续的地址（或寄存器）一次性写入，如果没有spi_message进行把这样的多个spi_transfer打包，因为通常真正的数据传送工作是在另一个内核线程（工作队列）中完成的，不打包的后果就是会造成更多的进程切换，效率降低，延迟增加，尤其对于多个不连续地址的小规模数据传送而言就更为明显。
spi_board_info struct spi_board_info { /* the device name and module name are coupled, like platform_bus; * &#34;modalias&#34; is normally the driver name. * * platform_data goes to spi_device.dev.platform_data, * controller_data goes to spi_device.controller_data, * irq is copied too */ char modalias[SPI_NAME_SIZE]; /*名字*/ const void *platform_data; /*平台数据*/ void *controller_data; /*控制器数据*/ int irq; /* slower signaling on noisy or low voltage boards */ u32 max_speed_hz; /*最大速率*/ /* bus_num is board specific and matches the bus_num of some * spi_master that will probably be registered later. * * chip_select reflects how this chip is wired to that master; * it&#39;s less than num_chipselect. */ u16 bus_num; /*spi总线编号*/ u16 chip_select; /*片选*/ /* mode becomes spi_device.mode, and is essential for chips * where the default of SPI_CS_HIGH = 0 is wrong. */ u8 mode; /*模式 */ /* ... may need additional spi_device chip config data here. * avoid stuff protocol drivers can set; but include stuff * needed to behave without being bound to a driver: * - quirks like clock rate mattering when not selected */ }; 数据传输流程 整体的数据传输流程大致上是这样的:
 定义一个spi_message结构； 用spi_message_init函数初始化spi_message； 定义一个或数个spi_transfer结构，初始化并为数据准备缓冲区并赋值给spi_transfer相应的字段（tx_buf，rx_buf等）； 通过spi_message_init函数把这些spi_transfer挂在spi_message结构下； 如果使用同步方式，调用spi_sync()，如果使用异步方式，调用spi_async();(我调试外设时，只使用过spi_sync  传输示意图如图2-5所示：
数据准备 spi_message_init static inline void spi_message_init(struct spi_message *m) { memset(m, 0, sizeof *m); INIT_LIST_HEAD(&amp;m-&gt;transfers); } 初始化spi_message：清空message，初始化transfers链表头。
spi_message_add_tail static inline void spi_message_add_tail(struct spi_transfer *t, struct spi_message *m) { list_add_tail(&amp;t-&gt;transfer_list, &amp;m-&gt;transfers); } 将spi_transfer加入到spi_message的链表尾部。
数据传输 SPI数据传输可以有两种方式：同步方式和异步方式。所谓同步方式是指数据传输的发起者必须等待本次传输的结束，期间不能做其它事情，用代码来解释就是，调用传输的函数后，直到数据传输完成，函数才会返回。而异步方式则正好相反，数据传输的发起者无需等待传输的结束，数据传输期间还可以做其它事情，用代码来解释就是，调用传输的函数后，函数会立刻返回而不用等待数据传输完成，我们只需设置一个回调函数，传输完成后，该回调函数会被调用以通知发起者数据传送已经完成。同步方式简单易用，很适合处理那些少量数据的单次传输。但是对于数据量大、次数多的传输来说，异步方式就显得更加合适。对于SPI控制器来说，要支持异步方式必须要考虑以下两种状况：
 对于同一个数据传输的发起者，既然异步方式无需等待数据传输完成即可返回，返回后，该发起者可以立刻又发起一个message，而这时上一个message还没有处理完。 对于另外一个不同的发起者来说，也有可能同时发起一次message传输请求 首先分析spi_sync()接口的实现流程，如图2-6：  其次分析spi_async_locked接口的实现流程，如图2-7所示：
spi_queued_transfer接口的实现流程如图3-8所示：
spi_pump_messages函数的处理流程如图3-9所示：
图中transfer_one_message是spi控制器驱动要实现的，主要功能是处理spi_message中的每个spi_transfer。
关键函数解析 spi_alloc_master 原型：
struct spi_master *spi_alloc_master(struct device *dev, unsigned size) 功能：分配一个spi_master结构体指针。
参数：dev:spi控制器device指针 size ：分配的driver-private data大小
返回值 ：成功，返回spi_master指针；否则返回NULL
spi_register_master 原型：
int spi_register_master(struct spi_master *master) 功能 注册spi控制器驱动到内核。
参数 master：spi_master指针
返回值 成功，返回0；否则返回错误码
spi_unregister_master 原型：
void spi_unregister_master(struct spi_master *master) 功能 注销spi控制器驱动。
参数 master：spi_master指针
返回值 无
实例Demo #include &lt;linux/types.h&gt;#include &lt;linux/kernel.h&gt;#include &lt;linux/delay.h&gt;#include &lt;linux/ide.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/errno.h&gt;#include &lt;linux/gpio.h&gt;#include &lt;linux/cdev.h&gt;#include &lt;linux/device.h&gt;#include &lt;linux/of_gpio.h&gt;#include &lt;linux/semaphore.h&gt;#include &lt;linux/timer.h&gt;#include &lt;linux/i2c.h&gt;#include &lt;linux/spi/spi.h&gt;#include &lt;linux/of.h&gt;#include &lt;linux/of_address.h&gt;#include &lt;linux/of_gpio.h&gt;#include &lt;linux/platform_device.h&gt;#include &lt;asm/mach/map.h&gt;#include &lt;asm/uaccess.h&gt;#include &lt;asm/io.h&gt;#include &#34;icm20608reg.h&#34;/*************************************************************** Copyright © ALIENTEK Co., Ltd. 1998-2029. All rights reserved. 文件名 : icm20608.c 作者 : 左工 版本 : V1.0 描述 : ICM20608 SPI驱动程序 其他 : 无 论坛 : 日志 : 初版V1.0 2019/9/2 左工创建 ***************************************************************/ #define ICM20608_CNT 1 #define ICM20608_NAME &#34;icm20608&#34;  struct icm20608_dev { dev_t devid; /* 设备号 */ struct cdev cdev; /* cdev */ struct class *class; /* 类 */ struct device *device; /* 设备 */ struct device_node *nd; /* 设备节点 */ int major; /* 主设备号 */ void *private_data; /* 私有数据 */ int cs_gpio; /* 片选所使用的GPIO编号 */ signed int gyro_x_adc; /* 陀螺仪X轴原始值 */ signed int gyro_y_adc; /* 陀螺仪Y轴原始值 */ signed int gyro_z_adc; /* 陀螺仪Z轴原始值 */ signed int accel_x_adc; /* 加速度计X轴原始值 */ signed int accel_y_adc; /* 加速度计Y轴原始值 */ signed int accel_z_adc; /* 加速度计Z轴原始值 */ signed int temp_adc; /* 温度原始值 */ }; static struct icm20608_dev icm20608dev; /* * @description : 从icm20608读取多个寄存器数据 * @param - dev: icm20608设备 * @param - reg: 要读取的寄存器首地址 * @param - val: 读取到的数据 * @param - len: 要读取的数据长度 * @return : 操作结果 */ static int icm20608_read_regs(struct icm20608_dev *dev, u8 reg, void *buf, int len) { int ret; unsigned char txdata[len]; struct spi_message m; struct spi_transfer *t; struct spi_device *spi = (struct spi_device *)dev-&gt;private_data; gpio_set_value(dev-&gt;cs_gpio, 0); /* 片选拉低，选中ICM20608 */ t = kzalloc(sizeof(struct spi_transfer), GFP_KERNEL); /* 申请内存 */ /* 第1次，发送要读取的寄存地址 */ txdata[0] = reg | 0x80; /* 写数据的时候寄存器地址bit8要置1 */ t-&gt;tx_buf = txdata; /* 要发送的数据 */ t-&gt;len = 1; /* 1个字节 */ spi_message_init(&amp;m); /* 初始化spi_message */ spi_message_add_tail(t, &amp;m);/* 将spi_transfer添加到spi_message队列 */ ret = spi_sync(spi, &amp;m); /* 同步发送 */ /* 第2次，读取数据 */ txdata[0] = 0xff; /* 随便一个值，此处无意义 */ t-&gt;rx_buf = buf; /* 读取到的数据 */ t-&gt;len = len; /* 要读取的数据长度 */ spi_message_init(&amp;m); /* 初始化spi_message */ spi_message_add_tail(t, &amp;m);/* 将spi_transfer添加到spi_message队列 */ ret = spi_sync(spi, &amp;m); /* 同步发送 */ kfree(t); /* 释放内存 */ gpio_set_value(dev-&gt;cs_gpio, 1); /* 片选拉高，释放ICM20608 */ return ret; } /* * @description : 向icm20608多个寄存器写入数据 * @param - dev: icm20608设备 * @param - reg: 要写入的寄存器首地址 * @param - val: 要写入的数据缓冲区 * @param - len: 要写入的数据长度 * @return : 操作结果 */ static s32 icm20608_write_regs(struct icm20608_dev *dev, u8 reg, u8 *buf, u8 len) { int ret; unsigned char txdata[len]; struct spi_message m; struct spi_transfer *t; struct spi_device *spi = (struct spi_device *)dev-&gt;private_data; t = kzalloc(sizeof(struct spi_transfer), GFP_KERNEL); /* 申请内存 */ gpio_set_value(dev-&gt;cs_gpio, 0); /* 片选拉低 */ /* 第1次，发送要读取的寄存地址 */ txdata[0] = reg &amp; ~0x80; /* 写数据的时候寄存器地址bit8要清零 */ t-&gt;tx_buf = txdata; /* 要发送的数据 */ t-&gt;len = 1; /* 1个字节 */ spi_message_init(&amp;m); /* 初始化spi_message */ spi_message_add_tail(t, &amp;m);/* 将spi_transfer添加到spi_message队列 */ ret = spi_sync(spi, &amp;m); /* 同步发送 */ /* 第2次，发送要写入的数据 */ t-&gt;tx_buf = buf; /* 要写入的数据 */ t-&gt;len = len; /* 写入的字节数 */ spi_message_init(&amp;m); /* 初始化spi_message */ spi_message_add_tail(t, &amp;m);/* 将spi_transfer添加到spi_message队列 */ ret = spi_sync(spi, &amp;m); /* 同步发送 */ kfree(t); /* 释放内存 */ gpio_set_value(dev-&gt;cs_gpio, 1);/* 片选拉高，释放ICM20608 */ return ret; } /* * @description : 读取icm20608指定寄存器值，读取一个寄存器 * @param - dev: icm20608设备 * @param - reg: 要读取的寄存器 * @return : 读取到的寄存器值 */ static unsigned char icm20608_read_onereg(struct icm20608_dev *dev, u8 reg) { u8 data = 0; icm20608_read_regs(dev, reg, &amp;data, 1); return data; } /* * @description : 向icm20608指定寄存器写入指定的值，写一个寄存器 * @param - dev: icm20608设备 * @param - reg: 要写的寄存器 * @param - data: 要写入的值 * @return : 无 */ static void icm20608_write_onereg(struct icm20608_dev *dev, u8 reg, u8 value) { u8 buf = value; icm20608_write_regs(dev, reg, &amp;buf, 1); } /* * @description : 读取ICM20608的数据，读取原始数据，包括三轴陀螺仪、 * : 三轴加速度计和内部温度。 * @param - dev : ICM20608设备 * @return : 无。 */ void icm20608_readdata(struct icm20608_dev *dev) { unsigned char data[14]; icm20608_read_regs(dev, ICM20_ACCEL_XOUT_H, data, 14); dev-&gt;accel_x_adc = (signed short)((data[0] &lt;&lt; 8) | data[1]); dev-&gt;accel_y_adc = (signed short)((data[2] &lt;&lt; 8) | data[3]); dev-&gt;accel_z_adc = (signed short)((data[4] &lt;&lt; 8) | data[5]); dev-&gt;temp_adc = (signed short)((data[6] &lt;&lt; 8) | data[7]); dev-&gt;gyro_x_adc = (signed short)((data[8] &lt;&lt; 8) | data[9]); dev-&gt;gyro_y_adc = (signed short)((data[10] &lt;&lt; 8) | data[11]); dev-&gt;gyro_z_adc = (signed short)((data[12] &lt;&lt; 8) | data[13]); } /* * @description : 打开设备 * @param - inode : 传递给驱动的inode * @param - filp : 设备文件，file结构体有个叫做privateate_data的成员变量 * 一般在open的时候将private_data似有向设备结构体。 * @return : 0 成功;其他 失败 */ static int icm20608_open(struct inode *inode, struct file *filp) { filp-&gt;private_data = &amp;icm20608dev; /* 设置私有数据 */ return 0; } /* * @description : 从设备读取数据 * @param - filp : 要打开的设备文件(文件描述符) * @param - buf : 返回给用户空间的数据缓冲区 * @param - cnt : 要读取的数据长度 * @param - offt : 相对于文件首地址的偏移 * @return : 读取的字节数，如果为负值，表示读取失败 */ static ssize_t icm20608_read(struct file *filp, char __user *buf, size_t cnt, loff_t *off) { signed int data[7]; long err = 0; struct icm20608_dev *dev = (struct icm20608_dev *)filp-&gt;private_data; icm20608_readdata(dev); data[0] = dev-&gt;gyro_x_adc; data[1] = dev-&gt;gyro_y_adc; data[2] = dev-&gt;gyro_z_adc; data[3] = dev-&gt;accel_x_adc; data[4] = dev-&gt;accel_y_adc; data[5] = dev-&gt;accel_z_adc; data[6] = dev-&gt;temp_adc; err = copy_to_user(buf, data, sizeof(data)); return 0; } /* * @description : 关闭/释放设备 * @param - filp : 要关闭的设备文件(文件描述符) * @return : 0 成功;其他 失败 */ static int icm20608_release(struct inode *inode, struct file *filp) { return 0; } /* icm20608操作函数 */ static const struct file_operations icm20608_ops = { .owner = THIS_MODULE, .open = icm20608_open, .read = icm20608_read, .release = icm20608_release, }; /* * ICM20608内部寄存器初始化函数 * @param : 无 * @return : 无 */ void icm20608_reginit(void) { u8 value = 0; icm20608_write_onereg(&amp;icm20608dev, ICM20_PWR_MGMT_1, 0x80); mdelay(50); icm20608_write_onereg(&amp;icm20608dev, ICM20_PWR_MGMT_1, 0x01); mdelay(50); value = icm20608_read_onereg(&amp;icm20608dev, ICM20_WHO_AM_I); printk(&#34;ICM20608 ID = %#X\r\n&#34;, value); icm20608_write_onereg(&amp;icm20608dev, ICM20_SMPLRT_DIV, 0x00); /* 输出速率是内部采样率 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_GYRO_CONFIG, 0x18); /* 陀螺仪±2000dps量程 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_ACCEL_CONFIG, 0x18); /* 加速度计±16G量程 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_CONFIG, 0x04); /* 陀螺仪低通滤波BW=20Hz */ icm20608_write_onereg(&amp;icm20608dev, ICM20_ACCEL_CONFIG2, 0x04); /* 加速度计低通滤波BW=21.2Hz */ icm20608_write_onereg(&amp;icm20608dev, ICM20_PWR_MGMT_2, 0x00); /* 打开加速度计和陀螺仪所有轴 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_LP_MODE_CFG, 0x00); /* 关闭低功耗 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_FIFO_EN, 0x00); /* 关闭FIFO */ } /* * @description : spi驱动的probe函数，当驱动与 * 设备匹配以后此函数就会执行 * @param - client : spi设备 * @param - id : spi设备ID * */ static int icm20608_probe(struct spi_device *spi) { int ret = 0; /* 1、构建设备号 */ if (icm20608dev.major) { icm20608dev.devid = MKDEV(icm20608dev.major, 0); register_chrdev_region(icm20608dev.devid, ICM20608_CNT, ICM20608_NAME); } else { alloc_chrdev_region(&amp;icm20608dev.devid, 0, ICM20608_CNT, ICM20608_NAME); icm20608dev.major = MAJOR(icm20608dev.devid); } /* 2、注册设备 */ cdev_init(&amp;icm20608dev.cdev, &amp;icm20608_ops); cdev_add(&amp;icm20608dev.cdev, icm20608dev.devid, ICM20608_CNT); /* 3、创建类 */ icm20608dev.class = class_create(THIS_MODULE, ICM20608_NAME); if (IS_ERR(icm20608dev.class)) { return PTR_ERR(icm20608dev.class); } /* 4、创建设备 */ icm20608dev.device = device_create(icm20608dev.class, NULL, icm20608dev.devid, NULL, ICM20608_NAME); if (IS_ERR(icm20608dev.device)) { return PTR_ERR(icm20608dev.device); } /* 获取设备树中cs片选信号 */ icm20608dev.nd = of_find_node_by_path(&#34;/soc/aips-bus@02000000/spba-bus@02000000/ecspi@02010000&#34;); if(icm20608dev.nd == NULL) { printk(&#34;ecspi3 node not find!\r\n&#34;); return -EINVAL; } /* 2、 获取设备树中的gpio属性，得到BEEP所使用的BEEP编号 */ icm20608dev.cs_gpio = of_get_named_gpio(icm20608dev.nd, &#34;cs-gpio&#34;, 0); if(icm20608dev.cs_gpio &lt; 0) { printk(&#34;can&#39;t get cs-gpio&#34;); return -EINVAL; } /* 3、设置GPIO1_IO20为输出，并且输出高电平 */ ret = gpio_direction_output(icm20608dev.cs_gpio, 1); if(ret &lt; 0) { printk(&#34;can&#39;t set gpio!\r\n&#34;); } /*初始化spi_device */ spi-&gt;mode = SPI_MODE_0; /*MODE0，CPOL=0，CPHA=0*/ spi_setup(spi); icm20608dev.private_data = spi; /* 设置私有数据 */ /* 初始化ICM20608内部寄存器 */ icm20608_reginit(); return 0; } /* * @description : spi驱动的remove函数，移除spi驱动的时候此函数会执行 * @param - client : spi设备 * @return : 0，成功;其他负值,失败 */ static int icm20608_remove(struct spi_device *spi) { /* 删除设备 */ cdev_del(&amp;icm20608dev.cdev); unregister_chrdev_region(icm20608dev.devid, ICM20608_CNT); /* 注销掉类和设备 */ device_destroy(icm20608dev.class, icm20608dev.devid); class_destroy(icm20608dev.class); return 0; } /* 传统匹配方式ID列表 */ static const struct spi_device_id icm20608_id[] = { {&#34;alientek,icm20608&#34;, 0}, {} }; /* 设备树匹配列表 */ static const struct of_device_id icm20608_of_match[] = { { .compatible = &#34;alientek,icm20608&#34; }, { /* Sentinel */ } }; /* SPI驱动结构体 */ static struct spi_driver icm20608_driver = { .probe = icm20608_probe, .remove = icm20608_remove, .driver = { .owner = THIS_MODULE, .name = &#34;icm20608&#34;, .of_match_table = icm20608_of_match, }, .id_table = icm20608_id, }; /* * @description : 驱动入口函数 * @param : 无 * @return : 无 */ static int __init icm20608_init(void) { return spi_register_driver(&amp;icm20608_driver); } /* * @description : 驱动出口函数 * @param : 无 * @return : 无 */ static void __exit icm20608_exit(void) { spi_unregister_driver(&amp;icm20608_driver); } module_init(icm20608_init); module_exit(icm20608_exit); MODULE_LICENSE(&#34;GPL&#34;); MODULE_AUTHOR(yikoulinux&#34;); ]]></content>
  </entry>
  
  <entry>
    <title>什么是 nftables ? 它与 iptables 的区别是什么？</title>
    <url>/post/linux/difference-between-nftables-and-iptables.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>nftables, iptables</tag>
    </tags>
    <content type="html"><![CDATA[几乎每个 Linux 管理员都使用过 iptables，它是一个 Linux 系统的防火墙。
什么是 nftables ? 它与 iptables 的区别是什么？ 但是你可能还不太熟悉 nftables，这是一个新的防火墙，可为我们提供一些必需的升级，还有可能会取代 iptables。
为什么要使用 nftables 呢？ nftables 是由 Netfilter 开发的，该组织目前维护 iptables。nftables 的创建是为了解决 iptables 的一些性能和扩展问题。
除了新的语法和一些升级以外，nftables 的功能与 iptables 几乎是一样的。之所以推出 nftables 的另一个原因，是因为 iptables 的框架变的有点复杂，iptables, ip6tables, arptables 以及 ebtables 都有不同但相似的功能。
比如，在 iptables 中创建 IPv4 规则和在 ip6tables 中创建 IPv6 规则并保持两者同步是非常低效的。Nftables 旨在取代所有这些，成为一个集中的解决方案。
尽管自 2014 年以来，nftables 就被包含在 Linux 内核中，但随着采用范围的扩大，它最近越来越受欢迎。Linux 世界的变化很慢，过时的实用程序通常需要几年或更长的时间才能逐步淘汰，取而代之的是升级后的实用程序。
今天我们就简单介绍一下 nftables 和 iptables 之间的差异，并展示在新的 nftables 语法中配置防火墙规则的例子。
nftables 中的链（chains）和规则 在 iptables 中，有三个默认的链：输入、输出和转发。这三个“链”（以及其他链）包含“规则”，iptables 通过将网络流量与 链中的规则列表匹配进行工作。如果正在检查的流量与任何规则都不匹配，则链的默认策略将用于流量（即ACCEPT、DROP）。
Nftables的工作原理与此类似，也有“链”和“规则”。然而，它一开始没有任何基础链，这使得配置更加灵活。
iptables 效率低下的一个方面是，即使流量与任何规则都不匹配，所有网络数据也必须遍历上述链中的一个或多个。无论你是否配置了链，iptables仍然会根据它们检查你的网络数据。
在 Linux 中安装 nftables nftables 在所有主要的 Linux 发行版中都可用，可以使用发行版的包管理器安装。
在 Ubuntu 或基于 Debian 的系统中可使用如下命令：
sudo apt install nftables 设置 nftables在系统重启的时候自动启动，可执行如下操作：
sudo systemctl enable nftables.service iptables 和 nftables 之间的语法差异 与 iptables 相比，nftables 的语法更加简单，不过对于 iptables 中的语法，在 nftables 中也能用。
大家可使用 iptables-translate 工具，该工具接受 iptables 命令并将其转为等效的 nftables 命令，这是了解两种语法差异的一种简单方法。
使用以下命令在 Ubuntu 和基于 Debian 的发行版上安装 iptables-translate：
sudo apt install iptables-nftables-compat 安装后，你可以将 iptables 语法传递给 iptables-translate 命令，它将返回 nftables 等效命令。
下面我们看一些具体的语法示例。
阻止传入连接 下述命令将阻止来自IP地址192.168.2.1的传入连接：
$ iptables-translate -A INPUT -s 192.168.2.1 -j DROP nft add rule ip filter INPUT ip saddr 192.168.2.1 counter drop 允许传入SSH连接 放开 ssh 连接权限：
$ iptables-translate -A INPUT -p tcp --dport 22 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT nft add rule ip filter INPUT tcp dport 22 ct state new,established counter accept 允许来自特定 IP 范围的传入SSH连接 如果只想允许来自192.168.1.0/24的传入SSH连接：
$ iptables-translate -A INPUT -p tcp -s 192.168.1.0/24 --dport 22 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT nft add rule ip filter INPUT ip saddr 192.168.1.0/24 tcp dport 22 ct state new,established counter accept 允许MySQL连接到eth0网络接口 $ iptables-translate -A INPUT -i eth0 -p tcp --dport 3306 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT nft add rule ip filter INPUT iifname eth0 tcp dport 3306ct state new,established counter accept 允许传入HTTP和HTTPS流量 为了允许特定类型的流量，以下是这两个命令的语法：
$ iptables-translate -A INPUT -p tcp -m multiport --dports 80,443 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT nft add rule ip filter INPUT ip protocol tcp tcp dport { 80,443} ct state new,established counter accept 从这些例子中可以看出，nftables 语法与 iptables 非常相似，但命令更直观一些。
nftables 日志 上述nft命令示例中的“counter”选项告诉nftables统计规则被触碰的次数，就像默认情况下使用的iptables一样。
在nftables中，需要指定：
nft add rule ip filter INPUT ip saddr 192.168.2.1 counter accept nftables内置了用于导出配置的选项。它目前支持XML和JSON。
nft export xml ]]></content>
  </entry>
  
  <entry>
    <title>风河支持NXP S32G3——信心百倍、加速创新</title>
    <url>/post/news/wind-river-supports-nxp-s32g3.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Wind River</tag>
      <tag>NXP</tag>
      <tag>S32G3</tag>
    </tags>
    <content type="html"><![CDATA[风河公司与NXP公司的合作伙伴关系深厚且长远，由此不断地为我们的共同客户带来新的效益。 风河公司非常兴奋地宣布其运行时（Runtime）产品组合和Wind River Studio Linux 服务都已经支持下一代NXP S32G3处理器，从而有力地促进企业客户加速智能边缘设备的创建与部署。
具体而言，风河将为VxWorks、Wind River Linux和Helix虚拟化平台提供S32G3 BSP（板级支持包），以及配套的设计、全生命周期安全与维护服务。例如，企业客户希望充分利用S32G3处理器独特的车辆场景功能，而风河的实时产品阵容以及久经验证的嵌入式专业知识都将在相应的软件支持平台上助力汽车解决方案的设计与构建。
以上都是风河与NXP长期合作伙伴关系的基本组成部分，双方将共同致力于为嵌入式行业提供成熟可靠的硬件和软件解决方案。两家公司密切合作，其系统化效益就是形成了紧密集成的解决方案，获得更高的开发人员生产力、更佳的成本效率，还有更高的可靠性以及更快的上市速度。
无论您属于哪个行业，无论您的企业正在为智能边缘创建什么样的系统或设备，风河广泛的软件产品阵容和DevOps成套工具都可以帮助您充分发挥NXP硬件潜能，加速您的项目进程。以下是风河为NXP客户提供支持的几个典型代表：
 BSP 支持：风河为NXP系列处理器提供众多BSP，包括S32G、I.MX和Layerscape系列。 NXP LINUX SDK支持：针对NXP基于Yocto的Linux软件开发工具包，Wind River Studio Linux Services提供安全扫描、漏洞缓解和补救以及全生命周期管理和维护服务。 汽车解决方案：VxWorks和Wind River Linux为汽车网关、域和区域控制器提供高性能实时解决方案。在运行Linux或Android的i.MX应用处理器上构建信息娱乐解决方案方面，风河也拥有丰富的经验。 工业、医疗和机器人解决方案：风河拥有大量的NXP BSP ，非常适合用于关键基础设施、医疗和机器人的设计，因为它们都需要依赖于VxWorks的实时和确定性或Wind River Linux的开源灵活性。风河还为多个i.MX应用处理器提供VxWorks和Wind River Linux BSP，包括最新的i.MX x 93以及Helix Virtualization Platform虚拟化平台。 航空航天和国防解决方案：凡是需要安全认证的嵌入式设计都将得益于我们对NXP处理器的支持，从传统的Power架构到最新的Arm架构解决方案，如LX2160。借助于我们的Helix Virtualization Platform虚拟化平台和VxWorks和Wind River Linux的BSP，可以将NXP解决方案作为当今许多飞行系统的基石。 面向NXP平台的数字孪生和模拟仿真：帮助测试前移且提前启动软件项目并更快地推进开发工作，更快地构建更高质量且更安全的软件系统，并与DevOps开发实践完全集成。模拟仿真基于NXP硬件和软件的完整系统，支持ARM和PowerPC架构。 风河与NXP合作的广度和深度以及对最新产品的支持，都将为企业客户带来了巨大的价值，例如简化整个团队的开发流程以及加快产品上市速度。我们期待在S32G3上看到令人兴奋的新产品。  原文连接 VxWorks俱乐部  
]]></content>
  </entry>
  
  <entry>
    <title>Linux中pdf转word的工具你知道几个</title>
    <url>/post/linux/five-tools-to-convert-pdf-to-word-in-linux.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>PDF</tag>
      <tag>Word</tag>
    </tags>
    <content type="html"><![CDATA[下面推荐5款Linux中pdf转word的工具
LibreOffice LibreOffice是一个免费的开源Office套件，可以将PDF文件转换为Word文档。
# 安装LibreOffice sudo apt-get install libreoffice # 将PDF转换为Word文档 libreoffice --convert-to docx filename.pdf 其中，“docx”表示要将PDF转换为的输出格式，“filename.pdf”是要转换的PDF文件的文件名。该工具可以在Linux系统中使用，并且命令简单易用。
Pdf2doc Pdf2doc是一个基于Python的命令行工具，可以将PDF文件转换为Microsoft Word文档。
# 安装Pdf2doc sudo apt-get install pdf2doc # 将PDF转换为Word文档 pdf2doc filename.pdf 在这个命令中，“filename.pdf”是要转换的PDF文件的文件名。该工具可以在Linux中使用，只需在终端输入相应的命令即可。
GImageReader GImageReader是一款免费的OCR（光学字符识别）软件，可以将扫描的PDF文件转换为Word文档。
# 安装GImageReader sudo apt-get install gimagereader # 将PDF转换为Word文档 gimagereader filename.pdf 在这个命令中，“filename.pdf”是要转换的PDF文件的文件名。该工具支持多种语言的OCR识别，可以在Linux中使用。
Pandoc Pandoc是一个跨平台的文档格式转换器，支持将PDF文件转换为Word文档。
# 安装Pandoc sudo apt-get install pandoc # 将PDF转换为Word文档 pandoc -s -o output.docx input.pdf 在这个命令中，“-s”表示生成带有样式的Word文档，“-o”后面跟输出文件的名称和保存的路径，“input.pdf”是要转换的PDF文件的文件名。该工具可以在Linux中进行使用。
Unoconv Unoconv是一个用于文件格式转换的Python包，可以将PDF文件转换为Word文档。
# 安装Unoconv sudo apt-get install unoconv # 将PDF转换为Word文档 unoconv -f docx filename.pdf 在这个命令中，“docx”表示要将PDF文件转换成的输出格式，“filename.pdf”表明要转换的PDF文件的文件名。这个工具也非常简单易用。
总结：以上是5个将PDF文件转换为Word文档的Linux工具，它们都是免费的工具，不需要任何商业版本。这些工具均可以在Linux平台上使用，并且可以快速并且容易地将PDF文件转换为Word文档。
]]></content>
  </entry>
  
  <entry>
    <title>Linux系统内核概述</title>
    <url>/post/linux/linux-kernel-overview.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Kernel</tag>
    </tags>
    <content type="html"><![CDATA[Linux 内核是一种开源的类 Unix 操作系统宏内核。
Linux 内核是 Linux 操作系统的主要组件，也是计算机硬件与其进程之间的核心接口。它负责两者之间的通信，还要尽可能高效地管理资源。之所以称为内核，是因为它在操作系统中就像果实硬壳中的种子一样，并且控制着硬件的所有主要功能。内核的用途主要有以下 4 项工作：
  内存管理：追踪记录有多少内存存储了什么以及存储在哪里
  进程管理：确定哪些进程可以使用中央处理器、何时使用以及持续多长时间
  设备驱动程序：充当硬件与进程之间的调解程序/解释程序
  系统调用和安全防护：从流程接受服务请求
  在正确实施的情况下，内核对于用户是不可见的，它在自己的小世界(称为内核空间)中工作，并从中分配内存和跟踪所有内容的存储位置。用户所看到的内容则被称为用户空间。这些应用通过系统调用接口(SCI)与内核进行交互。
内核简介 单内核体系设计、但充分借鉴了微内核设计体系的优点，为内核引入模块化机制。
Linux 内核的重要组成部分，主要有以下几部分：
kernel内核核心，一般为 bzImage通常在 /boot 目录下，名称为 vmlinuz-VERSION-RELEASE kernel object内核对象，一般放置于 /lib/modules/VERSION-RELEASE/[ ] ==&gt; N ==&gt; 不编译进内核[M] ==&gt; M ==&gt; 编译为模块文件[*] ==&gt; Y ==&gt; 编译进内核 辅助文件(ramdisk)initrdinitramfs 内核模块 uname 命令 使用格式 uname [OPTION]&hellip;
参数解释  -n 显示节点名称 -r 显示VERSION-RELEASE -s 内核名称 -v 内核版本 -n 节点名 -m 硬件名称 -i 硬件平台 -p 处理器类型 -o 操作系统  # uname -m i686 # uname -r 2.6.32-573.22.1.el6.i686 # uname -a Linux MyServer 2.6.32-573.22.1.el6.i686 ... i686 i386 GNU/Linux lsmod 命令 显示由核心已经装载的内核模块
命令定义 显示的内容来自于: /proc/modules 文件。
使用 lsmod 命令时，常会采用类似 lsmod | grep -i ext4 这样的命令来查询系统是否加载了某些模块。
# cat /proc/modules iptable_filter 2173 0 - Live 0xed9b2000 ip_tables 9567 1 iptable_filter, Live 0xed9a9000 ext3 203718 1 - Live 0xed962000 jbd 65315 1 ext3, Live 0xed904000 xenfs 4360 1 - Live 0xed8e6000 ipv6 271097 14 - Live 0xed88e000 xen_netfront 15871 0 - Live 0xed7d9000 ext4 339812 2 - Live 0xed764000 jbd2 75927 1 ext4, Live 0xed6d9000 mbcache 6017 2 ext3,ext4, Live 0xed6b7000 xen_blkfront 19209 5 - Live 0xed69f000 dm_mirror 11969 0 - Live 0xed68d000 dm_region_hash 9644 1 dm_mirror, Live 0xed67e000 dm_log 8322 2 dm_mirror,dm_region_hash, Live 0xed672000 dm_mod 84711 11 dm_mirror,dm_log, Live 0xed64e000 # lsmod | grep ext4 ext4 339812 2 jbd2 75927 1 ext4 mbcache 6017 2 ext3,ext4 字段含义  第 1 列：表示模块的名称 第 2 列：表示模块的大小 第 3 列：表示依赖模块的个数 第 4 列：表示依赖模块的内容  # lsmod Module Size Used by iptable_filter 2173 0 ip_tables 9567 1 iptable_filter ext3 203718 1 jbd 65315 1 ext3 xenfs 4360 1 ipv6 271097 14 xen_netfront 15871 0 ext4 339812 2 jbd2 75927 1 ext4 mbcache 6017 2 ext3,ext4 xen_blkfront 19209 5 dm_mirror 11969 0 dm_region_hash 9644 1 dm_mirror dm_log 8322 2 dm_mirror,dm_region_hash dm_mod 84711 11 dm_mirror,dm_log modinfo 命令 显示模块的详细描述信息
命令定义 modinfo 列出 Linux 内核中命令行指定的模块的信息。
modinfo 能够查询系统中未安装的模块信息。
若模块名不是一个文件名，则会在 /lib/modules/version 目录中搜索，就像 modprobe 一样。
modinfo 默认情况下，为了便于阅读，以下面的格式列出模块的每个属性：fieldname : value。
语法 modinfo [选项] [ modulename|filename&hellip; ]
选项  -n 只显示模块文件路径 -p 显示模块参数 -a author -d description -l license -0 使用’\0’字符分隔 field 值，而不是一个新行，对脚本比较有用  实战演示 # modinfo ext4 filename: /lib/modules/2.6.32-573.22.1.el6.i686/kernel/fs/ext4/ext4.ko license: GPL description: Fourth Extended Filesystem author: Remy Card, Stephen Tweedie, Andrew Morton, Andreas Dilger, Theodore and others srcversion: CB1B990F5A758DFB0FB12F1 depends: mbcache,jbd2 vermagic: 2.6.32-573.22.1.el6.i686 SMP mod_unload modversions 686 # modinfo btrfs filename: /lib/modules/2.6.32-573.22.1.el6.i686/kernel/fs/btrfs/btrfs.ko license: GPL alias: devname:btrfs-control alias: char-major-10-234 srcversion: B412C18B0F5BF7F1B3C941A depends: libcrc32c,zlib_deflate,lzo_compress,lzo_decompress vermagic: 2.6.32-573.22.1.el6.i686 SMP mod_unload modversions 686 modprobe 命令 装载或卸载内核模块
命令定义 配置文件/etc/modprobe.conf/etc/modprobe.d/*.conf
解决依赖modprobe需要一个最新的modules.dep文件，可以用depmod来生成该文件列出了每一个模块需要的其他模块，modprobe使用这个去自动添加或删除模块的依赖
bash # modules.dep为解决依赖的配置文件，modules.dep.bin二进制文件运行 # ls /lib/modules/2.6.32-358.6.1.el6.i686/ build modules.block modules.ieee1394map modules.ofmap modules.symbols.bin weak-updates extra modules.ccwmap modules.inputmap modules.order modules.usbmap kernel modules.dep modules.isapnpmap modules.pcimap source modules.alias modules.dep.bin modules.modesetting modules.seriomap updates modules.alias.bin modules.drm modules.networking modules.symbols vdso 语法 modprobe [ -c ]
modprobe [ -l ] [ -t dirname ] [ wildcard ]
modprobe [ -r ] [ -v ] [ -n ] [ -i ] [ modulename … ]
选项  -v显示程序在干什么，通常在出问题的情况下，modprobe 才显示信息 -C重载，默认配置文件(/etc/modprobe.conf 或 /etc/modprobe.d) -c输出配置文件并退出 -n可以和 -v 选项一起使用，调试非常有用 -i该选项会使得 modprobe 忽略配置文件中的，在命令行上输入的 install 和 remove -q一般 modprobe 删除或插入一个模块时，若没有找到会提示错误。使用该选项，会忽略指定的模块，并不提示任何错误信息。 -r该选项会导致 modprobe 去删除，而不是插入一个模块通常没有没有理由去删除内核模块，除非是一些有 bug 的模块 -f使用该选项是比较危险的和同时使用 –force-vermagic，–force-modversion 一样 -l列出所有模块 -a插入所有命令行中的模块 -t强制 -l 显示 dirname 中的模块 -s错误信息写入 syslog  depmod 命令 内核模块依赖关系文件及系统信息映射文件的生成工具
语法 depmod [-adeisvV][-m &lt;文件&gt;][&ndash;help][模块名称]
参数  -a 分析所有可用的模块 -d 执行排错模式 -e 输出无法参照的符号 -i 不检查符号表的版本 -m&lt;文件&gt; 使用指定的符号表文件 -s 在系统记录中记录错误 -v 执行时显示详细的信息 -V 显示版本信息 &ndash;help 显示帮助  insmod 和 rmmod 命令 装载或卸载内核模块
不解决依赖关系，需要自己手动卸载
insmod命令 向 Linux 内核中插入一个模块
insmod 是一个向内核插入模块的小程序
大多数用户使用 modprobe 因为它比较智能化
insmod [ filename ] [ module options&hellip; ]
rmmod命令 命令解析删除内核中的一模块rmmod 是一个可以从内核中删除模块的小程序，大多数用户使用modprobe -r去删除模块
语法格式rmmod [ modulename ]
参数选项-f除非编译内核时 CONFIG_MODULE_FORCE_UNLOAD 被设置该命令才有效果，否则没效果用该选项可以删除正在被使用的模块，设计为不能删除的模块，或者标记为 unsafe 的模块-wrmmod 拒绝删除正在被使用的模块使用该选项后，指定的模块会被孤立起来，直到不被使用-s将错误信息写入 syslog，而不是标准错误(stderr)
/proc 目录 内核把自己内部状态信息及统计信息，以及可配置参数通过 proc 伪文件系统加以输出。
# ls /proc/ 1 1173 22 29855 35 47 60 973 filesystems loadavg scsi version 10 12 23 3 36 48 600 buddyinfo fs locks self vmallocinfo 1071 13 232 30 37 49 61 bus interrupts mdstat slabinfo vmstat 1082 14 234 31 38 5 62 cgroups iomem meminfo softirqs xen 1085 15 24 31314 39 528 7 cmdline ioports misc stat zoneinfo 11 16 25 317 4 531 739 cpuinfo irq modules swaps 1150 17 252 318 40 543 8 crypto kallsyms mounts sys 1162 18 253 32 41 56 808 devices kcore mtd sysrq-trigger 1163 19 26 320 42 566 830 diskstats keys net sysvipc 1165 1908 27 33 43 567 853 dma key-users pagetypeinfo timer_list 1167 2 28 330 44 57 9 driver kmsg partitions timer_stats 1169 20 29 334 45 59 94 execdomains kpagecount sched_debug tty 1171 21 29853 34 46 6 95 fb kpageflags schedstat uptime sysctl 命令 语法格式 sysctl(选项)(参数)
命令参数  -n 打印值时不打印关键字 -e 忽略未知关键字错误 -N 仅打印名称 -w 当改变 sysctl 设置时使用此项 -p 从配置文件 /etc/sysctl.conf 加载内核参数设置 -a 打印当前所有可用的内核参数变量和值 -A 以表格方式打印当前所有可用的内核参数变量和值  默认配置文件 /etc/sysctl.conf
命令使用方式 (1) 设置某参数sysctl -w parameter=VALUE (2) 通过读取配置文件设置参数sysctl -p [/path/to/conf_file]
参数说明 只读：输出信息
可写：可接受用户指定“新值”来实现对内核某功能或特性的配置/proc/sys
两种修改方式 (1) sysctl 命令用于查看或设定此目录中诸多参数sysctl -w path.to.parameter=VALUEsysctl -w kernel.hostname=mail.escapelife.com
(2) echo 命令通过重定向的方式也可以修改大多数参数的值echo &ldquo;VALUE&rdquo; &gt; /proc/sys/path/to/parameterecho &ldquo; www.escapelife.com  &rdquo; &gt; /proc/sys/kernel/hostname
配置文件中常用的几个参数
net.ipv4.ip_forward /proc/sys/net/ipv4/ip_forward vm.drop_caches /proc/sys/vm/drop_caches kernel.hostname /proc/sys/kernel/hostname 修改配置文件 # cat /etc/sysctl.conf # Kernel sysctl configuration file for Red Hat Linux # Controls IP packet forwarding net.ipv4.ip_forward = 0 # Controls source route verification net.ipv4.conf.default.rp_filter = 1 # Do not accept source routing net.ipv4.conf.default.accept_source_route = 0 # Controls the System Request debugging functionality of the kernel kernel.sysrq = 0 # Controls whether core dumps will append the PID to the core filename. # Useful for debugging multi-threaded applications. kernel.core_uses_pid = 1 # Controls the use of TCP syncookies net.ipv4.tcp_syncookies = 1 # Disable netfilter on bridges. net.bridge.bridge-nf-call-ip6tables = 0 net.bridge.bridge-nf-call-iptables = 0 net.bridge.bridge-nf-call-arptables = 0 # Controls the default maxmimum size of a mesage queue kernel.msgmnb = 65536 # Controls the maximum size of a message, in bytes kernel.msgmax = 65536 # Controls the maximum shared segment size, in bytes kernel.shmmax = 4294967295 # Controls the maximum number of shared memory segments, in pages kernel.shmall = 268435456 # Auto-enabled by xs-tools:install.sh net.ipv4.conf.all.arp_notify = 1 实战演示 # 查看所有可读变量 sysctl -a # 修改对应参数 sysctl -w kernel.sysrq=0 sysctl -w kernel.core_uses_pid=1 sysctl -w net.ipv4.conf.default.accept_redirects=0 # 如果希望屏蔽别人 ping 你的主机，配置文件修改 net.ipv4.icmp_echo_ignore_all = 1 # 编辑完成后，请执行以下命令使变动立即生效 /sbin/sysctl -p /sbin/sysctl -w net.ipv4.route.flush=1 /sys 目录 sysfs 伪文件系统，输出内核识别出的各硬件设备的相关属性信息，也有内核对硬件特性的设定信息。有些参数是可以修改的，用于调整硬件工作特性。
udev  udev 是运行用户空间程序。 udev 通 /sys/ 路径下输出的信息动态为各设备创建所需要设备文件。 udev 是 Linux 内核的设备管理器，它取代了 udevadmin 和 hotplug，负责管理 /dev 中的设备节点。 udev 也处理所有用户空间发生的硬件添加、删除事件，以及某些特定设备所需的固件加载。 udev 为设备创建设备文件时，会读取其事先定义好的规则文件，一般在 /etc/udev/rules.d 及 /usr/lib/udev/rules.d 目录下。  ramdisk 文件的制作 方法一 mkinitrd 命令
为当前正在使用的内核重新制作 ramdisk 文件
mkinitrd /boot/initramfs-$(uname -r).img $(uname -r)
# 移动ramdisk文件到/root目录下 mv /boot/initramfs-2.6.32...img /root # 为当前正在使用的内核重新制作ramdisk文件 mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) 方法二 dracut 命令
为当前正在使用的内核重新制作 ramdisk 文件
dracut /boot/initramfs-$(uname -r).img $(uname -r)
# 移动ramdisk文件到/root目录下 mv /boot/initramfs-2.6.32...img /root # 为当前正在使用的内核重新制作ramdisk文件 dracut /boot/initramfs-$(uname -r).img $(uname -r) 查看 ramdisk # 使用file命令查看ramdisk文件发现是以gz压缩存放的 file /boot/initramfs-2.6.32-504.el6.x86_64.img # 改名称，解压 cd /boot/ mv initramfs-2.6.32-504.el6.x86_64.img initramfs-2.6.32-504.el6.x86_64.img.gz gzip -d initramfs-2.6.32-504.el6.x86_64.img.gz # 使用file命令查看发现是以cpio存放的文本文件 file initramfs-2.6.32-504.el6.x86_64.img # 解压这个文本文件 # 之后会在initrd目录下生成相应的文件，一个微型的/root mkdir initrd cd initrd cpio -id &lt; ../initramfs-2.6.32-504.el6.x86_64.img # 这个时候就可以查看init脚本文件了 cat init # 在sbin文件中存放着相关的命令 ls sbin 编译内核 前提准备 (1) 准备好开发环境
包组(CentOS 6)
Server Platform Development
Development Tools
(2) 获取目标主机上硬件设备的相关信息
CPUcat /proc/cpuinfox86info -alscpu
PCI 设备lspci-v-vvlsusb-v-vvlsblk
了解全部硬件设备信息hal-device
(3) 获取到目标主机系统功能的相关信息
(4) 获取内核源代码包
 www.kernel.org  
简易安装内核 简易安装 获取当前系统的安装文件作为模块安装较为方便
修改相应的参数即可
只适用于当前特定的内核版本
当前系统的安装文件在 config-2.6.32-504.el6.x86_64
简单依据模板文件的制作内核 # 下载对应的Linux内核版本进行解压缩 # 会在/usr/src目录下创建debug、kernels和linux-3.10.67目录 tar xf linux-3.10.67.tar.xz -C /usr/src # 为了方便多内核共存，使用连接指向 # 会在当前目录下创建一个链接文件 linux -&gt; linux-3.10.67 cd /usr/src ln -sv linux-3.10.67 linux # 创建模板 cd linux # 查看链接指向的文件内容 ls # 拷贝系统自带的模板文件 cp /boot/config-$(uname -r) .config # 打开图形界面配置内核选项，选择添加、删除内核模块 # 添加的默认选项来自.config配置文件 make menuconfig # 使用screen来不中断安装 screen # 采用几个线程进行编译 make -j n # 安装内核 make modules_install # make install中将会安装内容 # 安装bzImage为/boot/vmlinuz-VERSION-RELEASE # 生成initramfs文件 # 编辑grub的配置文件 make install # 重启系统，并测试使用新内核，不是默认启动内核 init 6 详解编译内核 (1) 配置内核选项 支持“更新”模式进行配置  (a) make config：基于命令行以遍历的方式去配置内核中可配置的每个选项 (b) make menuconfig：基于 curses 的文本窗口界面 (c) make gconfig：基于 GTK 开发环境的窗口界面 (d) make xconfig：基于 Qt 开发环境的窗口界面  支持“全新配置”模式进行配置  (a) make defconfig：基于内核为目标平台提供的“默认”配置进行配置 (b) make allnoconfig: 所有选项均回答为”no“  (2) 编译 - make [-j #] 如何只编译内核中的一部分功能
# (a)只编译某子目录中的相关代码 cd /usr/src/linux make dir/ # (b)只编译一个特定的模块 cd /usr/src/linux make dir/file.ko # 例如：只为e1000编译驱动 make drivers/net/ethernet/intel/e1000/e1000.ko 如何交叉编译内核
# 编译的目标平台与当前平台不相同； make ARCH=arch_name # 要获取特定目标平台的使用帮助 make ARCH=arch_name help 如何在已经执行过编译操作的内核源码树做重新编译
# 事先清理操作 # 清理大多数编译生成的文件，但会保留config文件等 make clean # 清理所有编译生成的文件、config及某些备份文件 make mrproper # mrproper、patches以及编辑器备份文件 make distclean ]]></content>
  </entry>
  
  <entry>
    <title>如何在 Linux 使用 pv 命令监控数据传输速度与进度</title>
    <url>/post/linux/using-pv-cmd-to-monitor-data-transfer-speed-and-progress.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>pv</tag>
    </tags>
    <content type="html"><![CDATA[pv 命令是一个在 Linux/Unix 系统的实用工具，用于监控数据的流动。pv 命令可以用于计算数据传输的速度，显示进度条以及估算剩余时间等。
pv命令可以通过管道监控数据流的进度，但是无法直接监控mv命令的进度。这是因为mv命令实际上是将文件从一个位置移动到另一个位置，而不是在管道中传输数据。
默认情况下，pv 命令只会显示一个进度条，以及传输速度和估算的剩余时间等信息。除了默认的进度条外，pv 命令还支持许多选项。
在本教程中，我们将会说明如何在 Linux 使用 pv 命令监控数据的传输速度并估算剩余时间等信息。
pv 命令 pv 命令的使用非常简单，只需在终端输入 pv 命令，后面是需要监视的文件或数据流即可。
pv file.txt &gt; /dev/null pv 命令选项 这些选项可以用于更好地控制 pv 命令的输出。下面是一些常用的选项：
 -f，&ndash;force：  强制 pv 命令执行，即使标准错误不是终端也输出。
 -n，&ndash;numeric：  显示数字的百分比和速度而不是进度条。
 -q，&ndash;quiet：  不输出错误和警告信息。
 -s，&ndash;size SIZE：  指定输入流的大小。
 -t，&ndash;timer：  显示时间估计。
 -h，&ndash;help：  显示 pv 命令的帮助信息。
 -V，&ndash;version：  显示 pv 命令的版本信息。
下面是一些使用pv命令的示例：
监控文件传输 在这个示例中，pv 命令将 file.txt 文件的内容输出到 /dev/null 空设备中，这是一个类似于垃圾桶的设备，只可写入但无法读取的设备。
可以将其用于丢弃不需要的输出。pv 命令会计算 file.txt 文件的大小并显示一个进度条，以及估算剩余时间和传输速度等信息。
pv file.txt &gt; /dev/null 监控标准输入流向标准输出的数据 在这个示例中，pv 命令将 file.txt 文件的内容通过管道传递给 gzip 命令进行压缩，然后将压缩后的数据写入到 file.txt.gz文件。
pv 命令会监控管道中的数据流，并显示一个进度条，以及估算剩余时间和传输速度等信息。
cat file.txt | pv | gzip &gt; file.txt.gz 评估数据传输时间 在这个示例中，pv 命令将 iso 镜像文件的内容通过管道传递给 dd 命令进行写入，pv命令会计算 iso 文件的大小并显示一个进度条，以及估算剩余时间和传输速度等信息。
pv -pteb file.iso | dd of=/dev/sdb 使用场景 以上示例只是 pv 命令的基本用法，但实际上，pv 命令可以在许多场景中发挥重要的作用。例如，在备份文件或复制大量文件时，pv 命令可以帮助用户跟踪数据的传输速度和进度，以及估算剩余时间。
对于网络传输或云存储等场景中，pv 命令可以帮助用户监视数据流，确保传输的可靠性和效率。
此外，在编写脚本或命令行工具时，pv 命令也可以用于监视数据流并提供更好的用户体验。
除了以上介绍的选项和示例外，pv 命令还具有许多其他功能。例如，pv 命令可以与其他命令和工具结合使用，如tar、rsync、scp等，实现更复杂的数据传输和备份操作。此外，pv 命令还支持在终端显示颜色，以便用户更容易地识别不同类型的信息。
限制 需要注意的是，pv 命令虽然非常实用，但也有一些局限性。首先，pv 命令只能监控单个数据流，而不能同时监控多个数据流。其次，pv 命令无法解密加密的数据流，因此无法直接监视加密的数据流。
最后，pv 命令会消耗一定的 CPU 资源和内存，因此在处理大文件或大量数据时，可能会对系统性能产生一定的影响。
总的来说，pv 命令是一个非常实用的 Linux/Unix 工具，可以帮助用户监控数据流，计算传输速度和估算剩余时间等信息。
通过结合不同的选项和示例，用户可以充分利用 pv 命令的功能，以更好地管理和监视数据传输和备份操作。
如果您有任何问题或反馈，请随时发表评论。点击下方阅读原文获取更好排版格式与文章参考引用。
]]></content>
  </entry>
  
  <entry>
    <title>关于extern C的的详细剖析</title>
    <url>/post/programming/extern-c-detailed-analysis.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>extern</tag>
    </tags>
    <content type="html"><![CDATA[在你工作过的系统里，不知能否看到类似下面的代码。
这好像没有什么问题，你应该还会想 “嗯，是啊，我们的代码都是这样写的，从来没有因此碰到过什么麻烦啊～”。
你说的没错，如果你的头文件从来没有被任何C++程序引用过的话。
这与C++有什么关系呢? 看看__cplusplus（注意前面是两个下划线）的名字你就应该知道它与C++有很大关系。__cplusplus是一个C++规范规定的预定义宏。你可以信任的是：所有的现代C++编译器都预先定义了它；而所有C语言编译器则不会。另外，按照规范__cplusplus的值应该等于1 9 9 7 1 1 L ，然而不是所有的编译器都照此实现，比如g++编译器就将它的值定义为1。
所以，如果上述代码被C语言程序引用的话，它的内容就等价于下列代码。
在这种情况下，既然extern &ldquo;C&rdquo; { }经过预处理之后根本就不存在，那么它和#include指令之间的关系问题自然也就是无中生有。
extern &ldquo;C&quot;的前世今生 在C++编译器里，有一位暗黑破坏神，专门从事一份称作“名字粉碎”(name mangling)的工作。当把一个C++的源文件投入编译的时候，它就开始工作，把每一个它在源文件里看到的外部可见的名字粉碎的面目全非，然后存储到二进制目标文件的符号表里。
之所以在C++的世界里存在这样一个怪物，是因为C++允许对一个名字给予不同的定义，只要在语义上没有二义性就好。比如，你可以让两个函数是同名的，只要它们的参数列表不同即可，这就是函数重载(function overloading)；甚至，你可以让两个函数的原型声明是完全相同的，只要它们所处的名字空间(namespace)不一样即可。事实上，当处于不同的名字空间时，所有的名字都是可以重复的，无论是函数名，变量名，还是类型名。
另外，C++程序的构造方式仍然继承了C语言的传统：编译器把每一个通过命令行指定的源代码文件看做一个独立的编译单元，生成目标文件；然后，链接器通过查找这些目标文件的符号表将它们链接在一起生成可执行程序。
编译和链接是两个阶段的事情；事实上，编译器和链接器是两个完全独立的工具。编译器可以通过语义分析知道那些同名的符号之间的差别；而链接器却只能通过目标文件符号表中保存的名字来识别对象。
所以，编译器进行名字粉碎的目的是为了让链接器在工作的时候不陷入困惑，将所有名字重新编码，生成全局唯一，不重复的新名字，让链接器能够准确识别每个名字所对应的对象。
但 C语言却是一门单一名字空间的语言，也不允许函数重载，也就是说，在一个编译和链接的范围之内，C语言不允许存在同名对象。比如，在一个编译单元内部，不允许存在同名的函数，无论这个函数是否用static修饰；在一个可执行程序对应的所有目标文件里，不允许存在同名对象，无论它代表一个全局变量，还是一个函数。所以，C语言编译器不需要对任何名字进行复杂的处理（或者仅仅对名字进行简单一致的修饰（decoration），比如在名字前面统一的加上单下划线_）。
C++的缔造者Bjarne Stroustrup在最初就把——能够兼容C，能够复用大量已经存在的C库——列为C++语言的重要目标。但两种语言的编译器对待名字的处理方式是不一致的，这就给链接过程带来了麻烦。
例如，现有一个名为my_handle.h的头文件，内容如下：
然后使用C语言编译器编译my_handle.c，生成目标文件my_handle.o。
由于C语言编译器不对名字进行粉碎，所以在my_handle.o的符号表里，这三个函数的名字和源代码文件中的声明是一致的。
随后，我们想让一个C++程序调用这些函数，所以，它也包含了头文件my_handle.h。
假设这个C++源代码文件的名字叫my_handle_client.cpp，其内容如下：
其中，粗体的部分就是那三个函数的名字被粉碎后的样子。
然后，为了让程序可以工作，你必须将my_handle.o和my_handle_client.o放在一起链接。由于在两个目标文件对于同一对象的命名不一样，链接器将报告相关的“符号未定义”错误。
为了解决这一问题，C++引入了链接规范(linkage specification)的概念，表示法为extern&quot;language string&rdquo;，C++编译器普遍支持的&quot;language string&quot;有&quot;C&quot;和&quot;C++&quot;，分别对应C语言和C++语言。
链接规范的作用是告诉C++编译：对于所有使用了链接规范进行修饰的声明或定义，应该按照指定语言的方式来处理，比如名字，调用习惯（calling convention）等等。
链接规范的用法有两种：  单个声明的链接规范，比如：  extern &#34;C&#34; void foo(); 一组声明的链接规范，比如：  extern &#34;C&#34; { void foo(); int bar(); } 对我们之前的例子而言，如果我们把头文件my_handle.h的内容改成：
然后使用C++编译器重新编译my_handle_client.cpp，所生成目标文件my_handle_client.o中的符号表就变为：
从中我们可以看出，此时，用extern &ldquo;C&rdquo; 修饰了的声明，其生成的符号和C语言编译器生成的符号保持了一致。这样，当你再次把my_handle.o和my_handle_client.o放在一起链接的时候，就不会再有之前的“符号未定义”错误了。
但此时，如果你重新编译my_handle.c，C语言编译器将会报告“语法错误”，因为extern&quot;C&quot;是C++的语法，C语言编译器不认识它。此时，可以按照我们之前已经讨论的，使用宏__cplusplus来识别C和C++编译器。修改后的my_handle.h的代码如下：
小心门后的未知世界 在我们清楚了 extern &ldquo;C&rdquo; 的来历和用途之后，回到我们本来的话题上，为什么不能把#include 指令放置在 extern &ldquo;C&rdquo; { &hellip; } 里面？
我们先来看一个例子，现有a.h，b.h，c.h以及foo.cpp，其中foo.cpp包含c.h，c.h包含b.h，b.h包含a.h，如下：
现使用C++编译器的预处理选项来编译foo.cpp，得到下面的结果：
正如你看到的，当你把#include指令放置在extern &ldquo;C&rdquo; { }里的时候，则会造成extern &ldquo;C&rdquo; { } 的嵌套。这种嵌套是被C++规范允许的。当嵌套发生时，以最内层的嵌套为准。比如在下面代码中，函数foo会使用C++的链接规范，而函数bar则会使用C的链接规范。
如果能够保证一个C语言头文件直接或间接依赖的所有头文件也都是C语言的，那么按照C++语言规范，这种嵌套应该不会有什么问题。
但具体到某些编译器的实现，比如MSVC2005，却可能由于 extern &ldquo;C&rdquo; { } 的嵌套过深而报告错误。
不要因此而责备微软，因为就这个问题而言，这种嵌套是毫无意义的。你完全可以通过把#include指令放置在extern &ldquo;C&rdquo; { }的外面来避免嵌套。
拿之前的例子来说，如果我们把各个头文件的 #include 指令都移到extern &ldquo;C&rdquo; { } 之外，然后使用C++编译器的预处理选项来编译foo.cpp，就会得到下面的结果：
这样的结果肯定不会引起编译问题的结果——即便是使用MSVC。
把 #include 指令放置在extern &ldquo;C&rdquo; { }里面的另外一个重大风险是，你可能会无意中改变一个函数声明的链接规范。比如：有两个头文件a.h，b.h，其中b.h包含a.h，如下：
按照a.h作者的本意，函数foo是一个C++自由函数，其链接规范为&quot;C++&quot;。但在b.h中，由于#include &ldquo;a.h&quot;被放到了extern &ldquo;C&rdquo; { }的内部，函数foo的链接规范被不正确地更改了。
由于每一条 #include 指令后面都隐藏这一个未知的世界，除非你刻意去探索，否则你永远都不知道，当你把一条条#include指令放置于extern &ldquo;C&rdquo; { }里面的时候，到底会产生怎样的结果，会带来何种的风险。
或许你会说，“我可以去查看这些被包含的头文件，我可以保证它们不会带来麻烦”。但，何必呢？毕竟，我们完全可以不必为不必要的事情买单，不是吗？
Q &amp; A Q: 难道任何# i n c l u d e指令都不能放在e x t e r n &ldquo;C&quot;里面吗？
A: 正像这个世界的大多数规则一样，总会存在特殊情况。
有时候，你可能利用头文件机制“巧妙”的解决一些问题。比如，#pragma pack的问题。这些头文件和常规的头文件作用是不一样的，它们里面不会放置C的函数声明或者变量定义，链接规范不会对它们的内容产生影响。这种情况下，你可以不必遵守这些规则。
更加一般的原则是，在你明白了这所有的原理之后，只要你明白自己在干什么，那就去做吧。
Q: 你只说了不应该放入e x t e r n &ldquo;C&quot;的，但什么可以放入呢？
A: 链接规范仅仅用于修饰函数和变量，以及函数类型。所以，严格的讲，你只应该把这三种对象放置于extern &ldquo;C&quot;的内部。
但，你把C语言的其它元素，比如非函数类型定义（结构体，枚举等）放入extern &ldquo;C&quot;内部，也不会带来任何影响。更不用说宏定义预处理指令了。
所以，如果你更加看重良好组织和管理的习惯，你应该只在必须使用extern &ldquo;C&quot;声明的地方使用它。即使你比较懒惰，绝大多数情况下，把一个头件自身的所有定义和声明都放置在extern&quot;C&quot;里面也不会有太大的问题。
Q: 如果一个带有函数/变量声明的C头文件里没有e x t e r n &ldquo;C&quot;声明怎么办？
A: 如果你可以判断，这个头文件永远不可能让C++代码来使用，那么就不要管它。
但现实是，大多数情况下，你无法准确的推测未来。你在现在就加上这个extern &ldquo;C&rdquo;，这花不了你多少成本，但如果你现在没有加，等到将来这个头文件无意中被别人的C++程序包含的时候，别人很可能需要更高的成本来定位错误和修复问题。
Q: 如果我的C+ +程序想包含一个C头文件a . h，它的内容包含了C的函数/变量声明，但它们却没有使用e x t e r n &ldquo;C&quot;链接规范，该怎么办？
A: 在a.h里面加上它。
某些人可能会建议你，如果a.h没有extern &ldquo;C&rdquo;，而b.cpp包含了a.h，可以在b.cpp里加上 ：
extern &#34;C&#34; { #include &#34;a.h&#34;} 这是一个邪恶的方案，原因在之前我们已经阐述。但值得探讨的是，这种方案这背后却可能隐含着一个假设，即我们不能修改a.h。不能修改的原因可能来自两个方面：
  头文件代码属于其它团队或者第三方公司，你没有修改代码的权限；
  虽然你拥有修改代码的权限，但由于这个头文件属于遗留系统，冒然修改可能会带来不可预知的问题。
  对 于第一种情况，不要试图自己进行workaround，因为这会给你带来不必要的麻烦。正确的解决方案是，把它当作一个bug，发送缺陷报告给相应的团队 或第三方公司。
如果是自己公司的团队或你已经付费的第三方公司，他们有义务为你进行这样的修改。如果他们不明白这件事情的重要性，告诉他们。如果这些头文 件属于一个免费开源软件，自己进行正确的修改，并发布patch给其开发团队。
在 第二种情况下，你需要抛弃掉这种不必要的安全意识。
因为，首先，对于大多数头文件而言，这种修改都不是一种复杂的，高风险的修改，一切都在可控的范围之 内；
其次，如果某个头文件混乱而复杂，虽然对于遗留系统的哲学应该是：“在它还没有带来麻烦之前不要动它”，但现在麻烦已经来了，逃避不如正视，所以上策 是，将其视作一个可以整理到干净合理状态的良好机会。
Q: 我们代码中关于e x t e r n &ldquo;C&quot;的写法如下，这正确吗?
A: 不确定。
按照C++的规范定义，__cplusplus 的值应该被定义为199711L，这是一个非零的值；尽管某些编译器并没有按照规范来实现，但仍然能够保证__cplusplus的值为非零——至少我到目前为止还没有看到哪款编译器将其实现为0。
这种情况下，#if __cplusplus &hellip; #endif完全是冗余的。
但，C++编译器的厂商是如此之多，没有人可以保证某款编译器，或某款编译器的早期版本没有将__cplusplus的值定义为0。
但即便如此，只要能够保证宏__cplusplus只在C++编译器中被预先定义 ，那么，仅仅使用#ifdef __cplusplus ⋯ #endif就足以确保意图的正确性；额外的使用#if __cplusplus &hellip; #endif反而是错误的。
只有在这种情况下：即某个厂商的C语言和C++语言编译器都预先定义了__cplusplus ，但通过其值为0和非零来进行区分，使用#if __cplusplus &hellip; #endif才是正确且必要的。
既然现实世界是如此复杂，你就需要明确自己的目标，然后根据目标定义相应的策略。比如：如果你的目标是让你的代码能够使用几款主流的、正确遵守了规范的编译器进行编译，那么你只需要简单的使用#ifdef __cplusplus &hellip; #endif就足够了。
但如果你的产品是一个雄心勃勃的，试图兼容各种编译器的（包括未知的）跨平台产品， 我们可能不得不使用下述方法来应对各种情况 ，其中__ALIEN_C_LINKAGE__是为了标识那些在C和C++编译中都定义了__cplusplus宏的编译器。
这应该可以工作，但在每个头文件中都写这么一大串，不仅有碍观瞻，还会造成一旦策略进行修改，就会到处修改的状况。违反了DRY(Don&rsquo;t Repeat Yourself)原则，你总要为之付出额外的代价。解决它的一个简单方案是，定义一个特定的头文件——比如clinkage.h，在其中增加这样的定义：
以下举例中c的函数声明和定义分别在cfun.h 和 cfun.c 中，函数打印字符串 “this is c fun call”，c++函数声明和定义分别在cppfun.h 和 cppfun.cpp中，函数打印字符串 &ldquo;this is cpp fun call&rdquo;, 编译环境vc2010
c++ 调用 c 的方法（关键是要让c的函数按照c的方式编译，而不是c++的方式）
（1） cfun.h如下：
#ifndef _C_FUN_H_ #define _C_FUN_H_  void cfun(); #endif cppfun.cpp 如下：
//#include &#34;cfun.h&#34; 不需要包含cfun.h #include &#34;cppfun.h&#34;#include &lt;iostream&gt;using namespace std; extern &#34;C&#34; void cfun(); //声明为 extern void cfun(); 错误  void cppfun() { cout&lt;&lt;&#34;this is cpp fun call&#34;&lt;&lt;endl; } int main() { cfun(); return 0; } （2）cfun.h同上，cppfun.cpp 如下：
extern &#34;C&#34; { #include &#34;cfun.h&#34;//注意include语句一定要单独占一行;} #include &#34;cppfun.h&#34;#include &lt;iostream&gt;using namespace std; void cppfun() { cout&lt;&lt;&#34;this is cpp fun call&#34;&lt;&lt;endl; } int main() { cfun(); return 0; } （3）cfun.h如下：
#ifndef _C_FUN_H_ #define _C_FUN_H_  #ifdef __cplusplus extern &#34;C&#34; { #endif  void cfun(); #ifdef __cplusplus } #endif  #endif cppfun.cpp如下：
#include &#34;cfun.h&#34;#include &#34;cppfun.h&#34;#include &lt;iostream&gt;using namespace std; void cppfun() { cout&lt;&lt;&#34;this is cpp fun call&#34;&lt;&lt;endl; } int main() { cfun(); return 0; } c调用c++（关键是C++ 提供一个符合 C 调用惯例的函数）
在vs2010上测试时，没有声明什么extern等，只在在cfun.c中包含cppfun.h，然后调用cppfun()也可以编译运行，在gcc下就编译出错，按照c++/c的标准这种做法应该是错误的。以下方法两种编译器都可以运行
cppfun.h如下：
#ifndef _CPP_FUN_H_ #define _CPP_FUN_H_  extern &#34;C&#34; void cppfun(); #endif cfun.c如下：
//#include &#34;cppfun.h&#34; //不要包含头文件，否则编译出错 #include &#34;cfun.h&#34;#include &lt;stdio.h&gt; void cfun() { printf(&#34;this is c fun call\n&#34;); } extern void cppfun(); int main() { #ifdef __cplusplus  cfun(); #endif  cppfun(); return 0; } ]]></content>
  </entry>
  
  <entry>
    <title>风河 Helix 虚拟化平台和 VxWorks 653 提供扩展的安全认证证据支持以加速下一代 A&D 系统的开发</title>
    <url>/post/news/wind-river-helix-virtualization-platform-and-vxWorks-653-deliver-expanded-safety-certification.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Wind River</tag>
      <tag>Helix Virtualization</tag>
      <tag>VxWorks 653</tag>
    </tags>
    <content type="html"><![CDATA[为关键任务智能系统提供软件的全球领导者 Wind River® 今天宣布扩展其行业领先平台的架构支持，以进一步满足高度计算的苛刻需求 - 重型任务关键型应用，特别是那些与航空航天和国防工业相关的应用。
DO-178C DAL A 认证证据现已可用于 Armv8-A 架构的 Wind River Helix™ 虚拟化平台。 最新版本的 VxWorks  ® 653 为 PowerPC 提供更新的 DO-178C DAL A 认证证据。
具有 DO-178C DAL A 证据的 Helix 平台是一个安全认证的多核、多租户平台，支持多个独立的关键级别。 它专为各种关键任务行业用例而设计，例如商业和军事航空电子设备，允许客户运行不安全的软件以及经过最高级别认证的软件，这些软件涉及航空电子设备 (DO-178C)、汽车 (ISO 26262)、工业 ( IEC 61508) 和其他类似标准。 Helix Platform 也符合 ARINC 653 标准，并在最新的硬件平台上提供强大的时间和空间分区，以确保故障遏制以及以最少的测试和集成需求升级应用程序的能力。
VxWorks 653，具有DO-178C DAL A证明，是一个安全可靠的多核、多租户平台，可用于PowerPC架构。 VxWorks 653 也符合 ARINC 653 标准，具有与 Helix 平台相同的稳健性。
“智能边缘的发展为航空航天和国防等行业提出了一系列独特的要求和挑战，包括与认证需求相关的复杂性增加。 随着 Helix 平台和 VxWorks 653 的更新安全认证证据的可用性，我们正在为我们的客户提供更多灵活性和加速创新的机会，以创建下一代安全可靠的多操作系统智能设备，”首席产品 Avijit Sinha 说 军官，风河。
风河技术已在最具挑战性的安全关键型应用中得到验证，使组织能够更轻松、更经济地满足 EN 50128、IEC 61508、ISO 26262、DO-178C 和 ED-12C 的严格安全认证要求。
凭借在 120 多架民用和军用飞机的 880 多个安全项目中得到 400 多家客户验证的技术，风河正在推动航空航天和国防领域向软件定义系统的过渡。
]]></content>
  </entry>
  
  <entry>
    <title>三星电子研发出其首款支持CXL 2.0的CXL DRAM</title>
    <url>/post/news/samsung-develops-first-CXL-DRAM-supporting-CXL-2.0.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Samsung</tag>
      <tag>CXL 2.0</tag>
      <tag>CXL Memory</tag>
    </tags>
    <content type="html"><![CDATA[基于先进CXL 2.0的128GB CXL DRAM将于今年量产，加速下一代存储器解决方案的商用化，三星将继续与全球数据中心、服务器、芯片企业合作，扩大CXL生态系统
三星电子今日宣布，研发出其首款支持Compute Express Link™（CXL™）2.0的128GB DRAM。同时，三星与英特尔密切合作，在英特尔®至强®平台上取得了具有里程碑意义的进展。
继2022年五月，三星电子研发出其首款基于CXL 1.1的CXL DRAM（内存扩展器）后，又继续推出支持CXL 2.0的128GB CXL DRAM，预计将加速下一代存储解决方案的商用化。该解决方案支持PCIe 5.0（x8通道），提供高达每秒35GB的带宽。
三星电子新业务企划副总裁Jangseok Choi表示： 作为CXL联盟的董事会成员，三星电子在CXL技术上一直处于前沿地位，这一突破性的进展强化了我们通过与全球各地的数据中心、企业级服务器和芯片公司合作，进一步扩大CXL生态系统的决心。
英特尔公司技术创新总监Jim Pappas表示： 英特尔很高兴与三星合作，共同投资一个充满活力的CXL生态系统。英特尔将继续与三星携手，促进创新CXL产品在整个行业的发展和采用。
澜起科技总裁Stephen Tai表示： 澜起科技很高兴能够量产第一批支持CXL 2.0的控制器，我们期待与三星继续加强合作，推进CXL技术发展并扩大其生态系统。
CXL 2.0是三星有史以来第一个支持内存池（Pooling）的产品。内存池是一种内存管理技术，它将服务器平台上的多个CXL内存块绑定在一起，形成一个内存池，使多个主机能够根据需要从池中动态分配内存。这项新技术使客户尽可能的降本增效，从而帮助企业将有限的资源重新投资于增强服务器内存中去。
三星电子计划于今年年底之前开始量产这一最新的CXL 2.0 DRAM，并准备推出多种容量的产品，以满足快速变化的下一代计算市场，进一步加速扩大CXL生态系统。
CXL作为下一代，能够为高性能服务器系统中与CPU一起使用的加速器、DRAM和存储设备提高效率。由于它与主内存（main DRAM）共同使用时可扩大带宽和容量，该技术的进步有望在人工智能（AI）和机器学习（ML）等核心技术，对处理高速数据的需求极大增加的下一代计算市场引起轰动。
]]></content>
  </entry>
  
  <entry>
    <title>6个与戈登・摩尔相关的冷知识</title>
    <url>/post/news/6-trivia-about-Gordon-moore.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Intel</tag>
      <tag>Integrated Electronics</tag>
      <tag>Gordon Moore</tag>
    </tags>
    <content type="html"><![CDATA[英特尔的创始人戈登・摩尔于上周五（2023年3月24日）逝世，享年 94 岁，他的一生对计算机科学和半导体工业的发展做出了巨大的贡献。
今天给大家分享6个与戈登・摩尔相关的“冷知识”。
]]></content>
  </entry>
  
  <entry>
    <title>北南南北</title>
    <url>/about.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[北南南北 是众多使用 VxWorks 嵌入式实时操作系统的网友分享经验的平台，为的就是让 VxWorks 的学习和应用变得相对开放一些，在此也欢迎你的加入！
我们的愿景 技术创新是技术持续发展的生命力，紧跟技术的发展趋势，研究最新的技术，保持对新技术的热情和好奇心，让技术为生产和生活服务。
使用反馈  加入 VxWorks Club   或 Google AI TPU     欢迎你的加入
 ]]></content>
  </entry>
  
  <entry>
    <title>友情链接</title>
    <url>/flinks.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
name: VxWorks俱乐部 desc: VxWorks实时操作系统 link: https://www.vxworks.net ]]></content>
  </entry>
  
</search>