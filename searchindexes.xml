<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<search>
  
  <entry>
    <title>Linux 超级漂亮的 Shell</title>
    <url>/post/linux/beautiful-linux-shell.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Shell</tag>
    </tags>
    <content type="html"><![CDATA[Linux/Unix 提供了很多种 Shell，为什么要这么多 Shell？
zsh 介绍 Linux shell 那我问你，你同类型的衣服怎么有那么多件？花色，质地还不一样。写程序比买衣服复杂多了，而且程序员往往负责把复杂的事情搞简单，简单的事情搞复杂。牛程序员看到不爽的 Shell，就会自己重新写一套，慢慢形成了一些标准，常用的 Shell 有这么几种，sh、bash、csh 等，想知道你的系统有几种 shell，可以通过以下命令查看：
cat/etc/shells 显示如下：
zsh 简介 Zsh 是一个 Linux 下强大的 shell, 由于大多数 Linux 产品安装，以及默认使用bash shell, 但是丝毫不影响极客们对 zsh 的热衷, 几乎每一款 Linux 产品都包含有 zsh，通常可以用 apt-get、urpmi 或 yum 等包管理器进行安装
Zsh 具有以下主要功能
 开箱即用、可编程的命令行补全功能可以帮助用户输入各种参数以及选项 在用户启动的所有 shell 中共享命令历史 通过扩展的文件通配符，可以不利用外部命令达到 find 命令一般展开文件名 改进的变量与数组处理 在缓冲区中编辑多行命令 多种兼容模式，例如使用 /bin/sh 运行时可以伪装成 Bourne shell 可以定制呈现形式的提示符；包括在屏幕右端显示信息，并在键入长命令时自动隐藏 可加载的模块，提供其他各种支持：完整的 TCP 与 Unix 域套接字控制，FTP 客户端与扩充过的数学函数 完全可定制化  zsh 与 oh-my-zsh 终极配置 之前是因为看到这篇文章：终极 Shell——Zsh 才选择使用 zsh，被它的自动完成、补全功能吸引了。官网：http://www.zsh.org
选择 oh-my-zsh, oh-my-zsh 是基于 zsh 的功能做了一个扩展，方便的插件管理、主题自定义，以及漂亮的自动完成效果。
在 Github 上找关于 zsh 的项目时发现的，试用了一下觉得很方便，不用像上面文章里面提到的那么复杂，配置一些插件的名称即可使用相应的功能。
官网：https://github.com/robbyrussell/oh-my-zsh
安装 zsh 安装 zsh 对于一般的 Ubuntu 系统，配置好正确的源之后，就能直接键入以下命令安装：
sudo apt-get install zsh 配置 zsh zsh的配置是一门大学问，这里不赘述，直接给出一个配置文件，大家可以下载后放入 zsh 配置文档直接使用。（我的一个法国朋友手配的，相当顺手）
把.zshrc拷贝到相应用户的home目录即可(也可以把你的bash的配置文件(~/.bash_prorile 或者 ~/.profile 等) 给拷贝到zsh的配置文件~/.zshrc里，因为zsh兼容bash)
取代bash，设为默认shell sudo usermod -s /bin/zsh username 或者
chsh -s /bin/zsh chsh -s `whichzsh` 如果要切换回去 bash：
chsh -s /bin/bash 当然你实在不愿意把 zsh 当成默认的 shell, 而又想使用它, 那么你可以每次进入是都使用zsh进入, 而输入exit退出
安装oh-my-zsh 直接用 zsh 会很麻烦，因为 zsh 功能很强大但是太复杂，所以需要 oh-my-zsh 来将它简单化
直接用 git 从 github 上面下载包 git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh 备份已有的 zshrc, 替换 zshrc cp ~/.zshrc ~/.zshrc.orig cp~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 直接使用脚本安装 cd oh-my-zsh/tools ./install.sh 你可以直接直接使用如下命令安装
sh -c &#34;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&#34; sh -c &#34;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&#34; 其本质就是下载并执行了 github 上的 install.sh 脚本, 该脚本位于oh-my-zsh/tools/install.sh
配置主题 oh-my-zsh 集成了大量的主题, 位于oh-my-zsh/theme
配置主题, 可以通过修改~/.zshrc中的环境变量ZSH_THEME来完成
ZSH_THEME=&#34;agnoster&#34; # (this is one of the fanc yones) 如果你觉得主题太多你可以选择使用随机模式, 来由系统随机选择
ZSH_THEME=&#34;random&#34;#(...please let it be pie... please be some pie..) 详细的主题信息, 可以参见 zsh 主题介绍
配置插件 修改～/.zshrc中plugins
plugins=(gitbundlerosxrakeruby)
详细的插件信息, 可以参见 zsh 插件 Plugins 介绍
更新 oh-my-zsh 默认情况下, 您将被提示检查每几周的升级. 如果你想我 ZSH 自动升级本身没有提示你, 修改 ~/.zshrc
disable_update_prompt=true 禁用自动升级, 修改~/.zshrc disable_auto_update=true 当然你也可以选择手动更新 如果你想在任何时间点升级（也许有人刚刚发布了一个新的插件，你不想等待一个星期？) 你只需要运行：
upgrade_oh_my_zsh
卸载 oh-my-zsh 如果你想卸载oh-my-zsh, 只需要执行uninstall_oh_my_zsh zsh， 从命令行运行，这将删除本身和恢复你以前的 bash 或者 zsh 配置。
]]></content>
  </entry>
  
  <entry>
    <title>如何在Linux中搭建DNS服务</title>
    <url>/post/linux/dns-server-configuration-in-linux.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>DNS</tag>
    </tags>
    <content type="html"><![CDATA[要在Linux系统上搭建DNS服务，你可以按照以下步骤进行操作：
安装BIND软件包 sudo yum install bind bind-utils 配置主DNS服务器 打开/etc/named.conf文件，编辑DNS服务器的配置。根据你的域名和网络环境，修改以下示例配置为适当的值：
options { listen-on port 53 { any; }; allow-query { any; }; recursion yes; }; zone &#34;example.com&#34; IN { type master; file &#34;/var/named/example.com.zone&#34;; allow-update { none; }; }; 创建主DNS区域文件 创建一个区域文件以存储DNS记录。在/var/named/目录下创建一个名为example.com.zone的文件，并添加相应的DNS记录。示例：
$TTL 86400 @ IN SOA ns1.example.com. root.example.com. ( 2018010101 ; Serial 3600 ; Refresh 1800 ; Retry 604800 ; Expire 86400 ; Minimum TTL ) @ IN NS ns1.example.com. @ IN A 192.168.1.10 www IN A 192.168.1.20 配置反向解析 打开/etc/named.conf文件，并添加反向解析配置。示例：
zone &#34;1.168.192.in-addr.arpa&#34; IN { type master; file &#34;/var/named/1.168.192.zone&#34;; allow-update { none; }; }; 创建反向解析区域文件 在/var/named/目录下创建一个名为1.168.192.zone的文件，用于反向解析。添加以下内容：
$TTL 86400 @ IN SOA ns1.example.com. root.example.com. ( 2018010101 ; Serial 3600 ; Refresh 1800 ; Retry 604800 ; Expire 86400 ; Minimum TTL ) @ IN NS ns1.example.com. 10 IN PTR example.com. 20 IN PTR www.example.com. 设置防火墙规则 如果您的防火墙处于启用状态，请确保允许DNS流量通过
sudo firewall-cmd --add-service=dns --permanent sudo firewall-cmd --reload 启动并启用DNS服务 sudo systemctl start named sudo systemctl enable named 现在，你的Linux系统上的DNS服务器就已经搭建完成了。您可以在其他设备上将DNS服务器设置为您的CentOS主机的IP地址，以使用该DNS服务器进行域名解析。
请注意，在实际生产环境中，你可能需要更复杂的配置来满足网络需求，例如添加其他区域或配置转发等。
DNS原理及解析流程 DNS是互联网中用于将域名解析为IP地址的系统。它充当了一个分布式数据库，将人类可读的域名映射到计算机可理解的IP地址。
DNS的解析流程如下：
 用户在浏览器中输入一个域名，比如www.example.com 操作系统首先会检查本地缓存（称为本地DNS缓存），看是否已经有该域名的解析结果。如果有，则直接返回并跳至第8步。如果没有，继续进行后续步骤。 操作系统向预配置的本地DNS服务器发送一个DNS查询请求。这个本地DNS服务器通常由用户的ISP（互联网服务提供商）或者自定义的DNS服务器提供。 本地DNS服务器收到查询请求后，首先检查自己的缓存，如果存在对应的域名解析结果，直接返回给操作系统。如果没有，则继续进行后续步骤。 本地DNS服务器根据域名的顶级域（TLD）来选择合适的根域名服务器（Root DNS Server）发送查询请求。根域名服务器负责管理顶级域名服务器的地址信息。 根域名服务器返回给本地DNS服务器一个顶级域名服务器的地址。 本地DNS服务器再次向顶级域名服务器发送查询请求。顶级域名服务器负责管理对应顶级域下的权威域名服务器（Authoritative DNS Server）的地址信息。 本地DNS服务器收到权威域名服务器的地址后，向权威域名服务器发送最终的查询请求。 权威域名服务器收到查询请求后，在自己的数据中查找该域名的解析结果。 如果权威域名服务器找到了该域名的解析结果，它将返回给本地DNS服务器。 本地DNS服务器收到解析结果后，会将其缓存下来，并将解析结果返回给操作系统。 操作系统将解析结果传递给应用程序，例如浏览器。 应用程序利用解析结果中的IP地址与服务器建立连接，并完成后续的通信过程。 整个DNS解析流程可能涉及多次查询和响应，但由于DNS系统的分布式结构和缓存机制，大部分解析结果可以从本地DNS缓存或者本地DNS服务器的缓存中获取，从而提高解析速度和减轻DNS服务器的负载压力。  需要注意的是，DNS解析并非一次性完成的，DNS记录可能会发生变化，因此在某些情况下，需要等待DNS记录的刷新时间（TTL）过期后才能获取到最新的解析结果。
原文连接: 如何在Linux中搭建DNS服务  
]]></content>
  </entry>
  
  <entry>
    <title>取代C++？谷歌开源编程语言Carbon</title>
    <url>/post/programming/google-open-source-programming-language-carbon.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>Google</tag>
      <tag>C++</tag>
      <tag>Carbon</tag>
    </tags>
    <content type="html"><![CDATA[号称替代C++，谷歌发布新的编程语言，已经过去了一年。去年7月，在多伦多举办的CppNorth大会上，谷歌宣布正式开源内部打造的编程语言Carbon，并称他是C++的继任者。
谷歌的工程师认为呢，尽管C++仍然是性能关键性软件的主流编程语言，并且拥有庞大且不断增长的代码库。但同时呢，也存在着应用性较差，掌握难度大以及由于语言功能过于丰富而导致的混乱的问题。
所以呢，他们决定自己开发一门语言来代替C++，于是呢，这个速度更快，并且可以和C++代码互相操作的新语言就应运而生了，Carbon编程语言已经在GitHub上开源了。
其实呢，Google在编程语言方面确实还挺强的，之前开源的go long呢，目前已经是使用非常广泛的一个编程语言了，但是这次Carbon能否延续Go语言的传奇？目前下结论呢，还为时尚早，毕竟上一个号称代替C++的 Rust  语言目前混的并不咋滴。
在谈到为何要替代 C++ 时，谷歌工程师Carruth表示，C++作为长期以来构建性能关键应用的首选语言，它自身的很多问题困扰着现代开发人员。C++积累了数十年的技术负债，带有的很多过时实践都是其前身C语言的一部分。C++ 的维护者优先考虑向后兼容，以便继续支持广泛使用的项目，例如Linux及其包管理生态系统等。
此外，C++语言的发展也受到了官僚委员会程序的阻碍，该程序以标准化而非设计为导向。这种做法导致很难添加新功能。C++在很大程度上处于一个隔绝的开发过程，其中可能经过数年才会做出一些重要决定。
因此，Carruth希望通过更开放的社区主导环境来构建Carbon语言，并已开源。到2023年7月中旬，该项目已在GitHub上获得30.8k的Stars。
Carbon的设计理念和特性 谷歌希望在2022年年底推出Carbon的核心工作版本，即v0.1。Carbon将建立在现代编程原则的基础上，包含一个泛型系统，使开发人员不再需要为每个实例检查和再核对代码。
C++ 语言中亟需的一个特性是内存安全。内存访问 bug是安全漏洞的罪魁祸首之一，Carbon 设计人员将探索追踪未初始化状态的更好方法、设计支持动态边界检查的 API和惯用语，并构建全面的默认debug构建模式。随着时间的推移，设计人员还计划构建一个安全的Carbon子集。
Carbon语言将支持以下功能：  性能关键型软件； 软件和语言演变； 易于阅读、理解和编写的代码； 实用的安全和测试机制； 快速且可扩展的开发； 现代操作系统平台、硬件架构和环境； 与现有C++代码的互操作性和迁移  同时，Carbon语言的亮点包括如下：  Introducer关键字和简单语法； 函数输入参数为只读值； 指针提供间接访问和变体； 使用表达式命名类型； 软件包为root命名空间； 通过包名导入APIs； 用显式对象参数来声明方法； 单继承、默认使用最终类； 强大且经过定义检查的泛型； 类型显式地实现接口。  Carbon设计团队将着手创建一个内置包管理器，这在C++中非常欠缺。此外，团队还计划编写一些将C++代码迁移到Carbon代码的工具。下图左为C++代码，右为Carbon编写的相同函数：
为何不大力发展Rust语言呢？ 有人或许会问了：最近有专门为解决内存安全性能应用的需求而构建的Rust语言，为何不直接使用它呢？Carruth对此表示，如果Rust适合你，就继续使用。但是，将C++的生态系统转移到Rust非常困难。
相比之下，Carbon是建立在已有C++生态系统之上，适合那些已经拥有大量C++代码库的开发人员，这些库很难转换到Rust。
目前 Carbon 语言的代码已完全开源。Chandler 表示，虽然 Carbon 诞生自谷歌内部，且目前的项目负责人主要（不完全）由谷歌员工组成，但它的目标是要成为一个 “独立且由社区驱动的开源项目”。
如果你对 Carbon 感兴趣，可以下载源代码并在自己的设备上进行试验，或者通过 Compiler Explorer 直接在浏览器中体验 Carbon 编程语言。
对于 Carbon 项目，有开发者透露了一些背景信息：2020 年 2 月，C++ 标准委员会就 “破坏 ABI 兼容性以保证性能” 提案进行了投票，这项工作主要由谷歌员工推动，但最终投票没有通过。因此，许多谷歌员工已经停止参与 C++ 的标准化工作，并辞去他们在委员会中的正式职务，clang 的开发工作也大大放缓。基于这些背景，再结合谷歌对 Carbon 设定的目标，这名开发者认为，谷歌确实希望把 Carbon 打造成替代 C++ 的语言。
]]></content>
  </entry>
  
  <entry>
    <title>RS422/485接口电路设计要点</title>
    <url>/post/hardware/design-points-of-rs422-485-circuit.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>UART</tag>
      <tag>RS422</tag>
      <tag>RS485</tag>
    </tags>
    <content type="html"><![CDATA[RS-422标准全称是“平衡电压数字接口电路的电气特性”，它定义了接口电路的特性。
实际上还有一根信号地线，共5根线。由于接收器采用高输入阻抗和发送驱动器比RS232更强的驱动能力，故允许在相同传输线上连接多个接收节点，最多可接10个节点。一个主设备（Master），其余为从设备（Slave），从设备之间不能通信，所以RS-422支持点对多的双向通信。接收器输入阻抗为4k，故发端最大负载能力是10&amp;TImes;4k+100Ω（终接电阻）。
 RS-422和RS-485电路  原理基本相同，都是以差动方式发送和接收，不需要数字地线。差动工作是同速率条件下传输距离远的根本原因，这正是二者与RS232的根本区别，因为RS232是单端输入输出，双工工作时至少需要数字地线。发送线和接收线三条线（异步传输），还可以加其它控制线完成同步等功能。
RS-422通过两对双绞线可以全双工工作收发互不影响，而RS485只能半双工工作，发收不能同时进行，但它只需要一对双绞线。RS422和RS485在19kpbs下能传输1200米。用新型收发器线路上可连接台设备。
典型的RS422接口电路 图 1 典型的RS422接口电路
典型的RS485接口电路 图 2 典型的RS485接口电路
图 3 全双工RS485接口电路拓扑
设计要点   接口保护用途的TVS管D1-8，通常选择最大反向工作电压VRWM为5.0V的双向TVS管，如Diodes SMBJ5.0CA。注：这里可以选择耐压更高的TVS元件。
  DI和RO引脚都使用10k电阻上拉，是为防止误触发，产生误动作，因为“UART以一个前导“0”触发一次接收动作”。
  图 1所示，差分接收器的端接电阻一般取值120 Ω，来源于通常RS422/485传输线所用的特征阻抗约为120 Ω。图 3所示的RS485多点应用中，若在SCH&amp;PCB设计时不清楚后期现场布线中哪两个设备距离最远，可在所有差分接收端都预留120 Ω端接电阻，以便后期现场应用时通过拨码开关选择性接入。
  由于RS422/485差分接收器的特性是，VIA - VIB的绝对值必须大于200 mV，否则无法正确识别高低电平。所以，图 1所示，当使用3.3V电源时，故障安全偏置电阻R5和R6最大取值为930 Ω；当使用5.0V电源时，R5和R6最大取值为1440 Ω。
  说明：故障安全偏置电阻，是为了解决“总线空闲、开路或短路”情况下，接收端状态不确定的问题。由于RS422只支持点对点应用，且故障安全偏置电阻只需要在接收端使用，所以图 1和图 2电路，R3-4不是必要的，R5-6和R12-15是必要的。注：如果R12/R13在发送端已经有，那么在接收端就不是必要的。
 图 1所示，在RS422点对点应用中，两端的差分接收器都需要120 Ω并联端接电阻。图 3所示，在RS485多点应用中，只需在最远的两点接收端使用120 Ω并联端接电阻，中间各支路不需要。
  图 2和图 3所示，各支路的A&amp;B引脚和Z&amp;Y引脚都串联0R电阻，当某路故障时将RS485总线拉低时，逐一断开电阻，方便排查故障。
  SCH&amp;PCB设计时，两个设备间的RS422/485通信线，除了两对差分线外，至少需要一根地线，防止共模电压超出规定的范围而导致通信故障。
  有选择的情况下，RS422/485通信电缆中，信号线不应与电源线并行或尽量远离电源线，若无法避免，信号线最好使用带屏蔽的双绞线。且现场布线，采用菊花链拓扑，不采用星形或环形拓扑，以免因反射等因素导致通信错误。
  原文地址： RS422/485接口电路设计要点  
]]></content>
  </entry>
  
  <entry>
    <title>5款超强大的FPGA开发板</title>
    <url>/post/fpga/5-ultra-powerful-fpga-development-boards.html</url>
    <categories><category>FPGA</category>
    </categories>
    <tags>
      <tag>FPGA</tag>
      <tag>Xilinx</tag>
      <tag>Microsemi</tag>
      <tag>Stratix 10</tag>
    </tags>
    <content type="html"><![CDATA[随着人工智能、深度学习在市场越来越受欢迎，除了GPU、众多独角兽公司的AI专用芯片，FPGA同样是深度学习的热门平台之一。本文将给大家介绍5款强大到不可思议的FPGA开发板，当然价格也是高的离谱，肯能对于大多数工程师来说，这些属于求而不得的高端“玩具”。
RTG4开发套件 RTG4-DEV-KIT是Microsemi公司的产品，当然目前的话已经被Microchip收购，这是一套为高端的客户提供的评估和开发平台，主要用于数据传输，串行连接，总线接口等高密度高性能FPGA的高速设计等应用 。
该开发板采用RT4G150器件，采用陶瓷封装，提供150,000个逻辑元件，具有1,657个引脚，下图是RTG4-DEV-KIT开发板的外设接口功能图。
RTG4开发套件主要包括的硬件功能如下：
 两个1GB DDR3同步动态随机存取存储器(SDRAM) 2GB SPI Flash PCI Express Gen1 接口1个 PCIe x4 接口 一对SMA连接器，用于测试全双工SERDES通道 两个带有HPC/LPC引脚排列的FMC连接器，用于扩展 用于10/100/1000以太网的RJ45接口 USB micro-AB连接器 SPI，GPIO的接口 FTDI编程器接口用于编程外部SPI Flash JTAG编程接口 用于应用程序编程和调试的RVI接口 Flashpro编程接口 用于调试的嵌入式跟踪宏(ETM)单元接口 用于用户应用的双列直插式封装(DIP)开关 按钮开关和LED 电流测量测试点  RTG4-DEV-KIT开发板的硬件框图
从硬件框图上也能看到RTG4-DEV-KIT复杂的电源管理系统，12V的DC直流供电，通过DCDC/以及LDO分配到各个功能部分的供电。
英特尔Stratix 10开发套件 Intel Stratix 10开发套件是包含各类软硬件的完整设计环境，用于评估Stratix 10 FPGA的功能。该套件可用于通过符合PCI-SIG的开发板来开发和测试PCI Express 3.0设计。使用这些开发板可开发和测试由DDR4、DDR3、QDR IV和RLDRAM III存储器组成的存储器子系统。通过使用FPGA夹层卡 (FMC) 连接器与FMC夹层卡连接，还可以开发模块化和可扩展设计。该套件支持JESD204B、Serial RapidIO、10Gbps以太网 (10GbE)、SONET、通用公共无线电接口 (CPRI)、OBSAI等诸多协议。
英特尔Stratix 10开发套件硬件框图
开发板板载的主要FPGA是Intel公司的Stratix 10系列产品，相比前一代产品成本提供2X性能和超低功耗，具有几个开创性的创新如新型的HyperFlex™和架构，能满足日益增长的带宽和处理性能，从而满足功率预算。嵌入硬件系统基于四核64位ARM Cortex-A53，采用Intel 14-nm Tri-Gate (FinFET)技术和混合性3D片上系统(SiP)技术，单片核多达550万和逻辑单元，多达96个全双工收发器，数据速率高达28.3Gbps，主要用在计算和存储，网络设备，光传输网络，广播，军用雷达，医疗设备，测试和测量以及5G无线设备，ASIC原型。
ADS8-V1 评估板 确切的说，ADS8-V1 评估板并不是一块专为FPGA评估的板卡，而是为了支持ADI公司高速数据转换，当连接到指定的 ADI 高速 ADC 评估板时，ADS8-V1 可用作数据采集板。ADS8-V1 上的 FPGA 设计用于支持最高速 JESD204B 模数转换器，可充当数据接收器，同时 ADC 为数据发射器。
ADS8-V1EBZ接口外设如下：
 Xilinx Kintex Ultrascale XCKU040-3FFVA1156E FPGA 一(1)个FMC +连接器 一(1)个FMC +连接器支持二十(20)个16Gbps收发器 DDR4 SDRAM 简单的USB 3.0端口接口  ADI强大的数据采集评估板可以应用于航空航天和防务、电子监控和对抗、仪器仪表和测量、通信测试设备、信号发生器(通过射频传输音频)、5G领域等。
REFLEX CES XpressVUP-LP9P REFLEX CES XpressVUP-LP9P是基于Virtex Ultrascale + VU9P FPGA的低配置PCIe网络处理FPGA板，专为HPC等网络应用而设计。该板提供2组DDR4，2组QDR2 +存储器和2个QSFP28网箱，用于多个10GbE / 40GbE / 100GbE网络解决方案。其主要的功能包括了：PCIe Gen3 x16、Xilinx Virtex UltraScale + VU9P FPGA、板载两个DDR4和两个QDR2 +独立组、两个QSFP28光纤笼用于多网络解决方案、具有16个通道，8 Gb/s链路速率的PCIe接口(Gen3)等。
XpressVUP-LP9P技术规格 FPGA和配置模块  Xilinx Virtex UltraScale + 16nm FPGA：XCVU9P-L2FLGB2104E(生产) XCVU9P-L2FLGB2104E(生产) 2,6 M系统逻辑单元 270 Mb UltraRAM(UltraScale +提供高密度，双端口，同步存储器模块) 用于外部Xilinx USB电缆的JTAG连接器 双四SPI(x8)配置模式的2x Nor Flash  通讯接口  PCI Express x16(第1,2或3代) 2 x QSFP28四光纤笼(2 x 4 XCVR：每条链路28 Gb/ s)，支持10GbE / 40GbE / 100GbE QSFP28模块支持的其他协议  存储  板载DDR4,2x组64位+ 4位ECC，总共8GB 板载QDR-II +，2x存储区，18位，总共144Mbits  功率  最大100W 提供定制散热器  其他资源  板载可编程PLL振荡器(Si5345)，高度灵活和可配置的时钟发生器。 板载高精度振荡器为精确时间协议(PTP)以太网提供时钟精确20MHz-0.05ppm，同步协议标准化IEEE 1588 一个用于PPS(每秒脉冲)的同轴连接器，允许多个电子部件同步  REFLEX CES XpressVUP-LP9P硬件框图
值得一提的是，XpressVUP在POWER9 CPU主机处理器(IBM)上支持CAPI 2.0，并且还支持IBM SNAP框架，只需很少的FPGA专业知识，SNAP框架允许应用工程师在服务器环境中快速创建基于FPGA的加速程序。它使用IBM CAPI 2.0接口，该接口可在标准PCIe物理通道上运行，但具有CPU和FPGA之间较低延迟和一致内存共享的优势。
Digilent NetFPGA-SUME NetFPGA-SUME是Digilent，剑桥大学和斯坦福大学之间的合作项目，是高性能和高密度网络设计的理想平台。
NetFPGA-SUME采用赛灵思Virtex-7 690T FPGA，支持30个13.1 GHz GTH收发器，四个SFP + 10Gb/s端口，五个独立的高速存储器组，由500MHz QDRII +和1866MT / s DDR3 SoDIMM器件构建，以及一个八通道第三代PCIe，可提供超大的吞吐量，并可支持大量高速数据流FPGA架构和存储器件，其它功能包括在FMC和QTH扩展连接器以及SATA端口上共展示20个收发器。
NetFPGA-SUME的主要任务是为学生，研究人员和开发人员提供最先进的网络平台，无论是学习基础知识还是创建新的硬件和软件应用程序，该板可轻松支持四个10Gb/s以太网端口上的同时线速处理，并可在板上操作和处理数据。
Digilent NetFPGA-SUME特征：  Xilinx Virtex-7 XC7V690T FFG1761-3 Xilinx CPLD XC2C512用于FPGA配置 PCIe Gen3 x8(8Gbps /通道) 两个512Mbits Micron StrataFlash(PC28F512G18A) 编程：赛灵思Vivado 设计套件 三个x36 72Mbits QDR II SRAM(CY7C25652KV18-500BZC) 两个4GB DDR3 SODIMM(MT8KTF51264Hz-1G9E1) 用于JTAG编程和调试的Micro USB连接器(与UART接口共享) 一根Micro USB线用于编程/ UART QTH连接器(8个RocketIO GTH收发器) 四个SFP +接口(4个RocketIO GTH收发器)，支持10Gbps 两个SATA-III端口 用户LED和按钮 一个HPC FMC连接器(10个RocketIO GTH收发器) 一个Pmod端口  总结 FPGA的强大还是在于其超灵活的可编程能力，随着人工智能越来越受市场的喜爱，无论是GPU还是专用的AI芯片都不可能像FPGA这样便于新进入这个领域的企业折腾、创新，带着这种与生俱来的优势，相信FPGA的春天还很漫长。
原文连接: 5款超强大的FPGA开发板  
]]></content>
  </entry>
  
  <entry>
    <title>10道经典的嵌入式C语言题目</title>
    <url>/post/programming/ten-classical-embedded-c-language-examination-questions.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Embedded</tag>
      <tag>Struct</tag>
    </tags>
    <content type="html"><![CDATA[10个C语言面试题，涉及指针、进程、运算、结构体、函数、内存，看看你能做出几个
gets()函数 问：请找出下面代码里的问题：
#include&lt;stdio.h&gt; int main(void) { char buff[10]; memset(buff,0,sizeof(buff)); gets(buff); printf(&#34;\nThe buffer entered is [%s]\n&#34;,buff); return 0; } 答：上面代码里的问题在于函数gets()的使用，这个函数从stdin接收一个字符串而不检查它所复制的缓存的容积，这可能会导致缓存溢出。这里推荐使用标准函数fgets()代替。
strcpy()函数 问：下面是一个简单的密码保护功能，你能在不知道密码的情况下将其破解吗？
#include&lt;stdio.h&gt;  int main(int argc, char *argv[]) { int flag = 0; char passwd[10]; memset(passwd,0,sizeof(passwd)); strcpy(passwd, argv[1]); if(0 == strcmp(&#34;LinuxGeek&#34;, passwd)) { flag = 1; } if(flag) { printf(&#34;\nPassword cracked \n&#34;); } else { printf(&#34;\nIncorrect passwd \n&#34;); } return 0; } 答：破解上述加密的关键在于利用攻破strcpy()函数的漏洞。所以用户在向“passwd”缓存输入随机密码的时候并没有提前检查“passwd”的容量是否足够。
所以，如果用户输入一个足够造成缓存溢出并且重写“flag”变量默认值所存在位置的内存的长“密码”，即使这个密码无法通过验证，flag验证位也变成了非零，也就可以获得被保护的数据了。例如：
$ ./psswd aaaaaaaaaaaaa Password cracked 虽然上面的密码并不正确，但我们仍然可以通过缓存溢出绕开密码安全保护。
要避免这样的问题，建议使用 strncpy()函数。
作者注：最近的编译器会在内部检测栈溢出的可能，所以这样往栈里存储变量很难出现栈溢出。在我的gcc里默认就是这样，所以我不得不使用编译命令‘-fno-stack-protector’来实现上述方案。
main()的返回类型 问：下面的代码能 编译通过吗？如果能，它有什么潜在的问题吗？
#include&lt;stdio.h&gt;  void main(void) { char *ptr = (char*)malloc(10); if(NULL == ptr) { printf(&#34;\nMalloc failed \n&#34;); return; } else { // Do some processing  free(ptr); } return; } 答：因为main()方法的返回类型，这段代码的错误在大多数编译器里会被当作警告。
main()的返回类型应该是“int”而不是“void”。因为“int”返回类型会让程序返回状态值。这点非常重要，特别当程序是作为依赖于程序成功运行的脚本的一部分运行时。
内存泄露 问：下面的代码会导致内存泄漏吗？
#include&lt;stdio.h&gt;  void main(void) { char *ptr = (char*)malloc(10); if(NULL == ptr) { printf(&#34;\nMalloc failed \n&#34;); return; } else { // Do some processing  } return; } 答：尽管上面的代码并没有释放分配给“ptr”的内存，但并不会在程序退出后导致内存泄漏。在程序结束后，所有这个程序分配的内存都会自动被处理掉。
但如果上面的代码处于一个“while循环”中，那将会导致严重的内存泄漏问题！
提示：如果你想知道更多关于内存泄漏的知识和内存泄漏检测工具，可以来看看我们在Valgrind上的文章。
free()函数 问：下面的程序会在用户输入’freeze’的时候出问题，而’zebra’则不会，为什么？
#include&lt;stdio.h&gt;  int main(int argc, char *argv[]) { char *ptr = (char*)malloc(10); if(NULL == ptr) { printf(&#34;\nMalloc failed \n&#34;); return -1; } else if(argc == 1) { printf(&#34;\nUsage \n&#34;); } else { memset(ptr, 0, 10); strncpy(ptr, argv[1], 9); while(*ptr != &#39;z&#39;) { if(*ptr == &#39;&#39;) break; else ptr++; } if(*ptr == &#39;z&#39;) { printf(&#34;\nString contains &#39;z&#39;\n&#34;); // Do some more processing  } free(ptr); } return 0; } 答：这里的问题在于，代码会（通过增加“ptr”）修改while循环里“ptr”存储的地址。当输入“zebra”时，while循环会在执行前被终止，因此传给free()的变量就是传给malloc()的地址。
但在“freeze”时，“ptr”存储的地址会在while循环里被修改，因此导致传给free()的地址出错，也就导致了seg-fault或者崩溃。
使用_exit退出 问：在下面的代码中，atexit()并没有被调用，为什么？
#include&lt;stdio.h&gt;  void func(void) { printf(&#34;\nCleanup function called \n&#34;); return; } int main(void) { int i = 0; atexit(func); for(;i&lt;0xffffff;i++); _exit(0); } 这是因为_exit()函数的使用，该函数并没有调用atexit()等函数清理。如果使用atexit()就应当使用exit()或者“return”与之相配合。
void*和C结构体 问：你能设计一个能接受任何类型的参数并返回interger（整数）结果的函数吗？
答：如下：
int func(void *ptr) 如果这个函数的参数超过一个，那么这个函数应该由一个结构体来调用，这个结构体可以由需要传递参数来填充。
* 和 ++ 操作 问：下面的操作会输出什么？为什么？
#include&lt;stdio.h&gt;  int main(void) { char *ptr = &#34;Linux&#34;; printf(&#34;\n[%c] \n&#34;,*ptr++); printf(&#34;\n[%c] \n&#34;,*ptr); return 0; } 答：输出结果应该是这样：
[L]
[i]
因为“++”和“ * ” 的优先权一样，所以“ * ptr++ ”相当于 “ * (ptr++) ”。即应该先执行 ptr++，然后才是 * ptr，所以操作结果是“L”。第二个结果是“i”。
问：修改代码片段 问：下面的代码段有错，你能指出来吗？
#include&lt;stdio.h&gt;  int main(void) { char *ptr = &#34;Linux&#34;; *ptr = &#39;T&#39;; printf(&#34;\n[%s] \n&#34;, ptr); return 0; } 答：这是因为，通过 * ptr = ‘T’，会改变内存中代码段（只读代码）“Linux”的第一个字母。这个操作是无效的，因此会造成segment-fault或者崩溃。
返回本地变量的地址 问：下面代码有问题吗？如果有，该怎么修改？
#include&lt;stdio.h&gt;  int* inc(int val) { int a = val; a++; return &amp;a; } int main(void) { int a = 10; int *val = inc(a); printf(&#34;\nIncremented value is equal to [%d] \n&#34;, *val); return 0; } 答：尽管上面的程序有时候能够正常运行，但是在“inc()”中存在严重的漏洞。这个函数返回本地变量的地址。因为本地变量的生命周期就是“inc()”的生命周期，所以在inc结束后，使用本地变量会发生不好的结果。这可以通过将main()中变量“a”的地址来避免，这样以后还可以修改这个地址存储的值。
]]></content>
  </entry>
  
  <entry>
    <title>Linux操作系统学习——启动</title>
    <url>/post/linux/linux-operating-system-study-boot.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Boot</tag>
    </tags>
    <content type="html"><![CDATA[Linux操作系统内核是服务端学习的根基，也是提高编程能力、源码阅读能力和进阶知识学习能力的重要部分，本文开始将记录Linux操作系统中的各个部分源码学习历程。
前言 关于如何学习源码，个人觉得可以从以下角度入手，有效地提高阅读和学习的效率。（学习语言就不说了，这是基本功。学习IDE推荐Source Insight或者Visual Studio，网站源码阅读推荐woboq）
理解代码的组织结构。 以Linux源码举例，首先你得知道操作系统分为哪几个部分，他们单独做了什么功能，如何进行配合完成更为具体的功能。建立整体的印象有助于后续深入学习的时候方便理解，毕竟代码是用的不是看的，理解他的作用有利于理解为什么要这么做。
深入各个模块学习 模块接口： 这里推荐微软的画图工具visio或者思维导图xmind，用其画图可以将各个模块的接口列出，并绘制各个模块之间的关系，通过了解接口可以清楚各个模块之间的关系，即绘制模块组织图
工作流程： 通过上面一步得到各模块间的关系，然后实际用断点或log等方式看一看整体的工作流程，在模块组织图的基础上绘制程序流程图
模块粘合层： 我们的代码有很多都是用来粘合代码的，比如中间件（middleware）、Promises 模式、回调（Callback）、代理委托、依赖注入等。这些代码模块间的粘合技术是非常重要的，因为它们会把本来平铺直述的代码给分裂开来，让你不容易看明白它们的关系。这些可以作为程序流程图的补充，让其中本来无法顺畅衔接的地方变得通畅无阻。
模块具体实现： 这是最难得地方，涉及到大量具体源码的学习。深入细节容易迷失在细节的海洋里，因此需要有一些重点去关注，将非重点的内容省略。通过学习绘制模块具体架构图和模块的算法时序图，可以帮助你更好的掌握源码的精髓。
需要关注的包括 代码逻辑。 代码有两种逻辑，一种是业务逻辑，这种逻辑是真正的业务处理逻辑；另一种是控制逻辑，这种逻辑只是用控制程序流转的，不是业务逻辑。比如：flag 之类的控制变量，多线程处理的代码，异步控制的代码，远程通讯的代码，对象序列化反序列化的代码等。这两种逻辑你要分开，很多代码之所以混乱就是把这两种逻辑混在一起了。
重要的算法。 一般来说，我们的代码里会有很多重要的算法，我说的并不一定是什么排序或是搜索算法，可能会是一些其它的核心算法，比如一些索引表的算法，全局唯一 ID 的算法、信息推荐的算法、统计算法、通读算法（如 Gossip）等。这些比较核心的算法可能会非常难读，但它们往往是最有技术含量的部分。
底层交互。 有一些代码是和底层系统的交互，一般来说是和操作系统或是 JVM 的交互。因此，读这些代码通常需要一定的底层技术知识，不然，很难读懂。
可以忽略的包括 出错处理。 根据二八原则，20% 的代码是正常的逻辑，80% 的代码是在处理各种错误，所以，你在读代码的时候，完全可以把处理错误的代码全部删除掉，这样就会留下比较干净和简单的正常逻辑的代码。排除干扰因素，可以更高效地读代码。
数据处理。 只要你认真观察，就会发现，我们好多代码就是在那里倒腾数据。比如 DAO、DTO，比如 JSON、XML，这些代码冗长无聊，不是主要逻辑，可以不理。
忽略过多的实现细节。 在第一遍阅读源码时，已弄懂整体流程为主，至于具体的实现细节先简单的理清处过一遍，不用过于纠结。当梳理清楚全部的框架逻辑后，第二遍再深入的学习研究各个模块的实现，此时应该解决第一遍中的疑惑。第三遍可以跳出代码的实现，来看Linux的设计思路、编程艺术和演进之路。
重在实践。 Linux的代码都是可以调试的，看很多遍也许不如跟着调试走一遍，然后再自己修改修改做一些小测试。
传授知识。 当你能将知识讲述给别人听，并让别人听懂时，你已经可以自豪的说洞悉了这些知识。所以不妨从一个小的例子开始自说自话，看能不能自圆其说，甚至写成博客、做成PPT给大家讲解。
说了一大堆的废话，下面就正式开始操作系统的深入学习记录之旅了。
混沌初开 本文分析从按下电源键到加载BIOS以及后续bootloader的整个过程。犹如盘古开天辟地一般，该过程将混沌的操作系统世界分为清晰的内核态和用户态，并经历从实模式到保护模式的变化。这里先简单介绍一下名词，便于后续理解。
实模式（Real Mode)：又名 Real Address Mode，在此模式下地址访问的是真实地内存地址所在位置。在此模式下，可以使用20位（1MB）的地址空间，软件可以不受限制的操作所有地址的空间和IO设备。
保护模式（Protected Mode)：又名 Protected Virtual Address Mode，采用虚拟内存、页等机制对内存进行了保护，比起实模式更为安全可靠，同时也增加了灵活性和扩展性。
从启动电源到BIOS 当我们按下电源键，主板会发向电源组发出信号，接收到信号后，电源会提供合适的电压给计算机。当主板收到电源正常启动的信号后，主板会启动CPU。CPU重置所有寄存器数据，并设置初始化数据，这个初始化数据在X86架构里如下所示：
1IP 0xfff0 2CS selector 0xf000 3CS base 0xffff0000 4IP/EIP (Instruction Pointer) : 指令指针寄存器，记录将要执行的指令在代码段内的偏移地址 5CS（Code Segment Register）：代码段寄存器，指向CPU当前执行代码在内存中的区域（定义了存放代码的存储器的起始地址） 实模式采取内存段来管理 0 - 0xFFFFF的这1M内存空间，但是由于只有16位寄存器，所以最大地址只能表示为0xFFFFF（64KB)，因此不得不采取将内存按段划分为64KB的方式来充分利用1M空间。也就是上所示的，采取段选择子 + 偏移量的表示法。这种方法在保护模式中对于页的设计上也沿用了下来，可谓祖传的智慧了。具体的计算公式如下所示：
1PhysicalAddress = Segment Selector * 16 + Offset 该部分由硬件完成，通过计算访问0XFFFF0，如果该位置没有可执行代码则计算机无法启动。如果有，则执行该部分代码，这里也就是我们故事的开始，BIOS程序了。
BIOS到BootLoader BIOS执行程序存储在ROM中，起始位置为0XFFFF0，当CS:IP指向该位置时，BIOS开始执行。BIOS主要包括以下内存映射：
10x00000000 - 0x000003FF - Real Mode Interrupt Vector Table 20x00000400 - 0x000004FF - BIOS Data Area 30x00000500 - 0x00007BFF - Unused 40x00007C00 - 0x00007DFF - Our Bootloader 50x00007E00 - 0x0009FFFF - Unused 60x000A0000 - 0x000BFFFF - Video RAM (VRAM) Memory 70x000B0000 - 0x000B7777 - Monochrome Video Memory 80x000B8000 - 0x000BFFFF - Color Video Memory 90x000C0000 - 0x000C7FFF - Video ROM BIOS 100x000C8000 - 0x000EFFFF - BIOS Shadow Area 110x000F0000 - 0x000FFFFF - System BIOS 12 其中最重要的莫过于中断向量表和中断服务程序。BIOS程序在内存最开始的位置（0x00000）用1 KB的内存空间（0x00000～0x003FF）构建中断向量表，在紧挨着它的位置用256字节的内存空间构建BIOS数据区（0x00400～0x004FF），并在大约57 KB以后的位置（0x0E05B）加载了8 KB左右的与中断向量表相应的若干中断服务程序。中断向量表中有256个中断向量，每个中断向量占4字节，其中两个字节是CS的值，两个字节是IP的值。每个中断向量都指向一个具体的中断服务程序。
BIOS程序会选择一个启动设备，并将控制权转交给启动扇区中的代码。主要工作即使用中断向量和中断服务程序完成BootLoader的加载，最终将boot.img加载至0X7C00的位置启动。Linux内核通过Boot Protocol定义如何实现该引导程序，有如GRUB 2和syslinux等具体实现方式，这里仅介绍GRUB2。
BootLoader的工作 boot.img由boot.S编译而成，512字节，安装在启动盘的第一个扇区，即MBR。由于空间有限，其代码十分简单，仅仅是起到一个引导的作用，指向后续的核心镜像文件，即core.img。core.img包括很多重要的部分，如lzma_decompress.img、diskboot.img、kernel.img等，结构如下图。
整个加载流程如下：
1、boot.img加载core.img的第一个扇区，即diskboot.img，对应代码为diskboot.S
2、diskboot.img加载core.img的其他部分模块，先是解压缩程序 lzma_decompress.img，再往下是 kernel.img，最后是各个模块 module 对应的映像。这里需要注意，它不是 Linux 的内核，而是 grub 的内核。注意，lzma_decompress.img 对应的代码是 startup_raw.S，本来 kernel.img 是压缩过的，现在执行的时候，需要解压缩。
3、加载完core之后，启动grub_main函数。
4、grub_main函数初始化控制台，计算模块基地址，设置 root 设备，读取 grub 配置文件，加载模块。最后，将 GRUB 置于 normal 模式，在这个模式中，grub_normal_execute (from grub-core/normal/main.c) 将被调用以完成最后的准备工作，然后显示一个菜单列出所用可用的操作系统。当某个操作系统被选择之后，grub_menu_execute_entry 开始执行，它将调用 GRUB 的 boot 命令，来引导被选中的操作系统。
 在这之前，我们所有遇到过的程序都非常非常小，完全可以在实模式下运行，但是随着我们加载的东西越来越大，实模式这 1M 的地址空间实在放不下了，所以在真正的解压缩之前，lzma_decompress.img 做了一个重要的决定，就是调用 real_to_prot，切换到保护模式，这样就能在更大的寻址空间里面，加载更多的东西。
开机时的16位实模式与内核启动的main函数执行需要的32位保护模式之间有很大的差距，这个差距谁来填补？head.S做的就是这项工作。就像 kernel boot protocol 所描述的，引导程序必须填充 kernel setup header （位于 kernel setup code 偏移 0x01f1 处） 的必要字段，这些均在head.S中定义。在这期间，head程序打开A20，打开pe、pg，废弃旧的、16位的中断响应机制，建立新的32位的IDT……这些工作都做完了，计算机已经处在32位的保护模式状态了，调用32位内核的一切条件已经准备完毕，这时顺理成章地调用main函数。后面的操作就可以用32位编译的main函数完成，从而正式启动内核，进入波澜壮阔的Linux内核操作系统之中。
总结 本文介绍了从按下电源开关至加载完毕BootLoader的整个过程，后续将继续分析从实模式进入保护模式，从而启动内核创建0号、1号、2号进程的整个过程。
]]></content>
  </entry>
  
  <entry>
    <title>Linux三剑客（grep,sed,awk）</title>
    <url>/post/linux/linux-three-musketeers.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Grep</tag>
      <tag>Sed</tag>
      <tag>Awk</tag>
    </tags>
    <content type="html"><![CDATA[在Linux系统中，awk、grep、sed等命令被广泛用于文本处理。它们是非常强大的命令行工具，可以用于搜索、替换、过滤、排序等多种操作。
本文将介绍这些命令的基本用法和示例，帮助读者更好地了解它们的功能和用法。
grep命令 grep是一种非常常见的文本搜索工具，它可以搜索指定字符串在一个或多个文件中出现的行，并将结果输出到标准输出。它的语法格式如下：
grep [OPTIONS] PATTERN [FILE...] 其中，OPTIONS表示选项，PATTERN表示要搜索的模式，FILE表示要搜索的文件名。
下面是一些grep命令的常用选项：
 -i：忽略大小写 -v：显示不匹配的行 -n：显示行号 -c：显示匹配行的数量 -r：递归搜索子目录 -e：搜索多个模式  下面是一些grep命令的实例：
在文件中搜索指定字符串 grep &#34;hello&#34; file.txt 在文件中搜索多个字符串 grep -e &#34;hello&#34; -e &#34;world&#34; file.txt 在文件中搜索并显示匹配行号 grep -n &#34;hello&#34; file.txt 在文件中搜索并显示不匹配的行 grep -v &#34;hello&#34; file.txt 在目录中递归搜索指定字符串 grep -r &#34;hello&#34; directory/ sed命令 sed是一种流编辑器，它可以执行各种文本操作，如替换、删除、插入等。它的语法格式如下：
sed [OPTIONS] COMMAND [FILE...] 其中，OPTIONS表示选项，COMMAND表示要执行的sed命令，FILE表示要处理的文件名。
下面是一些常用的sed命令：
 s：替换指定模式 d：删除指定行 i：插入指定字符串 c：替换指定行 y：字符转换 p：打印匹配的行  下面是一些sed命令的实例：
替换文件中的指定字符串 sed &#39;s/hello/world/&#39; file.txt 删除文件中的指定行 sed &#39;3d&#39; file.txt 在文件中指定行后插入指定字符串 sed &#39;2i\hello world&#39; file.txt 替换文件中指定行的内容 sed &#39;3c\hello world&#39; file.txt awk命令 awk是一种文本处理工具，它可以用于格式化、过滤、计算等操作。它的语法格式如下：
awk [OPTIONS] &#39;PATTERN { ACTION }&#39; [FILE...] 其中，OPTIONS表示选项，PATTERN表示要匹配的模式，ACTION表示要执行的操作，FILE表示要处理的文件名。
下面是一些常用的awk命令：
 print：打印指定内容 if：条件判断 for：循环结构 sum：计算指定  下面是一些awk命令的实例：
打印文件中的所有行 awk &#39;{print}&#39; file.txt 打印文件中第二列的内容 awk &#39;{print $2}&#39; file.txt 计算文件中所有数字的总和 awk &#39;{sum += $1} END {print sum}&#39; file.txt 打印文件中包含指定字符串的行 awk &#39;/hello/ {print}&#39; file.txt 在文件中指定列后面添加指定字符串 awk &#39;{$3 = $3 &#34;hello&#34;} {print}&#39; file.txt 以上是grep、sed、awk命令的基本语法和示例。这些命令可以通过选项和参数进行进一步定制和扩展。例如，grep命令可以通过-i选项忽略大小写，-r选项递归搜索子目录，-n选项显示行号等。
在实际应用中，这些命令通常会被结合使用。例如，可以使用grep命令搜索指定字符串，然后使用sed命令进行替换，最后使用awk命令进行计算和格式化。
此外，这些命令也可以通过管道符号（|）进行连接。例如，可以使用grep命令搜索指定字符串，然后将结果通过管道符号传递给sed命令进行替换，最后将结果再次通过管道符号传递给awk命令进行计算和格式化。
总之，grep、sed、awk等命令是Linux系统中非常重要和常用的文本处理工具。熟练掌握它们的基本语法和用法，可以大大提高文本处理的效率和质量。
]]></content>
  </entry>
  
  <entry>
    <title>如何在 Linux 中配置 IPv4 和 IPv6 地址</title>
    <url>/post/linux/how-to-configure-ipv4-and-ipv6.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>IPv4, IPv6</tag>
    </tags>
    <content type="html"><![CDATA[IPv4和IPv6是Internet上常用的两种IP地址协议。在Linux系统中，您可以通过配置网络接口来设置IPv4和IPv6地址。本文将详细介绍如何在Linux中配置IPv4和IPv6地址。
步骤 1：确定网络接口 在开始配置IP地址之前，您需要确定要配置的网络接口。执行以下命令来列出当前系统上的网络接口：
ifconfig -a 该命令将显示所有可用的网络接口及其相关信息。确定要配置的网络接口的名称，例如eth0或enp0s3。
步骤 2：配置 IPv4 地址 ###临时配置
要临时配置IPv4地址，可以使用ifconfig命令。执行以下命令来设置IPv4地址：
sudo ifconfig &lt;interface&gt; &lt;ipv4_address&gt; netmask &lt;netmask&gt; 将替换为要配置的网络接口的名称，&lt;ipv4_address&gt;替换为您要分配的IPv4地址，替换为子网掩码。
例如，要将IP地址为192.168.1.10，子网掩码为255.255.255.0的IPv4地址分配给eth0接口，执行以下命令：
sudo ifconfig eth0 192.168.1.10 netmask 255.255.255.0 永久配置 要永久配置IPv4地址，您需要编辑网络接口的配置文件。执行以下命令来打开配置文件：
sudo nano /etc/network/interfaces 在文件中找到要配置的接口部分，添加以下行：
auto &lt;interface&gt; iface &lt;interface&gt; inet static address &lt;ipv4_address&gt; netmask &lt;netmask&gt; gateway &lt;gateway_address&gt; 将替换为要配置的网络接口的名称，&lt;ipv4_address&gt;替换为您要分配的IPv4地址，替换为子网掩码，&lt;gateway_address&gt;替换为网关地址。
保存文件并关闭文本编辑器。然后，执行以下命令以使更改生效：
sudo systemctl restart networking 现在，您的Linux系统将使用配置的IPv4地址。
步骤 3：配置 IPv6 地址 临时配置 要临时配置IPv6地址，可以使用ifconfig命令。执行以下命令来设置IPv6地址：
sudo ifconfig &lt;interface&gt; inet6 add &lt;ipv6_address&gt;/&lt;prefix_length&gt; 将替换为要配置的网络接口的名称，&lt;ipv6_address&gt;替换为您要分配的IPv6地址，&lt;prefix_length&gt;替换为前缀长度。
例如，要将IPv6地址为2001:0db8:85a3:0000:0000:8a2e:0370:7334，前缀长度为64的IPv6地址分配给eth0接口，执行以下命令：
sudo ifconfig eth0 inet6 add 2001:0db8:85a3:0000:0000:8a2e:0370:7334/64 永久配置 要永久配置IPv6地址，您需要编辑网络接口的配置文件。执行以下命令来打开配置文件：
sudo nano /etc/network/interfaces 在文件中找到要配置的接口部分，添加以下行：
iface &lt;interface&gt; inet6 static address &lt;ipv6_address&gt;/&lt;prefix_length&gt; 将替换为要配置的网络接口的名称，&lt;ipv6_address&gt;替换为您要分配的IPv6地址，&lt;prefix_length&gt;替换为前缀长度。
保存文件并关闭文本编辑器。然后，执行以下命令以使更改生效：
sudo systemctl restart networking 现在，您的Linux系统将使用配置的IPv6地址。
步骤 4：验证配置 要验证IPv4和IPv6地址的配置是否成功，可以执行以下命令来查看网络接口的IP地址信息：
ifconfig &lt;interface&gt; 将&lt;interface&gt;替换为您配置的网络接口的名称。该命令将显示指定接口的IP地址信息，包括IPv4和IPv6地址。 结论 通过本文的指导，您已经学会了在Linux中配置IPv4和IPv6地址的详细步骤。根据您的网络需求，您可以临时或永久地配置这些地址。
具体的配置方式可能因Linux发行版和版本而有所不同。本文提供了一般的配置方法，但如果您的系统有特定的要求或网络环境，请参考相关文档或咨询系统管理员。
]]></content>
  </entry>
  
  <entry>
    <title>风河携手三星推进软件定义汽车演进</title>
    <url>/post/news/wind-river-and-samsung-drive-the-evolution-of-software-defined-vehicles.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Wind River</tag>
      <tag>Samsung</tag>
      <tag>SNV</tag>
    </tags>
    <content type="html"><![CDATA[领先的关键任务智能系统软件提供商风河公司宣布与三星电子系统LSI业务部建立新的合作关系。双方将致力于加速软件定义汽车的发展，开发高质量车载信息娱乐解决方案（IVI）、座舱监控和高级驾驶辅助系统。
汽车工业正在向软件定义汽车演进，越来越多的功能和特性都将由软件来驱动，并能快速简便地进行更新。确保开发人员拥有卓越的工具、流程和结构，有效实现软件的创建、测试与更新，这对整个行业来说皆属最高优先事项。
为了加速迭代演进，风河将基于三星Exynos Auto V920芯片组向客户提供自己的软件技术，创建一整套完全集成化的汽车软件与硬件解决方案，其中的核心是Wind River Helix™ Virtualization Platform（虚拟化平台）。这是一套获得安全认证的多核、多操作系统平台，支持最终用户融合不同安全性要求的运行时环境，包括VxWorks®实时操作系统(RTOS)、Linux和Android。
要设计和开发互联自动驾驶电动汽车，必须采用新的软件定义方法，以及高性能计算系统。我们与三星携手合作，支持OEM厂商和Tier 1供应商继承和发展过去三十多年来在航空航天与国防、工业、医疗和电信等诸多领域所积累的技术和经验，构建对未来软件定义车辆至关重要的软件系统，满足多种不同层次的关键性认证要求。
Exynos Auto V920是我们最新的5nm汽用处理器，提供强大的智能化性能和更高水平的车内体验，让汽车拥有更高的安全性。这套系统能够以高效节能的方式在多个虚拟机上同时运行多个应用，从而满足了行业的低功耗需求。通过与风河公司的密切合作，我们能够加强业界领先的IVI开发工作，并通过风河领先的运行时环境进一步扩展到多个安全关键领域。
]]></content>
  </entry>
  
  <entry>
    <title>英特尔宣布，出售设备公司股份</title>
    <url>/post/news/intel-announces-sale-of-stake-IMS.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Intel</tag>
      <tag>IMS</tag>
      <tag>Bain Capital</tag>
    </tags>
    <content type="html"><![CDATA[英特尔公司今天宣布，已同意将其 IMS Nanofabrication GmbH (“IMS”) 业务约 20% 的股份出售给 Bain Capital Special Situations（“贝恩资本”）处理的一项交易中，IMS 的估值约为 43 亿美元。
该交易预计将于 2023 年第三季度完成。IMS 将作为独立子公司运营，并继续由首席执行官 Elmar Platzgummer 博士领导。
英特尔方面透露：“考虑到估值水平和投资水平，这将成为我们有史以来最好的收购之一。”
自 2015 年发明多电子束技术并推出首款商用多光束掩模写入器以来，总部位于奥地利维也纳的 IMS 一直是先进技术节点多光束掩模写入领域的行业领导者。英特尔最初于 2009 年投资 IMS，并最终于 2015 年收购了该业务。自收购以来，IMS 为英特尔带来了显著的投资回报，同时将其员工和生产能力增长了四倍，并交付了另外三代产品。
如今，随着 EUV 技术在前沿技术中得到广泛采用，创建高级 EUV（极紫外光刻）掩模所需的多光束掩模写入工具已成为半导体制造生态系统中越来越重要的组成部分。这项投资将使 IMS 能够通过加速创新和实现更深入的跨行业合作来抓住多光束掩模写入工具的重要市场机会。
企业发展高级副总裁 Matt Poirier 表示：“光刻技术的进步对于推动半导体行业的持续进步至关重要，而掩模写入在行业向新图案技术（例如高数值孔径 EUV）过渡中发挥着核心作用。”在英特尔。“贝恩资本的投资和合作将为 IMS 提供更大的独立性，并带来战略视角，帮助加速下一阶段的光刻技术创新，最终使整个生态系统受益。”
Platzgummer 表示：“我们很高兴能获得贝恩资本这一宝贵的合作伙伴，贝恩资本在与企业合作推动增长和价值创造方面拥有悠久的历史。随着 EUV 变得更加普遍和高效，他们与我们一样坚信 IMS 面临着有意义的机遇。High-NA EUV 在本世纪下半叶从开发转向大批量制造。我们期待扩大我们的能力，为世界上最大的芯片生产商提供支持，他们依靠我们的技术来生产当前和下一代半导体产品。
贝恩资本 (Bain Capital) 合伙人 Marvin Larbi-Yeboa 表示：“作为半导体制造和纳米技术行业新兴技术的全球领导者和创新者，我们相信 IMS 处于有利地位，能够利用随着芯片产能增加而带来的有吸引力的长期有利因素在线并建立其领先的竞争地位、技术差异化和尖端的产品能力。”
贝恩资本董事总经理 Will Tetler 补充道：“我们期待与 IMS 卓越的管理团队和英特尔合作，利用我们深厚的行业经验和价值创造能力，通过进一步投资支持业务的长期增长战略其领先的技术和产品组合使 IMS 能够扩大其竞争市场地位。”
]]></content>
  </entry>
  
  <entry>
    <title>STM32的完整启动流程分析</title>
    <url>/post/mcu/STM32-whole-boot-up-process-analysis.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>STM32</tag>
      <tag>boot up</tag>
      <tag>process</tag>
    </tags>
    <content type="html"><![CDATA[关于STM32的启动流程，网上有的资料在讨论几种boot模式，有的在回答启动文件的内容，在查阅了很多资料后，本文给出一个比较全面的总结和回答。
根据boot引脚决定三种启动模式 复位后，在 SYSCLK 的第四个上升沿锁存 BOOT 引脚的值。BOOT0 为专用引脚，而 BOOT1 则与 GPIO 引脚共用。一旦完成对 BOOT1 的采样，相应 GPIO 引脚即进入空闲状态，可用于其它用途。BOOT0与BOOT1引脚的不同值指向了三种启动方式：
  从主Flash启动。主Flash指的是STM32的内置Flash。选择该启动模式后，内置Flash的起始地址将被重映射到0x00000000地址，代码将在该处开始执行。一般我们使用JTAG或者SWD模式下载调试程序时，就是下载到这里面，重启后也直接从这启动。
  从系统存储器启动。系统储存器指的是STM32的内置ROM，选择该启动模式后，内置ROM的起始地址将被重映射到0x00000000地址，代码在此处开始运行。ROM中有一段出厂预置的代码，这段代码起到一个桥的作用，允许外部通过UART/CAN或USB等将代码写入STM32的内置Flash中。这段代码也被称为ISP(In System Programing)代码，这种烧录代码的方式也被称为ISP烧录。关于ISP、ICP和IAP之间的区别将在后续章节中介绍。
  从嵌入式SRAM中启动。显然，该方法是在STM32的内置SRAM中启动，选择该启动模式后，内置SRAM的起始地址将被重映射到0x00000000地址，代码在此处开始运行。这种模式由于烧录程序过程中不需要擦写Flash，因此速度较快，适合调试，但是掉电丢失。
  总结：上面的每一种启动方式我都描述了“xxx的起始地址被重映射到了0x00000000地址，从而代码从xxx开始启动”，如下图是STM32F4xx中文参考手册中的图，可以看到类似的表述。同时，在下图中也展示了STM32F4xx中统一编址下，各内存的地址分配，注意一点，即使相应的内存被映射到了0x00000000起始的地址，通过其原来地址依然是可以访问的。
启动后bootloader做了什么？ 根据BOOT引脚确定了启动方式后，处理器进行的第二大步就是开始从0x00000000地址处开始执行代码，而该处存放的代码正是bootloader。
bootloader，也可以叫启动文件，无论性能高下，结构简繁，价格贵贱，每一种微控制器(处理器)都必须有启动文件，启动文件的作用便是负责执行微控制器从“复位”到“开始执行main函数”中间这段时间(称为启动过程)所必须进行的工作。最为常见的51，AVR或MSP430等微控制器当然也有对应启动文件，但开发环境往往自动完整地提供了这个启动文件，不需要开发人员再行干预启动过程，只需要从main函数开始进行应用程序的设计即可。同样，STM32微控制器，无论是keiluvision4还是IAR EWARM开发环境，ST公司都提供了现成的直接可用的启动文件。
网上有很多资料分析了STM32的启动文件的内容，在此我只进行简单的表述。启动文件中首先会定义堆栈，定义中断/异常向量表，而其中只实现了复位的异常处理函数Reset_Handler，该函数内容如下(STM32F4XX，IAR编译器)，可以看到其主要执行了SystemInit和__iar_program_start两个函数，其主要功能除了初始化时钟，FPU等，还会执行一个重要功能，那就是内存的搬移、初始化操作。 这是我想重点介绍的内容，同时也会回答一个疑问，就是如果从Flash启动的话，代码究竟是运行在哪儿的？在我之前接触ARM9、CortexA系列的时候，一般都是把代码搬到内部的SRAM或者外部DDR中执行的，STM32是如何呢？答案下一小节揭晓。
bootloader中对内存的搬移和初始化 本节针对程序在内置Flash中启动的情况进行分析。
我们知道烧录的镜像文件中包含只读代码段.text，已初始化数据段.data和未初始化的或者初始化为0的数据段.bss。代码段由于是只读的，所以是可以一直放在Flash中，CPU通过总线去读取代码执行就OK，但是.data段和.bss段由于会涉及读写为了，为了更高的读写效率是要一定搬到RAM中执行的，因此bootloader会执行很重要的一步，就是会在RAM中初始化.data和.bss段，搬移或清空相应内存区域。
因此我们知道，当启动方式选择的是从内置Flash启动的时候，代码依旧是在Flash中执行，而数据则会被拷贝到内部SRAM中，该过程是由bootloader完成的。bootloader在完成这些流程之后，就会将代码交给main函数开始执行用户代码。
  现在让我们思考一个问题，PC机在运行程序的时候将程序从外存（硬盘）中，调入到RAM中运行，CPU从RAM中读取程序和数据；而单片机的程序则是固化在Flash中，CPU运行时直接从Flash中读取程序，从RAM中读取数据，那么PC机能从Flash之类的存储介质中直接读代码执行吗？
  答案是不行。因为x86构架的CPU是基于冯.诺依曼体系的，即数据和程序存储在一起，而且PC机的RAM资源相当丰富，从几十M到几百M甚至是几个G，客观上能够承受大量的程序数据。但是单片机的构架大多是哈弗体系的，即程序和数据分开存储，而且单片的片内RAM资源是相当有限的，内部的RAM过大会带来成本的大幅度提高。
  ISP、IAP、ICP三种烧录方式 虽然这个小节稍稍偏题，但是由于上面在3中启动方式中介绍过了ISP烧录，因此一并在此介绍剩下的两种烧录方式。
  ICP(In Circuit Programing)。在电路编程，可通过CPU的Debug Access Port 烧录代码，比如ARM Cortex的Debug Interface主要是SWD(Serial Wire Debug)或JTAG(Joint Test Action Group)；
  ISP(In System Programing)。在系统编程，可借助MCU厂商预置的Bootloader 实现通过板载UART或USB接口烧录代码。
  IAP(In Applicating Programing)。在应用编程，由开发者实现Bootloader功能，比如STM32存储映射Code分区中的Flash本是存储用户应用程序的区间（上电从此处执行用户代码），开发者可以将自己实现的Bootloader存放到Flash区间，MCU上电启动先执行用户的Bootloader代码，该代码可为用户应用程序的下载、校验、增量/补丁更新、升级、恢复等提供支持，如果用户代码提供了网络访问功能，IAP 还能通过无线网络下载更新代码，实现OTA空中升级功能。
  IAP和ISP 的区别。
   ISP程序一般是芯片厂家提供的。IAP一般是用户自己编写的 ISP一般支持的烧录方式有限，只有串口等。IAP就比较灵活，可以灵活的使用各种通信协议烧录 isp一般需要芯片进行一些硬件上的操作才行，IAP全部工作由程序完成，不需要去现场 isp一般只需要按格式将升级文件通过串口发送就可以。IAP的话控制相对麻烦，如果是OTA的话还需要编写后台的。 注意，这里介绍的bootloader功能显然跟之前介绍的启动文件bootloader有所区别，其目的是为了能接受外部镜像进行烧录，而不是为了运行普通用户程序。 ]]></content>
  </entry>
  
  <entry>
    <title>什么是大数据时代</title>
    <url>/post/news/what-is-the-era-of-big-data.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Big Data</tag>
    </tags>
    <content type="html"><![CDATA[最早提出&quot;大数据&quot;时代到来的是全球知名咨询公司麦肯锡，麦肯锡称:&ldquo;数据，已经渗透到当今每一个行业和业务职能领域，成为重要的生产因素。
人们对于海量数据的挖掘和运用，预示着新一波生产率增长和消费者盈余浪潮的到来。&rdquo; &ldquo;大数据&quot;在物理学、生物学、环境生态学等领域以及军事、金融、通讯等行业存在已有时日，却因为近年来互联网和信息行业的发展而引起人们关注。简单来说：大量数据 + 云计算 = 大数据时代
大数据特征 ###数据量大(Volume)
第一个特征是数据量大。大数据的起始计量单位至少是P(1000个T)、E(100万个T)或Z(10亿个T)。
类型繁多(Variety) 第二个特征是数据类型繁多。包括网络日志、音频、视频、图片、地理位置信息等等，多类型的数据对数据的处理能力提出了更高的要求。
价值密度低(Value) 第三个特征是数据价值密度相对较低。如随着物联网的广泛应用，信息感知无处不在，信息海量，但价值密度较低，如何通过强大的机器算法更迅速地完成数据的价值&quot;提纯&rdquo;，是大数据时代亟待解决的难题。
速度快、时效高(Velocity) 第四个特征是处理速度快，时效性要求高。这是大数据区分于传统数据挖掘最显著的特征。
既有的技术架构和路线，已经无法高效处理如此海量的数据，而对于相关组织来说，如果投入巨大采集的信息无法通过及时处理反馈有效信息，那将是得不偿失的。可以说，大数据时代对人类的数据驾驭能力提出了新的挑战，也为人们获得更为深刻、全面的洞察能力提供了前所未有的空间与潜力。
那么数据生活距离我们遥远吗？ 正相反，数据与我们日常生活的联系从未如此紧密过，从没有像今天如此活跃，具体的记录着人类与世界。从最初的计算机，摄像头到家用计算机，智能手机，再到大数据和人工智能，我们不断升级采集和利用数据的方式。而现在，从一辆车的每日碳排放量统计到全球气温的检测，从预测个人在网上喜好分析到总统选举时投票趋势的预测，我们都可以做到。
数据将人与人，人与世界连接起来，构成一张繁密的网络，每个人都在影响世界，又在被他人影响着。传统的统计方法已经无法处理这种相互影响的数据，这么办？答案是让机器自己来处理数据，从数据中习得知识。
这便是当代人工智能的本质。与传统的数据记录定义不同，这种数据是有“生命”的。它更像是我们身体的一种自然延伸：聆听我们的声音，拓宽我们的视野，加深我们的记忆，甚至组成一个以数据形式存在的“我”。
生活中的大数据很多，以下是几个例子：  互联网搜索：每天有数百万的搜索请求，包含了大量的关键字和查询信息。通过分析这些数据，搜索引擎可以优化搜索算法，提高搜索结果的准确性。 电子商务：在线购物网站产生了大量的数据，包括用户浏览、购买、评论、评分等信息。通过分析这些数据，商家可以更好地了解消费者需求，优化产品和服务。 社交媒体：社交媒体如Facebook、Twitter、微信等产生了海量的数据，包括用户关系、兴趣爱好、社交网络等。通过分析这些数据，企业可以了解消费者的行为和需求，优化宣传和营销策略。 医疗健康：医疗领域的大数据可以帮助医生更好地诊断疾病、预测疾病风险、优化治疗方案等。例如，通过分析患者的基因组数据，可以提前预测某些疾病的发作可能性，及时采取干预措施。 交通运输：现代交通系统中产生了大量的数据，包括车辆位置、速度、路况、交通流量等。通过分析这些数据，交通运输管理者可以更好地规划交通、提高交通效率，优化城市交通管理。  大数据的利与弊可以概括为以下几点： 利：   提供更准确的信息：大数据可以提供海量、多样化、实时的数据，帮助企业和政府更好地了解市场、用户需求、社会趋势等，从而做出更准确的决策。
  优化产品和服务：通过分析大数据，企业可以了解消费者的需求和习惯，优化产品和服务，提高用户满意度和忠诚度。
  提高效率和生产力：大数据可以优化生产流程、提高生产效率，让企业更快地响应市场变化，提高生产力。
  弊：   隐私问题：大数据涵盖了大量的个人信息和数据，如果这些数据被不法分子获取，就会造成极大的隐私泄露风险。
  误导性：大数据中有时会出现伪相关关系，需要进行深入的数据分析和挖掘，否则可能会引起误导。
  质量问题：大数据中可能包含有误的、不准确的数据，这会影响到对数据的分析和应用。
  技术门槛高：大数据的处理需要高级的技术和工具，这会导致技术门槛较高，对于一些小型企业和普通用户来说比较困难。
  总之，大数据虽然带来了很多的机遇和优势，但也面临着一些挑战和风险，需要我们在使用大数据时保持警惕和谨慎。
]]></content>
  </entry>
  
  <entry>
    <title>Linux内核中使用的C语言技巧</title>
    <url>/post/programming/c-language-tricks-used-in-the-linux-kernel.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Embedded</tag>
      <tag>Struct</tag>
    </tags>
    <content type="html"><![CDATA[下面是Linux内核中常常使用到的C语言技巧，比较实用，小伙伴们学起来！注意需要GCC编译器才支持这些特性。
typeof的使用 下面是我们常用的返回最大值宏定义，这个写法存在一些问题。
#define max(a,b) ((a) &gt; (b) ? (a) : (b)) 如果a传入i++，b传入j++，那么这个比较大小就会出错。例如：
#define max(a,b) ((a)&gt;(b)?(a):(b))  int x = 1, y = 2; printf(&#34;max=%d\n&#34;, max(x++, y++)); printf(&#34;x = %d, y = %d\n&#34;, x, y); 上面代码输出：max=2，x=2，y=4，结果是错误。为修改此宏，可以定义一个变量将a和b的值分别赋给该变量，并将该变量作为参数传递给max宏进行比较。在GNU C语言中，可以使用以下代码实现：
#define max(a,b) ({ \ int _a = (a); \  int _b = (b); \ _a &gt; _b ? _a : _b; }) 如果不知道具体的数据类型，可以使用typeof类转换宏，Linux内核中的例子：
#define max(a, b) ({ \ typeof(a) _a = (a); \ typeof(b) _b = (b); \ (void) (&amp;_a == &amp;_b); \ _a &gt; _b ? _a : _b; })  typeof(a) _a = (a):定义一个a类型的变量_a，将a赋值给_a typeof(b) _b = (b):定义一个b类型的变量_b，将b赋值给_b (void) (&amp;_a == &amp;_b):判断两个数的类型是否相同，如果不相同，会抛出一个警告。因为a和b的类型不一样，其指针类型也会不一样，两个不一样的指针类型进行比较操作，会抛出警告。  typeof用法举例：
//typeof的参数可以是表达式或类型  //参数是类型 typeof(int *) a,b;//等价于：int *a,*b;  //参数是表达式 int foo(); typeof(foo()) var;//声明了int类型的var变量，因为表达式foo()是int类型的。由于表达式不会被执行，所以不会调用foo函数。 柔性数组 柔性数组，也称为零长数组，主要用于变长结构体。因此，它有时被称为变长数组。使用方法是在结构体的末尾声明一个长度为0的数组，从而使该结构体具有可变长度。对于编译器来说，长度为0的数组不占用空间，因为数组名本身只是一个偏移量，代表了一个不可修改的地址常量符号。
结构体中定义零长数组：
&lt;mm/percpu.c&gt; struct pcpu_chunk { struct list_head list; unsigned long populated[]; /* 变长数组 */ }; 数据结构最后一个元素被定义为零长度数组，不占结构体空间。这样，我们可以根据对象大小动态地分配结构的大小。
struct line { int length; char contents[0]; }; struct line *thisline = malloc(sizeof(struct line) + this_length); thisline-&gt;length = this_length; 如上例所示，struct line数据结构定义了一个int length变量和一个变长数组contents[0]，这个struct line数据结构的大小只包含int类型的大小，不包含contents的大小，也就是sizeof (struct line) = sizeof (int)。
创建结构体对象时，可根据实际的需要指定这个可变长数组的长度，并分配相应的空间，如上述实例代码分配了this_length 字节的内存，并且可以通过contents[index]来访问第index个地址的数据。
case范围 GNU C语言支持指定一个case的范围作为一个标签，如：
case low ...high: case &#39;A&#39; ...&#39;Z&#39;: 这里low到high表示一个区间范围，在ASCII字符代码中也非常有用。下面是Linux内核中的代码例子。
&lt;arch/x86/platform/uv/tlb_uv.c&gt; static int local_atoi(const char *name){ int val = 0; for (;; name++) { switch (*name) { case &#39;0&#39; ...&#39;9&#39;: val = 10*val+(*name-&#39;0&#39;); break; default: return val; } } } 另外，还可以用整形数来表示范围，但是这里需要注意在“&hellip;”两边有空格，否则编译会出错。
&lt;drivers/usb/gadget/udc/at91_udc.c&gt; static int at91sam9261_udc_init(struct at91_udc *udc){ for (i = 0; i &lt; NUM_ENDPOINTS; i++) { ep = &amp;udc-&gt;ep[i]; switch (i) { case 0: ep-&gt;maxpacket = 8; break; case 1 ... 3: ep-&gt;maxpacket = 64; break; case 4 ... 5: ep-&gt;maxpacket = 256; break; } } } 标号元素 GNU C语言可以通过指定索引或结构体成员名来初始化，不必按照原来的固定顺序进行初始化。
结构体成员的初始化在 Linux 内核中经常使用，如在设备驱动中初始化file_operations数据结构：
&lt;drivers/char/mem.c&gt; static const struct file_operations zero_fops = { .llseek = zero_lseek, .read = new_sync_read, .write = write_zero, .read_iter = read_iter_zero, .aio_write = aio_write_zero, .mmap = mmap_zero, }; 如上述代码中的zero_fops的成员llseek初始化为zero_lseek函数，read成员初始化为new_sync_read函数，依次类推。当file_operations数据结构的定义发生变化时，这种初始化方法依然能保证已知元素的正确性，对于未初始化成员的值为0或者NULL。
可变参数宏 在GNU C语言中，宏可以接受可变数目的参数，主要用在输出函数里。例如：
&lt;include/linux/printk.h&gt; #define pr_debug(fmt, ...) \ dynamic_pr_debug(fmt, ##__VA_ARGS__) “&hellip;”代表一个可以变化的参数表，“VA_ARGS”是编译器保留字段，预处理时把参数传递给宏。当宏的调用展开时，实际参数就传递给dynamic_pr_debug函数了。
UL 的使用 在Linux内核代码中，我们经常会看到一些数字的定义使用了UL后缀修饰。
数字常量会被隐形定义为int类型，两个int类型相加的结果可能会发生溢出。
因此使用UL强制把int类型数据转换为unsigned long类型，这是为了保证运算过程不会因为int的位数不同而导致溢出。
 1 ：表示有符号整型数字1 UL：表示无符号长整型数字1 ]]></content>
  </entry>
  
  <entry>
    <title>单片机基础概念：指令、数位、字节、存储器、总线</title>
    <url>/post/mcu/basic-concept-of-micro-processor-unit.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>ROM</tag>
      <tag>BUS</tag>
      <tag>Data Bit</tag>
    </tags>
    <content type="html"><![CDATA[本文介绍单片机基础概念：指令、数位、字节、存储器、总线
执行指令 我们来思考一个问题，当我们在编程器中把一条指令写进单片机内部，然后取下单片机，单片机就可以执行这条指令。
那么这条指令一定保存在单片机的某个地方，并且这个地方在单片机掉电后依然可以保持这条指令不会丢失，这是个什么地方呢？这个地方就是单片机内部的只读存储器即ROM(READ ONLY MEMORY)。
为什么称它为只读存储器呢？刚才我们不是明明把两个数字写进去了吗？原来在89C51中的ROM是一种电可擦除的ROM，称为FLASH ROM，刚才我们是用的编程器，在特殊的条件下由外部设备对ROM进行写的操作，在单片机正常工作条件下，只能从那面读，不能把数据写进去，所以我们还是把它称为ROM。
数的本质和物理现象 我们知道，计算机可以进行数学运算，这令我们非常难以理解，它们只是一些电子元器件，怎么可以进行数学运算呢？
我们人类做数学题如37+45是这样做的，先在纸上写37，然后在下面写45，然后大脑运算最后写出结果，运算的原材料是37和45，结果是82都是写在纸上的，计算机中又是放在什么地方呢？
为了解决这个问题，先让我们做一个实验：这里有一盏灯，我们知道灯要么亮，要么不亮，就有两种状态，我们可以用‘0’和‘1’来代替这两种状态：规定亮为‘1’、不亮为‘0’。
现在放上三盏灯，一共有几种状态呢？我们列表来看一下：000 / 001 / 010 / 011 / 100 / 101 / 110 / 111。我们来看，这个000 / 001 / 101 不就是我们学过的的二进制数吗？本来，灯的亮和灭只是一种物理现象，可当我们把它们按一定的顺序排好后，灯的亮和灭就代表了数字了。让我们再抽象一步，灯为什么会亮呢？是因为输出电路输出高电平，给灯通了电。因此，灯亮和灭就可以用电路的输出是高电平还是低电平来替代了。这样，数字就和电平的高、低联系上了。
数位的含义 通过上面的实验我们已经知道：一盏灯亮或者说一根线的电平的高低，可以代表两种状态：0和1，实际上这就是一个二进制位。
因此我们就把一根线称之为一“位”，用BIT表示。
一根线可以表示0和1，两根线可以表达00 / 01 / 10 / 11四种状态，也就是可以表达0~3，而三根可以表达0~7，计算机中通常用8根线放在一起，同时计数，就可以表示0~255一共256种状态。
这8根线或者8位就称之为一个字节(BYTE)。
存储器的构造 存储器就是用来存放数据的地方。它是利用电平的高低来存放数据的，也就是说，它存放的实际上是电平的高、低，而不是我们所习惯认为的1234这样的数字，这样，我们的一个谜团就解开了。
一个存储器就象一个个的小抽屉，一个小抽屉里有八个小格子，每个小格子就是用来存放“电荷”的，电荷通过与它相连的电线传进来或释放掉。至于电荷在小格子里是怎样存的，就不用我们操心了，你可以把电线想象成水管，小格子里的电荷就象是水，那就好理解了。存储器中的每个小抽屉就是一个放数据的地方，我们称之为一个“单元”。
有了这么一个构造，我们就可以开始存放数据了，想要放进一个数据12，也就是00001100，我们只要把第二号和第三号小格子里存满电荷，而其它小格子里的电荷给放掉就行了。
可问题出来了，一个存储器有好多单元，线是并联的，在放入电荷的时候，会将电荷放入所有的单元中，而释放电荷的时候，会把每个单元中的电荷都放掉。这样的话，不管存储器有多少个单元，都只能放同一个数，这当然不是我们所希望的。因此，要在结构上稍作变化。
需要在每个单元上有个控制线，想要把数据放进哪个单元，就把一个信号给这个单元的控制线，这个控制线就把开关打开，这样电荷就可以自由流动了。而其它单元控制线上没有信号，所以开关不打开，不会受到影响。
这样，只要控制不同单元的控制线，就可以向各单元写入不同的数据了。同样，如果要从某个单元中取数据，也只要打开相应的控制开关就行了。
存储器的译码 那么，我们怎样来控制各个单元的控制线呢？这个还不简单，把每个单元的控制线都引到集成电路的外面不就行了吗？
事情可没那么简单，一片27512存储器中有65536个单元，把每根线都引出来，这个集成电路就得有6万多个脚？不行，怎么办？要想法减少线的数量。
有一种方法称这为译码，简单介绍一下：一根线可以代表2种状态，2根线可以代表4种状态，3根线可以代表8种，256种状态又需要几根线代表？8根线，所以65536种状态我们只需要16根线就可以代表了。
存储器的选片概念 至此，译码的问题解决了，让我们再来关注另外一个问题。送入每个单元的八根线是用从什么地方来的呢？它就是从计算机上接过来的，一般地，这八根线除了接一个存储器之外，还要接其它的器件。
这样问题就出来了，这八根线既然不是存储器和计算机之间专用的，如果总是将某个单元接在这八根线上，就有问题出现了：比如这个存储器单元中的数值是0FFH另一个存储器的单元是00H，那么这根线到底是处于高电平，还是低电平？怎样分辨？
办法很简单，当外面的线接到集成电路的引脚进来后，不直接接到各单元去，中间再加一组开关就行了。平时我们让开关打开着，如果确实是要向这个存储器中写入数据，或要从存储器中读出数据，再让开关接通就行了。
这组开关由三根引线选择：读控制端、写控制端和片选端。要将数据写入片中，先选中该片，然后发出写信号，开关就合上了，并将传过来的数据(电荷)写入片中。如果要读，先选中该片，然后发出读信号，开关合上，数据就被送出去了。
读和写信号同时还接入到另一个存储器，但是由于片选端不同，所以虽有读或写信号，但没有片选信号，所以另一个存储器不会“误会”而开门，造成冲突。那么会不同时选中两片芯片呢？
只要是设计好的系统就不会，因为它是由计算控制的，而不是我们人来控制的，如果真的出现同时出现选中两片的情况，那就是电路出了故障了，这不在我们的讨论之列。
总线概念 从上面的介绍中我们已经看到，用来传递数据的八根线并不是专用的，而是很多器件大家共用的。
所以我们称之为数据总线，总线英文名为BUS，总即公交车道，谁也可以走。而十六根地址线也是连在一起的，称之为地址总线。
]]></content>
  </entry>
  
  <entry>
    <title>CPU、MPU、MCU和SOC的简介</title>
    <url>/post/mcu/introduction-of-cpu-mpu-mcu-soc.html</url>
    <categories><category>MCU</category>
    </categories>
    <tags>
      <tag>CPU</tag>
      <tag>MPU</tag>
      <tag>MCU</tag>
      <tag>SOC</tag>
    </tags>
    <content type="html"><![CDATA[在嵌入式开发中，我们会经常看到或接触一些专业术语，例如CPU、MPU、MCU和SOC等，并且这些专业术语出现的频率也是非常之高，在面试中也常常会作为提问的知识点，下面我们就来看一下他们之间的特点和区别。
CPU CPU是Central Processing Unit的缩写，计算机的运算控制核心就是CPU。CPU是由运算器、控制器和寄存器及相应的总线构成。众所周知的三级流水线：取址、译码、执行的对象就是CPU，CPU从存储器或高速缓冲存储器中取出指令，放入指令寄存器，并对指令译码，然后执行指令。而计算机的可编程性其实就是指对CPU的编程。
MPU MPU是Micro Processor Unit的缩写，指微处理器（这里要注意不是微控制器，很多人会把微处理器和微控制器混淆），微处理器通常代表功能强大的CPU（可理解为增强型的CPU），这种芯片往往是计算机和高端系统的核心CPU。例如嵌入式开发者最熟悉的 ARM  的Cortex-A芯片，他们都属于MPU。
MCU MCU是Micro Control Unit的缩写，指微控制器。随着大规模集成电路的出现及发展，把计算机的CPU、RAM、ROM、定时器和输入输出I/O引脚集成在一个芯片上，比如51，STC、Cortex-M这些芯片，它们的内部除了CPU外还包含了RAM和ROM，可直接添加简单的器件（电阻，电容）等构成最小系统就可以运行代码了。而像ARM（Cortex-A系列）直接放代码是运行不了的，因为它本质上只是增强版的CPU，必须添加相应的RAM和ROM。
SOC SOC是System on Chip的缩写，指的是片上系统。可以这样对比来看：MCU只是芯片级的芯片，而SOC是系统级的芯片，它集成了MCU和MPU的优点，即拥有内置RAM和ROM的同时又像MPU那样强大，它可以存放并运行系统级别的代码，也就是说可以运行操作系统（以Linux OS为主）
另外，SOPC也是一个值得了解的概念，与上述几项概念相比，SOPC的出现频率并不是那么高，但这并不影响它的重要性。SOPC是System On a Programmable Chip的缩写，即 可编程片上系统，SOPC与MCU、MPU、SOC最明显的区别在于：可更改硬件配置，也就是说自己构造芯片。
举个例子说明便于理解，单片机的硬件配置是固化好了的， 我们能够编程修改的就是软件配置，本来是串口通信功能，通过修改代码变成AD采样功能，也就是说硬件配置是固定了的，我们只能通过修改软件来选择其中的一项或多项功能；而SOPC可以修改硬件配置信息使其成为相应的芯片，可以是MCU，也可以是SOC。
结语 在嵌入式开发中，接触频率较多的一般是MCU和SOC，而现在STM32也几乎成为了MCU的代名词，SOC目前则以Cortex-A系列为主，开发难度也有所差异，对于嵌入式从业者来说，弄清楚这些专业概念是必备的。
]]></content>
  </entry>
  
  <entry>
    <title>嵌入式C语言之结构体封装函数</title>
    <url>/post/programming/embedded-c-programming-language-struct-pack-function.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>Embedded</tag>
      <tag>Struct</tag>
    </tags>
    <content type="html"><![CDATA[在嵌入式系统中，结构体封装函数可以用于对于嵌入式硬件资源进行抽象和封装，从而提高软件的可维护性和可移植性。结构体封装函数通常包含数据和行为，并提供了对数据的访问和操作方法。
比如可以将硬件驱动函数封装在结构体中，方便对外提供统一的API接口，同时也便于代码的移植和扩展。另外，结构体封装函数还可以用于实现状态机、任务调度等复杂的系统功能。
在C语言中，结构体不仅可以封装数据，还可以封装函数指针。这种方式可以用于实现回调函数、状态机等，提高代码的复用性和可维护性。特别是在嵌入式当中，应用是非常多的。
结构体封装函数的作用  将函数指针和参数打包成一个结构体，实现了代码的模块化和可复用性。 在结构体中可以定义多个函数指针，实现了对函数的分类管理和调用。 结构体可以作为函数的参数或返回值，传递和返回函数指针和参数。  结构体封装函数的应用  回调函数：将函数指针和参数打包成一个结构体，传递给API函数，在API函数内部执行该函数。 状态机：将每个状态对应的处理函数封装成一个结构体，根据当前状态调用相应的处理函数。 事件驱动：将事件处理函数封装成一个结构体，通过事件触发调用相应的处理函数。 线程池：将任务处理函数封装成一个结构体，加入任务队列后由线程池调用执行  结构体封装函数的好处  更好的隐藏实现细节：结构体封装函数使得函数的实现细节被封装在结构体内部，只有结构体暴露给外部的函数指针，实现了良好的封装和信息隐藏。 更加灵活的函数调用：函数指针可以被动态修改，从而实现动态的函数调用。例如，在状态机中，根据不同的状态，可以将相应的处理函数指针赋值给一个函数指针变量，从而实现状态的转换和函数的调用。 更加方便的扩展性：结构体封装函数可以轻松地添加新的函数指针，从而扩展功能。在需要添加新功能时，只需要定义一个新的函数指针，并添加到结构体中，就可以实现功能的扩展，而不需要修改原有的代码。 更加通用的代码：结构体封装函数可以使用于各种不同的编程范式，例如面向对象编程（OOP）和函数式编程（FP），从而实现通用的代码。例如，在OOP中，结构体可以被看作是一个对象，函数指针可以被看作是对象的方法，从而实现OOP编程的思想。 更加易于维护：结构体封装函数使得代码更加清晰、易于维护和修改。由于函数指针的定义和使用都在结构体内部，因此修改或调整代码时，只需要修改结构体中的函数指针定义或调用方式，而不需要修改其他部分的代码，从而使得代码更加健壮、易于维护和修改 模块化：通过结构体封装函数，可以将多个函数和数据结构组合成一个模块，以便于模块化设计和维护。这种方法可以将代码的复杂性分解到不同的模块中，降低了代码的耦合性，提高了代码的可读性和可维护性。 代码复用：结构体封装的函数可以通过传递结构体的方式重用同一个函数。这种方式可以大大减少代码量，提高代码的复用性和可维护性。 可扩展性：当需要增加新的功能时，只需增加新的函数和数据结构，而不需要修改现有代码。这种方式可以大大减少代码的修改和调试时间，提高代码的可扩展性和可维护性。 保护数据：通过结构体封装函数，可以将数据和函数封装在一个结构体中，防止外部代码对数据的非法访问和修改。 提高安全性：将函数和数据封装在一个结构体中，可以防止其他函数对数据的非法操作，从而提高程序的安全性。  举例1 /* 定义封装函数结构体由外部调用*/ typedef struct { int x; int y; void (*move_up)(int steps); void (*move_down)(int steps); void (*move_left)(int steps); void (*move_right)(int steps); } Point; // 定义结构体中的函数 void move_up(int steps) { // 向上移动steps个单位  // ... } void move_down(int steps) { // 向下移动steps个单位  // ... } void move_left(int steps) { // 向左移动steps个单位  // ... } void move_right(int steps) { // 向右移动steps个单位  // ... } int main() { // 初始化结构体  Point point = { .x = 0, .y = 0, .move_up = move_up, .move_down = move_down, .move_left = move_left, .move_right = move_right }; // 调用结构体中的函数  point.move_up(10); point.move_right(5); return 0; } 在上面的示例代码中，我们定义了一个结构体Point，其中包含了两个整型变量x和y，以及四个函数指针move_up、move_down、move_left和move_right。每个函数指针指向一个移动函数，用于在平面坐标系中移动点的位置。通过使用结构体封装函数，我们可以将函数和数据封装在一起，方便地进行操作和管理。
在main()函数中，我们首先通过初始化的方式，将结构体中的成员变量和函数指针初始化。然后，我们使用结构体中的函数指针，调用了move_up()和move_right()函数，分别将点向上移动10个单位和向右移动5个单位。
值得注意的是，在实际应用中，我们需要根据实际情况修改函数的实现，以及结构体中的成员变量和函数指针的数量和类型。同时避免滥用。
举例2 typedef struct { void (*init)(void); void (*write)(uint8_t data); uint8_t (*read)(void); } spi_t; void spi_init(void) { /* SPI初始化代码 */ } void spi_write(uint8_t data) { /* SPI写入数据 */ } uint8_t spi_read(void) { /* SPI读取数据 */ } int main(void) { spi_t spi = {spi_init, spi_write, spi_read}; spi.init(); spi.write(0xAA); uint8_t data = spi.read(); return 0; } 在举例2这个例子中，我们定义了一个spi_t类型的结构体，它包含了三个成员函数指针，分别对应SPI总线的初始化、写入和读取操作。在main函数中，我们定义了一个spi结构体变量，并且初始化它的函数指针成员。接下来，我们通过spi结构体变量的函数指针成员，分别调用了SPI总线的初始化、写入和读取操作。
使用结构体封装函数可以使代码更加清晰明了，减少了代码的冗余和重复，同时也方便代码的扩展和维护。
举例3 假设我们需要控制一个LED灯的亮度，可以使用PWM（脉冲宽度调制）技术来实现。为了方便控制，我们可以使用一个结构体来封装控制LED灯的函数和变量。
typedef struct { uint8_t duty_cycle; // 占空比  void (*set_duty_cycle)(uint8_t duty_cycle); // 设置占空比的函数指针  void (*start)(void); // 启动PWM输出的函数指针  void (*stop)(void); // 停止PWM输出的函数指针 } pwm_control_t; // 设置占空比 void set_duty_cycle(uint8_t duty_cycle) { // 设置占空比的代码 } // 启动PWM输出 void start_pwm(void) { // 启动PWM输出的代码 } // 停止PWM输出 void stop_pwm(void) { // 停止PWM输出的代码 } int main(void) { pwm_control_t pwm; pwm.duty_cycle = 50; // 设置占空比为50%  pwm.set_duty_cycle = set_duty_cycle; pwm.start = start_pwm; pwm.stop = stop_pwm; pwm.set_duty_cycle(pwm.duty_cycle); // 设置占空比  pwm.start(); // 启动PWM输出  while (1) { // 循环执行其他任务  } } 在上面的代码中，我们定义了一个名为pwm_control_t的结构体，其中包含了一个占空比成员变量duty_cycle和三个函数指针set_duty_cycle、start和stop。set_duty_cycle函数用于设置占空比，start函数用于启动PWM输出，stop函数用于停止PWM输出。
在main函数中，我们创建了一个pwm_control_t类型的结构体变量pwm，并分别给结构体的成员变量和函数指针赋值。接着，我们调用了set_duty_cycle和start函数来设置占空比和启动PWM输出。
结构体封装函数的好处在于，我们可以通过创建不同的结构体变量来控制多个LED灯，而且不同的LED灯可以使用不同的PWM参数。此外，如果需要修改PWM输出的实现方式，只需要修改start和stop函数即可，而不需要修改每个LED灯。
]]></content>
  </entry>
  
  <entry>
    <title>Linux驱动IO篇——mmap操作</title>
    <url>/post/linux/linux-io-device-driver-mmap-operation.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Device Driver</tag>
      <tag>mmap</tag>
      <tag>IO</tag>
    </tags>
    <content type="html"><![CDATA[平时我们写Linux驱动和用户空间交互时，都是通过copy_from_user把用户空间传过来的数据进行拷贝，为什么要这么做呢？
前言 因为用户空间是不能直接内核空间数据的，他们映射的是不同的地址空间，只能先将数据拷贝过来，然后再操作。
如果用户空间需要传几MB的数据给内核，那么原来的拷贝方式显然效率特别低，也不太现实，那怎么办呢？
想想，之所以要拷贝是因为用户空间不能直接访问内核空间，那如果可以直接访问内核空间的buffer，是不是就解决了。
简单来说，就是让一块物理内存拥有两份映射，即拥有两个虚拟地址，一个在内核空间，一个在用户空间。关系如下：
通过mmap映射就可以实现。
应用层 应用层代码很简单，主要就是通过mmap系统调用进行映射，然后就可以对返回的地址进行操作。
char * buf; /* 1. 打开文件 */ fd = open(&#34;/dev/hello&#34;, O_RDWR); if (fd == -1) { printf(&#34;can not open file /dev/hello\n&#34;); return -1; } /* 2. mmap * MAP_SHARED : 多个APP都调用mmap映射同一块内存时, 对内存的修改大家都可以看到。 * 就是说多个APP、驱动程序实际上访问的都是同一块内存 * MAP_PRIVATE : 创建一个copy on write的私有映射。 * 当APP对该内存进行修改时，其他程序是看不到这些修改的。 * 就是当APP写内存时, 内核会先创建一个拷贝给这个APP, * 这个拷贝是这个APP私有的, 其他APP、驱动无法访问。 */ buf = mmap(NULL, 1024*8, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); mmap的第一个参数是想要映射的起始地址，通常设置为NULL，表示由内核来决定该起始地址。
第二参数是要映射的内存空间的大小。
第三个参数PROT_READ | PROT_WRITE表示映射后的空间是可读可写的。
第四个参数可填MAP_SHARED或MAP_PRIVATE：
 MAP_SHARED：多个APP都调用mmap映射同一块内存时, 对内存的修改大家都可以看到。就是说多个APP、驱动程序实际上访问的都是同一块内存。 MAP_PRIVATE：创建一个copy on write的私有映射。当APP对该内存进行修改时，其他程序是看不到这些修改的。就是当APP写内存时, 内核会先创建一个拷贝给这个APP，这个拷贝是这个APP私有的, 其他APP、驱动无法访问。  驱动层 驱动层主要是实现mmap接口，而mmap接口的实现，主要是调用了remap_pfn_range函数，函数原型如下：
int remap_pfn_range( struct vm_area_struct *vma, unsigned long addr, unsigned long pfn, unsigned long size, pgprot_t prot); vma：描述一片映射区域的结构体指针 addr：要映射的虚拟地址起始地址 pfn：物理内存所对应的页框号，就是将物理地址除以页大小得到的值 size：映射的大小 prot：该内存区域的访问权限
驱动主要步骤：
  使用kmalloc或者kzalloc函数分配一块内存kernel_buf，因为这样分配的内存物理地址是连续的，mmap后应用层会对这一个基地址去访问这块内存。
  实现mmap函数
  static int hello_drv_mmap(struct file *file, struct vm_area_struct *vma) { /* 获得物理地址 */ unsigned long phy = virt_to_phys(kernel_buf);//kernel_buf是内核空间分配的一块虚拟地址空间  /* 设置属性：cache, buffer*/ vma-&gt;vm_page_prot = pgprot_writecombine(vma-&gt;vm_page_prot); /* map */ if(remap_pfn_range(vma, vma-&gt;vm_start, phy&gt;&gt;PAGE_SHFIT, vma-&gt;vm_end - vma-&gt;start, vma-&gt;vm_page_prot)){ printk(&#34;mmap remap_pfn_range failed\n&#34;); return -ENOBUFS; } return 0; } static struct file_operations my_fops = { .mmap = hello_drv_mmap, };  通过virt_to_phys将虚拟地址转为物理地址，这里的kernel_buf是内核空间的一块虚拟地址空间 设置属性：不使用cache，使用buffer 映射：通过remap_pfn_range函数映射，phy&raquo;PAGE_SHIFT其实就是按page映射，除了这个参数，其他的起始地址、大小和权限都可以由用户在系统调用函数中指定。  当应用层调用mmap后，就会调用到驱动层的mmap函数，最终应用层的虚拟地址和驱动中的物理地址就建立了映射关系，应用层也就可以直接访问驱动的buffer了。
]]></content>
  </entry>
  
  <entry>
    <title>Linux下SPI驱动详解</title>
    <url>/post/linux/linux-spi-device-driver-detailed-explanation.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Linux</tag>
      <tag>SPI</tag>
      <tag>Device Driver</tag>
    </tags>
    <content type="html"><![CDATA[SPI，是英语Serial Peripheral interface的缩写，顾名思义就是串行外围设备接口。
SPI总线 SPI总线概述 SPI是Motorola首先在其MC68HCXX系列处理器上定义的。SPI接口主要应用在 EEPROM，FLASH，实时时钟，AD转换器，还有数字信号处理器和数字信号解码器之间。SPI，是一种高速的，全双工，同步的通信总线，并且在芯片的管脚上只占用四根线，节约了芯片的管脚，同时为PCB的布局上节省空间，提供方便，正是出于这种简单易用的特性，现在越来越多的芯片集成了这种通信协议。SPI总线的构成及信号类型如图1-1所示：
 MOSI – 主设备数据输出，从设备数据输入 对应MOSI master output slave input MISO – 主设备数据输入，从设备数据输出 对应MISO master input slave output CLK – 时钟信号，由主设备产生 nCS – 从设备使能信号，由主设备控制  图1-1 SPI总线模型
SPI总线时序 SPI接口在Master控制下产生的从设备使能信号和时钟信号，两个双向移位寄存器按位传输进行数据交换，传输数据高位在前（MSB first），低位在后。如下图所示，在CLK的下降沿上数据改变，上升沿一位数据被存入移位寄存器。
图1-2 spi传输时序图
在一个SPI时钟周期内，会完成如下操作：（1）Master通过MOSI线发送1位数据，同时Slave通过MOSI线读取这1位数据；（2）Slave通过MISO线发送1位数据，同时Master通过MISO线读取这1位数据。Master和Slave各有一个移位寄存器，如图1-3所示，而且这两个移位寄存器连接成环状。依照CLK的变化，数据以MSB first的方式依次移出Master寄存器和Slave寄存器，并且依次移入Slave寄存器和Master寄存器。当寄存器中的内容全部移出时，相当于完成了两个寄存器内容的交换。
SPI总线传输模式 SPI总线传输一共有4种模式，这4种模式分别由时钟极性(CPOL，Clock Polarity)和时钟相位(CPHA，Clock Phase)来定义，其中CPOL参数规定了SCK时钟信号空闲状态的电平，CPHA规定了数据是在SCK时钟的上升沿被采样还是下降沿被采样。这四种模式的时序图如下图1-4所示：
 模式0：CPOL= 0，CPHA=0。CLK串行时钟线空闲是为低电平，数据在SCK时钟的上升沿被采样，数据在CLK时钟的下降沿切换 模式1：CPOL= 0，CPHA=1。CLK串行时钟线空闲是为低电平，数据在SCK时钟的下降沿被采样，数据在CLK时钟的上升沿切换 模式2：CPOL= 1，CPHA=0。CLK串行时钟线空闲是为高电平，数据在SCK时钟的下降沿被采样，数据在CLK时钟的上升沿切换 模式3：CPOL= 1，CPHA=1。CLK串行时钟线空闲是为高电平，数据在SCK时钟的上升沿被采样，数据在CLK时钟的下降沿切换 其中比较常用的模式是模式0和模式3。为了更清晰的描述SPI总线的时序，下面展现了模式0下的SPI时序图1-5：  图1-5 mode0下的SPI时序图
SPI总线的优缺点  在点对点的通信中，SPI接口不需要进行寻址操作，且为全双工通信，显得简单高效。 SPI接口没有指定的流控制，没有应答机制确认是否接收到数据。  Linux SPI 框架 软件架构 Linux系统对spi设备具有很好的支持，linux系统下的spi驱动程序从逻辑上可以分为3个部分：
 spi核心（SPI Core）：SPI Core是Linux内核用来维护和管理spi的核心部分，SPI Core提供操作接口函数，允许一个spi master，spi driver和spi device初始化时在SPI Core中进行注册，以及退出时进行注销。 spi控制器驱动（SPI Master Driver）：SPI Master针对不同类型的spi控制器硬件，实现spi总线的硬件访问操作。SPI Master通过接口函数向SPI Core注册一个控制器。 spi设备驱动（SPI Device Driver）：SPI Driver是对应于spi设备端的驱动程序，通过接口函数向SPI Core进行注册，SPI Driver的作用是将spi设备挂接到spi总线上；Linux的软件架构图如图2-1所示：  图2-1 spi软件架构图
初始化及退出流程 注册spi控制器 注册spi控制器到内核分为两个阶段：第一个阶段，使用spi_alloc_master,分配一个spi_master的空间，具体流程如图2-2所示：
第二阶段，使用spi_register_master将第一阶段分配的spi_master注册到内核中，具体流程如2-3所示：
注销spi控制器 spi控制器注销的流程如图2-4所示：
关键数据结构 spi_device struct spi_device { struct device dev; /*spi控制器对应的device结构 struct spi_master *master; /*设备使用的master结构，挂在哪个主控制器下*/ u32 max_speed_hz; /*通讯时钟最大频率*/ u8 chip_select; /*片选号，每个master支持多个spi_device */ u8 mode; #define SPI_CPHA 0x01 /* clock phase */#define SPI_CPOL 0x02 /* clock polarity */#define SPI_MODE_0 (0|0) /* (original MicroWire) */#define SPI_MODE_1 (0|SPI_CPHA) #define SPI_MODE_2 (SPI_CPOL|0) #define SPI_MODE_3 (SPI_CPOL|SPI_CPHA) #define SPI_CS_HIGH 0x04 /* chipselect active high? */#define SPI_LSB_FIRST 0x08 /* per-word bits-on-wire */#define SPI_3WIRE 0x10 /* SI/SO signals shared */#define SPI_LOOP 0x20 /* loopback mode */#define SPI_NO_CS 0x40 /* 1 dev/bus, no chipselect */#define SPI_READY 0x80 /* slave pulls low to pause */ u8 bits_per_word; /*每个字长的比特数，默认是8*/ int irq; void *controller_state; /*控制器状态*/ void *controller_data; /*控制器数据*/ char modalias[SPI_NAME_SIZE]; /* 设备驱动的名字 */ int cs_gpio; /* chip select gpio */ /* * likely need more hooks for more protocol options affecting how * the controller talks to each chip, like: * - memory packing (12 bit samples into low bits, others zeroed) * - priority * - drop chipselect after each word * - chipselect delays * - ... */ }; spi_device代表一个外围spi设备，由master controller driver注册完成后扫描BSP中注册设备产生的设备链表并向spi_bus注册产生。在内核中，每个spi_device代表一个物理的spi设备。
spi_driver struct spi_driver { const struct spi_device_id *id_table; /*支持的spi_device设备表*/ int (*probe)(struct spi_device *spi); int (*remove)(struct spi_device *spi); void (*shutdown)(struct spi_device *spi); int (*suspend)(struct spi_device *spi, pm_message_t mesg); int (*resume)(struct spi_device *spi); struct device_driver driver; }; spi_driver代表一个SPI protocol drivers，即外设驱动
struct spi_master struct spi_master { struct device dev; /*spi控制器对应的device结构*/ struct list_head list; /*链表 /* other than negative (== assign one dynamically), bus_num is fully * board-specific. usually that simplifies to being SOC-specific. * example: one SOC has three SPI controllers, numbered 0..2, * and one board&#39;s schematics might show it using SPI-2. software * would normally use bus_num=2 for that controller. */ s16 bus_num; /*总线（或控制器编号）*/ /* chipselects will be integral to many controllers; some others * might use board-specific GPIOs. */ u16 num_chipselect; /*片选数量*/ /* some SPI controllers pose alignment requirements on DMAable * buffers; let protocol drivers know about these requirements. */ u16 dma_alignment; /* spi_device.mode flags understood by this controller driver */ u16 mode_bits; /* master支持的设备模式 */ /* bitmask of supported bits_per_word for transfers */ u32 bits_per_word_mask; /* other constraints relevant to this driver */ u16 flags; /*用于限定某些限制条件的标志位 #define SPI_MASTER_HALF_DUPLEX BIT(0) /* can&#39;t do full duplex */ #define SPI_MASTER_NO_RX BIT(1) /* can&#39;t do buffer read */#define SPI_MASTER_NO_TX BIT(2) /* can&#39;t do buffer write */ /* lock and mutex for SPI bus locking */ spinlock_t bus_lock_spinlock; struct mutex bus_lock_mutex; /* flag indicating that the SPI bus is locked for exclusive use */ bool bus_lock_flag; /* Setup mode and clock, etc (spi driver may call many times). * * IMPORTANT: this may be called when transfers to another * device are active. DO NOT UPDATE SHARED REGISTERS in ways * which could break those transfers. */ int (*setup)(struct spi_device *spi); /*根据spi设备更新硬件配置。设置spi工作模式、时钟等*/ /* bidirectional bulk transfers * * + The transfer() method may not sleep; its main role is * just to add the message to the queue. * + For now there&#39;s no remove-from-queue operation, or * any other request management * + To a given spi_device, message queueing is pure fifo * * + The master&#39;s main job is to process its message queue, * selecting a chip then transferring data * + If there are multiple spi_device children, the i/o queue * arbitration algorithm is unspecified (round robin, fifo, * priority, reservations, preemption, etc) * * + Chipselect stays active during the entire message * (unless modified by spi_transfer.cs_change != 0). * + The message transfers use clock and SPI mode parameters * previously established by setup() for this device */ int (*transfer)(struct spi_device *spi, struct spi_message *mesg); /*添加消息到队列的方法，此函数不可睡眠。它的职责是安排发生的传送并且调用注册的回调函数complete()*/ /* called on release() to free memory provided by spi_master */ void (*cleanup)(struct spi_device *spi);/*cleanup函数会在spidev_release函数中被调用，spidev_release被登记为spi dev的release函数。*/ /* * These hooks are for drivers that want to use the generic * master transfer queueing mechanism. If these are used, the * transfer() function above must NOT be specified by the driver. * Over time we expect SPI drivers to be phased over to this API. */ bool queued; struct kthread_worker kworker; /*用于管理数据传输消息队列的工作队列线程*/ struct task_struct *kworker_task; struct kthread_work pump_messages; /*具体实现数据传输队列的工作队列*/ spinlock_t queue_lock; struct list_head queue; /*该控制器的消息队列，所有等待传输的队列挂在该链表下*/ struct spi_message *cur_msg;/*当前正在处理的消息队列*/ bool busy; /忙状态*/ bool running; /*正在跑*/ bool rt; int (*prepare_transfer_hardware)(struct spi_master *master); /*回调函数，正式发起传输前会被调用，用于准备硬件资源*/ int (*transfer_one_message)(struct spi_master *master, struct spi_message *mesg); /*单个消息的原子传输回调函数，队列中每个消息都会回调一次该回调来完成传输工作*/ int (*unprepare_transfer_hardware)(struct spi_master *master); /*清理回调函数*/ /* gpio chip select */ int *cs_gpios; }; spi_master代表一个spi控制器。
struct spi_message 和spi_transfer 要完成和SPI设备的数据传输工作，我们还需要另外两个数据结构：spi_message和spi_transfer。
spi_message包含了一个的spi_transfer结构序列，一旦控制器接收了一个spi_message，其中的spi_transfer应该按顺序被发送，并且不能被其它spi_message打断，所以我们认为spi_message就是一次SPI数据交换的原子操作。下面我们看看这两个数据结构的定义：
struct spi_message ：
struct spi_message { struct list_head transfers; /*spi_transfer链表队列，此次消息的传输段队列，一个消息可以包含多个传输段。*/ struct spi_device *spi; /*传输的目的设备*/ unsigned is_dma_mapped:1; /*如果为真，此次调用提供dma和cpu虚拟地址。*/ /* REVISIT: we might want a flag affecting the behavior of the * last transfer ... allowing things like &#34;read 16 bit length L&#34; * immediately followed by &#34;read L bytes&#34;. Basically imposing * a specific message scheduling algorithm. * * Some controller drivers (message-at-a-time queue processing) * could provide that as their default scheduling algorithm. But * others (with multi-message pipelines) could need a flag to * tell them about such special cases. */ /* completion is reported through a callback */ void (*complete)(void *context);/*异步调用完成后的回调函数*/ void *context; /*回调函数的参数*/ unsigned actual_length; /*实际传输的长度*/ int status; /*该消息的发送结果，成功被置0，否则是一个负的错误码。*/ /* for optional use by whatever driver currently owns the * spi_message ... between calls to spi_async and then later * complete(), that&#39;s the spi_master controller driver. */ struct list_head queue; void *state; }; 链表字段queue用于把该结构挂在代表控制器的spi_master结构的queue字段上，控制器上可以同时被加入多个spi_message进行排队。另一个链表字段transfers则用于链接挂在本message下的spi_tranfer结构。complete回调函数则会在该message下的所有spi_transfer都被传输完成时被调用，以便通知协议驱动处理接收到的数据以及准备下一批需要发送的数据。我们再来看看spi_transfer结构：spi_transfer
struct spi_transfer { /* it&#39;s ok if tx_buf == rx_buf (right?) * for MicroWire, one buffer must be null * buffers must work with dma_*map_single() calls, unless * spi_message.is_dma_mapped reports a pre-existing mapping */ const void *tx_buf; /*发送缓冲区*/ void *rx_buf; /*接收缓冲区*/ unsigned len; /*缓冲区长度，tx和rx的大小（字节数）。指它们各自的大小*/ dma_addr_t tx_dma; /*tx的dma地址*/ dma_addr_t rx_dma; /*rx的dma地址*/ unsigned cs_change:1; /*当前spi_transfer发送完成之后重新片选*/ u8 bits_per_word; /*每个字长的比特数，0代表使用spi_device中的默认值8*/ u16 delay_usecs; /*发送完成一个spi_transfer后的延时时间，此次传输结束和片选改变之间的延时，之后就会启动另一个传输或者结束整个消息*/ u32 speed_hz; /*通信时钟。如果是0，使用默认值*/ #ifdef CONFIG_SPI_LOMBO  struct lombo_spi_operate_para *esop; #endif  struct list_head transfer_list; /*用于链接到spi_message，用来连接的双向链接节点*/ }; 首先，transfer_list链表字段用于把该transfer挂在一个spi_message结构中，tx_buf和rx_buf提供了非dma模式下的数据缓冲区地址，len则是需要传输数据的长度，tx_dma和rx_dma则给出了dma模式下的缓冲区地址。原则来讲，spi_transfer才是传输的最小单位，之所以又引进了spi_message进行打包，我觉得原因是：有时候希望往spi设备的多个不连续的地址（或寄存器）一次性写入，如果没有spi_message进行把这样的多个spi_transfer打包，因为通常真正的数据传送工作是在另一个内核线程（工作队列）中完成的，不打包的后果就是会造成更多的进程切换，效率降低，延迟增加，尤其对于多个不连续地址的小规模数据传送而言就更为明显。
spi_board_info struct spi_board_info { /* the device name and module name are coupled, like platform_bus; * &#34;modalias&#34; is normally the driver name. * * platform_data goes to spi_device.dev.platform_data, * controller_data goes to spi_device.controller_data, * irq is copied too */ char modalias[SPI_NAME_SIZE]; /*名字*/ const void *platform_data; /*平台数据*/ void *controller_data; /*控制器数据*/ int irq; /* slower signaling on noisy or low voltage boards */ u32 max_speed_hz; /*最大速率*/ /* bus_num is board specific and matches the bus_num of some * spi_master that will probably be registered later. * * chip_select reflects how this chip is wired to that master; * it&#39;s less than num_chipselect. */ u16 bus_num; /*spi总线编号*/ u16 chip_select; /*片选*/ /* mode becomes spi_device.mode, and is essential for chips * where the default of SPI_CS_HIGH = 0 is wrong. */ u8 mode; /*模式 */ /* ... may need additional spi_device chip config data here. * avoid stuff protocol drivers can set; but include stuff * needed to behave without being bound to a driver: * - quirks like clock rate mattering when not selected */ }; 数据传输流程 整体的数据传输流程大致上是这样的:
 定义一个spi_message结构； 用spi_message_init函数初始化spi_message； 定义一个或数个spi_transfer结构，初始化并为数据准备缓冲区并赋值给spi_transfer相应的字段（tx_buf，rx_buf等）； 通过spi_message_init函数把这些spi_transfer挂在spi_message结构下； 如果使用同步方式，调用spi_sync()，如果使用异步方式，调用spi_async();(我调试外设时，只使用过spi_sync  传输示意图如图2-5所示：
数据准备 spi_message_init static inline void spi_message_init(struct spi_message *m) { memset(m, 0, sizeof *m); INIT_LIST_HEAD(&amp;m-&gt;transfers); } 初始化spi_message：清空message，初始化transfers链表头。
spi_message_add_tail static inline void spi_message_add_tail(struct spi_transfer *t, struct spi_message *m) { list_add_tail(&amp;t-&gt;transfer_list, &amp;m-&gt;transfers); } 将spi_transfer加入到spi_message的链表尾部。
数据传输 SPI数据传输可以有两种方式：同步方式和异步方式。所谓同步方式是指数据传输的发起者必须等待本次传输的结束，期间不能做其它事情，用代码来解释就是，调用传输的函数后，直到数据传输完成，函数才会返回。而异步方式则正好相反，数据传输的发起者无需等待传输的结束，数据传输期间还可以做其它事情，用代码来解释就是，调用传输的函数后，函数会立刻返回而不用等待数据传输完成，我们只需设置一个回调函数，传输完成后，该回调函数会被调用以通知发起者数据传送已经完成。同步方式简单易用，很适合处理那些少量数据的单次传输。但是对于数据量大、次数多的传输来说，异步方式就显得更加合适。对于SPI控制器来说，要支持异步方式必须要考虑以下两种状况：
 对于同一个数据传输的发起者，既然异步方式无需等待数据传输完成即可返回，返回后，该发起者可以立刻又发起一个message，而这时上一个message还没有处理完。 对于另外一个不同的发起者来说，也有可能同时发起一次message传输请求 首先分析spi_sync()接口的实现流程，如图2-6：  其次分析spi_async_locked接口的实现流程，如图2-7所示：
spi_queued_transfer接口的实现流程如图3-8所示：
spi_pump_messages函数的处理流程如图3-9所示：
图中transfer_one_message是spi控制器驱动要实现的，主要功能是处理spi_message中的每个spi_transfer。
关键函数解析 spi_alloc_master 原型：
struct spi_master *spi_alloc_master(struct device *dev, unsigned size) 功能：分配一个spi_master结构体指针。
参数：dev:spi控制器device指针 size ：分配的driver-private data大小
返回值 ：成功，返回spi_master指针；否则返回NULL
spi_register_master 原型：
int spi_register_master(struct spi_master *master) 功能 注册spi控制器驱动到内核。
参数 master：spi_master指针
返回值 成功，返回0；否则返回错误码
spi_unregister_master 原型：
void spi_unregister_master(struct spi_master *master) 功能 注销spi控制器驱动。
参数 master：spi_master指针
返回值 无
实例Demo #include &lt;linux/types.h&gt;#include &lt;linux/kernel.h&gt;#include &lt;linux/delay.h&gt;#include &lt;linux/ide.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/errno.h&gt;#include &lt;linux/gpio.h&gt;#include &lt;linux/cdev.h&gt;#include &lt;linux/device.h&gt;#include &lt;linux/of_gpio.h&gt;#include &lt;linux/semaphore.h&gt;#include &lt;linux/timer.h&gt;#include &lt;linux/i2c.h&gt;#include &lt;linux/spi/spi.h&gt;#include &lt;linux/of.h&gt;#include &lt;linux/of_address.h&gt;#include &lt;linux/of_gpio.h&gt;#include &lt;linux/platform_device.h&gt;#include &lt;asm/mach/map.h&gt;#include &lt;asm/uaccess.h&gt;#include &lt;asm/io.h&gt;#include &#34;icm20608reg.h&#34;/*************************************************************** Copyright © ALIENTEK Co., Ltd. 1998-2029. All rights reserved. 文件名 : icm20608.c 作者 : 左工 版本 : V1.0 描述 : ICM20608 SPI驱动程序 其他 : 无 论坛 : 日志 : 初版V1.0 2019/9/2 左工创建 ***************************************************************/ #define ICM20608_CNT 1 #define ICM20608_NAME &#34;icm20608&#34;  struct icm20608_dev { dev_t devid; /* 设备号 */ struct cdev cdev; /* cdev */ struct class *class; /* 类 */ struct device *device; /* 设备 */ struct device_node *nd; /* 设备节点 */ int major; /* 主设备号 */ void *private_data; /* 私有数据 */ int cs_gpio; /* 片选所使用的GPIO编号 */ signed int gyro_x_adc; /* 陀螺仪X轴原始值 */ signed int gyro_y_adc; /* 陀螺仪Y轴原始值 */ signed int gyro_z_adc; /* 陀螺仪Z轴原始值 */ signed int accel_x_adc; /* 加速度计X轴原始值 */ signed int accel_y_adc; /* 加速度计Y轴原始值 */ signed int accel_z_adc; /* 加速度计Z轴原始值 */ signed int temp_adc; /* 温度原始值 */ }; static struct icm20608_dev icm20608dev; /* * @description : 从icm20608读取多个寄存器数据 * @param - dev: icm20608设备 * @param - reg: 要读取的寄存器首地址 * @param - val: 读取到的数据 * @param - len: 要读取的数据长度 * @return : 操作结果 */ static int icm20608_read_regs(struct icm20608_dev *dev, u8 reg, void *buf, int len) { int ret; unsigned char txdata[len]; struct spi_message m; struct spi_transfer *t; struct spi_device *spi = (struct spi_device *)dev-&gt;private_data; gpio_set_value(dev-&gt;cs_gpio, 0); /* 片选拉低，选中ICM20608 */ t = kzalloc(sizeof(struct spi_transfer), GFP_KERNEL); /* 申请内存 */ /* 第1次，发送要读取的寄存地址 */ txdata[0] = reg | 0x80; /* 写数据的时候寄存器地址bit8要置1 */ t-&gt;tx_buf = txdata; /* 要发送的数据 */ t-&gt;len = 1; /* 1个字节 */ spi_message_init(&amp;m); /* 初始化spi_message */ spi_message_add_tail(t, &amp;m);/* 将spi_transfer添加到spi_message队列 */ ret = spi_sync(spi, &amp;m); /* 同步发送 */ /* 第2次，读取数据 */ txdata[0] = 0xff; /* 随便一个值，此处无意义 */ t-&gt;rx_buf = buf; /* 读取到的数据 */ t-&gt;len = len; /* 要读取的数据长度 */ spi_message_init(&amp;m); /* 初始化spi_message */ spi_message_add_tail(t, &amp;m);/* 将spi_transfer添加到spi_message队列 */ ret = spi_sync(spi, &amp;m); /* 同步发送 */ kfree(t); /* 释放内存 */ gpio_set_value(dev-&gt;cs_gpio, 1); /* 片选拉高，释放ICM20608 */ return ret; } /* * @description : 向icm20608多个寄存器写入数据 * @param - dev: icm20608设备 * @param - reg: 要写入的寄存器首地址 * @param - val: 要写入的数据缓冲区 * @param - len: 要写入的数据长度 * @return : 操作结果 */ static s32 icm20608_write_regs(struct icm20608_dev *dev, u8 reg, u8 *buf, u8 len) { int ret; unsigned char txdata[len]; struct spi_message m; struct spi_transfer *t; struct spi_device *spi = (struct spi_device *)dev-&gt;private_data; t = kzalloc(sizeof(struct spi_transfer), GFP_KERNEL); /* 申请内存 */ gpio_set_value(dev-&gt;cs_gpio, 0); /* 片选拉低 */ /* 第1次，发送要读取的寄存地址 */ txdata[0] = reg &amp; ~0x80; /* 写数据的时候寄存器地址bit8要清零 */ t-&gt;tx_buf = txdata; /* 要发送的数据 */ t-&gt;len = 1; /* 1个字节 */ spi_message_init(&amp;m); /* 初始化spi_message */ spi_message_add_tail(t, &amp;m);/* 将spi_transfer添加到spi_message队列 */ ret = spi_sync(spi, &amp;m); /* 同步发送 */ /* 第2次，发送要写入的数据 */ t-&gt;tx_buf = buf; /* 要写入的数据 */ t-&gt;len = len; /* 写入的字节数 */ spi_message_init(&amp;m); /* 初始化spi_message */ spi_message_add_tail(t, &amp;m);/* 将spi_transfer添加到spi_message队列 */ ret = spi_sync(spi, &amp;m); /* 同步发送 */ kfree(t); /* 释放内存 */ gpio_set_value(dev-&gt;cs_gpio, 1);/* 片选拉高，释放ICM20608 */ return ret; } /* * @description : 读取icm20608指定寄存器值，读取一个寄存器 * @param - dev: icm20608设备 * @param - reg: 要读取的寄存器 * @return : 读取到的寄存器值 */ static unsigned char icm20608_read_onereg(struct icm20608_dev *dev, u8 reg) { u8 data = 0; icm20608_read_regs(dev, reg, &amp;data, 1); return data; } /* * @description : 向icm20608指定寄存器写入指定的值，写一个寄存器 * @param - dev: icm20608设备 * @param - reg: 要写的寄存器 * @param - data: 要写入的值 * @return : 无 */ static void icm20608_write_onereg(struct icm20608_dev *dev, u8 reg, u8 value) { u8 buf = value; icm20608_write_regs(dev, reg, &amp;buf, 1); } /* * @description : 读取ICM20608的数据，读取原始数据，包括三轴陀螺仪、 * : 三轴加速度计和内部温度。 * @param - dev : ICM20608设备 * @return : 无。 */ void icm20608_readdata(struct icm20608_dev *dev) { unsigned char data[14]; icm20608_read_regs(dev, ICM20_ACCEL_XOUT_H, data, 14); dev-&gt;accel_x_adc = (signed short)((data[0] &lt;&lt; 8) | data[1]); dev-&gt;accel_y_adc = (signed short)((data[2] &lt;&lt; 8) | data[3]); dev-&gt;accel_z_adc = (signed short)((data[4] &lt;&lt; 8) | data[5]); dev-&gt;temp_adc = (signed short)((data[6] &lt;&lt; 8) | data[7]); dev-&gt;gyro_x_adc = (signed short)((data[8] &lt;&lt; 8) | data[9]); dev-&gt;gyro_y_adc = (signed short)((data[10] &lt;&lt; 8) | data[11]); dev-&gt;gyro_z_adc = (signed short)((data[12] &lt;&lt; 8) | data[13]); } /* * @description : 打开设备 * @param - inode : 传递给驱动的inode * @param - filp : 设备文件，file结构体有个叫做privateate_data的成员变量 * 一般在open的时候将private_data似有向设备结构体。 * @return : 0 成功;其他 失败 */ static int icm20608_open(struct inode *inode, struct file *filp) { filp-&gt;private_data = &amp;icm20608dev; /* 设置私有数据 */ return 0; } /* * @description : 从设备读取数据 * @param - filp : 要打开的设备文件(文件描述符) * @param - buf : 返回给用户空间的数据缓冲区 * @param - cnt : 要读取的数据长度 * @param - offt : 相对于文件首地址的偏移 * @return : 读取的字节数，如果为负值，表示读取失败 */ static ssize_t icm20608_read(struct file *filp, char __user *buf, size_t cnt, loff_t *off) { signed int data[7]; long err = 0; struct icm20608_dev *dev = (struct icm20608_dev *)filp-&gt;private_data; icm20608_readdata(dev); data[0] = dev-&gt;gyro_x_adc; data[1] = dev-&gt;gyro_y_adc; data[2] = dev-&gt;gyro_z_adc; data[3] = dev-&gt;accel_x_adc; data[4] = dev-&gt;accel_y_adc; data[5] = dev-&gt;accel_z_adc; data[6] = dev-&gt;temp_adc; err = copy_to_user(buf, data, sizeof(data)); return 0; } /* * @description : 关闭/释放设备 * @param - filp : 要关闭的设备文件(文件描述符) * @return : 0 成功;其他 失败 */ static int icm20608_release(struct inode *inode, struct file *filp) { return 0; } /* icm20608操作函数 */ static const struct file_operations icm20608_ops = { .owner = THIS_MODULE, .open = icm20608_open, .read = icm20608_read, .release = icm20608_release, }; /* * ICM20608内部寄存器初始化函数 * @param : 无 * @return : 无 */ void icm20608_reginit(void) { u8 value = 0; icm20608_write_onereg(&amp;icm20608dev, ICM20_PWR_MGMT_1, 0x80); mdelay(50); icm20608_write_onereg(&amp;icm20608dev, ICM20_PWR_MGMT_1, 0x01); mdelay(50); value = icm20608_read_onereg(&amp;icm20608dev, ICM20_WHO_AM_I); printk(&#34;ICM20608 ID = %#X\r\n&#34;, value); icm20608_write_onereg(&amp;icm20608dev, ICM20_SMPLRT_DIV, 0x00); /* 输出速率是内部采样率 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_GYRO_CONFIG, 0x18); /* 陀螺仪±2000dps量程 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_ACCEL_CONFIG, 0x18); /* 加速度计±16G量程 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_CONFIG, 0x04); /* 陀螺仪低通滤波BW=20Hz */ icm20608_write_onereg(&amp;icm20608dev, ICM20_ACCEL_CONFIG2, 0x04); /* 加速度计低通滤波BW=21.2Hz */ icm20608_write_onereg(&amp;icm20608dev, ICM20_PWR_MGMT_2, 0x00); /* 打开加速度计和陀螺仪所有轴 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_LP_MODE_CFG, 0x00); /* 关闭低功耗 */ icm20608_write_onereg(&amp;icm20608dev, ICM20_FIFO_EN, 0x00); /* 关闭FIFO */ } /* * @description : spi驱动的probe函数，当驱动与 * 设备匹配以后此函数就会执行 * @param - client : spi设备 * @param - id : spi设备ID * */ static int icm20608_probe(struct spi_device *spi) { int ret = 0; /* 1、构建设备号 */ if (icm20608dev.major) { icm20608dev.devid = MKDEV(icm20608dev.major, 0); register_chrdev_region(icm20608dev.devid, ICM20608_CNT, ICM20608_NAME); } else { alloc_chrdev_region(&amp;icm20608dev.devid, 0, ICM20608_CNT, ICM20608_NAME); icm20608dev.major = MAJOR(icm20608dev.devid); } /* 2、注册设备 */ cdev_init(&amp;icm20608dev.cdev, &amp;icm20608_ops); cdev_add(&amp;icm20608dev.cdev, icm20608dev.devid, ICM20608_CNT); /* 3、创建类 */ icm20608dev.class = class_create(THIS_MODULE, ICM20608_NAME); if (IS_ERR(icm20608dev.class)) { return PTR_ERR(icm20608dev.class); } /* 4、创建设备 */ icm20608dev.device = device_create(icm20608dev.class, NULL, icm20608dev.devid, NULL, ICM20608_NAME); if (IS_ERR(icm20608dev.device)) { return PTR_ERR(icm20608dev.device); } /* 获取设备树中cs片选信号 */ icm20608dev.nd = of_find_node_by_path(&#34;/soc/aips-bus@02000000/spba-bus@02000000/ecspi@02010000&#34;); if(icm20608dev.nd == NULL) { printk(&#34;ecspi3 node not find!\r\n&#34;); return -EINVAL; } /* 2、 获取设备树中的gpio属性，得到BEEP所使用的BEEP编号 */ icm20608dev.cs_gpio = of_get_named_gpio(icm20608dev.nd, &#34;cs-gpio&#34;, 0); if(icm20608dev.cs_gpio &lt; 0) { printk(&#34;can&#39;t get cs-gpio&#34;); return -EINVAL; } /* 3、设置GPIO1_IO20为输出，并且输出高电平 */ ret = gpio_direction_output(icm20608dev.cs_gpio, 1); if(ret &lt; 0) { printk(&#34;can&#39;t set gpio!\r\n&#34;); } /*初始化spi_device */ spi-&gt;mode = SPI_MODE_0; /*MODE0，CPOL=0，CPHA=0*/ spi_setup(spi); icm20608dev.private_data = spi; /* 设置私有数据 */ /* 初始化ICM20608内部寄存器 */ icm20608_reginit(); return 0; } /* * @description : spi驱动的remove函数，移除spi驱动的时候此函数会执行 * @param - client : spi设备 * @return : 0，成功;其他负值,失败 */ static int icm20608_remove(struct spi_device *spi) { /* 删除设备 */ cdev_del(&amp;icm20608dev.cdev); unregister_chrdev_region(icm20608dev.devid, ICM20608_CNT); /* 注销掉类和设备 */ device_destroy(icm20608dev.class, icm20608dev.devid); class_destroy(icm20608dev.class); return 0; } /* 传统匹配方式ID列表 */ static const struct spi_device_id icm20608_id[] = { {&#34;alientek,icm20608&#34;, 0}, {} }; /* 设备树匹配列表 */ static const struct of_device_id icm20608_of_match[] = { { .compatible = &#34;alientek,icm20608&#34; }, { /* Sentinel */ } }; /* SPI驱动结构体 */ static struct spi_driver icm20608_driver = { .probe = icm20608_probe, .remove = icm20608_remove, .driver = { .owner = THIS_MODULE, .name = &#34;icm20608&#34;, .of_match_table = icm20608_of_match, }, .id_table = icm20608_id, }; /* * @description : 驱动入口函数 * @param : 无 * @return : 无 */ static int __init icm20608_init(void) { return spi_register_driver(&amp;icm20608_driver); } /* * @description : 驱动出口函数 * @param : 无 * @return : 无 */ static void __exit icm20608_exit(void) { spi_unregister_driver(&amp;icm20608_driver); } module_init(icm20608_init); module_exit(icm20608_exit); MODULE_LICENSE(&#34;GPL&#34;); MODULE_AUTHOR(yikoulinux&#34;); ]]></content>
  </entry>
  
  <entry>
    <title>什么是 nftables ? 它与 iptables 的区别是什么？</title>
    <url>/post/linux/difference-between-nftables-and-iptables.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>nftables, iptables</tag>
    </tags>
    <content type="html"><![CDATA[几乎每个 Linux 管理员都使用过 iptables，它是一个 Linux 系统的防火墙。
什么是 nftables ? 它与 iptables 的区别是什么？ 但是你可能还不太熟悉 nftables，这是一个新的防火墙，可为我们提供一些必需的升级，还有可能会取代 iptables。
为什么要使用 nftables 呢？ nftables 是由 Netfilter 开发的，该组织目前维护 iptables。nftables 的创建是为了解决 iptables 的一些性能和扩展问题。
除了新的语法和一些升级以外，nftables 的功能与 iptables 几乎是一样的。之所以推出 nftables 的另一个原因，是因为 iptables 的框架变的有点复杂，iptables, ip6tables, arptables 以及 ebtables 都有不同但相似的功能。
比如，在 iptables 中创建 IPv4 规则和在 ip6tables 中创建 IPv6 规则并保持两者同步是非常低效的。Nftables 旨在取代所有这些，成为一个集中的解决方案。
尽管自 2014 年以来，nftables 就被包含在 Linux 内核中，但随着采用范围的扩大，它最近越来越受欢迎。Linux 世界的变化很慢，过时的实用程序通常需要几年或更长的时间才能逐步淘汰，取而代之的是升级后的实用程序。
今天我们就简单介绍一下 nftables 和 iptables 之间的差异，并展示在新的 nftables 语法中配置防火墙规则的例子。
nftables 中的链（chains）和规则 在 iptables 中，有三个默认的链：输入、输出和转发。这三个“链”（以及其他链）包含“规则”，iptables 通过将网络流量与 链中的规则列表匹配进行工作。如果正在检查的流量与任何规则都不匹配，则链的默认策略将用于流量（即ACCEPT、DROP）。
Nftables的工作原理与此类似，也有“链”和“规则”。然而，它一开始没有任何基础链，这使得配置更加灵活。
iptables 效率低下的一个方面是，即使流量与任何规则都不匹配，所有网络数据也必须遍历上述链中的一个或多个。无论你是否配置了链，iptables仍然会根据它们检查你的网络数据。
在 Linux 中安装 nftables nftables 在所有主要的 Linux 发行版中都可用，可以使用发行版的包管理器安装。
在 Ubuntu 或基于 Debian 的系统中可使用如下命令：
sudo apt install nftables 设置 nftables在系统重启的时候自动启动，可执行如下操作：
sudo systemctl enable nftables.service iptables 和 nftables 之间的语法差异 与 iptables 相比，nftables 的语法更加简单，不过对于 iptables 中的语法，在 nftables 中也能用。
大家可使用 iptables-translate 工具，该工具接受 iptables 命令并将其转为等效的 nftables 命令，这是了解两种语法差异的一种简单方法。
使用以下命令在 Ubuntu 和基于 Debian 的发行版上安装 iptables-translate：
sudo apt install iptables-nftables-compat 安装后，你可以将 iptables 语法传递给 iptables-translate 命令，它将返回 nftables 等效命令。
下面我们看一些具体的语法示例。
阻止传入连接 下述命令将阻止来自IP地址192.168.2.1的传入连接：
$ iptables-translate -A INPUT -s 192.168.2.1 -j DROP nft add rule ip filter INPUT ip saddr 192.168.2.1 counter drop 允许传入SSH连接 放开 ssh 连接权限：
$ iptables-translate -A INPUT -p tcp --dport 22 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT nft add rule ip filter INPUT tcp dport 22 ct state new,established counter accept 允许来自特定 IP 范围的传入SSH连接 如果只想允许来自192.168.1.0/24的传入SSH连接：
$ iptables-translate -A INPUT -p tcp -s 192.168.1.0/24 --dport 22 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT nft add rule ip filter INPUT ip saddr 192.168.1.0/24 tcp dport 22 ct state new,established counter accept 允许MySQL连接到eth0网络接口 $ iptables-translate -A INPUT -i eth0 -p tcp --dport 3306 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT nft add rule ip filter INPUT iifname eth0 tcp dport 3306ct state new,established counter accept 允许传入HTTP和HTTPS流量 为了允许特定类型的流量，以下是这两个命令的语法：
$ iptables-translate -A INPUT -p tcp -m multiport --dports 80,443 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT nft add rule ip filter INPUT ip protocol tcp tcp dport { 80,443} ct state new,established counter accept 从这些例子中可以看出，nftables 语法与 iptables 非常相似，但命令更直观一些。
nftables 日志 上述nft命令示例中的“counter”选项告诉nftables统计规则被触碰的次数，就像默认情况下使用的iptables一样。
在nftables中，需要指定：
nft add rule ip filter INPUT ip saddr 192.168.2.1 counter accept nftables内置了用于导出配置的选项。它目前支持XML和JSON。
nft export xml ]]></content>
  </entry>
  
  <entry>
    <title>风河支持NXP S32G3——信心百倍、加速创新</title>
    <url>/post/news/wind-river-supports-nxp-s32g3.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Wind River</tag>
      <tag>NXP</tag>
      <tag>S32G3</tag>
    </tags>
    <content type="html"><![CDATA[风河公司与NXP公司的合作伙伴关系深厚且长远，由此不断地为我们的共同客户带来新的效益。 风河公司非常兴奋地宣布其运行时（Runtime）产品组合和Wind River Studio Linux 服务都已经支持下一代NXP S32G3处理器，从而有力地促进企业客户加速智能边缘设备的创建与部署。
具体而言，风河将为VxWorks、Wind River Linux和Helix虚拟化平台提供S32G3 BSP（板级支持包），以及配套的设计、全生命周期安全与维护服务。例如，企业客户希望充分利用S32G3处理器独特的车辆场景功能，而风河的实时产品阵容以及久经验证的嵌入式专业知识都将在相应的软件支持平台上助力汽车解决方案的设计与构建。
以上都是风河与NXP长期合作伙伴关系的基本组成部分，双方将共同致力于为嵌入式行业提供成熟可靠的硬件和软件解决方案。两家公司密切合作，其系统化效益就是形成了紧密集成的解决方案，获得更高的开发人员生产力、更佳的成本效率，还有更高的可靠性以及更快的上市速度。
无论您属于哪个行业，无论您的企业正在为智能边缘创建什么样的系统或设备，风河广泛的软件产品阵容和DevOps成套工具都可以帮助您充分发挥NXP硬件潜能，加速您的项目进程。以下是风河为NXP客户提供支持的几个典型代表：
 BSP 支持：风河为NXP系列处理器提供众多BSP，包括S32G、I.MX和Layerscape系列。 NXP LINUX SDK支持：针对NXP基于Yocto的Linux软件开发工具包，Wind River Studio Linux Services提供安全扫描、漏洞缓解和补救以及全生命周期管理和维护服务。 汽车解决方案：VxWorks和Wind River Linux为汽车网关、域和区域控制器提供高性能实时解决方案。在运行Linux或Android的i.MX应用处理器上构建信息娱乐解决方案方面，风河也拥有丰富的经验。 工业、医疗和机器人解决方案：风河拥有大量的NXP BSP ，非常适合用于关键基础设施、医疗和机器人的设计，因为它们都需要依赖于VxWorks的实时和确定性或Wind River Linux的开源灵活性。风河还为多个i.MX应用处理器提供VxWorks和Wind River Linux BSP，包括最新的i.MX x 93以及Helix Virtualization Platform虚拟化平台。 航空航天和国防解决方案：凡是需要安全认证的嵌入式设计都将得益于我们对NXP处理器的支持，从传统的Power架构到最新的Arm架构解决方案，如LX2160。借助于我们的Helix Virtualization Platform虚拟化平台和VxWorks和Wind River Linux的BSP，可以将NXP解决方案作为当今许多飞行系统的基石。 面向NXP平台的数字孪生和模拟仿真：帮助测试前移且提前启动软件项目并更快地推进开发工作，更快地构建更高质量且更安全的软件系统，并与DevOps开发实践完全集成。模拟仿真基于NXP硬件和软件的完整系统，支持ARM和PowerPC架构。 风河与NXP合作的广度和深度以及对最新产品的支持，都将为企业客户带来了巨大的价值，例如简化整个团队的开发流程以及加快产品上市速度。我们期待在S32G3上看到令人兴奋的新产品。  原文连接 VxWorks俱乐部  
]]></content>
  </entry>
  
  <entry>
    <title>Linux中pdf转word的工具你知道几个</title>
    <url>/post/linux/five-tools-to-convert-pdf-to-word-in-linux.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>PDF</tag>
      <tag>Word</tag>
    </tags>
    <content type="html"><![CDATA[下面推荐5款Linux中pdf转word的工具
LibreOffice LibreOffice是一个免费的开源Office套件，可以将PDF文件转换为Word文档。
# 安装LibreOffice sudo apt-get install libreoffice # 将PDF转换为Word文档 libreoffice --convert-to docx filename.pdf 其中，“docx”表示要将PDF转换为的输出格式，“filename.pdf”是要转换的PDF文件的文件名。该工具可以在Linux系统中使用，并且命令简单易用。
Pdf2doc Pdf2doc是一个基于Python的命令行工具，可以将PDF文件转换为Microsoft Word文档。
# 安装Pdf2doc sudo apt-get install pdf2doc # 将PDF转换为Word文档 pdf2doc filename.pdf 在这个命令中，“filename.pdf”是要转换的PDF文件的文件名。该工具可以在Linux中使用，只需在终端输入相应的命令即可。
GImageReader GImageReader是一款免费的OCR（光学字符识别）软件，可以将扫描的PDF文件转换为Word文档。
# 安装GImageReader sudo apt-get install gimagereader # 将PDF转换为Word文档 gimagereader filename.pdf 在这个命令中，“filename.pdf”是要转换的PDF文件的文件名。该工具支持多种语言的OCR识别，可以在Linux中使用。
Pandoc Pandoc是一个跨平台的文档格式转换器，支持将PDF文件转换为Word文档。
# 安装Pandoc sudo apt-get install pandoc # 将PDF转换为Word文档 pandoc -s -o output.docx input.pdf 在这个命令中，“-s”表示生成带有样式的Word文档，“-o”后面跟输出文件的名称和保存的路径，“input.pdf”是要转换的PDF文件的文件名。该工具可以在Linux中进行使用。
Unoconv Unoconv是一个用于文件格式转换的Python包，可以将PDF文件转换为Word文档。
# 安装Unoconv sudo apt-get install unoconv # 将PDF转换为Word文档 unoconv -f docx filename.pdf 在这个命令中，“docx”表示要将PDF文件转换成的输出格式，“filename.pdf”表明要转换的PDF文件的文件名。这个工具也非常简单易用。
总结：以上是5个将PDF文件转换为Word文档的Linux工具，它们都是免费的工具，不需要任何商业版本。这些工具均可以在Linux平台上使用，并且可以快速并且容易地将PDF文件转换为Word文档。
]]></content>
  </entry>
  
  <entry>
    <title>Linux系统内核概述</title>
    <url>/post/linux/linux-kernel-overview.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Kernel</tag>
    </tags>
    <content type="html"><![CDATA[Linux 内核是一种开源的类 Unix 操作系统宏内核。
Linux 内核是 Linux 操作系统的主要组件，也是计算机硬件与其进程之间的核心接口。它负责两者之间的通信，还要尽可能高效地管理资源。之所以称为内核，是因为它在操作系统中就像果实硬壳中的种子一样，并且控制着硬件的所有主要功能。内核的用途主要有以下 4 项工作：
  内存管理：追踪记录有多少内存存储了什么以及存储在哪里
  进程管理：确定哪些进程可以使用中央处理器、何时使用以及持续多长时间
  设备驱动程序：充当硬件与进程之间的调解程序/解释程序
  系统调用和安全防护：从流程接受服务请求
  在正确实施的情况下，内核对于用户是不可见的，它在自己的小世界(称为内核空间)中工作，并从中分配内存和跟踪所有内容的存储位置。用户所看到的内容则被称为用户空间。这些应用通过系统调用接口(SCI)与内核进行交互。
内核简介 单内核体系设计、但充分借鉴了微内核设计体系的优点，为内核引入模块化机制。
Linux 内核的重要组成部分，主要有以下几部分：
kernel内核核心，一般为 bzImage通常在 /boot 目录下，名称为 vmlinuz-VERSION-RELEASE kernel object内核对象，一般放置于 /lib/modules/VERSION-RELEASE/[ ] ==&gt; N ==&gt; 不编译进内核[M] ==&gt; M ==&gt; 编译为模块文件[*] ==&gt; Y ==&gt; 编译进内核 辅助文件(ramdisk)initrdinitramfs 内核模块 uname 命令 使用格式 uname [OPTION]&hellip;
参数解释  -n 显示节点名称 -r 显示VERSION-RELEASE -s 内核名称 -v 内核版本 -n 节点名 -m 硬件名称 -i 硬件平台 -p 处理器类型 -o 操作系统  # uname -m i686 # uname -r 2.6.32-573.22.1.el6.i686 # uname -a Linux MyServer 2.6.32-573.22.1.el6.i686 ... i686 i386 GNU/Linux lsmod 命令 显示由核心已经装载的内核模块
命令定义 显示的内容来自于: /proc/modules 文件。
使用 lsmod 命令时，常会采用类似 lsmod | grep -i ext4 这样的命令来查询系统是否加载了某些模块。
# cat /proc/modules iptable_filter 2173 0 - Live 0xed9b2000 ip_tables 9567 1 iptable_filter, Live 0xed9a9000 ext3 203718 1 - Live 0xed962000 jbd 65315 1 ext3, Live 0xed904000 xenfs 4360 1 - Live 0xed8e6000 ipv6 271097 14 - Live 0xed88e000 xen_netfront 15871 0 - Live 0xed7d9000 ext4 339812 2 - Live 0xed764000 jbd2 75927 1 ext4, Live 0xed6d9000 mbcache 6017 2 ext3,ext4, Live 0xed6b7000 xen_blkfront 19209 5 - Live 0xed69f000 dm_mirror 11969 0 - Live 0xed68d000 dm_region_hash 9644 1 dm_mirror, Live 0xed67e000 dm_log 8322 2 dm_mirror,dm_region_hash, Live 0xed672000 dm_mod 84711 11 dm_mirror,dm_log, Live 0xed64e000 # lsmod | grep ext4 ext4 339812 2 jbd2 75927 1 ext4 mbcache 6017 2 ext3,ext4 字段含义  第 1 列：表示模块的名称 第 2 列：表示模块的大小 第 3 列：表示依赖模块的个数 第 4 列：表示依赖模块的内容  # lsmod Module Size Used by iptable_filter 2173 0 ip_tables 9567 1 iptable_filter ext3 203718 1 jbd 65315 1 ext3 xenfs 4360 1 ipv6 271097 14 xen_netfront 15871 0 ext4 339812 2 jbd2 75927 1 ext4 mbcache 6017 2 ext3,ext4 xen_blkfront 19209 5 dm_mirror 11969 0 dm_region_hash 9644 1 dm_mirror dm_log 8322 2 dm_mirror,dm_region_hash dm_mod 84711 11 dm_mirror,dm_log modinfo 命令 显示模块的详细描述信息
命令定义 modinfo 列出 Linux 内核中命令行指定的模块的信息。
modinfo 能够查询系统中未安装的模块信息。
若模块名不是一个文件名，则会在 /lib/modules/version 目录中搜索，就像 modprobe 一样。
modinfo 默认情况下，为了便于阅读，以下面的格式列出模块的每个属性：fieldname : value。
语法 modinfo [选项] [ modulename|filename&hellip; ]
选项  -n 只显示模块文件路径 -p 显示模块参数 -a author -d description -l license -0 使用’\0’字符分隔 field 值，而不是一个新行，对脚本比较有用  实战演示 # modinfo ext4 filename: /lib/modules/2.6.32-573.22.1.el6.i686/kernel/fs/ext4/ext4.ko license: GPL description: Fourth Extended Filesystem author: Remy Card, Stephen Tweedie, Andrew Morton, Andreas Dilger, Theodore and others srcversion: CB1B990F5A758DFB0FB12F1 depends: mbcache,jbd2 vermagic: 2.6.32-573.22.1.el6.i686 SMP mod_unload modversions 686 # modinfo btrfs filename: /lib/modules/2.6.32-573.22.1.el6.i686/kernel/fs/btrfs/btrfs.ko license: GPL alias: devname:btrfs-control alias: char-major-10-234 srcversion: B412C18B0F5BF7F1B3C941A depends: libcrc32c,zlib_deflate,lzo_compress,lzo_decompress vermagic: 2.6.32-573.22.1.el6.i686 SMP mod_unload modversions 686 modprobe 命令 装载或卸载内核模块
命令定义 配置文件/etc/modprobe.conf/etc/modprobe.d/*.conf
解决依赖modprobe需要一个最新的modules.dep文件，可以用depmod来生成该文件列出了每一个模块需要的其他模块，modprobe使用这个去自动添加或删除模块的依赖
bash # modules.dep为解决依赖的配置文件，modules.dep.bin二进制文件运行 # ls /lib/modules/2.6.32-358.6.1.el6.i686/ build modules.block modules.ieee1394map modules.ofmap modules.symbols.bin weak-updates extra modules.ccwmap modules.inputmap modules.order modules.usbmap kernel modules.dep modules.isapnpmap modules.pcimap source modules.alias modules.dep.bin modules.modesetting modules.seriomap updates modules.alias.bin modules.drm modules.networking modules.symbols vdso 语法 modprobe [ -c ]
modprobe [ -l ] [ -t dirname ] [ wildcard ]
modprobe [ -r ] [ -v ] [ -n ] [ -i ] [ modulename … ]
选项  -v显示程序在干什么，通常在出问题的情况下，modprobe 才显示信息 -C重载，默认配置文件(/etc/modprobe.conf 或 /etc/modprobe.d) -c输出配置文件并退出 -n可以和 -v 选项一起使用，调试非常有用 -i该选项会使得 modprobe 忽略配置文件中的，在命令行上输入的 install 和 remove -q一般 modprobe 删除或插入一个模块时，若没有找到会提示错误。使用该选项，会忽略指定的模块，并不提示任何错误信息。 -r该选项会导致 modprobe 去删除，而不是插入一个模块通常没有没有理由去删除内核模块，除非是一些有 bug 的模块 -f使用该选项是比较危险的和同时使用 –force-vermagic，–force-modversion 一样 -l列出所有模块 -a插入所有命令行中的模块 -t强制 -l 显示 dirname 中的模块 -s错误信息写入 syslog  depmod 命令 内核模块依赖关系文件及系统信息映射文件的生成工具
语法 depmod [-adeisvV][-m &lt;文件&gt;][&ndash;help][模块名称]
参数  -a 分析所有可用的模块 -d 执行排错模式 -e 输出无法参照的符号 -i 不检查符号表的版本 -m&lt;文件&gt; 使用指定的符号表文件 -s 在系统记录中记录错误 -v 执行时显示详细的信息 -V 显示版本信息 &ndash;help 显示帮助  insmod 和 rmmod 命令 装载或卸载内核模块
不解决依赖关系，需要自己手动卸载
insmod命令 向 Linux 内核中插入一个模块
insmod 是一个向内核插入模块的小程序
大多数用户使用 modprobe 因为它比较智能化
insmod [ filename ] [ module options&hellip; ]
rmmod命令 命令解析删除内核中的一模块rmmod 是一个可以从内核中删除模块的小程序，大多数用户使用modprobe -r去删除模块
语法格式rmmod [ modulename ]
参数选项-f除非编译内核时 CONFIG_MODULE_FORCE_UNLOAD 被设置该命令才有效果，否则没效果用该选项可以删除正在被使用的模块，设计为不能删除的模块，或者标记为 unsafe 的模块-wrmmod 拒绝删除正在被使用的模块使用该选项后，指定的模块会被孤立起来，直到不被使用-s将错误信息写入 syslog，而不是标准错误(stderr)
/proc 目录 内核把自己内部状态信息及统计信息，以及可配置参数通过 proc 伪文件系统加以输出。
# ls /proc/ 1 1173 22 29855 35 47 60 973 filesystems loadavg scsi version 10 12 23 3 36 48 600 buddyinfo fs locks self vmallocinfo 1071 13 232 30 37 49 61 bus interrupts mdstat slabinfo vmstat 1082 14 234 31 38 5 62 cgroups iomem meminfo softirqs xen 1085 15 24 31314 39 528 7 cmdline ioports misc stat zoneinfo 11 16 25 317 4 531 739 cpuinfo irq modules swaps 1150 17 252 318 40 543 8 crypto kallsyms mounts sys 1162 18 253 32 41 56 808 devices kcore mtd sysrq-trigger 1163 19 26 320 42 566 830 diskstats keys net sysvipc 1165 1908 27 33 43 567 853 dma key-users pagetypeinfo timer_list 1167 2 28 330 44 57 9 driver kmsg partitions timer_stats 1169 20 29 334 45 59 94 execdomains kpagecount sched_debug tty 1171 21 29853 34 46 6 95 fb kpageflags schedstat uptime sysctl 命令 语法格式 sysctl(选项)(参数)
命令参数  -n 打印值时不打印关键字 -e 忽略未知关键字错误 -N 仅打印名称 -w 当改变 sysctl 设置时使用此项 -p 从配置文件 /etc/sysctl.conf 加载内核参数设置 -a 打印当前所有可用的内核参数变量和值 -A 以表格方式打印当前所有可用的内核参数变量和值  默认配置文件 /etc/sysctl.conf
命令使用方式 (1) 设置某参数sysctl -w parameter=VALUE (2) 通过读取配置文件设置参数sysctl -p [/path/to/conf_file]
参数说明 只读：输出信息
可写：可接受用户指定“新值”来实现对内核某功能或特性的配置/proc/sys
两种修改方式 (1) sysctl 命令用于查看或设定此目录中诸多参数sysctl -w path.to.parameter=VALUEsysctl -w kernel.hostname=mail.escapelife.com
(2) echo 命令通过重定向的方式也可以修改大多数参数的值echo &ldquo;VALUE&rdquo; &gt; /proc/sys/path/to/parameterecho &ldquo; www.escapelife.com  &rdquo; &gt; /proc/sys/kernel/hostname
配置文件中常用的几个参数
net.ipv4.ip_forward /proc/sys/net/ipv4/ip_forward vm.drop_caches /proc/sys/vm/drop_caches kernel.hostname /proc/sys/kernel/hostname 修改配置文件 # cat /etc/sysctl.conf # Kernel sysctl configuration file for Red Hat Linux # Controls IP packet forwarding net.ipv4.ip_forward = 0 # Controls source route verification net.ipv4.conf.default.rp_filter = 1 # Do not accept source routing net.ipv4.conf.default.accept_source_route = 0 # Controls the System Request debugging functionality of the kernel kernel.sysrq = 0 # Controls whether core dumps will append the PID to the core filename. # Useful for debugging multi-threaded applications. kernel.core_uses_pid = 1 # Controls the use of TCP syncookies net.ipv4.tcp_syncookies = 1 # Disable netfilter on bridges. net.bridge.bridge-nf-call-ip6tables = 0 net.bridge.bridge-nf-call-iptables = 0 net.bridge.bridge-nf-call-arptables = 0 # Controls the default maxmimum size of a mesage queue kernel.msgmnb = 65536 # Controls the maximum size of a message, in bytes kernel.msgmax = 65536 # Controls the maximum shared segment size, in bytes kernel.shmmax = 4294967295 # Controls the maximum number of shared memory segments, in pages kernel.shmall = 268435456 # Auto-enabled by xs-tools:install.sh net.ipv4.conf.all.arp_notify = 1 实战演示 # 查看所有可读变量 sysctl -a # 修改对应参数 sysctl -w kernel.sysrq=0 sysctl -w kernel.core_uses_pid=1 sysctl -w net.ipv4.conf.default.accept_redirects=0 # 如果希望屏蔽别人 ping 你的主机，配置文件修改 net.ipv4.icmp_echo_ignore_all = 1 # 编辑完成后，请执行以下命令使变动立即生效 /sbin/sysctl -p /sbin/sysctl -w net.ipv4.route.flush=1 /sys 目录 sysfs 伪文件系统，输出内核识别出的各硬件设备的相关属性信息，也有内核对硬件特性的设定信息。有些参数是可以修改的，用于调整硬件工作特性。
udev  udev 是运行用户空间程序。 udev 通 /sys/ 路径下输出的信息动态为各设备创建所需要设备文件。 udev 是 Linux 内核的设备管理器，它取代了 udevadmin 和 hotplug，负责管理 /dev 中的设备节点。 udev 也处理所有用户空间发生的硬件添加、删除事件，以及某些特定设备所需的固件加载。 udev 为设备创建设备文件时，会读取其事先定义好的规则文件，一般在 /etc/udev/rules.d 及 /usr/lib/udev/rules.d 目录下。  ramdisk 文件的制作 方法一 mkinitrd 命令
为当前正在使用的内核重新制作 ramdisk 文件
mkinitrd /boot/initramfs-$(uname -r).img $(uname -r)
# 移动ramdisk文件到/root目录下 mv /boot/initramfs-2.6.32...img /root # 为当前正在使用的内核重新制作ramdisk文件 mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) 方法二 dracut 命令
为当前正在使用的内核重新制作 ramdisk 文件
dracut /boot/initramfs-$(uname -r).img $(uname -r)
# 移动ramdisk文件到/root目录下 mv /boot/initramfs-2.6.32...img /root # 为当前正在使用的内核重新制作ramdisk文件 dracut /boot/initramfs-$(uname -r).img $(uname -r) 查看 ramdisk # 使用file命令查看ramdisk文件发现是以gz压缩存放的 file /boot/initramfs-2.6.32-504.el6.x86_64.img # 改名称，解压 cd /boot/ mv initramfs-2.6.32-504.el6.x86_64.img initramfs-2.6.32-504.el6.x86_64.img.gz gzip -d initramfs-2.6.32-504.el6.x86_64.img.gz # 使用file命令查看发现是以cpio存放的文本文件 file initramfs-2.6.32-504.el6.x86_64.img # 解压这个文本文件 # 之后会在initrd目录下生成相应的文件，一个微型的/root mkdir initrd cd initrd cpio -id &lt; ../initramfs-2.6.32-504.el6.x86_64.img # 这个时候就可以查看init脚本文件了 cat init # 在sbin文件中存放着相关的命令 ls sbin 编译内核 前提准备 (1) 准备好开发环境
包组(CentOS 6)
Server Platform Development
Development Tools
(2) 获取目标主机上硬件设备的相关信息
CPUcat /proc/cpuinfox86info -alscpu
PCI 设备lspci-v-vvlsusb-v-vvlsblk
了解全部硬件设备信息hal-device
(3) 获取到目标主机系统功能的相关信息
(4) 获取内核源代码包
 www.kernel.org  
简易安装内核 简易安装 获取当前系统的安装文件作为模块安装较为方便
修改相应的参数即可
只适用于当前特定的内核版本
当前系统的安装文件在 config-2.6.32-504.el6.x86_64
简单依据模板文件的制作内核 # 下载对应的Linux内核版本进行解压缩 # 会在/usr/src目录下创建debug、kernels和linux-3.10.67目录 tar xf linux-3.10.67.tar.xz -C /usr/src # 为了方便多内核共存，使用连接指向 # 会在当前目录下创建一个链接文件 linux -&gt; linux-3.10.67 cd /usr/src ln -sv linux-3.10.67 linux # 创建模板 cd linux # 查看链接指向的文件内容 ls # 拷贝系统自带的模板文件 cp /boot/config-$(uname -r) .config # 打开图形界面配置内核选项，选择添加、删除内核模块 # 添加的默认选项来自.config配置文件 make menuconfig # 使用screen来不中断安装 screen # 采用几个线程进行编译 make -j n # 安装内核 make modules_install # make install中将会安装内容 # 安装bzImage为/boot/vmlinuz-VERSION-RELEASE # 生成initramfs文件 # 编辑grub的配置文件 make install # 重启系统，并测试使用新内核，不是默认启动内核 init 6 详解编译内核 (1) 配置内核选项 支持“更新”模式进行配置  (a) make config：基于命令行以遍历的方式去配置内核中可配置的每个选项 (b) make menuconfig：基于 curses 的文本窗口界面 (c) make gconfig：基于 GTK 开发环境的窗口界面 (d) make xconfig：基于 Qt 开发环境的窗口界面  支持“全新配置”模式进行配置  (a) make defconfig：基于内核为目标平台提供的“默认”配置进行配置 (b) make allnoconfig: 所有选项均回答为”no“  (2) 编译 - make [-j #] 如何只编译内核中的一部分功能
# (a)只编译某子目录中的相关代码 cd /usr/src/linux make dir/ # (b)只编译一个特定的模块 cd /usr/src/linux make dir/file.ko # 例如：只为e1000编译驱动 make drivers/net/ethernet/intel/e1000/e1000.ko 如何交叉编译内核
# 编译的目标平台与当前平台不相同； make ARCH=arch_name # 要获取特定目标平台的使用帮助 make ARCH=arch_name help 如何在已经执行过编译操作的内核源码树做重新编译
# 事先清理操作 # 清理大多数编译生成的文件，但会保留config文件等 make clean # 清理所有编译生成的文件、config及某些备份文件 make mrproper # mrproper、patches以及编辑器备份文件 make distclean ]]></content>
  </entry>
  
  <entry>
    <title>如何在 Linux 使用 pv 命令监控数据传输速度与进度</title>
    <url>/post/linux/using-pv-cmd-to-monitor-data-transfer-speed-and-progress.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>pv</tag>
    </tags>
    <content type="html"><![CDATA[pv 命令是一个在 Linux/Unix 系统的实用工具，用于监控数据的流动。pv 命令可以用于计算数据传输的速度，显示进度条以及估算剩余时间等。
pv命令可以通过管道监控数据流的进度，但是无法直接监控mv命令的进度。这是因为mv命令实际上是将文件从一个位置移动到另一个位置，而不是在管道中传输数据。
默认情况下，pv 命令只会显示一个进度条，以及传输速度和估算的剩余时间等信息。除了默认的进度条外，pv 命令还支持许多选项。
在本教程中，我们将会说明如何在 Linux 使用 pv 命令监控数据的传输速度并估算剩余时间等信息。
pv 命令 pv 命令的使用非常简单，只需在终端输入 pv 命令，后面是需要监视的文件或数据流即可。
pv file.txt &gt; /dev/null pv 命令选项 这些选项可以用于更好地控制 pv 命令的输出。下面是一些常用的选项：
 -f，&ndash;force：  强制 pv 命令执行，即使标准错误不是终端也输出。
 -n，&ndash;numeric：  显示数字的百分比和速度而不是进度条。
 -q，&ndash;quiet：  不输出错误和警告信息。
 -s，&ndash;size SIZE：  指定输入流的大小。
 -t，&ndash;timer：  显示时间估计。
 -h，&ndash;help：  显示 pv 命令的帮助信息。
 -V，&ndash;version：  显示 pv 命令的版本信息。
下面是一些使用pv命令的示例：
监控文件传输 在这个示例中，pv 命令将 file.txt 文件的内容输出到 /dev/null 空设备中，这是一个类似于垃圾桶的设备，只可写入但无法读取的设备。
可以将其用于丢弃不需要的输出。pv 命令会计算 file.txt 文件的大小并显示一个进度条，以及估算剩余时间和传输速度等信息。
pv file.txt &gt; /dev/null 监控标准输入流向标准输出的数据 在这个示例中，pv 命令将 file.txt 文件的内容通过管道传递给 gzip 命令进行压缩，然后将压缩后的数据写入到 file.txt.gz文件。
pv 命令会监控管道中的数据流，并显示一个进度条，以及估算剩余时间和传输速度等信息。
cat file.txt | pv | gzip &gt; file.txt.gz 评估数据传输时间 在这个示例中，pv 命令将 iso 镜像文件的内容通过管道传递给 dd 命令进行写入，pv命令会计算 iso 文件的大小并显示一个进度条，以及估算剩余时间和传输速度等信息。
pv -pteb file.iso | dd of=/dev/sdb 使用场景 以上示例只是 pv 命令的基本用法，但实际上，pv 命令可以在许多场景中发挥重要的作用。例如，在备份文件或复制大量文件时，pv 命令可以帮助用户跟踪数据的传输速度和进度，以及估算剩余时间。
对于网络传输或云存储等场景中，pv 命令可以帮助用户监视数据流，确保传输的可靠性和效率。
此外，在编写脚本或命令行工具时，pv 命令也可以用于监视数据流并提供更好的用户体验。
除了以上介绍的选项和示例外，pv 命令还具有许多其他功能。例如，pv 命令可以与其他命令和工具结合使用，如tar、rsync、scp等，实现更复杂的数据传输和备份操作。此外，pv 命令还支持在终端显示颜色，以便用户更容易地识别不同类型的信息。
限制 需要注意的是，pv 命令虽然非常实用，但也有一些局限性。首先，pv 命令只能监控单个数据流，而不能同时监控多个数据流。其次，pv 命令无法解密加密的数据流，因此无法直接监视加密的数据流。
最后，pv 命令会消耗一定的 CPU 资源和内存，因此在处理大文件或大量数据时，可能会对系统性能产生一定的影响。
总的来说，pv 命令是一个非常实用的 Linux/Unix 工具，可以帮助用户监控数据流，计算传输速度和估算剩余时间等信息。
通过结合不同的选项和示例，用户可以充分利用 pv 命令的功能，以更好地管理和监视数据传输和备份操作。
如果您有任何问题或反馈，请随时发表评论。点击下方阅读原文获取更好排版格式与文章参考引用。
]]></content>
  </entry>
  
  <entry>
    <title>关于extern C的的详细剖析</title>
    <url>/post/programming/extern-c-detailed-analysis.html</url>
    <categories><category>Programming</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>extern</tag>
    </tags>
    <content type="html"><![CDATA[在你工作过的系统里，不知能否看到类似下面的代码。
这好像没有什么问题，你应该还会想 “嗯，是啊，我们的代码都是这样写的，从来没有因此碰到过什么麻烦啊～”。
你说的没错，如果你的头文件从来没有被任何C++程序引用过的话。
这与C++有什么关系呢? 看看__cplusplus（注意前面是两个下划线）的名字你就应该知道它与C++有很大关系。__cplusplus是一个C++规范规定的预定义宏。你可以信任的是：所有的现代C++编译器都预先定义了它；而所有C语言编译器则不会。另外，按照规范__cplusplus的值应该等于1 9 9 7 1 1 L ，然而不是所有的编译器都照此实现，比如g++编译器就将它的值定义为1。
所以，如果上述代码被C语言程序引用的话，它的内容就等价于下列代码。
在这种情况下，既然extern &ldquo;C&rdquo; { }经过预处理之后根本就不存在，那么它和#include指令之间的关系问题自然也就是无中生有。
extern &ldquo;C&quot;的前世今生 在C++编译器里，有一位暗黑破坏神，专门从事一份称作“名字粉碎”(name mangling)的工作。当把一个C++的源文件投入编译的时候，它就开始工作，把每一个它在源文件里看到的外部可见的名字粉碎的面目全非，然后存储到二进制目标文件的符号表里。
之所以在C++的世界里存在这样一个怪物，是因为C++允许对一个名字给予不同的定义，只要在语义上没有二义性就好。比如，你可以让两个函数是同名的，只要它们的参数列表不同即可，这就是函数重载(function overloading)；甚至，你可以让两个函数的原型声明是完全相同的，只要它们所处的名字空间(namespace)不一样即可。事实上，当处于不同的名字空间时，所有的名字都是可以重复的，无论是函数名，变量名，还是类型名。
另外，C++程序的构造方式仍然继承了C语言的传统：编译器把每一个通过命令行指定的源代码文件看做一个独立的编译单元，生成目标文件；然后，链接器通过查找这些目标文件的符号表将它们链接在一起生成可执行程序。
编译和链接是两个阶段的事情；事实上，编译器和链接器是两个完全独立的工具。编译器可以通过语义分析知道那些同名的符号之间的差别；而链接器却只能通过目标文件符号表中保存的名字来识别对象。
所以，编译器进行名字粉碎的目的是为了让链接器在工作的时候不陷入困惑，将所有名字重新编码，生成全局唯一，不重复的新名字，让链接器能够准确识别每个名字所对应的对象。
但 C语言却是一门单一名字空间的语言，也不允许函数重载，也就是说，在一个编译和链接的范围之内，C语言不允许存在同名对象。比如，在一个编译单元内部，不允许存在同名的函数，无论这个函数是否用static修饰；在一个可执行程序对应的所有目标文件里，不允许存在同名对象，无论它代表一个全局变量，还是一个函数。所以，C语言编译器不需要对任何名字进行复杂的处理（或者仅仅对名字进行简单一致的修饰（decoration），比如在名字前面统一的加上单下划线_）。
C++的缔造者Bjarne Stroustrup在最初就把——能够兼容C，能够复用大量已经存在的C库——列为C++语言的重要目标。但两种语言的编译器对待名字的处理方式是不一致的，这就给链接过程带来了麻烦。
例如，现有一个名为my_handle.h的头文件，内容如下：
然后使用C语言编译器编译my_handle.c，生成目标文件my_handle.o。
由于C语言编译器不对名字进行粉碎，所以在my_handle.o的符号表里，这三个函数的名字和源代码文件中的声明是一致的。
随后，我们想让一个C++程序调用这些函数，所以，它也包含了头文件my_handle.h。
假设这个C++源代码文件的名字叫my_handle_client.cpp，其内容如下：
其中，粗体的部分就是那三个函数的名字被粉碎后的样子。
然后，为了让程序可以工作，你必须将my_handle.o和my_handle_client.o放在一起链接。由于在两个目标文件对于同一对象的命名不一样，链接器将报告相关的“符号未定义”错误。
为了解决这一问题，C++引入了链接规范(linkage specification)的概念，表示法为extern&quot;language string&rdquo;，C++编译器普遍支持的&quot;language string&quot;有&quot;C&quot;和&quot;C++&quot;，分别对应C语言和C++语言。
链接规范的作用是告诉C++编译：对于所有使用了链接规范进行修饰的声明或定义，应该按照指定语言的方式来处理，比如名字，调用习惯（calling convention）等等。
链接规范的用法有两种：  单个声明的链接规范，比如：  extern &#34;C&#34; void foo(); 一组声明的链接规范，比如：  extern &#34;C&#34; { void foo(); int bar(); } 对我们之前的例子而言，如果我们把头文件my_handle.h的内容改成：
然后使用C++编译器重新编译my_handle_client.cpp，所生成目标文件my_handle_client.o中的符号表就变为：
从中我们可以看出，此时，用extern &ldquo;C&rdquo; 修饰了的声明，其生成的符号和C语言编译器生成的符号保持了一致。这样，当你再次把my_handle.o和my_handle_client.o放在一起链接的时候，就不会再有之前的“符号未定义”错误了。
但此时，如果你重新编译my_handle.c，C语言编译器将会报告“语法错误”，因为extern&quot;C&quot;是C++的语法，C语言编译器不认识它。此时，可以按照我们之前已经讨论的，使用宏__cplusplus来识别C和C++编译器。修改后的my_handle.h的代码如下：
小心门后的未知世界 在我们清楚了 extern &ldquo;C&rdquo; 的来历和用途之后，回到我们本来的话题上，为什么不能把#include 指令放置在 extern &ldquo;C&rdquo; { &hellip; } 里面？
我们先来看一个例子，现有a.h，b.h，c.h以及foo.cpp，其中foo.cpp包含c.h，c.h包含b.h，b.h包含a.h，如下：
现使用C++编译器的预处理选项来编译foo.cpp，得到下面的结果：
正如你看到的，当你把#include指令放置在extern &ldquo;C&rdquo; { }里的时候，则会造成extern &ldquo;C&rdquo; { } 的嵌套。这种嵌套是被C++规范允许的。当嵌套发生时，以最内层的嵌套为准。比如在下面代码中，函数foo会使用C++的链接规范，而函数bar则会使用C的链接规范。
如果能够保证一个C语言头文件直接或间接依赖的所有头文件也都是C语言的，那么按照C++语言规范，这种嵌套应该不会有什么问题。
但具体到某些编译器的实现，比如MSVC2005，却可能由于 extern &ldquo;C&rdquo; { } 的嵌套过深而报告错误。
不要因此而责备微软，因为就这个问题而言，这种嵌套是毫无意义的。你完全可以通过把#include指令放置在extern &ldquo;C&rdquo; { }的外面来避免嵌套。
拿之前的例子来说，如果我们把各个头文件的 #include 指令都移到extern &ldquo;C&rdquo; { } 之外，然后使用C++编译器的预处理选项来编译foo.cpp，就会得到下面的结果：
这样的结果肯定不会引起编译问题的结果——即便是使用MSVC。
把 #include 指令放置在extern &ldquo;C&rdquo; { }里面的另外一个重大风险是，你可能会无意中改变一个函数声明的链接规范。比如：有两个头文件a.h，b.h，其中b.h包含a.h，如下：
按照a.h作者的本意，函数foo是一个C++自由函数，其链接规范为&quot;C++&quot;。但在b.h中，由于#include &ldquo;a.h&quot;被放到了extern &ldquo;C&rdquo; { }的内部，函数foo的链接规范被不正确地更改了。
由于每一条 #include 指令后面都隐藏这一个未知的世界，除非你刻意去探索，否则你永远都不知道，当你把一条条#include指令放置于extern &ldquo;C&rdquo; { }里面的时候，到底会产生怎样的结果，会带来何种的风险。
或许你会说，“我可以去查看这些被包含的头文件，我可以保证它们不会带来麻烦”。但，何必呢？毕竟，我们完全可以不必为不必要的事情买单，不是吗？
Q &amp; A Q: 难道任何# i n c l u d e指令都不能放在e x t e r n &ldquo;C&quot;里面吗？
A: 正像这个世界的大多数规则一样，总会存在特殊情况。
有时候，你可能利用头文件机制“巧妙”的解决一些问题。比如，#pragma pack的问题。这些头文件和常规的头文件作用是不一样的，它们里面不会放置C的函数声明或者变量定义，链接规范不会对它们的内容产生影响。这种情况下，你可以不必遵守这些规则。
更加一般的原则是，在你明白了这所有的原理之后，只要你明白自己在干什么，那就去做吧。
Q: 你只说了不应该放入e x t e r n &ldquo;C&quot;的，但什么可以放入呢？
A: 链接规范仅仅用于修饰函数和变量，以及函数类型。所以，严格的讲，你只应该把这三种对象放置于extern &ldquo;C&quot;的内部。
但，你把C语言的其它元素，比如非函数类型定义（结构体，枚举等）放入extern &ldquo;C&quot;内部，也不会带来任何影响。更不用说宏定义预处理指令了。
所以，如果你更加看重良好组织和管理的习惯，你应该只在必须使用extern &ldquo;C&quot;声明的地方使用它。即使你比较懒惰，绝大多数情况下，把一个头件自身的所有定义和声明都放置在extern&quot;C&quot;里面也不会有太大的问题。
Q: 如果一个带有函数/变量声明的C头文件里没有e x t e r n &ldquo;C&quot;声明怎么办？
A: 如果你可以判断，这个头文件永远不可能让C++代码来使用，那么就不要管它。
但现实是，大多数情况下，你无法准确的推测未来。你在现在就加上这个extern &ldquo;C&rdquo;，这花不了你多少成本，但如果你现在没有加，等到将来这个头文件无意中被别人的C++程序包含的时候，别人很可能需要更高的成本来定位错误和修复问题。
Q: 如果我的C+ +程序想包含一个C头文件a . h，它的内容包含了C的函数/变量声明，但它们却没有使用e x t e r n &ldquo;C&quot;链接规范，该怎么办？
A: 在a.h里面加上它。
某些人可能会建议你，如果a.h没有extern &ldquo;C&rdquo;，而b.cpp包含了a.h，可以在b.cpp里加上 ：
extern &#34;C&#34; { #include &#34;a.h&#34;} 这是一个邪恶的方案，原因在之前我们已经阐述。但值得探讨的是，这种方案这背后却可能隐含着一个假设，即我们不能修改a.h。不能修改的原因可能来自两个方面：
  头文件代码属于其它团队或者第三方公司，你没有修改代码的权限；
  虽然你拥有修改代码的权限，但由于这个头文件属于遗留系统，冒然修改可能会带来不可预知的问题。
  对 于第一种情况，不要试图自己进行workaround，因为这会给你带来不必要的麻烦。正确的解决方案是，把它当作一个bug，发送缺陷报告给相应的团队 或第三方公司。
如果是自己公司的团队或你已经付费的第三方公司，他们有义务为你进行这样的修改。如果他们不明白这件事情的重要性，告诉他们。如果这些头文 件属于一个免费开源软件，自己进行正确的修改，并发布patch给其开发团队。
在 第二种情况下，你需要抛弃掉这种不必要的安全意识。
因为，首先，对于大多数头文件而言，这种修改都不是一种复杂的，高风险的修改，一切都在可控的范围之 内；
其次，如果某个头文件混乱而复杂，虽然对于遗留系统的哲学应该是：“在它还没有带来麻烦之前不要动它”，但现在麻烦已经来了，逃避不如正视，所以上策 是，将其视作一个可以整理到干净合理状态的良好机会。
Q: 我们代码中关于e x t e r n &ldquo;C&quot;的写法如下，这正确吗?
A: 不确定。
按照C++的规范定义，__cplusplus 的值应该被定义为199711L，这是一个非零的值；尽管某些编译器并没有按照规范来实现，但仍然能够保证__cplusplus的值为非零——至少我到目前为止还没有看到哪款编译器将其实现为0。
这种情况下，#if __cplusplus &hellip; #endif完全是冗余的。
但，C++编译器的厂商是如此之多，没有人可以保证某款编译器，或某款编译器的早期版本没有将__cplusplus的值定义为0。
但即便如此，只要能够保证宏__cplusplus只在C++编译器中被预先定义 ，那么，仅仅使用#ifdef __cplusplus ⋯ #endif就足以确保意图的正确性；额外的使用#if __cplusplus &hellip; #endif反而是错误的。
只有在这种情况下：即某个厂商的C语言和C++语言编译器都预先定义了__cplusplus ，但通过其值为0和非零来进行区分，使用#if __cplusplus &hellip; #endif才是正确且必要的。
既然现实世界是如此复杂，你就需要明确自己的目标，然后根据目标定义相应的策略。比如：如果你的目标是让你的代码能够使用几款主流的、正确遵守了规范的编译器进行编译，那么你只需要简单的使用#ifdef __cplusplus &hellip; #endif就足够了。
但如果你的产品是一个雄心勃勃的，试图兼容各种编译器的（包括未知的）跨平台产品， 我们可能不得不使用下述方法来应对各种情况 ，其中__ALIEN_C_LINKAGE__是为了标识那些在C和C++编译中都定义了__cplusplus宏的编译器。
这应该可以工作，但在每个头文件中都写这么一大串，不仅有碍观瞻，还会造成一旦策略进行修改，就会到处修改的状况。违反了DRY(Don&rsquo;t Repeat Yourself)原则，你总要为之付出额外的代价。解决它的一个简单方案是，定义一个特定的头文件——比如clinkage.h，在其中增加这样的定义：
以下举例中c的函数声明和定义分别在cfun.h 和 cfun.c 中，函数打印字符串 “this is c fun call”，c++函数声明和定义分别在cppfun.h 和 cppfun.cpp中，函数打印字符串 &ldquo;this is cpp fun call&rdquo;, 编译环境vc2010
c++ 调用 c 的方法（关键是要让c的函数按照c的方式编译，而不是c++的方式）
（1） cfun.h如下：
#ifndef _C_FUN_H_ #define _C_FUN_H_  void cfun(); #endif cppfun.cpp 如下：
//#include &#34;cfun.h&#34; 不需要包含cfun.h #include &#34;cppfun.h&#34;#include &lt;iostream&gt;using namespace std; extern &#34;C&#34; void cfun(); //声明为 extern void cfun(); 错误  void cppfun() { cout&lt;&lt;&#34;this is cpp fun call&#34;&lt;&lt;endl; } int main() { cfun(); return 0; } （2）cfun.h同上，cppfun.cpp 如下：
extern &#34;C&#34; { #include &#34;cfun.h&#34;//注意include语句一定要单独占一行;} #include &#34;cppfun.h&#34;#include &lt;iostream&gt;using namespace std; void cppfun() { cout&lt;&lt;&#34;this is cpp fun call&#34;&lt;&lt;endl; } int main() { cfun(); return 0; } （3）cfun.h如下：
#ifndef _C_FUN_H_ #define _C_FUN_H_  #ifdef __cplusplus extern &#34;C&#34; { #endif  void cfun(); #ifdef __cplusplus } #endif  #endif cppfun.cpp如下：
#include &#34;cfun.h&#34;#include &#34;cppfun.h&#34;#include &lt;iostream&gt;using namespace std; void cppfun() { cout&lt;&lt;&#34;this is cpp fun call&#34;&lt;&lt;endl; } int main() { cfun(); return 0; } c调用c++（关键是C++ 提供一个符合 C 调用惯例的函数）
在vs2010上测试时，没有声明什么extern等，只在在cfun.c中包含cppfun.h，然后调用cppfun()也可以编译运行，在gcc下就编译出错，按照c++/c的标准这种做法应该是错误的。以下方法两种编译器都可以运行
cppfun.h如下：
#ifndef _CPP_FUN_H_ #define _CPP_FUN_H_  extern &#34;C&#34; void cppfun(); #endif cfun.c如下：
//#include &#34;cppfun.h&#34; //不要包含头文件，否则编译出错 #include &#34;cfun.h&#34;#include &lt;stdio.h&gt; void cfun() { printf(&#34;this is c fun call\n&#34;); } extern void cppfun(); int main() { #ifdef __cplusplus  cfun(); #endif  cppfun(); return 0; } ]]></content>
  </entry>
  
  <entry>
    <title>风河 Helix 虚拟化平台和 VxWorks 653 提供扩展的安全认证证据支持以加速下一代 A&D 系统的开发</title>
    <url>/post/news/wind-river-helix-virtualization-platform-and-vxWorks-653-deliver-expanded-safety-certification.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Wind River</tag>
      <tag>Helix Virtualization</tag>
      <tag>VxWorks 653</tag>
    </tags>
    <content type="html"><![CDATA[为关键任务智能系统提供软件的全球领导者 Wind River® 今天宣布扩展其行业领先平台的架构支持，以进一步满足高度计算的苛刻需求 - 重型任务关键型应用，特别是那些与航空航天和国防工业相关的应用。
DO-178C DAL A 认证证据现已可用于 Armv8-A 架构的 Wind River Helix™ 虚拟化平台。 最新版本的 VxWorks  ® 653 为 PowerPC 提供更新的 DO-178C DAL A 认证证据。
具有 DO-178C DAL A 证据的 Helix 平台是一个安全认证的多核、多租户平台，支持多个独立的关键级别。 它专为各种关键任务行业用例而设计，例如商业和军事航空电子设备，允许客户运行不安全的软件以及经过最高级别认证的软件，这些软件涉及航空电子设备 (DO-178C)、汽车 (ISO 26262)、工业 ( IEC 61508) 和其他类似标准。 Helix Platform 也符合 ARINC 653 标准，并在最新的硬件平台上提供强大的时间和空间分区，以确保故障遏制以及以最少的测试和集成需求升级应用程序的能力。
VxWorks 653，具有DO-178C DAL A证明，是一个安全可靠的多核、多租户平台，可用于PowerPC架构。 VxWorks 653 也符合 ARINC 653 标准，具有与 Helix 平台相同的稳健性。
“智能边缘的发展为航空航天和国防等行业提出了一系列独特的要求和挑战，包括与认证需求相关的复杂性增加。 随着 Helix 平台和 VxWorks 653 的更新安全认证证据的可用性，我们正在为我们的客户提供更多灵活性和加速创新的机会，以创建下一代安全可靠的多操作系统智能设备，”首席产品 Avijit Sinha 说 军官，风河。
风河技术已在最具挑战性的安全关键型应用中得到验证，使组织能够更轻松、更经济地满足 EN 50128、IEC 61508、ISO 26262、DO-178C 和 ED-12C 的严格安全认证要求。
凭借在 120 多架民用和军用飞机的 880 多个安全项目中得到 400 多家客户验证的技术，风河正在推动航空航天和国防领域向软件定义系统的过渡。
]]></content>
  </entry>
  
  <entry>
    <title>三星电子研发出其首款支持CXL 2.0的CXL DRAM</title>
    <url>/post/news/samsung-develops-first-CXL-DRAM-supporting-CXL-2.0.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Samsung</tag>
      <tag>CXL 2.0</tag>
      <tag>CXL Memory</tag>
    </tags>
    <content type="html"><![CDATA[基于先进CXL 2.0的128GB CXL DRAM将于今年量产，加速下一代存储器解决方案的商用化，三星将继续与全球数据中心、服务器、芯片企业合作，扩大CXL生态系统
三星电子今日宣布，研发出其首款支持Compute Express Link™（CXL™）2.0的128GB DRAM。同时，三星与英特尔密切合作，在英特尔®至强®平台上取得了具有里程碑意义的进展。
继2022年五月，三星电子研发出其首款基于CXL 1.1的CXL DRAM（内存扩展器）后，又继续推出支持CXL 2.0的128GB CXL DRAM，预计将加速下一代存储解决方案的商用化。该解决方案支持PCIe 5.0（x8通道），提供高达每秒35GB的带宽。
三星电子新业务企划副总裁Jangseok Choi表示： 作为CXL联盟的董事会成员，三星电子在CXL技术上一直处于前沿地位，这一突破性的进展强化了我们通过与全球各地的数据中心、企业级服务器和芯片公司合作，进一步扩大CXL生态系统的决心。
英特尔公司技术创新总监Jim Pappas表示： 英特尔很高兴与三星合作，共同投资一个充满活力的CXL生态系统。英特尔将继续与三星携手，促进创新CXL产品在整个行业的发展和采用。
澜起科技总裁Stephen Tai表示： 澜起科技很高兴能够量产第一批支持CXL 2.0的控制器，我们期待与三星继续加强合作，推进CXL技术发展并扩大其生态系统。
CXL 2.0是三星有史以来第一个支持内存池（Pooling）的产品。内存池是一种内存管理技术，它将服务器平台上的多个CXL内存块绑定在一起，形成一个内存池，使多个主机能够根据需要从池中动态分配内存。这项新技术使客户尽可能的降本增效，从而帮助企业将有限的资源重新投资于增强服务器内存中去。
三星电子计划于今年年底之前开始量产这一最新的CXL 2.0 DRAM，并准备推出多种容量的产品，以满足快速变化的下一代计算市场，进一步加速扩大CXL生态系统。
CXL作为下一代，能够为高性能服务器系统中与CPU一起使用的加速器、DRAM和存储设备提高效率。由于它与主内存（main DRAM）共同使用时可扩大带宽和容量，该技术的进步有望在人工智能（AI）和机器学习（ML）等核心技术，对处理高速数据的需求极大增加的下一代计算市场引起轰动。
]]></content>
  </entry>
  
  <entry>
    <title>6个与戈登・摩尔相关的冷知识</title>
    <url>/post/news/6-trivia-about-Gordon-moore.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Intel</tag>
      <tag>Integrated Electronics</tag>
      <tag>Gordon Moore</tag>
    </tags>
    <content type="html"><![CDATA[英特尔的创始人戈登・摩尔于上周五（2023年3月24日）逝世，享年 94 岁，他的一生对计算机科学和半导体工业的发展做出了巨大的贡献。
今天给大家分享6个与戈登・摩尔相关的“冷知识”。
]]></content>
  </entry>
  
  <entry>
    <title>北南南北</title>
    <url>/about.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[北南南北 是众多使用 VxWorks 嵌入式实时操作系统的网友分享经验的平台，为的就是让 VxWorks 的学习和应用变得相对开放一些，在此也欢迎你的加入！
我们的愿景 技术创新是技术持续发展的生命力，紧跟技术的发展趋势，研究最新的技术，保持对新技术的热情和好奇心，让技术为生产和生活服务。
使用反馈  加入 VxWorks Club   或 Google AI TPU     欢迎你的加入
 ]]></content>
  </entry>
  
  <entry>
    <title>友情链接</title>
    <url>/flinks.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
name: VxWorks俱乐部 desc: VxWorks实时操作系统 link: https://www.vxworks.net ]]></content>
  </entry>
  
</search>